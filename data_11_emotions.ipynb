{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import itertools\n",
    "from collections import Counter\n",
    "import data_helpers\n",
    "from text_cnn import TextCNN\n",
    "from tensorflow.contrib import learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "ArgumentError",
     "evalue": "argument --dev_sample_percentage: conflicting option string(s): --dev_sample_percentage",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArgumentError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-a05544a57be2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Data loading params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFINE_float\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dev_sample_percentage\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Percentage of the training data to use for validation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFINE_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"positive_data_file\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"./data/rt-polaritydata/rt-polarity.pos\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Data source for the positive data.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFINE_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"negative_data_file\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"./data/rt-polaritydata/rt-polarity.neg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Data source for the negative data.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.local/lib/python2.7/site-packages/tensorflow/python/platform/flags.pyc\u001b[0m in \u001b[0;36mDEFINE_float\u001b[0;34m(flag_name, default_value, docstring)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0mdocstring\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m \u001b[0mhelpful\u001b[0m \u001b[0mmessage\u001b[0m \u001b[0mexplaining\u001b[0m \u001b[0mthe\u001b[0m \u001b[0muse\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m   \"\"\"\n\u001b[0;32m--> 132\u001b[0;31m   \u001b[0m_define_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflag_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m _allowed_symbols = [\n",
      "\u001b[0;32m/home/ubuntu/.local/lib/python2.7/site-packages/tensorflow/python/platform/flags.pyc\u001b[0m in \u001b[0;36m_define_helper\u001b[0;34m(flag_name, default_value, docstring, flagtype)\u001b[0m\n\u001b[1;32m     63\u001b[0m                               \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                               \u001b[0mhelp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdocstring\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                               type=flagtype)\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/argparse.pyc\u001b[0m in \u001b[0;36madd_argument\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1306\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"length of metavar tuple does not match nargs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1308\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1310\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd_argument_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/argparse.pyc\u001b[0m in \u001b[0;36m_add_action\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m   1680\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_add_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1681\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moption_strings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1682\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optionals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1683\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1684\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_positionals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/argparse.pyc\u001b[0m in \u001b[0;36m_add_action\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m   1507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1508\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_add_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1509\u001b[0;31m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ArgumentGroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1510\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_group_actions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1511\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/argparse.pyc\u001b[0m in \u001b[0;36m_add_action\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m   1320\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_add_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0;31m# resolve any conflicts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_conflict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m         \u001b[0;31m# add to actions list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/argparse.pyc\u001b[0m in \u001b[0;36m_check_conflict\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m   1458\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconfl_optionals\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1459\u001b[0m             \u001b[0mconflict_handler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1460\u001b[0;31m             \u001b[0mconflict_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfl_optionals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1462\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_handle_conflict_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconflicting_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/argparse.pyc\u001b[0m in \u001b[0;36m_handle_conflict_error\u001b[0;34m(self, action, conflicting_actions)\u001b[0m\n\u001b[1;32m   1465\u001b[0m                                      \u001b[0;32mfor\u001b[0m \u001b[0moption_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1466\u001b[0m                                      in conflicting_actions])\n\u001b[0;32m-> 1467\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mArgumentError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mconflict_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1469\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_handle_conflict_resolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconflicting_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mArgumentError\u001b[0m: argument --dev_sample_percentage: conflicting option string(s): --dev_sample_percentage"
     ]
    }
   ],
   "source": [
    "\n",
    "# Parameters\n",
    "# ==================================================\n",
    "\n",
    "# Data loading params\n",
    "tf.flags.DEFINE_float(\"dev_sample_percentage\", .1, \"Percentage of the training data to use for validation\")\n",
    "tf.flags.DEFINE_string(\"positive_data_file\", \"./data/rt-polaritydata/rt-polarity.pos\", \"Data source for the positive data.\")\n",
    "tf.flags.DEFINE_string(\"negative_data_file\", \"./data/rt-polaritydata/rt-polarity.neg\", \"Data source for the negative data.\")\n",
    "tf.flags.DEFINE_string(\"tweets\",\"./data/text_emotion.csv\", \"Data source from crowdflower\")\n",
    "tf.flags.DEFINE_string(\"isear\",\"./data/isear.csv\", \"Data source from ISEAR\")\n",
    "\n",
    "# Model Hyperparameters\n",
    "tf.flags.DEFINE_integer(\"embedding_dim\", 128, \"Dimensionality of character embedding (default: 128)\")\n",
    "tf.flags.DEFINE_string(\"filter_sizes\", \"3,4,5\", \"Comma-separated filter sizes (default: '3,4,5')\")\n",
    "tf.flags.DEFINE_integer(\"num_filters\", 128, \"Number of filters per filter size (default: 128)\")\n",
    "tf.flags.DEFINE_float(\"dropout_keep_prob\", 0.5, \"Dropout keep probability (default: 0.5)\")\n",
    "tf.flags.DEFINE_float(\"l2_reg_lambda\", 0.0, \"L2 regularization lambda (default: 0.0)\")\n",
    "\n",
    "# Training parameters\n",
    "tf.flags.DEFINE_integer(\"batch_size\", 64, \"Batch Size (default: 64)\")\n",
    "tf.flags.DEFINE_integer(\"num_epochs\", 200, \"Number of training epochs (default: 200)\")\n",
    "tf.flags.DEFINE_integer(\"evaluate_every\", 100, \"Evaluate model on dev set after this many steps (default: 100)\")\n",
    "tf.flags.DEFINE_integer(\"checkpoint_every\", 100, \"Save model after this many steps (default: 100)\")\n",
    "tf.flags.DEFINE_integer(\"num_checkpoints\", 5, \"Number of checkpoints to store (default: 5)\")\n",
    "# Misc Parameters\n",
    "tf.flags.DEFINE_boolean(\"allow_soft_placement\", True, \"Allow device soft device placement\")\n",
    "tf.flags.DEFINE_boolean(\"log_device_placement\", False, \"Log placement of ops on devices\")\n",
    "\n",
    "FLAGS = tf.flags.FLAGS\n",
    "FLAGS._parse_flags()\n",
    "print(\"\\nParameters:\")\n",
    "for attr, value in sorted(FLAGS.__flags.items()):\n",
    "    print(\"{}={}\".format(attr.upper(), value))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def clean_str(string):\n",
    "    \"\"\"\n",
    "    Tokenization/string cleaning for all datasets except for SST.\n",
    "    Original taken from https://github.com/yoonkim/CNN_sentence/blob/master/process_data.py\n",
    "    \"\"\"\n",
    "    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
    "    string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
    "    string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
    "    string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
    "    string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
    "    string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
    "    string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
    "    string = re.sub(r\",\", \" , \", string)\n",
    "    string = re.sub(r\"!\", \" ! \", string)\n",
    "    string = re.sub(r\"\\(\", \" \\( \", string)\n",
    "    string = re.sub(r\"\\)\", \" \\) \", string)\n",
    "    string = re.sub(r\"\\?\", \" \\? \", string)\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    return string.strip().lower()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(FLAGS.tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1956967341</td>\n",
       "      <td>neutral</td>\n",
       "      <td>xoshayzers</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>wannamama</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956967696</td>\n",
       "      <td>sadness</td>\n",
       "      <td>coolfunky</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956967789</td>\n",
       "      <td>happy</td>\n",
       "      <td>czareaquino</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1956968416</td>\n",
       "      <td>neutral</td>\n",
       "      <td>xkilljoyx</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweet_id sentiment       author  \\\n",
       "0  1956967341   neutral   xoshayzers   \n",
       "1  1956967666   sadness    wannamama   \n",
       "2  1956967696   sadness    coolfunky   \n",
       "3  1956967789     happy  czareaquino   \n",
       "4  1956968416   neutral    xkilljoyx   \n",
       "\n",
       "                                             content  \n",
       "0  @tiffanylue i know  i was listenin to bad habi...  \n",
       "1  Layin n bed with a headache  ughhhh...waitin o...  \n",
       "2                Funeral ceremony...gloomy friday...  \n",
       "3               wants to hang out with friends SOON!  \n",
       "4  @dannycastillo We want to trade with someone w...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x_text = data[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neutral', 'sadness', 'happy', 'worry', 'surprise', 'love', 'fun',\n",
       "       'hate', 'boredom', 'relief', 'anger'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"sentiment\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "    data['sentiment'] = data['sentiment'].map({'sadness': [1,0,0,0,0,0,0,0,0,0,0], 'happy': [0,1,0,0,0,0,0,0,0,0,0], 'neutral': [0,0,1,0,0,0,0,0,0,0,0], 'worry': [0,0,0,1,0,0,0,0,0,0,0], 'surprise': [0,0,0,0,1,0,0,0,0,0,0], 'love': [0,0,0,0,0,1,0,0,0,0,0], 'fun': [0,0,0,0,0,0,1,0,0,0,0], 'hate': [0,0,0,0,0,0,0,1,0,0,0], 'boredom': [0,0,0,0,0,0,0,0,1,0,0], 'relief': [0,0,0,0,0,0,0,0,0,1,0], 'anger': [0,0,0,0,0,0,0,0,0,0,1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y = data['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_text.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@tiffanylue i know  i was listenin to bad habit earlier and i started freakin at his part =['"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x_text=[data_helpers.clean_str(sent) for sent in x_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tiffanylue i know i was listenin to bad habit earlier and i started freakin at his part'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Build vocabulary\n",
    "max_document_length = max([len(x.split(\" \")) for x in x_text])\n",
    "vocab_processor = learn.preprocessing.VocabularyProcessor(max_document_length)\n",
    "x = np.array(list(vocab_processor.fit_transform(x_text) ))\n",
    "y = np.array(list(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    1,     2,     3, ...,     0,     0,     0],\n",
       "       [   16,    17,    18, ...,     0,     0,     0],\n",
       "       [   27,    28,    29, ...,     0,     0,     0],\n",
       "       ..., \n",
       "       [  481,  3360,    73, ...,     0,     0,     0],\n",
       "       [ 4790, 14844,  2465, ...,     0,     0,     0],\n",
       "       [47325, 25561,  3543, ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       ..., \n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Randomly shuffle data\n",
    "np.random.seed(10)\n",
    "shuffle_indices = np.random.permutation(np.arange(len(y)))\n",
    "x_shuffled = x[shuffle_indices]\n",
    "y_shuffled = y[shuffle_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[35661,  3625,   310, ...,     0,     0,     0],\n",
       "       [    2,    91,  6532, ...,     0,     0,     0],\n",
       "       [23080,     2,   304, ...,     0,     0,     0],\n",
       "       ..., \n",
       "       [36827,  9308,   354, ...,     0,     0,     0],\n",
       "       [  303,  5114,     2, ...,     0,     0,     0],\n",
       "       [   59,   638,   907, ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103\n",
      "Vocabulary Size: 48151\n",
      "Train/Dev split: 36000/4000\n"
     ]
    }
   ],
   "source": [
    "# Split train/test set\n",
    "# TODO: This is very crude, should use cross-validation\n",
    "dev_sample_index = -1 * int(FLAGS.dev_sample_percentage * float(len(y)))\n",
    "x_train, x_dev = x_shuffled[:dev_sample_index], x_shuffled[dev_sample_index:]\n",
    "y_train, y_dev = y_shuffled[:dev_sample_index], y_shuffled[dev_sample_index:]\n",
    "print x_train.shape[1]\n",
    "\n",
    "print(\"Vocabulary Size: {:d}\".format(len(vocab_processor.vocabulary_)))\n",
    "print(\"Train/Dev split: {:d}/{:d}\".format(len(y_train), len(y_dev)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#data helper function\n",
    "def batch_iter(data, batch_size, num_epochs, shuffle=True):\n",
    "    \"\"\"\n",
    "    Generates a batch iterator for a dataset.\n",
    "    \"\"\"\n",
    "    data = np.array(data)\n",
    "    data_size = len(data)\n",
    "    num_batches_per_epoch = int((len(data)-1)/batch_size) + 1\n",
    "    for epoch in range(num_epochs):\n",
    "        # Shuffle the data at each epoch\n",
    "        if shuffle:\n",
    "            shuffle_indices = np.random.permutation(np.arange(data_size))\n",
    "            shuffled_data = data[shuffle_indices]\n",
    "        else:\n",
    "            shuffled_data = data\n",
    "        for batch_num in range(num_batches_per_epoch):\n",
    "            start_index = batch_num * batch_size\n",
    "            end_index = min((batch_num + 1) * batch_size, data_size)\n",
    "            yield shuffled_data[start_index:end_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to /home/ubuntu/cnn-text-classification-tf/runs/1491227132\n",
      "\n",
      "2017-04-03T19:15:33.646996: step 1, loss 6.50659, acc 0.0625\n",
      "2017-04-03T19:15:33.948640: step 2, loss 5.35337, acc 0.078125\n",
      "2017-04-03T19:15:34.226971: step 3, loss 4.78166, acc 0.078125\n",
      "2017-04-03T19:15:34.502992: step 4, loss 4.58668, acc 0.15625\n",
      "2017-04-03T19:15:34.791156: step 5, loss 5.01657, acc 0.15625\n",
      "2017-04-03T19:15:35.115203: step 6, loss 4.60659, acc 0.171875\n",
      "2017-04-03T19:15:35.430824: step 7, loss 3.47901, acc 0.25\n",
      "2017-04-03T19:15:35.722640: step 8, loss 4.30357, acc 0.25\n",
      "2017-04-03T19:15:36.012136: step 9, loss 4.97262, acc 0.171875\n",
      "2017-04-03T19:15:36.323223: step 10, loss 4.71274, acc 0.203125\n",
      "2017-04-03T19:15:36.645066: step 11, loss 4.25187, acc 0.171875\n",
      "2017-04-03T19:15:36.995913: step 12, loss 4.22511, acc 0.1875\n",
      "2017-04-03T19:15:37.303179: step 13, loss 4.64774, acc 0.1875\n",
      "2017-04-03T19:15:37.658844: step 14, loss 4.71993, acc 0.15625\n",
      "2017-04-03T19:15:37.947915: step 15, loss 4.07658, acc 0.140625\n",
      "2017-04-03T19:15:38.230724: step 16, loss 4.16463, acc 0.09375\n",
      "2017-04-03T19:15:38.502530: step 17, loss 3.71586, acc 0.203125\n",
      "2017-04-03T19:15:38.810308: step 18, loss 4.57045, acc 0.125\n",
      "2017-04-03T19:15:39.102491: step 19, loss 3.76772, acc 0.171875\n",
      "2017-04-03T19:15:39.400943: step 20, loss 4.53532, acc 0.125\n",
      "2017-04-03T19:15:39.690003: step 21, loss 4.56417, acc 0.171875\n",
      "2017-04-03T19:15:39.998145: step 22, loss 4.02995, acc 0.1875\n",
      "2017-04-03T19:15:40.343954: step 23, loss 3.96437, acc 0.1875\n",
      "2017-04-03T19:15:40.659653: step 24, loss 5.73031, acc 0.125\n",
      "2017-04-03T19:15:40.977125: step 25, loss 5.28234, acc 0.15625\n",
      "2017-04-03T19:15:41.266559: step 26, loss 5.25867, acc 0.15625\n",
      "2017-04-03T19:15:41.587998: step 27, loss 4.82021, acc 0.125\n",
      "2017-04-03T19:15:41.889756: step 28, loss 3.46948, acc 0.3125\n",
      "2017-04-03T19:15:42.193448: step 29, loss 3.93912, acc 0.1875\n",
      "2017-04-03T19:15:42.542684: step 30, loss 4.50442, acc 0.171875\n",
      "2017-04-03T19:15:42.848609: step 31, loss 3.29556, acc 0.234375\n",
      "2017-04-03T19:15:43.153366: step 32, loss 3.41658, acc 0.234375\n",
      "2017-04-03T19:15:43.459293: step 33, loss 4.26455, acc 0.125\n",
      "2017-04-03T19:15:43.769321: step 34, loss 3.37605, acc 0.234375\n",
      "2017-04-03T19:15:44.043159: step 35, loss 4.39564, acc 0.140625\n",
      "2017-04-03T19:15:44.318159: step 36, loss 4.43429, acc 0.203125\n",
      "2017-04-03T19:15:44.605530: step 37, loss 4.47856, acc 0.171875\n",
      "2017-04-03T19:15:44.880417: step 38, loss 4.45979, acc 0.171875\n",
      "2017-04-03T19:15:45.189893: step 39, loss 4.27528, acc 0.09375\n",
      "2017-04-03T19:15:45.475695: step 40, loss 3.28771, acc 0.28125\n",
      "2017-04-03T19:15:45.766888: step 41, loss 3.78115, acc 0.234375\n",
      "2017-04-03T19:15:46.075107: step 42, loss 4.86035, acc 0.171875\n",
      "2017-04-03T19:15:46.376704: step 43, loss 4.85543, acc 0.046875\n",
      "2017-04-03T19:15:46.680666: step 44, loss 4.3051, acc 0.15625\n",
      "2017-04-03T19:15:46.977653: step 45, loss 3.52115, acc 0.15625\n",
      "2017-04-03T19:15:47.277699: step 46, loss 4.43131, acc 0.171875\n",
      "2017-04-03T19:15:47.578150: step 47, loss 3.93726, acc 0.1875\n",
      "2017-04-03T19:15:47.873739: step 48, loss 3.85099, acc 0.203125\n",
      "2017-04-03T19:15:48.173822: step 49, loss 3.67603, acc 0.1875\n",
      "2017-04-03T19:15:48.456664: step 50, loss 4.01589, acc 0.171875\n",
      "2017-04-03T19:15:48.748966: step 51, loss 3.08015, acc 0.234375\n",
      "2017-04-03T19:15:49.042009: step 52, loss 3.77814, acc 0.1875\n",
      "2017-04-03T19:15:49.331402: step 53, loss 3.8979, acc 0.109375\n",
      "2017-04-03T19:15:49.627621: step 54, loss 4.15308, acc 0.21875\n",
      "2017-04-03T19:15:49.951955: step 55, loss 3.56782, acc 0.265625\n",
      "2017-04-03T19:15:50.245723: step 56, loss 3.58025, acc 0.140625\n",
      "2017-04-03T19:15:50.553042: step 57, loss 3.18353, acc 0.25\n",
      "2017-04-03T19:15:50.840435: step 58, loss 3.9815, acc 0.09375\n",
      "2017-04-03T19:15:51.135482: step 59, loss 4.16408, acc 0.09375\n",
      "2017-04-03T19:15:51.435867: step 60, loss 3.4501, acc 0.21875\n",
      "2017-04-03T19:15:51.716861: step 61, loss 3.51615, acc 0.25\n",
      "2017-04-03T19:15:52.088839: step 62, loss 4.44282, acc 0.078125\n",
      "2017-04-03T19:15:52.540635: step 63, loss 5.01082, acc 0.125\n",
      "2017-04-03T19:15:52.935096: step 64, loss 3.79542, acc 0.15625\n",
      "2017-04-03T19:15:53.364713: step 65, loss 3.14576, acc 0.25\n",
      "2017-04-03T19:15:53.831405: step 66, loss 4.01839, acc 0.140625\n",
      "2017-04-03T19:15:54.191004: step 67, loss 4.37298, acc 0.109375\n",
      "2017-04-03T19:15:54.638375: step 68, loss 3.66832, acc 0.15625\n",
      "2017-04-03T19:15:54.890979: step 69, loss 4.02216, acc 0.25\n",
      "2017-04-03T19:15:55.178966: step 70, loss 3.66109, acc 0.28125\n",
      "2017-04-03T19:15:55.474991: step 71, loss 3.86224, acc 0.15625\n",
      "2017-04-03T19:15:55.752808: step 72, loss 3.38868, acc 0.1875\n",
      "2017-04-03T19:15:56.023389: step 73, loss 3.21193, acc 0.25\n",
      "2017-04-03T19:15:56.300180: step 74, loss 3.41325, acc 0.265625\n",
      "2017-04-03T19:15:56.619762: step 75, loss 4.05906, acc 0.171875\n",
      "2017-04-03T19:15:56.929967: step 76, loss 4.21264, acc 0.125\n",
      "2017-04-03T19:15:57.238989: step 77, loss 3.91501, acc 0.21875\n",
      "2017-04-03T19:15:57.499408: step 78, loss 3.30002, acc 0.265625\n",
      "2017-04-03T19:15:57.789981: step 79, loss 3.26429, acc 0.25\n",
      "2017-04-03T19:15:58.082217: step 80, loss 3.90826, acc 0.140625\n",
      "2017-04-03T19:15:58.388650: step 81, loss 3.38113, acc 0.21875\n",
      "2017-04-03T19:15:58.658786: step 82, loss 3.87016, acc 0.171875\n",
      "2017-04-03T19:15:58.962920: step 83, loss 4.2289, acc 0.1875\n",
      "2017-04-03T19:15:59.271085: step 84, loss 3.00027, acc 0.28125\n",
      "2017-04-03T19:15:59.551123: step 85, loss 3.76337, acc 0.21875\n",
      "2017-04-03T19:15:59.875175: step 86, loss 3.95405, acc 0.140625\n",
      "2017-04-03T19:16:00.166960: step 87, loss 3.89229, acc 0.140625\n",
      "2017-04-03T19:16:00.458944: step 88, loss 4.05012, acc 0.1875\n",
      "2017-04-03T19:16:00.781961: step 89, loss 3.23874, acc 0.21875\n",
      "2017-04-03T19:16:01.074966: step 90, loss 4.0385, acc 0.25\n",
      "2017-04-03T19:16:01.386956: step 91, loss 3.66349, acc 0.1875\n",
      "2017-04-03T19:16:01.709679: step 92, loss 3.33826, acc 0.203125\n",
      "2017-04-03T19:16:01.998574: step 93, loss 3.66188, acc 0.125\n",
      "2017-04-03T19:16:02.285957: step 94, loss 3.3272, acc 0.25\n",
      "2017-04-03T19:16:02.626236: step 95, loss 3.70029, acc 0.140625\n",
      "2017-04-03T19:16:02.916161: step 96, loss 3.80768, acc 0.15625\n",
      "2017-04-03T19:16:03.235948: step 97, loss 3.30625, acc 0.171875\n",
      "2017-04-03T19:16:03.546754: step 98, loss 3.20728, acc 0.21875\n",
      "2017-04-03T19:16:03.906006: step 99, loss 3.64111, acc 0.21875\n",
      "2017-04-03T19:16:04.214758: step 100, loss 3.68691, acc 0.15625\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:16:07.122310: step 100, loss 2.23086, acc 0.24525\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-100\n",
      "\n",
      "2017-04-03T19:16:07.553716: step 101, loss 3.70199, acc 0.140625\n",
      "2017-04-03T19:16:07.870998: step 102, loss 3.55164, acc 0.171875\n",
      "2017-04-03T19:16:08.135668: step 103, loss 3.39951, acc 0.234375\n",
      "2017-04-03T19:16:08.435138: step 104, loss 3.37366, acc 0.265625\n",
      "2017-04-03T19:16:08.739302: step 105, loss 3.76775, acc 0.171875\n",
      "2017-04-03T19:16:09.050804: step 106, loss 3.41956, acc 0.21875\n",
      "2017-04-03T19:16:09.307565: step 107, loss 3.24092, acc 0.1875\n",
      "2017-04-03T19:16:09.602422: step 108, loss 3.37412, acc 0.15625\n",
      "2017-04-03T19:16:09.897240: step 109, loss 3.14494, acc 0.28125\n",
      "2017-04-03T19:16:10.191234: step 110, loss 3.24238, acc 0.203125\n",
      "2017-04-03T19:16:10.483158: step 111, loss 3.8937, acc 0.203125\n",
      "2017-04-03T19:16:10.837351: step 112, loss 3.15522, acc 0.25\n",
      "2017-04-03T19:16:11.132975: step 113, loss 3.28646, acc 0.203125\n",
      "2017-04-03T19:16:11.442888: step 114, loss 3.23159, acc 0.28125\n",
      "2017-04-03T19:16:11.762831: step 115, loss 3.39129, acc 0.234375\n",
      "2017-04-03T19:16:12.058441: step 116, loss 3.26736, acc 0.1875\n",
      "2017-04-03T19:16:12.355004: step 117, loss 2.89763, acc 0.265625\n",
      "2017-04-03T19:16:12.648884: step 118, loss 2.66212, acc 0.234375\n",
      "2017-04-03T19:16:12.980086: step 119, loss 3.46058, acc 0.140625\n",
      "2017-04-03T19:16:13.289671: step 120, loss 3.25278, acc 0.234375\n",
      "2017-04-03T19:16:13.618980: step 121, loss 3.36197, acc 0.171875\n",
      "2017-04-03T19:16:13.939863: step 122, loss 4.02347, acc 0.15625\n",
      "2017-04-03T19:16:14.237166: step 123, loss 3.14614, acc 0.15625\n",
      "2017-04-03T19:16:14.545413: step 124, loss 3.3118, acc 0.234375\n",
      "2017-04-03T19:16:14.825831: step 125, loss 3.06627, acc 0.1875\n",
      "2017-04-03T19:16:15.110973: step 126, loss 3.47996, acc 0.203125\n",
      "2017-04-03T19:16:15.458989: step 127, loss 3.64228, acc 0.1875\n",
      "2017-04-03T19:16:15.755005: step 128, loss 3.66137, acc 0.15625\n",
      "2017-04-03T19:16:16.045589: step 129, loss 3.13434, acc 0.203125\n",
      "2017-04-03T19:16:16.362793: step 130, loss 3.42992, acc 0.203125\n",
      "2017-04-03T19:16:16.652492: step 131, loss 2.56879, acc 0.296875\n",
      "2017-04-03T19:16:16.978918: step 132, loss 3.24053, acc 0.25\n",
      "2017-04-03T19:16:17.305894: step 133, loss 3.22539, acc 0.21875\n",
      "2017-04-03T19:16:17.641795: step 134, loss 3.52625, acc 0.140625\n",
      "2017-04-03T19:16:17.985455: step 135, loss 3.54801, acc 0.1875\n",
      "2017-04-03T19:16:18.287749: step 136, loss 3.25507, acc 0.1875\n",
      "2017-04-03T19:16:18.629303: step 137, loss 3.70387, acc 0.140625\n",
      "2017-04-03T19:16:18.952278: step 138, loss 3.57467, acc 0.109375\n",
      "2017-04-03T19:16:19.268833: step 139, loss 3.45706, acc 0.1875\n",
      "2017-04-03T19:16:19.558903: step 140, loss 3.42585, acc 0.21875\n",
      "2017-04-03T19:16:19.891452: step 141, loss 3.33535, acc 0.125\n",
      "2017-04-03T19:16:20.210629: step 142, loss 3.42438, acc 0.1875\n",
      "2017-04-03T19:16:20.518034: step 143, loss 2.99539, acc 0.265625\n",
      "2017-04-03T19:16:20.848153: step 144, loss 3.25285, acc 0.25\n",
      "2017-04-03T19:16:21.066958: step 145, loss 3.52667, acc 0.09375\n",
      "2017-04-03T19:16:21.267206: step 146, loss 3.59372, acc 0.21875\n",
      "2017-04-03T19:16:21.481516: step 147, loss 3.77647, acc 0.15625\n",
      "2017-04-03T19:16:21.691331: step 148, loss 3.30687, acc 0.234375\n",
      "2017-04-03T19:16:21.896633: step 149, loss 2.97979, acc 0.21875\n",
      "2017-04-03T19:16:22.110559: step 150, loss 3.93535, acc 0.140625\n",
      "2017-04-03T19:16:22.317924: step 151, loss 3.59847, acc 0.25\n",
      "2017-04-03T19:16:22.526331: step 152, loss 3.49509, acc 0.140625\n",
      "2017-04-03T19:16:22.738871: step 153, loss 3.38091, acc 0.140625\n",
      "2017-04-03T19:16:22.948641: step 154, loss 3.01967, acc 0.140625\n",
      "2017-04-03T19:16:23.155549: step 155, loss 3.87751, acc 0.203125\n",
      "2017-04-03T19:16:23.365124: step 156, loss 3.19245, acc 0.15625\n",
      "2017-04-03T19:16:23.563440: step 157, loss 2.99446, acc 0.203125\n",
      "2017-04-03T19:16:23.765041: step 158, loss 3.30444, acc 0.1875\n",
      "2017-04-03T19:16:23.970772: step 159, loss 3.36371, acc 0.265625\n",
      "2017-04-03T19:16:24.181275: step 160, loss 3.10597, acc 0.1875\n",
      "2017-04-03T19:16:24.388865: step 161, loss 2.83596, acc 0.21875\n",
      "2017-04-03T19:16:24.595943: step 162, loss 3.88519, acc 0.171875\n",
      "2017-04-03T19:16:24.804932: step 163, loss 3.14252, acc 0.1875\n",
      "2017-04-03T19:16:25.004230: step 164, loss 3.60038, acc 0.125\n",
      "2017-04-03T19:16:25.202538: step 165, loss 3.46544, acc 0.15625\n",
      "2017-04-03T19:16:25.401767: step 166, loss 2.71747, acc 0.171875\n",
      "2017-04-03T19:16:25.600767: step 167, loss 3.81906, acc 0.109375\n",
      "2017-04-03T19:16:25.809361: step 168, loss 2.72556, acc 0.28125\n",
      "2017-04-03T19:16:26.024414: step 169, loss 3.81499, acc 0.1875\n",
      "2017-04-03T19:16:26.226566: step 170, loss 3.32634, acc 0.1875\n",
      "2017-04-03T19:16:26.433008: step 171, loss 2.97258, acc 0.171875\n",
      "2017-04-03T19:16:26.635087: step 172, loss 2.68978, acc 0.3125\n",
      "2017-04-03T19:16:26.841440: step 173, loss 3.51148, acc 0.09375\n",
      "2017-04-03T19:16:27.045478: step 174, loss 3.20049, acc 0.171875\n",
      "2017-04-03T19:16:27.250611: step 175, loss 3.57628, acc 0.21875\n",
      "2017-04-03T19:16:27.449259: step 176, loss 3.04449, acc 0.203125\n",
      "2017-04-03T19:16:27.644293: step 177, loss 3.64822, acc 0.140625\n",
      "2017-04-03T19:16:27.846475: step 178, loss 2.94967, acc 0.265625\n",
      "2017-04-03T19:16:28.042759: step 179, loss 3.25295, acc 0.140625\n",
      "2017-04-03T19:16:28.240396: step 180, loss 3.15714, acc 0.25\n",
      "2017-04-03T19:16:28.437800: step 181, loss 3.39774, acc 0.21875\n",
      "2017-04-03T19:16:28.641493: step 182, loss 2.87132, acc 0.140625\n",
      "2017-04-03T19:16:28.839902: step 183, loss 2.98227, acc 0.25\n",
      "2017-04-03T19:16:29.038799: step 184, loss 3.43106, acc 0.140625\n",
      "2017-04-03T19:16:29.245495: step 185, loss 3.67306, acc 0.171875\n",
      "2017-04-03T19:16:29.448515: step 186, loss 2.81002, acc 0.265625\n",
      "2017-04-03T19:16:29.647354: step 187, loss 3.26632, acc 0.25\n",
      "2017-04-03T19:16:29.849345: step 188, loss 2.87339, acc 0.1875\n",
      "2017-04-03T19:16:30.064364: step 189, loss 3.59352, acc 0.109375\n",
      "2017-04-03T19:16:30.265049: step 190, loss 2.76357, acc 0.3125\n",
      "2017-04-03T19:16:30.479274: step 191, loss 3.14425, acc 0.203125\n",
      "2017-04-03T19:16:30.689483: step 192, loss 2.98371, acc 0.1875\n",
      "2017-04-03T19:16:30.886612: step 193, loss 3.49475, acc 0.15625\n",
      "2017-04-03T19:16:31.088074: step 194, loss 2.90519, acc 0.234375\n",
      "2017-04-03T19:16:31.287240: step 195, loss 3.08981, acc 0.234375\n",
      "2017-04-03T19:16:31.487025: step 196, loss 3.55645, acc 0.15625\n",
      "2017-04-03T19:16:31.685273: step 197, loss 2.80122, acc 0.21875\n",
      "2017-04-03T19:16:31.892185: step 198, loss 2.97853, acc 0.21875\n",
      "2017-04-03T19:16:32.093919: step 199, loss 2.82366, acc 0.21875\n",
      "2017-04-03T19:16:32.297664: step 200, loss 3.33062, acc 0.15625\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:16:34.336259: step 200, loss 2.18753, acc 0.261\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-200\n",
      "\n",
      "2017-04-03T19:16:34.665565: step 201, loss 3.07522, acc 0.234375\n",
      "2017-04-03T19:16:34.871995: step 202, loss 3.04225, acc 0.1875\n",
      "2017-04-03T19:16:35.069521: step 203, loss 3.3177, acc 0.140625\n",
      "2017-04-03T19:16:35.267072: step 204, loss 3.19213, acc 0.15625\n",
      "2017-04-03T19:16:35.469103: step 205, loss 3.27569, acc 0.109375\n",
      "2017-04-03T19:16:35.663094: step 206, loss 2.77982, acc 0.25\n",
      "2017-04-03T19:16:35.857709: step 207, loss 2.9142, acc 0.234375\n",
      "2017-04-03T19:16:36.054901: step 208, loss 3.00997, acc 0.234375\n",
      "2017-04-03T19:16:36.254905: step 209, loss 3.05361, acc 0.234375\n",
      "2017-04-03T19:16:36.453224: step 210, loss 2.98186, acc 0.171875\n",
      "2017-04-03T19:16:36.649671: step 211, loss 2.33151, acc 0.296875\n",
      "2017-04-03T19:16:36.848740: step 212, loss 3.3937, acc 0.203125\n",
      "2017-04-03T19:16:37.047928: step 213, loss 2.88441, acc 0.1875\n",
      "2017-04-03T19:16:37.245310: step 214, loss 2.58816, acc 0.296875\n",
      "2017-04-03T19:16:37.446941: step 215, loss 2.80873, acc 0.203125\n",
      "2017-04-03T19:16:37.641554: step 216, loss 3.18024, acc 0.171875\n",
      "2017-04-03T19:16:37.836291: step 217, loss 3.00965, acc 0.21875\n",
      "2017-04-03T19:16:38.034856: step 218, loss 2.94939, acc 0.1875\n",
      "2017-04-03T19:16:38.230192: step 219, loss 3.26331, acc 0.15625\n",
      "2017-04-03T19:16:38.426602: step 220, loss 3.10998, acc 0.171875\n",
      "2017-04-03T19:16:38.621651: step 221, loss 3.05059, acc 0.15625\n",
      "2017-04-03T19:16:38.816766: step 222, loss 2.6877, acc 0.21875\n",
      "2017-04-03T19:16:39.022970: step 223, loss 3.00252, acc 0.25\n",
      "2017-04-03T19:16:39.220556: step 224, loss 2.79871, acc 0.25\n",
      "2017-04-03T19:16:39.419135: step 225, loss 2.75506, acc 0.21875\n",
      "2017-04-03T19:16:39.625326: step 226, loss 3.03731, acc 0.21875\n",
      "2017-04-03T19:16:39.829162: step 227, loss 3.16481, acc 0.15625\n",
      "2017-04-03T19:16:40.035060: step 228, loss 2.94573, acc 0.15625\n",
      "2017-04-03T19:16:40.243821: step 229, loss 2.94784, acc 0.234375\n",
      "2017-04-03T19:16:40.446401: step 230, loss 2.76053, acc 0.203125\n",
      "2017-04-03T19:16:40.649692: step 231, loss 3.30002, acc 0.1875\n",
      "2017-04-03T19:16:40.849310: step 232, loss 3.06162, acc 0.21875\n",
      "2017-04-03T19:16:41.057018: step 233, loss 2.5601, acc 0.296875\n",
      "2017-04-03T19:16:41.271852: step 234, loss 3.35668, acc 0.15625\n",
      "2017-04-03T19:16:41.478104: step 235, loss 2.98356, acc 0.21875\n",
      "2017-04-03T19:16:41.679653: step 236, loss 2.79589, acc 0.21875\n",
      "2017-04-03T19:16:41.886763: step 237, loss 2.81193, acc 0.21875\n",
      "2017-04-03T19:16:42.092608: step 238, loss 2.72171, acc 0.21875\n",
      "2017-04-03T19:16:42.291959: step 239, loss 3.08855, acc 0.203125\n",
      "2017-04-03T19:16:42.494184: step 240, loss 2.98704, acc 0.1875\n",
      "2017-04-03T19:16:42.696807: step 241, loss 3.13363, acc 0.140625\n",
      "2017-04-03T19:16:42.896577: step 242, loss 2.83211, acc 0.25\n",
      "2017-04-03T19:16:43.104608: step 243, loss 2.73781, acc 0.21875\n",
      "2017-04-03T19:16:43.305211: step 244, loss 3.26543, acc 0.21875\n",
      "2017-04-03T19:16:43.503147: step 245, loss 2.46524, acc 0.265625\n",
      "2017-04-03T19:16:43.702247: step 246, loss 2.962, acc 0.25\n",
      "2017-04-03T19:16:43.908299: step 247, loss 3.02388, acc 0.15625\n",
      "2017-04-03T19:16:44.105131: step 248, loss 3.04054, acc 0.1875\n",
      "2017-04-03T19:16:44.309166: step 249, loss 2.45325, acc 0.265625\n",
      "2017-04-03T19:16:44.511372: step 250, loss 3.15121, acc 0.15625\n",
      "2017-04-03T19:16:44.714913: step 251, loss 2.79886, acc 0.1875\n",
      "2017-04-03T19:16:44.925675: step 252, loss 3.04071, acc 0.203125\n",
      "2017-04-03T19:16:45.134683: step 253, loss 2.76049, acc 0.140625\n",
      "2017-04-03T19:16:45.344887: step 254, loss 2.57631, acc 0.21875\n",
      "2017-04-03T19:16:45.557207: step 255, loss 3.1717, acc 0.140625\n",
      "2017-04-03T19:16:45.754984: step 256, loss 2.69823, acc 0.234375\n",
      "2017-04-03T19:16:45.963676: step 257, loss 2.8591, acc 0.21875\n",
      "2017-04-03T19:16:46.174867: step 258, loss 2.46005, acc 0.34375\n",
      "2017-04-03T19:16:46.383798: step 259, loss 2.89955, acc 0.3125\n",
      "2017-04-03T19:16:46.591774: step 260, loss 2.92451, acc 0.21875\n",
      "2017-04-03T19:16:46.793710: step 261, loss 2.77373, acc 0.28125\n",
      "2017-04-03T19:16:46.989978: step 262, loss 2.72401, acc 0.140625\n",
      "2017-04-03T19:16:47.192254: step 263, loss 3.16229, acc 0.21875\n",
      "2017-04-03T19:16:47.386525: step 264, loss 2.67744, acc 0.15625\n",
      "2017-04-03T19:16:47.590808: step 265, loss 3.181, acc 0.140625\n",
      "2017-04-03T19:16:47.789915: step 266, loss 2.62506, acc 0.265625\n",
      "2017-04-03T19:16:47.991370: step 267, loss 2.70598, acc 0.234375\n",
      "2017-04-03T19:16:48.188931: step 268, loss 3.07391, acc 0.203125\n",
      "2017-04-03T19:16:48.388025: step 269, loss 2.65202, acc 0.203125\n",
      "2017-04-03T19:16:48.583093: step 270, loss 2.40265, acc 0.25\n",
      "2017-04-03T19:16:48.783938: step 271, loss 3.01553, acc 0.15625\n",
      "2017-04-03T19:16:48.981299: step 272, loss 2.96267, acc 0.1875\n",
      "2017-04-03T19:16:49.189231: step 273, loss 2.69405, acc 0.28125\n",
      "2017-04-03T19:16:49.391695: step 274, loss 2.34401, acc 0.3125\n",
      "2017-04-03T19:16:49.611559: step 275, loss 2.85476, acc 0.1875\n",
      "2017-04-03T19:16:49.824792: step 276, loss 2.87879, acc 0.25\n",
      "2017-04-03T19:16:50.032200: step 277, loss 2.49876, acc 0.25\n",
      "2017-04-03T19:16:50.237044: step 278, loss 2.66273, acc 0.3125\n",
      "2017-04-03T19:16:50.440918: step 279, loss 2.9582, acc 0.15625\n",
      "2017-04-03T19:16:50.639541: step 280, loss 2.51551, acc 0.234375\n",
      "2017-04-03T19:16:50.857415: step 281, loss 2.87265, acc 0.1875\n",
      "2017-04-03T19:16:51.057281: step 282, loss 2.66997, acc 0.21875\n",
      "2017-04-03T19:16:51.258794: step 283, loss 2.94445, acc 0.1875\n",
      "2017-04-03T19:16:51.461286: step 284, loss 2.94689, acc 0.171875\n",
      "2017-04-03T19:16:51.667375: step 285, loss 2.26545, acc 0.359375\n",
      "2017-04-03T19:16:51.864928: step 286, loss 2.91498, acc 0.234375\n",
      "2017-04-03T19:16:52.070714: step 287, loss 2.64996, acc 0.1875\n",
      "2017-04-03T19:16:52.273180: step 288, loss 2.88291, acc 0.21875\n",
      "2017-04-03T19:16:52.468741: step 289, loss 2.75113, acc 0.25\n",
      "2017-04-03T19:16:52.669283: step 290, loss 3.14773, acc 0.203125\n",
      "2017-04-03T19:16:52.872046: step 291, loss 2.47936, acc 0.3125\n",
      "2017-04-03T19:16:53.074293: step 292, loss 2.30808, acc 0.28125\n",
      "2017-04-03T19:16:53.275200: step 293, loss 2.74574, acc 0.234375\n",
      "2017-04-03T19:16:53.481586: step 294, loss 2.81065, acc 0.171875\n",
      "2017-04-03T19:16:53.685940: step 295, loss 2.63431, acc 0.21875\n",
      "2017-04-03T19:16:53.892629: step 296, loss 3.10129, acc 0.140625\n",
      "2017-04-03T19:16:54.099115: step 297, loss 2.69945, acc 0.171875\n",
      "2017-04-03T19:16:54.304309: step 298, loss 2.47814, acc 0.203125\n",
      "2017-04-03T19:16:54.511647: step 299, loss 2.66466, acc 0.171875\n",
      "2017-04-03T19:16:54.713316: step 300, loss 3.33759, acc 0.171875\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:16:56.676736: step 300, loss 2.03662, acc 0.274\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-300\n",
      "\n",
      "2017-04-03T19:16:57.015475: step 301, loss 2.73561, acc 0.265625\n",
      "2017-04-03T19:16:57.212178: step 302, loss 2.30093, acc 0.296875\n",
      "2017-04-03T19:16:57.419352: step 303, loss 2.71345, acc 0.140625\n",
      "2017-04-03T19:16:57.616852: step 304, loss 2.33359, acc 0.234375\n",
      "2017-04-03T19:16:57.821749: step 305, loss 3.01509, acc 0.15625\n",
      "2017-04-03T19:16:58.026334: step 306, loss 2.54819, acc 0.234375\n",
      "2017-04-03T19:16:58.228658: step 307, loss 2.75179, acc 0.1875\n",
      "2017-04-03T19:16:58.436807: step 308, loss 2.93743, acc 0.21875\n",
      "2017-04-03T19:16:58.635885: step 309, loss 2.58374, acc 0.140625\n",
      "2017-04-03T19:16:58.839736: step 310, loss 2.71177, acc 0.21875\n",
      "2017-04-03T19:16:59.036717: step 311, loss 3.22546, acc 0.15625\n",
      "2017-04-03T19:16:59.244861: step 312, loss 2.55557, acc 0.171875\n",
      "2017-04-03T19:16:59.447755: step 313, loss 2.56414, acc 0.28125\n",
      "2017-04-03T19:16:59.652161: step 314, loss 2.64275, acc 0.1875\n",
      "2017-04-03T19:16:59.853812: step 315, loss 2.83161, acc 0.203125\n",
      "2017-04-03T19:17:00.055001: step 316, loss 2.82257, acc 0.171875\n",
      "2017-04-03T19:17:00.260004: step 317, loss 2.66248, acc 0.171875\n",
      "2017-04-03T19:17:00.462589: step 318, loss 2.95147, acc 0.21875\n",
      "2017-04-03T19:17:00.666517: step 319, loss 2.28716, acc 0.296875\n",
      "2017-04-03T19:17:00.865088: step 320, loss 2.58402, acc 0.21875\n",
      "2017-04-03T19:17:01.064038: step 321, loss 2.56073, acc 0.21875\n",
      "2017-04-03T19:17:01.262720: step 322, loss 2.58945, acc 0.21875\n",
      "2017-04-03T19:17:01.461182: step 323, loss 2.52016, acc 0.15625\n",
      "2017-04-03T19:17:01.662255: step 324, loss 3.0299, acc 0.125\n",
      "2017-04-03T19:17:01.864616: step 325, loss 2.54309, acc 0.171875\n",
      "2017-04-03T19:17:02.068200: step 326, loss 2.44486, acc 0.265625\n",
      "2017-04-03T19:17:02.274529: step 327, loss 2.45805, acc 0.21875\n",
      "2017-04-03T19:17:02.476221: step 328, loss 2.50381, acc 0.28125\n",
      "2017-04-03T19:17:02.676594: step 329, loss 2.68106, acc 0.265625\n",
      "2017-04-03T19:17:02.882895: step 330, loss 2.79599, acc 0.15625\n",
      "2017-04-03T19:17:03.081989: step 331, loss 2.87375, acc 0.21875\n",
      "2017-04-03T19:17:03.280858: step 332, loss 2.43279, acc 0.1875\n",
      "2017-04-03T19:17:03.480569: step 333, loss 2.34778, acc 0.1875\n",
      "2017-04-03T19:17:03.683474: step 334, loss 2.49278, acc 0.234375\n",
      "2017-04-03T19:17:03.883901: step 335, loss 2.56261, acc 0.1875\n",
      "2017-04-03T19:17:04.086575: step 336, loss 2.41937, acc 0.234375\n",
      "2017-04-03T19:17:04.278048: step 337, loss 2.41269, acc 0.21875\n",
      "2017-04-03T19:17:04.481910: step 338, loss 2.55333, acc 0.109375\n",
      "2017-04-03T19:17:04.676045: step 339, loss 1.99594, acc 0.296875\n",
      "2017-04-03T19:17:04.882113: step 340, loss 2.47115, acc 0.265625\n",
      "2017-04-03T19:17:05.084096: step 341, loss 2.4197, acc 0.21875\n",
      "2017-04-03T19:17:05.283029: step 342, loss 2.9157, acc 0.25\n",
      "2017-04-03T19:17:05.484710: step 343, loss 2.55568, acc 0.265625\n",
      "2017-04-03T19:17:05.685943: step 344, loss 2.67678, acc 0.234375\n",
      "2017-04-03T19:17:05.885513: step 345, loss 2.42359, acc 0.296875\n",
      "2017-04-03T19:17:06.086320: step 346, loss 2.59778, acc 0.28125\n",
      "2017-04-03T19:17:06.281809: step 347, loss 2.42694, acc 0.234375\n",
      "2017-04-03T19:17:06.490520: step 348, loss 2.52962, acc 0.21875\n",
      "2017-04-03T19:17:06.688139: step 349, loss 2.17967, acc 0.265625\n",
      "2017-04-03T19:17:06.887976: step 350, loss 2.44087, acc 0.25\n",
      "2017-04-03T19:17:07.084337: step 351, loss 2.5968, acc 0.25\n",
      "2017-04-03T19:17:07.287629: step 352, loss 2.66594, acc 0.203125\n",
      "2017-04-03T19:17:07.482257: step 353, loss 2.50421, acc 0.28125\n",
      "2017-04-03T19:17:07.685166: step 354, loss 2.95076, acc 0.171875\n",
      "2017-04-03T19:17:07.885573: step 355, loss 2.64814, acc 0.15625\n",
      "2017-04-03T19:17:08.090731: step 356, loss 2.28147, acc 0.296875\n",
      "2017-04-03T19:17:08.289971: step 357, loss 2.36596, acc 0.140625\n",
      "2017-04-03T19:17:08.491153: step 358, loss 2.39888, acc 0.203125\n",
      "2017-04-03T19:17:08.688428: step 359, loss 2.40931, acc 0.25\n",
      "2017-04-03T19:17:08.891666: step 360, loss 2.32076, acc 0.15625\n",
      "2017-04-03T19:17:09.092060: step 361, loss 2.71333, acc 0.21875\n",
      "2017-04-03T19:17:09.298046: step 362, loss 2.74748, acc 0.1875\n",
      "2017-04-03T19:17:09.498476: step 363, loss 2.57501, acc 0.234375\n",
      "2017-04-03T19:17:09.698939: step 364, loss 2.48912, acc 0.234375\n",
      "2017-04-03T19:17:09.895565: step 365, loss 2.37944, acc 0.25\n",
      "2017-04-03T19:17:10.102442: step 366, loss 2.23785, acc 0.265625\n",
      "2017-04-03T19:17:10.298843: step 367, loss 2.73743, acc 0.3125\n",
      "2017-04-03T19:17:10.507897: step 368, loss 2.31035, acc 0.171875\n",
      "2017-04-03T19:17:10.731419: step 369, loss 2.71241, acc 0.203125\n",
      "2017-04-03T19:17:10.935103: step 370, loss 2.32686, acc 0.265625\n",
      "2017-04-03T19:17:11.135403: step 371, loss 2.68863, acc 0.1875\n",
      "2017-04-03T19:17:11.340095: step 372, loss 2.32452, acc 0.296875\n",
      "2017-04-03T19:17:11.543241: step 373, loss 2.75553, acc 0.171875\n",
      "2017-04-03T19:17:11.746446: step 374, loss 2.4126, acc 0.171875\n",
      "2017-04-03T19:17:11.952652: step 375, loss 2.30557, acc 0.234375\n",
      "2017-04-03T19:17:12.149169: step 376, loss 2.38923, acc 0.234375\n",
      "2017-04-03T19:17:12.349115: step 377, loss 1.92532, acc 0.359375\n",
      "2017-04-03T19:17:12.544390: step 378, loss 2.79414, acc 0.1875\n",
      "2017-04-03T19:17:12.758399: step 379, loss 2.22675, acc 0.234375\n",
      "2017-04-03T19:17:12.950129: step 380, loss 2.84188, acc 0.203125\n",
      "2017-04-03T19:17:13.154307: step 381, loss 2.56682, acc 0.28125\n",
      "2017-04-03T19:17:13.351750: step 382, loss 2.43386, acc 0.25\n",
      "2017-04-03T19:17:13.554488: step 383, loss 2.47654, acc 0.234375\n",
      "2017-04-03T19:17:13.756660: step 384, loss 2.64928, acc 0.25\n",
      "2017-04-03T19:17:13.956269: step 385, loss 2.05407, acc 0.328125\n",
      "2017-04-03T19:17:14.159146: step 386, loss 2.33343, acc 0.203125\n",
      "2017-04-03T19:17:14.359085: step 387, loss 2.42111, acc 0.171875\n",
      "2017-04-03T19:17:14.559689: step 388, loss 2.68696, acc 0.234375\n",
      "2017-04-03T19:17:14.760257: step 389, loss 2.06089, acc 0.25\n",
      "2017-04-03T19:17:14.966714: step 390, loss 2.16824, acc 0.21875\n",
      "2017-04-03T19:17:15.164998: step 391, loss 2.42456, acc 0.34375\n",
      "2017-04-03T19:17:15.363570: step 392, loss 2.32566, acc 0.203125\n",
      "2017-04-03T19:17:15.559128: step 393, loss 2.36135, acc 0.28125\n",
      "2017-04-03T19:17:15.760685: step 394, loss 2.61685, acc 0.1875\n",
      "2017-04-03T19:17:15.958591: step 395, loss 1.93032, acc 0.3125\n",
      "2017-04-03T19:17:16.159903: step 396, loss 2.40669, acc 0.265625\n",
      "2017-04-03T19:17:16.359971: step 397, loss 2.60851, acc 0.234375\n",
      "2017-04-03T19:17:16.563507: step 398, loss 2.08835, acc 0.234375\n",
      "2017-04-03T19:17:16.763192: step 399, loss 2.61591, acc 0.234375\n",
      "2017-04-03T19:17:16.962635: step 400, loss 2.09872, acc 0.28125\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:17:18.928318: step 400, loss 2.04315, acc 0.283\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-400\n",
      "\n",
      "2017-04-03T19:17:19.268190: step 401, loss 2.34097, acc 0.21875\n",
      "2017-04-03T19:17:19.466633: step 402, loss 2.63803, acc 0.234375\n",
      "2017-04-03T19:17:19.671104: step 403, loss 2.56597, acc 0.171875\n",
      "2017-04-03T19:17:19.866470: step 404, loss 2.39252, acc 0.1875\n",
      "2017-04-03T19:17:20.069714: step 405, loss 2.49134, acc 0.1875\n",
      "2017-04-03T19:17:20.269281: step 406, loss 2.65592, acc 0.25\n",
      "2017-04-03T19:17:20.471567: step 407, loss 2.63521, acc 0.21875\n",
      "2017-04-03T19:17:20.668391: step 408, loss 2.87169, acc 0.265625\n",
      "2017-04-03T19:17:20.872392: step 409, loss 2.48156, acc 0.25\n",
      "2017-04-03T19:17:21.072527: step 410, loss 2.60282, acc 0.171875\n",
      "2017-04-03T19:17:21.275041: step 411, loss 2.26134, acc 0.265625\n",
      "2017-04-03T19:17:21.479955: step 412, loss 2.37588, acc 0.265625\n",
      "2017-04-03T19:17:21.683305: step 413, loss 2.43453, acc 0.265625\n",
      "2017-04-03T19:17:21.887987: step 414, loss 2.27582, acc 0.25\n",
      "2017-04-03T19:17:22.090606: step 415, loss 2.75106, acc 0.28125\n",
      "2017-04-03T19:17:22.295745: step 416, loss 2.52942, acc 0.15625\n",
      "2017-04-03T19:17:22.499055: step 417, loss 2.2432, acc 0.234375\n",
      "2017-04-03T19:17:22.704340: step 418, loss 2.37285, acc 0.1875\n",
      "2017-04-03T19:17:22.904987: step 419, loss 2.28037, acc 0.296875\n",
      "2017-04-03T19:17:23.110406: step 420, loss 2.361, acc 0.28125\n",
      "2017-04-03T19:17:23.309039: step 421, loss 2.27765, acc 0.203125\n",
      "2017-04-03T19:17:23.506722: step 422, loss 2.31733, acc 0.25\n",
      "2017-04-03T19:17:23.705492: step 423, loss 2.71156, acc 0.1875\n",
      "2017-04-03T19:17:23.914176: step 424, loss 2.56735, acc 0.15625\n",
      "2017-04-03T19:17:24.110864: step 425, loss 2.12349, acc 0.203125\n",
      "2017-04-03T19:17:24.315187: step 426, loss 2.32649, acc 0.15625\n",
      "2017-04-03T19:17:24.513232: step 427, loss 2.34397, acc 0.265625\n",
      "2017-04-03T19:17:24.722045: step 428, loss 2.2609, acc 0.140625\n",
      "2017-04-03T19:17:24.918657: step 429, loss 2.23892, acc 0.328125\n",
      "2017-04-03T19:17:25.122313: step 430, loss 2.27066, acc 0.1875\n",
      "2017-04-03T19:17:25.322846: step 431, loss 2.41291, acc 0.21875\n",
      "2017-04-03T19:17:25.534108: step 432, loss 2.59607, acc 0.25\n",
      "2017-04-03T19:17:25.728120: step 433, loss 2.53099, acc 0.25\n",
      "2017-04-03T19:17:25.928800: step 434, loss 2.11872, acc 0.28125\n",
      "2017-04-03T19:17:26.127904: step 435, loss 2.54683, acc 0.21875\n",
      "2017-04-03T19:17:26.328320: step 436, loss 2.69967, acc 0.203125\n",
      "2017-04-03T19:17:26.520607: step 437, loss 2.69292, acc 0.234375\n",
      "2017-04-03T19:17:26.720873: step 438, loss 2.18554, acc 0.21875\n",
      "2017-04-03T19:17:26.918275: step 439, loss 2.35206, acc 0.3125\n",
      "2017-04-03T19:17:27.117565: step 440, loss 2.49774, acc 0.25\n",
      "2017-04-03T19:17:27.322102: step 441, loss 2.43991, acc 0.234375\n",
      "2017-04-03T19:17:27.529568: step 442, loss 2.25624, acc 0.1875\n",
      "2017-04-03T19:17:27.734171: step 443, loss 2.40691, acc 0.25\n",
      "2017-04-03T19:17:27.937683: step 444, loss 2.43638, acc 0.234375\n",
      "2017-04-03T19:17:28.141861: step 445, loss 2.27186, acc 0.234375\n",
      "2017-04-03T19:17:28.345978: step 446, loss 2.15839, acc 0.328125\n",
      "2017-04-03T19:17:28.547029: step 447, loss 2.26397, acc 0.21875\n",
      "2017-04-03T19:17:28.750493: step 448, loss 2.68145, acc 0.234375\n",
      "2017-04-03T19:17:28.952358: step 449, loss 2.28921, acc 0.109375\n",
      "2017-04-03T19:17:29.157262: step 450, loss 2.31461, acc 0.25\n",
      "2017-04-03T19:17:29.359587: step 451, loss 2.35715, acc 0.234375\n",
      "2017-04-03T19:17:29.570405: step 452, loss 2.65262, acc 0.1875\n",
      "2017-04-03T19:17:29.770328: step 453, loss 2.22693, acc 0.21875\n",
      "2017-04-03T19:17:29.974534: step 454, loss 2.39032, acc 0.28125\n",
      "2017-04-03T19:17:30.189998: step 455, loss 1.95993, acc 0.328125\n",
      "2017-04-03T19:17:30.391918: step 456, loss 2.04485, acc 0.3125\n",
      "2017-04-03T19:17:30.595097: step 457, loss 2.25263, acc 0.265625\n",
      "2017-04-03T19:17:30.797246: step 458, loss 2.13787, acc 0.359375\n",
      "2017-04-03T19:17:31.001858: step 459, loss 2.78684, acc 0.171875\n",
      "2017-04-03T19:17:31.205270: step 460, loss 2.35238, acc 0.234375\n",
      "2017-04-03T19:17:31.409524: step 461, loss 2.47312, acc 0.203125\n",
      "2017-04-03T19:17:31.610882: step 462, loss 2.12162, acc 0.25\n",
      "2017-04-03T19:17:31.810867: step 463, loss 2.44222, acc 0.265625\n",
      "2017-04-03T19:17:32.016104: step 464, loss 2.24082, acc 0.328125\n",
      "2017-04-03T19:17:32.213702: step 465, loss 2.33833, acc 0.265625\n",
      "2017-04-03T19:17:32.420465: step 466, loss 2.49742, acc 0.203125\n",
      "2017-04-03T19:17:32.617166: step 467, loss 2.29571, acc 0.296875\n",
      "2017-04-03T19:17:32.818492: step 468, loss 2.47148, acc 0.25\n",
      "2017-04-03T19:17:33.015240: step 469, loss 2.37539, acc 0.203125\n",
      "2017-04-03T19:17:33.216942: step 470, loss 2.64673, acc 0.109375\n",
      "2017-04-03T19:17:33.412219: step 471, loss 2.43764, acc 0.234375\n",
      "2017-04-03T19:17:33.617942: step 472, loss 2.27392, acc 0.234375\n",
      "2017-04-03T19:17:33.814630: step 473, loss 2.61662, acc 0.1875\n",
      "2017-04-03T19:17:34.014596: step 474, loss 2.15803, acc 0.28125\n",
      "2017-04-03T19:17:34.208944: step 475, loss 2.27933, acc 0.234375\n",
      "2017-04-03T19:17:34.410571: step 476, loss 2.18423, acc 0.3125\n",
      "2017-04-03T19:17:34.610916: step 477, loss 2.25299, acc 0.3125\n",
      "2017-04-03T19:17:34.810281: step 478, loss 2.09693, acc 0.265625\n",
      "2017-04-03T19:17:35.012445: step 479, loss 2.20002, acc 0.171875\n",
      "2017-04-03T19:17:35.213983: step 480, loss 2.26146, acc 0.25\n",
      "2017-04-03T19:17:35.423318: step 481, loss 2.30496, acc 0.203125\n",
      "2017-04-03T19:17:35.626224: step 482, loss 2.34552, acc 0.234375\n",
      "2017-04-03T19:17:35.827275: step 483, loss 2.2753, acc 0.296875\n",
      "2017-04-03T19:17:36.026110: step 484, loss 2.19276, acc 0.234375\n",
      "2017-04-03T19:17:36.231299: step 485, loss 2.01426, acc 0.265625\n",
      "2017-04-03T19:17:36.428927: step 486, loss 2.25207, acc 0.25\n",
      "2017-04-03T19:17:36.630044: step 487, loss 2.33027, acc 0.1875\n",
      "2017-04-03T19:17:36.827423: step 488, loss 2.34737, acc 0.21875\n",
      "2017-04-03T19:17:37.027178: step 489, loss 2.4921, acc 0.171875\n",
      "2017-04-03T19:17:37.222485: step 490, loss 2.31272, acc 0.3125\n",
      "2017-04-03T19:17:37.423362: step 491, loss 2.49506, acc 0.1875\n",
      "2017-04-03T19:17:37.620622: step 492, loss 2.36533, acc 0.234375\n",
      "2017-04-03T19:17:37.818372: step 493, loss 2.3464, acc 0.1875\n",
      "2017-04-03T19:17:38.017527: step 494, loss 1.97661, acc 0.265625\n",
      "2017-04-03T19:17:38.218206: step 495, loss 2.21705, acc 0.25\n",
      "2017-04-03T19:17:38.418031: step 496, loss 2.37281, acc 0.296875\n",
      "2017-04-03T19:17:38.617068: step 497, loss 2.40804, acc 0.125\n",
      "2017-04-03T19:17:38.818301: step 498, loss 2.30727, acc 0.28125\n",
      "2017-04-03T19:17:39.019244: step 499, loss 2.20848, acc 0.21875\n",
      "2017-04-03T19:17:39.222437: step 500, loss 2.24545, acc 0.28125\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:17:41.209775: step 500, loss 1.99965, acc 0.28125\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-500\n",
      "\n",
      "2017-04-03T19:17:41.537750: step 501, loss 2.7077, acc 0.203125\n",
      "2017-04-03T19:17:41.736871: step 502, loss 2.0017, acc 0.375\n",
      "2017-04-03T19:17:41.936933: step 503, loss 2.37794, acc 0.21875\n",
      "2017-04-03T19:17:42.133193: step 504, loss 2.427, acc 0.265625\n",
      "2017-04-03T19:17:42.334031: step 505, loss 2.57251, acc 0.21875\n",
      "2017-04-03T19:17:42.528817: step 506, loss 2.64283, acc 0.21875\n",
      "2017-04-03T19:17:42.733940: step 507, loss 2.2629, acc 0.3125\n",
      "2017-04-03T19:17:42.931270: step 508, loss 2.28531, acc 0.21875\n",
      "2017-04-03T19:17:43.135368: step 509, loss 2.20289, acc 0.1875\n",
      "2017-04-03T19:17:43.331364: step 510, loss 2.63211, acc 0.234375\n",
      "2017-04-03T19:17:43.540192: step 511, loss 2.18041, acc 0.265625\n",
      "2017-04-03T19:17:43.739510: step 512, loss 2.21586, acc 0.25\n",
      "2017-04-03T19:17:43.942600: step 513, loss 2.31735, acc 0.25\n",
      "2017-04-03T19:17:44.140859: step 514, loss 2.28775, acc 0.171875\n",
      "2017-04-03T19:17:44.346691: step 515, loss 2.04621, acc 0.265625\n",
      "2017-04-03T19:17:44.551198: step 516, loss 2.10571, acc 0.234375\n",
      "2017-04-03T19:17:44.751139: step 517, loss 2.18485, acc 0.234375\n",
      "2017-04-03T19:17:44.954254: step 518, loss 2.40788, acc 0.171875\n",
      "2017-04-03T19:17:45.150472: step 519, loss 2.40323, acc 0.25\n",
      "2017-04-03T19:17:45.351686: step 520, loss 1.97163, acc 0.3125\n",
      "2017-04-03T19:17:45.550052: step 521, loss 2.22686, acc 0.265625\n",
      "2017-04-03T19:17:45.761277: step 522, loss 2.54284, acc 0.296875\n",
      "2017-04-03T19:17:45.961661: step 523, loss 2.33624, acc 0.328125\n",
      "2017-04-03T19:17:46.167959: step 524, loss 2.40858, acc 0.3125\n",
      "2017-04-03T19:17:46.370396: step 525, loss 2.34931, acc 0.28125\n",
      "2017-04-03T19:17:46.572934: step 526, loss 2.64352, acc 0.21875\n",
      "2017-04-03T19:17:46.783492: step 527, loss 2.53943, acc 0.203125\n",
      "2017-04-03T19:17:46.986357: step 528, loss 2.24096, acc 0.25\n",
      "2017-04-03T19:17:47.186420: step 529, loss 2.76413, acc 0.203125\n",
      "2017-04-03T19:17:47.389960: step 530, loss 2.33803, acc 0.28125\n",
      "2017-04-03T19:17:47.590175: step 531, loss 2.18671, acc 0.265625\n",
      "2017-04-03T19:17:47.788137: step 532, loss 2.44257, acc 0.1875\n",
      "2017-04-03T19:17:47.987084: step 533, loss 2.06549, acc 0.234375\n",
      "2017-04-03T19:17:48.188942: step 534, loss 2.19377, acc 0.234375\n",
      "2017-04-03T19:17:48.385228: step 535, loss 2.21128, acc 0.171875\n",
      "2017-04-03T19:17:48.589526: step 536, loss 2.28068, acc 0.25\n",
      "2017-04-03T19:17:48.787057: step 537, loss 2.39827, acc 0.171875\n",
      "2017-04-03T19:17:48.988468: step 538, loss 2.35831, acc 0.265625\n",
      "2017-04-03T19:17:49.185213: step 539, loss 1.9365, acc 0.3125\n",
      "2017-04-03T19:17:49.390463: step 540, loss 2.19501, acc 0.25\n",
      "2017-04-03T19:17:49.585140: step 541, loss 2.38091, acc 0.265625\n",
      "2017-04-03T19:17:49.791270: step 542, loss 2.11257, acc 0.203125\n",
      "2017-04-03T19:17:49.991509: step 543, loss 2.49996, acc 0.078125\n",
      "2017-04-03T19:17:50.188782: step 544, loss 2.23966, acc 0.25\n",
      "2017-04-03T19:17:50.388031: step 545, loss 2.34639, acc 0.28125\n",
      "2017-04-03T19:17:50.594026: step 546, loss 2.09753, acc 0.34375\n",
      "2017-04-03T19:17:50.793768: step 547, loss 2.28087, acc 0.328125\n",
      "2017-04-03T19:17:50.992854: step 548, loss 2.04956, acc 0.28125\n",
      "2017-04-03T19:17:51.199230: step 549, loss 2.30811, acc 0.296875\n",
      "2017-04-03T19:17:51.400177: step 550, loss 2.11959, acc 0.3125\n",
      "2017-04-03T19:17:51.609785: step 551, loss 2.04006, acc 0.28125\n",
      "2017-04-03T19:17:51.812734: step 552, loss 2.16897, acc 0.296875\n",
      "2017-04-03T19:17:52.016987: step 553, loss 2.16809, acc 0.265625\n",
      "2017-04-03T19:17:52.221151: step 554, loss 2.33504, acc 0.21875\n",
      "2017-04-03T19:17:52.424084: step 555, loss 2.29353, acc 0.265625\n",
      "2017-04-03T19:17:52.620132: step 556, loss 2.37737, acc 0.28125\n",
      "2017-04-03T19:17:52.823082: step 557, loss 2.18217, acc 0.1875\n",
      "2017-04-03T19:17:53.021806: step 558, loss 2.04224, acc 0.3125\n",
      "2017-04-03T19:17:53.226532: step 559, loss 2.18571, acc 0.234375\n",
      "2017-04-03T19:17:53.427704: step 560, loss 2.27231, acc 0.25\n",
      "2017-04-03T19:17:53.627500: step 561, loss 2.15003, acc 0.328125\n",
      "2017-04-03T19:17:53.830224: step 562, loss 1.92538, acc 0.234375\n",
      "2017-04-03T19:17:53.973617: step 563, loss 1.85095, acc 0.3125\n",
      "2017-04-03T19:17:54.178653: step 564, loss 2.34408, acc 0.203125\n",
      "2017-04-03T19:17:54.373765: step 565, loss 1.93236, acc 0.1875\n",
      "2017-04-03T19:17:54.579747: step 566, loss 1.97373, acc 0.265625\n",
      "2017-04-03T19:17:54.774378: step 567, loss 2.03046, acc 0.1875\n",
      "2017-04-03T19:17:54.975208: step 568, loss 1.85088, acc 0.34375\n",
      "2017-04-03T19:17:55.174797: step 569, loss 1.8894, acc 0.28125\n",
      "2017-04-03T19:17:55.372178: step 570, loss 2.09441, acc 0.28125\n",
      "2017-04-03T19:17:55.567649: step 571, loss 2.05591, acc 0.296875\n",
      "2017-04-03T19:17:55.765569: step 572, loss 1.96591, acc 0.421875\n",
      "2017-04-03T19:17:55.962936: step 573, loss 2.18788, acc 0.265625\n",
      "2017-04-03T19:17:56.163865: step 574, loss 1.72038, acc 0.390625\n",
      "2017-04-03T19:17:56.362951: step 575, loss 1.91717, acc 0.296875\n",
      "2017-04-03T19:17:56.563847: step 576, loss 1.93511, acc 0.3125\n",
      "2017-04-03T19:17:56.764789: step 577, loss 2.01573, acc 0.34375\n",
      "2017-04-03T19:17:56.964770: step 578, loss 1.86688, acc 0.34375\n",
      "2017-04-03T19:17:57.171416: step 579, loss 2.28445, acc 0.296875\n",
      "2017-04-03T19:17:57.381104: step 580, loss 2.23812, acc 0.3125\n",
      "2017-04-03T19:17:57.594604: step 581, loss 2.06243, acc 0.296875\n",
      "2017-04-03T19:17:57.796467: step 582, loss 2.14251, acc 0.265625\n",
      "2017-04-03T19:17:58.012783: step 583, loss 2.05017, acc 0.265625\n",
      "2017-04-03T19:17:58.218369: step 584, loss 2.15258, acc 0.21875\n",
      "2017-04-03T19:17:58.427241: step 585, loss 1.91854, acc 0.25\n",
      "2017-04-03T19:17:58.632761: step 586, loss 2.23685, acc 0.234375\n",
      "2017-04-03T19:17:58.836313: step 587, loss 2.47259, acc 0.265625\n",
      "2017-04-03T19:17:59.036357: step 588, loss 1.96937, acc 0.390625\n",
      "2017-04-03T19:17:59.246682: step 589, loss 2.3001, acc 0.265625\n",
      "2017-04-03T19:17:59.445821: step 590, loss 2.25346, acc 0.234375\n",
      "2017-04-03T19:17:59.650334: step 591, loss 2.07263, acc 0.296875\n",
      "2017-04-03T19:17:59.859444: step 592, loss 2.28591, acc 0.265625\n",
      "2017-04-03T19:18:00.083661: step 593, loss 2.10033, acc 0.28125\n",
      "2017-04-03T19:18:00.302050: step 594, loss 2.1411, acc 0.28125\n",
      "2017-04-03T19:18:00.507929: step 595, loss 2.03441, acc 0.21875\n",
      "2017-04-03T19:18:00.706283: step 596, loss 2.27489, acc 0.203125\n",
      "2017-04-03T19:18:00.916574: step 597, loss 1.99393, acc 0.25\n",
      "2017-04-03T19:18:01.118545: step 598, loss 1.73276, acc 0.4375\n",
      "2017-04-03T19:18:01.323247: step 599, loss 1.97425, acc 0.234375\n",
      "2017-04-03T19:18:01.532127: step 600, loss 1.87863, acc 0.3125\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:18:03.488420: step 600, loss 1.9568, acc 0.3\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-600\n",
      "\n",
      "2017-04-03T19:18:03.835493: step 601, loss 2.02219, acc 0.234375\n",
      "2017-04-03T19:18:04.036298: step 602, loss 2.03775, acc 0.296875\n",
      "2017-04-03T19:18:04.238202: step 603, loss 2.08835, acc 0.328125\n",
      "2017-04-03T19:18:04.443999: step 604, loss 2.19771, acc 0.296875\n",
      "2017-04-03T19:18:04.648254: step 605, loss 1.98744, acc 0.375\n",
      "2017-04-03T19:18:04.849663: step 606, loss 2.1602, acc 0.3125\n",
      "2017-04-03T19:18:05.054002: step 607, loss 2.04802, acc 0.296875\n",
      "2017-04-03T19:18:05.265656: step 608, loss 2.21312, acc 0.234375\n",
      "2017-04-03T19:18:05.470840: step 609, loss 2.16554, acc 0.25\n",
      "2017-04-03T19:18:05.676101: step 610, loss 2.00835, acc 0.28125\n",
      "2017-04-03T19:18:05.879025: step 611, loss 1.83675, acc 0.296875\n",
      "2017-04-03T19:18:06.082377: step 612, loss 2.24813, acc 0.1875\n",
      "2017-04-03T19:18:06.285632: step 613, loss 2.15625, acc 0.28125\n",
      "2017-04-03T19:18:06.490845: step 614, loss 2.01602, acc 0.28125\n",
      "2017-04-03T19:18:06.694031: step 615, loss 2.24504, acc 0.296875\n",
      "2017-04-03T19:18:06.893585: step 616, loss 2.10846, acc 0.296875\n",
      "2017-04-03T19:18:07.095761: step 617, loss 1.98505, acc 0.453125\n",
      "2017-04-03T19:18:07.288174: step 618, loss 2.09097, acc 0.234375\n",
      "2017-04-03T19:18:07.489743: step 619, loss 1.859, acc 0.265625\n",
      "2017-04-03T19:18:07.687944: step 620, loss 2.11168, acc 0.25\n",
      "2017-04-03T19:18:07.890844: step 621, loss 2.08314, acc 0.3125\n",
      "2017-04-03T19:18:08.086463: step 622, loss 1.90337, acc 0.375\n",
      "2017-04-03T19:18:08.287253: step 623, loss 1.97129, acc 0.28125\n",
      "2017-04-03T19:18:08.487124: step 624, loss 2.06054, acc 0.234375\n",
      "2017-04-03T19:18:08.685144: step 625, loss 2.01245, acc 0.296875\n",
      "2017-04-03T19:18:08.881750: step 626, loss 2.14603, acc 0.3125\n",
      "2017-04-03T19:18:09.088139: step 627, loss 2.10106, acc 0.234375\n",
      "2017-04-03T19:18:09.293563: step 628, loss 1.99518, acc 0.234375\n",
      "2017-04-03T19:18:09.498226: step 629, loss 2.21526, acc 0.28125\n",
      "2017-04-03T19:18:09.702292: step 630, loss 1.93159, acc 0.3125\n",
      "2017-04-03T19:18:09.901959: step 631, loss 2.0594, acc 0.21875\n",
      "2017-04-03T19:18:10.104941: step 632, loss 2.1911, acc 0.265625\n",
      "2017-04-03T19:18:10.301186: step 633, loss 2.17132, acc 0.34375\n",
      "2017-04-03T19:18:10.503334: step 634, loss 2.01408, acc 0.3125\n",
      "2017-04-03T19:18:10.705951: step 635, loss 1.981, acc 0.296875\n",
      "2017-04-03T19:18:10.902875: step 636, loss 1.81623, acc 0.375\n",
      "2017-04-03T19:18:11.105311: step 637, loss 2.05672, acc 0.34375\n",
      "2017-04-03T19:18:11.304189: step 638, loss 1.77098, acc 0.390625\n",
      "2017-04-03T19:18:11.508868: step 639, loss 2.27188, acc 0.28125\n",
      "2017-04-03T19:18:11.705881: step 640, loss 1.93558, acc 0.25\n",
      "2017-04-03T19:18:11.910635: step 641, loss 2.06645, acc 0.25\n",
      "2017-04-03T19:18:12.105595: step 642, loss 1.85831, acc 0.296875\n",
      "2017-04-03T19:18:12.310383: step 643, loss 1.96027, acc 0.3125\n",
      "2017-04-03T19:18:12.513027: step 644, loss 1.86573, acc 0.328125\n",
      "2017-04-03T19:18:12.715881: step 645, loss 2.14741, acc 0.296875\n",
      "2017-04-03T19:18:12.918106: step 646, loss 1.86697, acc 0.40625\n",
      "2017-04-03T19:18:13.120578: step 647, loss 1.95493, acc 0.265625\n",
      "2017-04-03T19:18:13.322314: step 648, loss 1.8158, acc 0.296875\n",
      "2017-04-03T19:18:13.527217: step 649, loss 1.91821, acc 0.3125\n",
      "2017-04-03T19:18:13.731426: step 650, loss 1.86366, acc 0.359375\n",
      "2017-04-03T19:18:13.932648: step 651, loss 2.05919, acc 0.28125\n",
      "2017-04-03T19:18:14.138279: step 652, loss 1.67618, acc 0.40625\n",
      "2017-04-03T19:18:14.341274: step 653, loss 2.02573, acc 0.28125\n",
      "2017-04-03T19:18:14.541332: step 654, loss 1.90706, acc 0.4375\n",
      "2017-04-03T19:18:14.742709: step 655, loss 1.96491, acc 0.296875\n",
      "2017-04-03T19:18:14.946132: step 656, loss 2.08927, acc 0.265625\n",
      "2017-04-03T19:18:15.144554: step 657, loss 1.90976, acc 0.390625\n",
      "2017-04-03T19:18:15.347847: step 658, loss 1.89636, acc 0.28125\n",
      "2017-04-03T19:18:15.544908: step 659, loss 2.08661, acc 0.28125\n",
      "2017-04-03T19:18:15.750164: step 660, loss 2.19263, acc 0.25\n",
      "2017-04-03T19:18:15.947779: step 661, loss 2.14378, acc 0.1875\n",
      "2017-04-03T19:18:16.150182: step 662, loss 2.1077, acc 0.28125\n",
      "2017-04-03T19:18:16.345177: step 663, loss 2.09617, acc 0.296875\n",
      "2017-04-03T19:18:16.551995: step 664, loss 2.2125, acc 0.3125\n",
      "2017-04-03T19:18:16.746117: step 665, loss 2.21205, acc 0.109375\n",
      "2017-04-03T19:18:16.950449: step 666, loss 2.00612, acc 0.28125\n",
      "2017-04-03T19:18:17.147040: step 667, loss 2.07668, acc 0.265625\n",
      "2017-04-03T19:18:17.350691: step 668, loss 2.06329, acc 0.21875\n",
      "2017-04-03T19:18:17.547716: step 669, loss 1.98543, acc 0.359375\n",
      "2017-04-03T19:18:17.751706: step 670, loss 1.9855, acc 0.234375\n",
      "2017-04-03T19:18:17.948663: step 671, loss 1.92199, acc 0.390625\n",
      "2017-04-03T19:18:18.150034: step 672, loss 2.28662, acc 0.171875\n",
      "2017-04-03T19:18:18.346495: step 673, loss 1.8732, acc 0.3125\n",
      "2017-04-03T19:18:18.549626: step 674, loss 2.06233, acc 0.3125\n",
      "2017-04-03T19:18:18.744702: step 675, loss 1.92794, acc 0.328125\n",
      "2017-04-03T19:18:18.950848: step 676, loss 2.00467, acc 0.34375\n",
      "2017-04-03T19:18:19.155054: step 677, loss 2.20689, acc 0.21875\n",
      "2017-04-03T19:18:19.356802: step 678, loss 2.0425, acc 0.296875\n",
      "2017-04-03T19:18:19.557458: step 679, loss 1.90622, acc 0.25\n",
      "2017-04-03T19:18:19.759378: step 680, loss 1.92526, acc 0.25\n",
      "2017-04-03T19:18:19.962288: step 681, loss 2.05515, acc 0.28125\n",
      "2017-04-03T19:18:20.165921: step 682, loss 2.08627, acc 0.3125\n",
      "2017-04-03T19:18:20.374174: step 683, loss 1.92074, acc 0.3125\n",
      "2017-04-03T19:18:20.570889: step 684, loss 1.90944, acc 0.375\n",
      "2017-04-03T19:18:20.773059: step 685, loss 2.15421, acc 0.25\n",
      "2017-04-03T19:18:20.968642: step 686, loss 2.05898, acc 0.25\n",
      "2017-04-03T19:18:21.172867: step 687, loss 2.09506, acc 0.171875\n",
      "2017-04-03T19:18:21.369211: step 688, loss 1.86712, acc 0.328125\n",
      "2017-04-03T19:18:21.573253: step 689, loss 2.09046, acc 0.296875\n",
      "2017-04-03T19:18:21.771025: step 690, loss 2.07426, acc 0.328125\n",
      "2017-04-03T19:18:21.973053: step 691, loss 2.04174, acc 0.25\n",
      "2017-04-03T19:18:22.166157: step 692, loss 2.09661, acc 0.234375\n",
      "2017-04-03T19:18:22.368978: step 693, loss 2.07032, acc 0.296875\n",
      "2017-04-03T19:18:22.567821: step 694, loss 1.86965, acc 0.328125\n",
      "2017-04-03T19:18:22.773760: step 695, loss 1.98287, acc 0.328125\n",
      "2017-04-03T19:18:22.973533: step 696, loss 2.11512, acc 0.171875\n",
      "2017-04-03T19:18:23.173317: step 697, loss 2.02477, acc 0.25\n",
      "2017-04-03T19:18:23.370492: step 698, loss 1.98459, acc 0.3125\n",
      "2017-04-03T19:18:23.578292: step 699, loss 1.93756, acc 0.390625\n",
      "2017-04-03T19:18:23.782063: step 700, loss 1.96972, acc 0.28125\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:18:25.800580: step 700, loss 1.94047, acc 0.29\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-700\n",
      "\n",
      "2017-04-03T19:18:26.157182: step 701, loss 1.94675, acc 0.296875\n",
      "2017-04-03T19:18:26.358631: step 702, loss 1.85873, acc 0.34375\n",
      "2017-04-03T19:18:26.572127: step 703, loss 2.34165, acc 0.15625\n",
      "2017-04-03T19:18:26.776774: step 704, loss 2.07177, acc 0.28125\n",
      "2017-04-03T19:18:26.977759: step 705, loss 2.18139, acc 0.3125\n",
      "2017-04-03T19:18:27.194253: step 706, loss 2.02754, acc 0.28125\n",
      "2017-04-03T19:18:27.396754: step 707, loss 2.10322, acc 0.265625\n",
      "2017-04-03T19:18:27.609379: step 708, loss 2.19094, acc 0.296875\n",
      "2017-04-03T19:18:27.811628: step 709, loss 2.01907, acc 0.328125\n",
      "2017-04-03T19:18:28.009859: step 710, loss 2.33975, acc 0.234375\n",
      "2017-04-03T19:18:28.212541: step 711, loss 2.10048, acc 0.234375\n",
      "2017-04-03T19:18:28.414552: step 712, loss 1.90945, acc 0.34375\n",
      "2017-04-03T19:18:28.616173: step 713, loss 1.96398, acc 0.34375\n",
      "2017-04-03T19:18:28.825006: step 714, loss 2.13168, acc 0.265625\n",
      "2017-04-03T19:18:29.031991: step 715, loss 1.9347, acc 0.421875\n",
      "2017-04-03T19:18:29.235583: step 716, loss 2.20873, acc 0.25\n",
      "2017-04-03T19:18:29.439351: step 717, loss 2.05983, acc 0.296875\n",
      "2017-04-03T19:18:29.641458: step 718, loss 2.08455, acc 0.296875\n",
      "2017-04-03T19:18:29.860806: step 719, loss 2.0321, acc 0.265625\n",
      "2017-04-03T19:18:30.058868: step 720, loss 2.15543, acc 0.28125\n",
      "2017-04-03T19:18:30.262880: step 721, loss 1.96489, acc 0.3125\n",
      "2017-04-03T19:18:30.460037: step 722, loss 2.29613, acc 0.234375\n",
      "2017-04-03T19:18:30.666019: step 723, loss 2.0378, acc 0.359375\n",
      "2017-04-03T19:18:30.861500: step 724, loss 1.9852, acc 0.34375\n",
      "2017-04-03T19:18:31.072908: step 725, loss 1.82875, acc 0.234375\n",
      "2017-04-03T19:18:31.273655: step 726, loss 1.75566, acc 0.359375\n",
      "2017-04-03T19:18:31.480908: step 727, loss 2.09011, acc 0.21875\n",
      "2017-04-03T19:18:31.678115: step 728, loss 1.89962, acc 0.265625\n",
      "2017-04-03T19:18:31.876662: step 729, loss 2.27219, acc 0.265625\n",
      "2017-04-03T19:18:32.074978: step 730, loss 2.07389, acc 0.296875\n",
      "2017-04-03T19:18:32.274758: step 731, loss 2.03449, acc 0.34375\n",
      "2017-04-03T19:18:32.469809: step 732, loss 2.08641, acc 0.25\n",
      "2017-04-03T19:18:32.672131: step 733, loss 2.58621, acc 0.1875\n",
      "2017-04-03T19:18:32.867843: step 734, loss 1.77928, acc 0.328125\n",
      "2017-04-03T19:18:33.070489: step 735, loss 1.89625, acc 0.375\n",
      "2017-04-03T19:18:33.269669: step 736, loss 2.13096, acc 0.328125\n",
      "2017-04-03T19:18:33.475629: step 737, loss 2.10348, acc 0.296875\n",
      "2017-04-03T19:18:33.671367: step 738, loss 1.82972, acc 0.3125\n",
      "2017-04-03T19:18:33.876093: step 739, loss 2.00424, acc 0.21875\n",
      "2017-04-03T19:18:34.071236: step 740, loss 1.96837, acc 0.34375\n",
      "2017-04-03T19:18:34.278864: step 741, loss 1.97998, acc 0.296875\n",
      "2017-04-03T19:18:34.484294: step 742, loss 1.84507, acc 0.28125\n",
      "2017-04-03T19:18:34.685950: step 743, loss 1.81962, acc 0.296875\n",
      "2017-04-03T19:18:34.891988: step 744, loss 1.93679, acc 0.359375\n",
      "2017-04-03T19:18:35.098339: step 745, loss 1.89452, acc 0.265625\n",
      "2017-04-03T19:18:35.307970: step 746, loss 1.93928, acc 0.296875\n",
      "2017-04-03T19:18:35.521539: step 747, loss 2.00272, acc 0.296875\n",
      "2017-04-03T19:18:35.728324: step 748, loss 1.79985, acc 0.3125\n",
      "2017-04-03T19:18:35.935897: step 749, loss 2.28401, acc 0.1875\n",
      "2017-04-03T19:18:36.141539: step 750, loss 1.99947, acc 0.265625\n",
      "2017-04-03T19:18:36.356719: step 751, loss 1.78187, acc 0.421875\n",
      "2017-04-03T19:18:36.569293: step 752, loss 2.0926, acc 0.21875\n",
      "2017-04-03T19:18:36.765912: step 753, loss 1.84627, acc 0.34375\n",
      "2017-04-03T19:18:36.968489: step 754, loss 2.17089, acc 0.1875\n",
      "2017-04-03T19:18:37.178359: step 755, loss 2.01559, acc 0.3125\n",
      "2017-04-03T19:18:37.379848: step 756, loss 1.95747, acc 0.296875\n",
      "2017-04-03T19:18:37.579447: step 757, loss 2.09907, acc 0.234375\n",
      "2017-04-03T19:18:37.784632: step 758, loss 2.03539, acc 0.359375\n",
      "2017-04-03T19:18:37.978826: step 759, loss 2.01717, acc 0.21875\n",
      "2017-04-03T19:18:38.175954: step 760, loss 1.93595, acc 0.28125\n",
      "2017-04-03T19:18:38.369471: step 761, loss 1.98583, acc 0.3125\n",
      "2017-04-03T19:18:38.569104: step 762, loss 2.03553, acc 0.265625\n",
      "2017-04-03T19:18:38.766714: step 763, loss 1.85651, acc 0.28125\n",
      "2017-04-03T19:18:38.966720: step 764, loss 1.91928, acc 0.328125\n",
      "2017-04-03T19:18:39.161115: step 765, loss 1.90699, acc 0.234375\n",
      "2017-04-03T19:18:39.359710: step 766, loss 2.03113, acc 0.3125\n",
      "2017-04-03T19:18:39.557563: step 767, loss 1.83758, acc 0.3125\n",
      "2017-04-03T19:18:39.757517: step 768, loss 2.03568, acc 0.25\n",
      "2017-04-03T19:18:39.955058: step 769, loss 2.03301, acc 0.34375\n",
      "2017-04-03T19:18:40.157210: step 770, loss 1.93517, acc 0.265625\n",
      "2017-04-03T19:18:40.351477: step 771, loss 2.06195, acc 0.375\n",
      "2017-04-03T19:18:40.556840: step 772, loss 2.02332, acc 0.25\n",
      "2017-04-03T19:18:40.752188: step 773, loss 2.10849, acc 0.265625\n",
      "2017-04-03T19:18:40.955856: step 774, loss 2.152, acc 0.296875\n",
      "2017-04-03T19:18:41.154454: step 775, loss 1.93173, acc 0.296875\n",
      "2017-04-03T19:18:41.358757: step 776, loss 1.96026, acc 0.3125\n",
      "2017-04-03T19:18:41.555719: step 777, loss 1.98271, acc 0.328125\n",
      "2017-04-03T19:18:41.758216: step 778, loss 1.70329, acc 0.4375\n",
      "2017-04-03T19:18:41.950565: step 779, loss 2.17942, acc 0.203125\n",
      "2017-04-03T19:18:42.151081: step 780, loss 1.90582, acc 0.3125\n",
      "2017-04-03T19:18:42.344979: step 781, loss 2.41036, acc 0.25\n",
      "2017-04-03T19:18:42.545536: step 782, loss 2.04101, acc 0.296875\n",
      "2017-04-03T19:18:42.746525: step 783, loss 2.15804, acc 0.234375\n",
      "2017-04-03T19:18:42.946879: step 784, loss 2.04098, acc 0.28125\n",
      "2017-04-03T19:18:43.151705: step 785, loss 1.94309, acc 0.3125\n",
      "2017-04-03T19:18:43.344104: step 786, loss 1.91575, acc 0.34375\n",
      "2017-04-03T19:18:43.547905: step 787, loss 2.1544, acc 0.203125\n",
      "2017-04-03T19:18:43.740400: step 788, loss 1.79497, acc 0.265625\n",
      "2017-04-03T19:18:43.940972: step 789, loss 2.00929, acc 0.3125\n",
      "2017-04-03T19:18:44.134586: step 790, loss 2.23975, acc 0.203125\n",
      "2017-04-03T19:18:44.338271: step 791, loss 2.12178, acc 0.234375\n",
      "2017-04-03T19:18:44.533629: step 792, loss 2.2419, acc 0.28125\n",
      "2017-04-03T19:18:44.733738: step 793, loss 1.92691, acc 0.40625\n",
      "2017-04-03T19:18:44.929445: step 794, loss 2.09411, acc 0.25\n",
      "2017-04-03T19:18:45.127659: step 795, loss 2.10836, acc 0.21875\n",
      "2017-04-03T19:18:45.320853: step 796, loss 2.1485, acc 0.140625\n",
      "2017-04-03T19:18:45.523599: step 797, loss 1.81424, acc 0.34375\n",
      "2017-04-03T19:18:45.718697: step 798, loss 1.90736, acc 0.25\n",
      "2017-04-03T19:18:45.921510: step 799, loss 1.8121, acc 0.28125\n",
      "2017-04-03T19:18:46.115614: step 800, loss 2.00428, acc 0.28125\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:18:48.041691: step 800, loss 1.91785, acc 0.3\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-800\n",
      "\n",
      "2017-04-03T19:18:48.381208: step 801, loss 1.79559, acc 0.375\n",
      "2017-04-03T19:18:48.579803: step 802, loss 2.12269, acc 0.1875\n",
      "2017-04-03T19:18:48.777794: step 803, loss 1.9853, acc 0.265625\n",
      "2017-04-03T19:18:48.969557: step 804, loss 2.08719, acc 0.28125\n",
      "2017-04-03T19:18:49.167843: step 805, loss 1.96539, acc 0.203125\n",
      "2017-04-03T19:18:49.361594: step 806, loss 1.9305, acc 0.25\n",
      "2017-04-03T19:18:49.571538: step 807, loss 1.87942, acc 0.375\n",
      "2017-04-03T19:18:49.768213: step 808, loss 1.98378, acc 0.296875\n",
      "2017-04-03T19:18:49.965309: step 809, loss 1.78373, acc 0.34375\n",
      "2017-04-03T19:18:50.154298: step 810, loss 1.77463, acc 0.328125\n",
      "2017-04-03T19:18:50.353466: step 811, loss 2.05976, acc 0.234375\n",
      "2017-04-03T19:18:50.550468: step 812, loss 1.92753, acc 0.296875\n",
      "2017-04-03T19:18:50.749454: step 813, loss 2.01737, acc 0.328125\n",
      "2017-04-03T19:18:50.948118: step 814, loss 2.07932, acc 0.234375\n",
      "2017-04-03T19:18:51.152599: step 815, loss 1.99077, acc 0.328125\n",
      "2017-04-03T19:18:51.348655: step 816, loss 1.97953, acc 0.265625\n",
      "2017-04-03T19:18:51.545166: step 817, loss 1.83674, acc 0.3125\n",
      "2017-04-03T19:18:51.740606: step 818, loss 1.80557, acc 0.359375\n",
      "2017-04-03T19:18:51.942797: step 819, loss 1.96762, acc 0.296875\n",
      "2017-04-03T19:18:52.139617: step 820, loss 1.68275, acc 0.4375\n",
      "2017-04-03T19:18:52.341898: step 821, loss 1.72568, acc 0.359375\n",
      "2017-04-03T19:18:52.540579: step 822, loss 1.93099, acc 0.328125\n",
      "2017-04-03T19:18:52.737674: step 823, loss 2.09392, acc 0.21875\n",
      "2017-04-03T19:18:52.936852: step 824, loss 2.23694, acc 0.21875\n",
      "2017-04-03T19:18:53.134765: step 825, loss 2.13859, acc 0.265625\n",
      "2017-04-03T19:18:53.329267: step 826, loss 1.9795, acc 0.3125\n",
      "2017-04-03T19:18:53.530680: step 827, loss 1.77691, acc 0.453125\n",
      "2017-04-03T19:18:53.725319: step 828, loss 2.12298, acc 0.25\n",
      "2017-04-03T19:18:53.921326: step 829, loss 2.21155, acc 0.265625\n",
      "2017-04-03T19:18:54.114112: step 830, loss 1.96568, acc 0.296875\n",
      "2017-04-03T19:18:54.311608: step 831, loss 1.9384, acc 0.328125\n",
      "2017-04-03T19:18:54.507328: step 832, loss 1.80016, acc 0.359375\n",
      "2017-04-03T19:18:54.710170: step 833, loss 1.88842, acc 0.328125\n",
      "2017-04-03T19:18:54.908158: step 834, loss 1.95677, acc 0.234375\n",
      "2017-04-03T19:18:55.107133: step 835, loss 1.90784, acc 0.34375\n",
      "2017-04-03T19:18:55.303903: step 836, loss 1.89006, acc 0.359375\n",
      "2017-04-03T19:18:55.504700: step 837, loss 1.85515, acc 0.328125\n",
      "2017-04-03T19:18:55.697793: step 838, loss 2.08195, acc 0.28125\n",
      "2017-04-03T19:18:55.897052: step 839, loss 1.96113, acc 0.21875\n",
      "2017-04-03T19:18:56.093015: step 840, loss 1.93365, acc 0.359375\n",
      "2017-04-03T19:18:56.293677: step 841, loss 1.95967, acc 0.359375\n",
      "2017-04-03T19:18:56.489623: step 842, loss 2.15615, acc 0.1875\n",
      "2017-04-03T19:18:56.690663: step 843, loss 1.89749, acc 0.296875\n",
      "2017-04-03T19:18:56.884555: step 844, loss 2.09579, acc 0.34375\n",
      "2017-04-03T19:18:57.084641: step 845, loss 1.90597, acc 0.390625\n",
      "2017-04-03T19:18:57.281232: step 846, loss 1.89149, acc 0.375\n",
      "2017-04-03T19:18:57.479660: step 847, loss 1.9817, acc 0.28125\n",
      "2017-04-03T19:18:57.676877: step 848, loss 1.89379, acc 0.375\n",
      "2017-04-03T19:18:57.876469: step 849, loss 2.25021, acc 0.265625\n",
      "2017-04-03T19:18:58.070509: step 850, loss 1.76575, acc 0.390625\n",
      "2017-04-03T19:18:58.269952: step 851, loss 2.05244, acc 0.234375\n",
      "2017-04-03T19:18:58.464323: step 852, loss 1.91943, acc 0.359375\n",
      "2017-04-03T19:18:58.662020: step 853, loss 1.94683, acc 0.28125\n",
      "2017-04-03T19:18:58.858614: step 854, loss 2.21221, acc 0.25\n",
      "2017-04-03T19:18:59.059799: step 855, loss 2.20155, acc 0.25\n",
      "2017-04-03T19:18:59.255925: step 856, loss 2.06472, acc 0.296875\n",
      "2017-04-03T19:18:59.455913: step 857, loss 2.10818, acc 0.203125\n",
      "2017-04-03T19:18:59.651374: step 858, loss 1.84574, acc 0.296875\n",
      "2017-04-03T19:18:59.848163: step 859, loss 1.76367, acc 0.375\n",
      "2017-04-03T19:19:00.044262: step 860, loss 1.90394, acc 0.21875\n",
      "2017-04-03T19:19:00.247204: step 861, loss 2.05605, acc 0.203125\n",
      "2017-04-03T19:19:00.437613: step 862, loss 1.96504, acc 0.1875\n",
      "2017-04-03T19:19:00.635618: step 863, loss 1.90884, acc 0.328125\n",
      "2017-04-03T19:19:00.832290: step 864, loss 1.95426, acc 0.3125\n",
      "2017-04-03T19:19:01.032051: step 865, loss 1.80277, acc 0.359375\n",
      "2017-04-03T19:19:01.226943: step 866, loss 1.86275, acc 0.21875\n",
      "2017-04-03T19:19:01.426912: step 867, loss 1.90235, acc 0.234375\n",
      "2017-04-03T19:19:01.622418: step 868, loss 1.82533, acc 0.3125\n",
      "2017-04-03T19:19:01.827247: step 869, loss 2.24508, acc 0.15625\n",
      "2017-04-03T19:19:02.022004: step 870, loss 2.10727, acc 0.328125\n",
      "2017-04-03T19:19:02.226592: step 871, loss 2.17713, acc 0.25\n",
      "2017-04-03T19:19:02.420439: step 872, loss 1.9868, acc 0.1875\n",
      "2017-04-03T19:19:02.619222: step 873, loss 1.96527, acc 0.3125\n",
      "2017-04-03T19:19:02.815323: step 874, loss 2.14072, acc 0.296875\n",
      "2017-04-03T19:19:03.017024: step 875, loss 2.17603, acc 0.296875\n",
      "2017-04-03T19:19:03.211210: step 876, loss 1.93059, acc 0.296875\n",
      "2017-04-03T19:19:03.408628: step 877, loss 2.22035, acc 0.1875\n",
      "2017-04-03T19:19:03.603206: step 878, loss 1.80841, acc 0.359375\n",
      "2017-04-03T19:19:03.804973: step 879, loss 2.09451, acc 0.3125\n",
      "2017-04-03T19:19:04.002208: step 880, loss 2.20224, acc 0.203125\n",
      "2017-04-03T19:19:04.202164: step 881, loss 2.28645, acc 0.21875\n",
      "2017-04-03T19:19:04.396710: step 882, loss 2.07446, acc 0.328125\n",
      "2017-04-03T19:19:04.596283: step 883, loss 2.12107, acc 0.25\n",
      "2017-04-03T19:19:04.793185: step 884, loss 1.9666, acc 0.328125\n",
      "2017-04-03T19:19:04.995114: step 885, loss 2.04628, acc 0.265625\n",
      "2017-04-03T19:19:05.190464: step 886, loss 2.0604, acc 0.265625\n",
      "2017-04-03T19:19:05.394330: step 887, loss 1.95995, acc 0.296875\n",
      "2017-04-03T19:19:05.590065: step 888, loss 1.93362, acc 0.265625\n",
      "2017-04-03T19:19:05.791280: step 889, loss 1.91105, acc 0.34375\n",
      "2017-04-03T19:19:05.986999: step 890, loss 1.91008, acc 0.296875\n",
      "2017-04-03T19:19:06.189672: step 891, loss 2.0135, acc 0.3125\n",
      "2017-04-03T19:19:06.388590: step 892, loss 1.96794, acc 0.21875\n",
      "2017-04-03T19:19:06.591840: step 893, loss 1.77865, acc 0.375\n",
      "2017-04-03T19:19:06.786756: step 894, loss 1.84577, acc 0.328125\n",
      "2017-04-03T19:19:06.985139: step 895, loss 2.21566, acc 0.265625\n",
      "2017-04-03T19:19:07.180881: step 896, loss 1.7723, acc 0.375\n",
      "2017-04-03T19:19:07.382435: step 897, loss 1.9537, acc 0.21875\n",
      "2017-04-03T19:19:07.581324: step 898, loss 1.95147, acc 0.40625\n",
      "2017-04-03T19:19:07.783511: step 899, loss 1.93995, acc 0.25\n",
      "2017-04-03T19:19:07.976641: step 900, loss 2.12463, acc 0.34375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:19:09.907149: step 900, loss 1.93701, acc 0.314\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-900\n",
      "\n",
      "2017-04-03T19:19:10.240855: step 901, loss 1.94661, acc 0.328125\n",
      "2017-04-03T19:19:10.436749: step 902, loss 2.07373, acc 0.28125\n",
      "2017-04-03T19:19:10.644829: step 903, loss 1.86513, acc 0.328125\n",
      "2017-04-03T19:19:10.838871: step 904, loss 2.15221, acc 0.1875\n",
      "2017-04-03T19:19:11.036711: step 905, loss 2.28911, acc 0.234375\n",
      "2017-04-03T19:19:11.228809: step 906, loss 1.97056, acc 0.203125\n",
      "2017-04-03T19:19:11.435388: step 907, loss 2.01607, acc 0.34375\n",
      "2017-04-03T19:19:11.628958: step 908, loss 1.89304, acc 0.375\n",
      "2017-04-03T19:19:11.826599: step 909, loss 1.85522, acc 0.34375\n",
      "2017-04-03T19:19:12.020012: step 910, loss 2.06115, acc 0.25\n",
      "2017-04-03T19:19:12.221286: step 911, loss 1.88406, acc 0.34375\n",
      "2017-04-03T19:19:12.416812: step 912, loss 1.95981, acc 0.25\n",
      "2017-04-03T19:19:12.632768: step 913, loss 2.0865, acc 0.265625\n",
      "2017-04-03T19:19:12.828649: step 914, loss 1.974, acc 0.3125\n",
      "2017-04-03T19:19:13.028852: step 915, loss 1.98389, acc 0.25\n",
      "2017-04-03T19:19:13.226887: step 916, loss 1.8904, acc 0.3125\n",
      "2017-04-03T19:19:13.429709: step 917, loss 1.83836, acc 0.28125\n",
      "2017-04-03T19:19:13.630197: step 918, loss 1.83429, acc 0.28125\n",
      "2017-04-03T19:19:13.831976: step 919, loss 1.97171, acc 0.328125\n",
      "2017-04-03T19:19:14.029385: step 920, loss 1.93978, acc 0.265625\n",
      "2017-04-03T19:19:14.229893: step 921, loss 1.70432, acc 0.328125\n",
      "2017-04-03T19:19:14.421668: step 922, loss 1.94131, acc 0.3125\n",
      "2017-04-03T19:19:14.623713: step 923, loss 1.94525, acc 0.3125\n",
      "2017-04-03T19:19:14.817257: step 924, loss 1.88527, acc 0.390625\n",
      "2017-04-03T19:19:15.020997: step 925, loss 1.89481, acc 0.234375\n",
      "2017-04-03T19:19:15.215773: step 926, loss 1.66471, acc 0.34375\n",
      "2017-04-03T19:19:15.416998: step 927, loss 1.89395, acc 0.3125\n",
      "2017-04-03T19:19:15.612105: step 928, loss 2.01573, acc 0.265625\n",
      "2017-04-03T19:19:15.813072: step 929, loss 2.12529, acc 0.328125\n",
      "2017-04-03T19:19:16.007131: step 930, loss 1.99451, acc 0.25\n",
      "2017-04-03T19:19:16.205136: step 931, loss 1.87748, acc 0.34375\n",
      "2017-04-03T19:19:16.396988: step 932, loss 2.08689, acc 0.171875\n",
      "2017-04-03T19:19:16.595415: step 933, loss 2.10446, acc 0.28125\n",
      "2017-04-03T19:19:16.792834: step 934, loss 2.04407, acc 0.296875\n",
      "2017-04-03T19:19:16.992337: step 935, loss 1.94384, acc 0.3125\n",
      "2017-04-03T19:19:17.186842: step 936, loss 1.92489, acc 0.296875\n",
      "2017-04-03T19:19:17.391607: step 937, loss 1.97061, acc 0.390625\n",
      "2017-04-03T19:19:17.585992: step 938, loss 1.79821, acc 0.28125\n",
      "2017-04-03T19:19:17.785425: step 939, loss 2.23222, acc 0.265625\n",
      "2017-04-03T19:19:17.981625: step 940, loss 1.94211, acc 0.328125\n",
      "2017-04-03T19:19:18.182640: step 941, loss 2.07022, acc 0.296875\n",
      "2017-04-03T19:19:18.378353: step 942, loss 1.81621, acc 0.421875\n",
      "2017-04-03T19:19:18.578297: step 943, loss 1.94277, acc 0.3125\n",
      "2017-04-03T19:19:18.770163: step 944, loss 1.88389, acc 0.296875\n",
      "2017-04-03T19:19:18.968200: step 945, loss 1.87452, acc 0.390625\n",
      "2017-04-03T19:19:19.157853: step 946, loss 1.86351, acc 0.296875\n",
      "2017-04-03T19:19:19.358277: step 947, loss 1.94649, acc 0.265625\n",
      "2017-04-03T19:19:19.553414: step 948, loss 1.91609, acc 0.296875\n",
      "2017-04-03T19:19:19.751241: step 949, loss 1.84851, acc 0.28125\n",
      "2017-04-03T19:19:19.948465: step 950, loss 1.80735, acc 0.359375\n",
      "2017-04-03T19:19:20.146324: step 951, loss 1.75579, acc 0.359375\n",
      "2017-04-03T19:19:20.342092: step 952, loss 1.91492, acc 0.296875\n",
      "2017-04-03T19:19:20.540446: step 953, loss 1.86745, acc 0.25\n",
      "2017-04-03T19:19:20.732474: step 954, loss 1.92601, acc 0.375\n",
      "2017-04-03T19:19:20.932098: step 955, loss 1.8928, acc 0.296875\n",
      "2017-04-03T19:19:21.128841: step 956, loss 1.7656, acc 0.359375\n",
      "2017-04-03T19:19:21.325034: step 957, loss 1.87549, acc 0.3125\n",
      "2017-04-03T19:19:21.517814: step 958, loss 2.02414, acc 0.25\n",
      "2017-04-03T19:19:21.719414: step 959, loss 2.00937, acc 0.296875\n",
      "2017-04-03T19:19:21.916330: step 960, loss 1.80065, acc 0.359375\n",
      "2017-04-03T19:19:22.117198: step 961, loss 2.07483, acc 0.21875\n",
      "2017-04-03T19:19:22.313055: step 962, loss 1.67862, acc 0.421875\n",
      "2017-04-03T19:19:22.516602: step 963, loss 1.94054, acc 0.359375\n",
      "2017-04-03T19:19:22.712903: step 964, loss 1.92843, acc 0.203125\n",
      "2017-04-03T19:19:22.911330: step 965, loss 1.74354, acc 0.375\n",
      "2017-04-03T19:19:23.107860: step 966, loss 2.1695, acc 0.3125\n",
      "2017-04-03T19:19:23.310319: step 967, loss 2.18334, acc 0.25\n",
      "2017-04-03T19:19:23.505233: step 968, loss 2.08249, acc 0.296875\n",
      "2017-04-03T19:19:23.705398: step 969, loss 1.93353, acc 0.25\n",
      "2017-04-03T19:19:23.897523: step 970, loss 1.94094, acc 0.3125\n",
      "2017-04-03T19:19:24.098337: step 971, loss 1.96585, acc 0.296875\n",
      "2017-04-03T19:19:24.294731: step 972, loss 1.74108, acc 0.359375\n",
      "2017-04-03T19:19:24.494887: step 973, loss 1.94567, acc 0.234375\n",
      "2017-04-03T19:19:24.691786: step 974, loss 1.67273, acc 0.421875\n",
      "2017-04-03T19:19:24.893562: step 975, loss 1.82547, acc 0.328125\n",
      "2017-04-03T19:19:25.083459: step 976, loss 2.27838, acc 0.25\n",
      "2017-04-03T19:19:25.280940: step 977, loss 2.05535, acc 0.21875\n",
      "2017-04-03T19:19:25.476742: step 978, loss 2.23527, acc 0.28125\n",
      "2017-04-03T19:19:25.680664: step 979, loss 2.03095, acc 0.3125\n",
      "2017-04-03T19:19:25.875900: step 980, loss 2.03362, acc 0.265625\n",
      "2017-04-03T19:19:26.075786: step 981, loss 1.93381, acc 0.359375\n",
      "2017-04-03T19:19:26.272465: step 982, loss 1.73402, acc 0.375\n",
      "2017-04-03T19:19:26.472861: step 983, loss 2.18761, acc 0.265625\n",
      "2017-04-03T19:19:26.665691: step 984, loss 2.04017, acc 0.34375\n",
      "2017-04-03T19:19:26.865512: step 985, loss 1.86584, acc 0.328125\n",
      "2017-04-03T19:19:27.061866: step 986, loss 1.75032, acc 0.40625\n",
      "2017-04-03T19:19:27.263545: step 987, loss 1.91933, acc 0.296875\n",
      "2017-04-03T19:19:27.459222: step 988, loss 2.07024, acc 0.296875\n",
      "2017-04-03T19:19:27.659383: step 989, loss 2.17011, acc 0.140625\n",
      "2017-04-03T19:19:27.857100: step 990, loss 1.9098, acc 0.359375\n",
      "2017-04-03T19:19:28.057912: step 991, loss 1.9894, acc 0.296875\n",
      "2017-04-03T19:19:28.256657: step 992, loss 1.67476, acc 0.421875\n",
      "2017-04-03T19:19:28.458290: step 993, loss 2.04163, acc 0.296875\n",
      "2017-04-03T19:19:28.655947: step 994, loss 1.83398, acc 0.296875\n",
      "2017-04-03T19:19:28.860328: step 995, loss 2.02409, acc 0.234375\n",
      "2017-04-03T19:19:29.055046: step 996, loss 2.07196, acc 0.28125\n",
      "2017-04-03T19:19:29.253989: step 997, loss 2.05458, acc 0.140625\n",
      "2017-04-03T19:19:29.445869: step 998, loss 1.74075, acc 0.421875\n",
      "2017-04-03T19:19:29.645098: step 999, loss 2.00014, acc 0.296875\n",
      "2017-04-03T19:19:29.840855: step 1000, loss 1.92529, acc 0.34375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:19:31.799775: step 1000, loss 1.90448, acc 0.312\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-1000\n",
      "\n",
      "2017-04-03T19:19:32.140730: step 1001, loss 2.15694, acc 0.34375\n",
      "2017-04-03T19:19:32.333835: step 1002, loss 1.96711, acc 0.234375\n",
      "2017-04-03T19:19:32.536796: step 1003, loss 1.81392, acc 0.34375\n",
      "2017-04-03T19:19:32.730992: step 1004, loss 1.86285, acc 0.328125\n",
      "2017-04-03T19:19:32.930589: step 1005, loss 2.1034, acc 0.3125\n",
      "2017-04-03T19:19:33.123828: step 1006, loss 1.89028, acc 0.296875\n",
      "2017-04-03T19:19:33.325431: step 1007, loss 1.8554, acc 0.34375\n",
      "2017-04-03T19:19:33.524953: step 1008, loss 1.8805, acc 0.359375\n",
      "2017-04-03T19:19:33.727091: step 1009, loss 2.01679, acc 0.25\n",
      "2017-04-03T19:19:33.922891: step 1010, loss 1.68258, acc 0.4375\n",
      "2017-04-03T19:19:34.122927: step 1011, loss 2.17068, acc 0.265625\n",
      "2017-04-03T19:19:34.321121: step 1012, loss 1.98266, acc 0.21875\n",
      "2017-04-03T19:19:34.522900: step 1013, loss 1.94936, acc 0.34375\n",
      "2017-04-03T19:19:34.716183: step 1014, loss 1.90074, acc 0.296875\n",
      "2017-04-03T19:19:34.920067: step 1015, loss 2.11938, acc 0.296875\n",
      "2017-04-03T19:19:35.120326: step 1016, loss 2.18309, acc 0.21875\n",
      "2017-04-03T19:19:35.320814: step 1017, loss 1.82869, acc 0.296875\n",
      "2017-04-03T19:19:35.522346: step 1018, loss 2.01104, acc 0.203125\n",
      "2017-04-03T19:19:35.723976: step 1019, loss 2.01654, acc 0.265625\n",
      "2017-04-03T19:19:35.928533: step 1020, loss 1.71702, acc 0.3125\n",
      "2017-04-03T19:19:36.132098: step 1021, loss 1.89473, acc 0.3125\n",
      "2017-04-03T19:19:36.334392: step 1022, loss 1.8946, acc 0.328125\n",
      "2017-04-03T19:19:36.532737: step 1023, loss 2.01765, acc 0.265625\n",
      "2017-04-03T19:19:36.739371: step 1024, loss 2.07361, acc 0.21875\n",
      "2017-04-03T19:19:36.934648: step 1025, loss 1.96864, acc 0.296875\n",
      "2017-04-03T19:19:37.137856: step 1026, loss 1.9196, acc 0.3125\n",
      "2017-04-03T19:19:37.330687: step 1027, loss 2.028, acc 0.1875\n",
      "2017-04-03T19:19:37.532967: step 1028, loss 1.99995, acc 0.25\n",
      "2017-04-03T19:19:37.725569: step 1029, loss 2.00823, acc 0.265625\n",
      "2017-04-03T19:19:37.927101: step 1030, loss 1.86504, acc 0.375\n",
      "2017-04-03T19:19:38.125197: step 1031, loss 1.81557, acc 0.359375\n",
      "2017-04-03T19:19:38.325247: step 1032, loss 1.84492, acc 0.28125\n",
      "2017-04-03T19:19:38.519367: step 1033, loss 1.9751, acc 0.296875\n",
      "2017-04-03T19:19:38.720042: step 1034, loss 2.10077, acc 0.21875\n",
      "2017-04-03T19:19:38.917242: step 1035, loss 1.88491, acc 0.28125\n",
      "2017-04-03T19:19:39.116982: step 1036, loss 1.92159, acc 0.359375\n",
      "2017-04-03T19:19:39.309504: step 1037, loss 2.0997, acc 0.3125\n",
      "2017-04-03T19:19:39.509777: step 1038, loss 1.97768, acc 0.3125\n",
      "2017-04-03T19:19:39.709449: step 1039, loss 1.82957, acc 0.390625\n",
      "2017-04-03T19:19:39.913393: step 1040, loss 1.90862, acc 0.3125\n",
      "2017-04-03T19:19:40.112378: step 1041, loss 2.10353, acc 0.296875\n",
      "2017-04-03T19:19:40.313754: step 1042, loss 1.7409, acc 0.328125\n",
      "2017-04-03T19:19:40.512868: step 1043, loss 2.00068, acc 0.34375\n",
      "2017-04-03T19:19:40.711641: step 1044, loss 1.83638, acc 0.359375\n",
      "2017-04-03T19:19:40.910162: step 1045, loss 1.91292, acc 0.328125\n",
      "2017-04-03T19:19:41.111951: step 1046, loss 1.96954, acc 0.296875\n",
      "2017-04-03T19:19:41.310222: step 1047, loss 1.85986, acc 0.375\n",
      "2017-04-03T19:19:41.507025: step 1048, loss 1.85365, acc 0.3125\n",
      "2017-04-03T19:19:41.703865: step 1049, loss 1.6884, acc 0.5\n",
      "2017-04-03T19:19:41.901945: step 1050, loss 1.93917, acc 0.21875\n",
      "2017-04-03T19:19:42.100532: step 1051, loss 2.03063, acc 0.34375\n",
      "2017-04-03T19:19:42.301893: step 1052, loss 1.83549, acc 0.328125\n",
      "2017-04-03T19:19:42.498621: step 1053, loss 1.7713, acc 0.4375\n",
      "2017-04-03T19:19:42.703375: step 1054, loss 1.7495, acc 0.359375\n",
      "2017-04-03T19:19:42.899199: step 1055, loss 2.11306, acc 0.328125\n",
      "2017-04-03T19:19:43.098580: step 1056, loss 1.76106, acc 0.359375\n",
      "2017-04-03T19:19:43.297104: step 1057, loss 1.84193, acc 0.328125\n",
      "2017-04-03T19:19:43.503069: step 1058, loss 1.81226, acc 0.375\n",
      "2017-04-03T19:19:43.699582: step 1059, loss 2.00549, acc 0.265625\n",
      "2017-04-03T19:19:43.903661: step 1060, loss 1.79112, acc 0.296875\n",
      "2017-04-03T19:19:44.098735: step 1061, loss 1.91342, acc 0.359375\n",
      "2017-04-03T19:19:44.301054: step 1062, loss 1.97833, acc 0.328125\n",
      "2017-04-03T19:19:44.499500: step 1063, loss 1.827, acc 0.453125\n",
      "2017-04-03T19:19:44.701325: step 1064, loss 1.97002, acc 0.28125\n",
      "2017-04-03T19:19:44.897142: step 1065, loss 2.19362, acc 0.296875\n",
      "2017-04-03T19:19:45.097405: step 1066, loss 1.62807, acc 0.46875\n",
      "2017-04-03T19:19:45.296700: step 1067, loss 1.98931, acc 0.3125\n",
      "2017-04-03T19:19:45.503204: step 1068, loss 1.85847, acc 0.328125\n",
      "2017-04-03T19:19:45.699571: step 1069, loss 2.00766, acc 0.265625\n",
      "2017-04-03T19:19:45.898803: step 1070, loss 1.98616, acc 0.234375\n",
      "2017-04-03T19:19:46.096656: step 1071, loss 1.86313, acc 0.359375\n",
      "2017-04-03T19:19:46.303767: step 1072, loss 1.91579, acc 0.34375\n",
      "2017-04-03T19:19:46.512060: step 1073, loss 1.84396, acc 0.3125\n",
      "2017-04-03T19:19:46.716668: step 1074, loss 2.0322, acc 0.28125\n",
      "2017-04-03T19:19:46.931838: step 1075, loss 1.86784, acc 0.4375\n",
      "2017-04-03T19:19:47.145266: step 1076, loss 2.25024, acc 0.28125\n",
      "2017-04-03T19:19:47.351199: step 1077, loss 2.22084, acc 0.203125\n",
      "2017-04-03T19:19:47.569731: step 1078, loss 2.03187, acc 0.328125\n",
      "2017-04-03T19:19:47.777095: step 1079, loss 1.92153, acc 0.40625\n",
      "2017-04-03T19:19:47.988619: step 1080, loss 1.97981, acc 0.375\n",
      "2017-04-03T19:19:48.201354: step 1081, loss 2.03353, acc 0.265625\n",
      "2017-04-03T19:19:48.418416: step 1082, loss 1.81808, acc 0.375\n",
      "2017-04-03T19:19:48.633804: step 1083, loss 1.75188, acc 0.375\n",
      "2017-04-03T19:19:48.841791: step 1084, loss 1.8846, acc 0.296875\n",
      "2017-04-03T19:19:49.055221: step 1085, loss 1.90138, acc 0.359375\n",
      "2017-04-03T19:19:49.265212: step 1086, loss 2.06941, acc 0.375\n",
      "2017-04-03T19:19:49.474470: step 1087, loss 1.80198, acc 0.328125\n",
      "2017-04-03T19:19:49.679125: step 1088, loss 2.0209, acc 0.328125\n",
      "2017-04-03T19:19:49.887123: step 1089, loss 1.83093, acc 0.328125\n",
      "2017-04-03T19:19:50.099313: step 1090, loss 2.02242, acc 0.3125\n",
      "2017-04-03T19:19:50.303084: step 1091, loss 2.03788, acc 0.359375\n",
      "2017-04-03T19:19:50.508733: step 1092, loss 1.92432, acc 0.359375\n",
      "2017-04-03T19:19:50.714901: step 1093, loss 1.98741, acc 0.296875\n",
      "2017-04-03T19:19:50.942188: step 1094, loss 1.96922, acc 0.328125\n",
      "2017-04-03T19:19:51.143643: step 1095, loss 2.01188, acc 0.234375\n",
      "2017-04-03T19:19:51.351493: step 1096, loss 2.09753, acc 0.1875\n",
      "2017-04-03T19:19:51.556104: step 1097, loss 1.75041, acc 0.328125\n",
      "2017-04-03T19:19:51.761171: step 1098, loss 1.80269, acc 0.359375\n",
      "2017-04-03T19:19:51.965647: step 1099, loss 1.82544, acc 0.34375\n",
      "2017-04-03T19:19:52.171665: step 1100, loss 2.07358, acc 0.28125\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:19:54.124273: step 1100, loss 1.89261, acc 0.31375\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-1100\n",
      "\n",
      "2017-04-03T19:19:54.456184: step 1101, loss 1.84539, acc 0.234375\n",
      "2017-04-03T19:19:54.655101: step 1102, loss 1.90917, acc 0.359375\n",
      "2017-04-03T19:19:54.862531: step 1103, loss 1.83792, acc 0.390625\n",
      "2017-04-03T19:19:55.060672: step 1104, loss 1.98661, acc 0.3125\n",
      "2017-04-03T19:19:55.263096: step 1105, loss 1.78653, acc 0.390625\n",
      "2017-04-03T19:19:55.460405: step 1106, loss 2.06544, acc 0.25\n",
      "2017-04-03T19:19:55.669085: step 1107, loss 1.77866, acc 0.296875\n",
      "2017-04-03T19:19:55.869724: step 1108, loss 1.94098, acc 0.296875\n",
      "2017-04-03T19:19:56.071771: step 1109, loss 1.74169, acc 0.375\n",
      "2017-04-03T19:19:56.267815: step 1110, loss 1.9298, acc 0.234375\n",
      "2017-04-03T19:19:56.470102: step 1111, loss 1.88838, acc 0.296875\n",
      "2017-04-03T19:19:56.670423: step 1112, loss 1.89875, acc 0.375\n",
      "2017-04-03T19:19:56.877048: step 1113, loss 2.1944, acc 0.1875\n",
      "2017-04-03T19:19:57.077519: step 1114, loss 2.0173, acc 0.296875\n",
      "2017-04-03T19:19:57.284851: step 1115, loss 1.75092, acc 0.40625\n",
      "2017-04-03T19:19:57.486326: step 1116, loss 2.13372, acc 0.3125\n",
      "2017-04-03T19:19:57.689844: step 1117, loss 1.89632, acc 0.265625\n",
      "2017-04-03T19:19:57.897882: step 1118, loss 2.12826, acc 0.1875\n",
      "2017-04-03T19:19:58.100567: step 1119, loss 1.90424, acc 0.296875\n",
      "2017-04-03T19:19:58.303904: step 1120, loss 2.04983, acc 0.203125\n",
      "2017-04-03T19:19:58.507981: step 1121, loss 2.17751, acc 0.296875\n",
      "2017-04-03T19:19:58.710428: step 1122, loss 1.76639, acc 0.375\n",
      "2017-04-03T19:19:58.916309: step 1123, loss 2.31372, acc 0.265625\n",
      "2017-04-03T19:19:59.120994: step 1124, loss 1.91098, acc 0.3125\n",
      "2017-04-03T19:19:59.325108: step 1125, loss 2.00511, acc 0.296875\n",
      "2017-04-03T19:19:59.476306: step 1126, loss 1.95489, acc 0.28125\n",
      "2017-04-03T19:19:59.683233: step 1127, loss 1.89167, acc 0.3125\n",
      "2017-04-03T19:19:59.879805: step 1128, loss 1.82396, acc 0.359375\n",
      "2017-04-03T19:20:00.085448: step 1129, loss 2.0167, acc 0.25\n",
      "2017-04-03T19:20:00.285677: step 1130, loss 1.8297, acc 0.265625\n",
      "2017-04-03T19:20:00.492427: step 1131, loss 1.82283, acc 0.296875\n",
      "2017-04-03T19:20:00.699441: step 1132, loss 1.81856, acc 0.34375\n",
      "2017-04-03T19:20:00.903739: step 1133, loss 2.01632, acc 0.328125\n",
      "2017-04-03T19:20:01.108554: step 1134, loss 1.85845, acc 0.375\n",
      "2017-04-03T19:20:01.310275: step 1135, loss 1.60459, acc 0.34375\n",
      "2017-04-03T19:20:01.512194: step 1136, loss 1.7026, acc 0.453125\n",
      "2017-04-03T19:20:01.713517: step 1137, loss 1.89551, acc 0.34375\n",
      "2017-04-03T19:20:01.916590: step 1138, loss 1.95783, acc 0.234375\n",
      "2017-04-03T19:20:02.122802: step 1139, loss 1.89848, acc 0.3125\n",
      "2017-04-03T19:20:02.327191: step 1140, loss 1.96937, acc 0.28125\n",
      "2017-04-03T19:20:02.530250: step 1141, loss 1.80851, acc 0.40625\n",
      "2017-04-03T19:20:02.730361: step 1142, loss 1.95994, acc 0.1875\n",
      "2017-04-03T19:20:02.936503: step 1143, loss 1.77477, acc 0.34375\n",
      "2017-04-03T19:20:03.129147: step 1144, loss 1.89608, acc 0.328125\n",
      "2017-04-03T19:20:03.332760: step 1145, loss 1.72336, acc 0.421875\n",
      "2017-04-03T19:20:03.534387: step 1146, loss 2.01666, acc 0.21875\n",
      "2017-04-03T19:20:03.736936: step 1147, loss 1.98026, acc 0.328125\n",
      "2017-04-03T19:20:03.939715: step 1148, loss 1.71571, acc 0.359375\n",
      "2017-04-03T19:20:04.135327: step 1149, loss 1.94548, acc 0.1875\n",
      "2017-04-03T19:20:04.337727: step 1150, loss 1.71736, acc 0.375\n",
      "2017-04-03T19:20:04.531737: step 1151, loss 1.84, acc 0.359375\n",
      "2017-04-03T19:20:04.844282: step 1152, loss 1.93687, acc 0.28125\n",
      "2017-04-03T19:20:05.041491: step 1153, loss 1.81663, acc 0.328125\n",
      "2017-04-03T19:20:05.249955: step 1154, loss 2.02, acc 0.265625\n",
      "2017-04-03T19:20:05.446505: step 1155, loss 1.86501, acc 0.375\n",
      "2017-04-03T19:20:05.646015: step 1156, loss 1.89553, acc 0.34375\n",
      "2017-04-03T19:20:05.844614: step 1157, loss 1.79898, acc 0.34375\n",
      "2017-04-03T19:20:06.051481: step 1158, loss 1.78084, acc 0.28125\n",
      "2017-04-03T19:20:06.249128: step 1159, loss 1.78643, acc 0.34375\n",
      "2017-04-03T19:20:06.449516: step 1160, loss 1.83756, acc 0.40625\n",
      "2017-04-03T19:20:06.650674: step 1161, loss 1.85751, acc 0.296875\n",
      "2017-04-03T19:20:06.855965: step 1162, loss 1.80143, acc 0.390625\n",
      "2017-04-03T19:20:07.055692: step 1163, loss 1.66361, acc 0.359375\n",
      "2017-04-03T19:20:07.257980: step 1164, loss 1.79805, acc 0.3125\n",
      "2017-04-03T19:20:07.454632: step 1165, loss 1.95078, acc 0.28125\n",
      "2017-04-03T19:20:07.656706: step 1166, loss 1.74884, acc 0.34375\n",
      "2017-04-03T19:20:07.852058: step 1167, loss 1.621, acc 0.390625\n",
      "2017-04-03T19:20:08.052495: step 1168, loss 1.79266, acc 0.34375\n",
      "2017-04-03T19:20:08.248600: step 1169, loss 1.96584, acc 0.28125\n",
      "2017-04-03T19:20:08.455076: step 1170, loss 1.79906, acc 0.359375\n",
      "2017-04-03T19:20:08.653913: step 1171, loss 1.77086, acc 0.40625\n",
      "2017-04-03T19:20:08.858502: step 1172, loss 1.7916, acc 0.40625\n",
      "2017-04-03T19:20:09.051961: step 1173, loss 1.85899, acc 0.375\n",
      "2017-04-03T19:20:09.259568: step 1174, loss 1.96262, acc 0.234375\n",
      "2017-04-03T19:20:09.458575: step 1175, loss 1.87644, acc 0.390625\n",
      "2017-04-03T19:20:09.657023: step 1176, loss 1.80238, acc 0.328125\n",
      "2017-04-03T19:20:09.853020: step 1177, loss 2.26423, acc 0.265625\n",
      "2017-04-03T19:20:10.054305: step 1178, loss 1.78843, acc 0.40625\n",
      "2017-04-03T19:20:10.250933: step 1179, loss 1.91626, acc 0.296875\n",
      "2017-04-03T19:20:10.453780: step 1180, loss 2.05153, acc 0.296875\n",
      "2017-04-03T19:20:10.651132: step 1181, loss 1.75154, acc 0.40625\n",
      "2017-04-03T19:20:10.848703: step 1182, loss 1.57639, acc 0.46875\n",
      "2017-04-03T19:20:11.049044: step 1183, loss 1.80204, acc 0.375\n",
      "2017-04-03T19:20:11.249237: step 1184, loss 2.0411, acc 0.234375\n",
      "2017-04-03T19:20:11.444738: step 1185, loss 1.7244, acc 0.359375\n",
      "2017-04-03T19:20:11.644864: step 1186, loss 2.12707, acc 0.296875\n",
      "2017-04-03T19:20:11.839650: step 1187, loss 1.59111, acc 0.578125\n",
      "2017-04-03T19:20:12.040431: step 1188, loss 2.02779, acc 0.34375\n",
      "2017-04-03T19:20:12.238317: step 1189, loss 1.84449, acc 0.375\n",
      "2017-04-03T19:20:12.435765: step 1190, loss 1.94308, acc 0.3125\n",
      "2017-04-03T19:20:12.634098: step 1191, loss 1.81602, acc 0.359375\n",
      "2017-04-03T19:20:12.837442: step 1192, loss 1.87876, acc 0.328125\n",
      "2017-04-03T19:20:13.033339: step 1193, loss 1.98772, acc 0.34375\n",
      "2017-04-03T19:20:13.235706: step 1194, loss 1.80264, acc 0.28125\n",
      "2017-04-03T19:20:13.431456: step 1195, loss 1.87935, acc 0.296875\n",
      "2017-04-03T19:20:13.634158: step 1196, loss 1.55076, acc 0.4375\n",
      "2017-04-03T19:20:13.832986: step 1197, loss 1.80435, acc 0.390625\n",
      "2017-04-03T19:20:14.037380: step 1198, loss 1.89691, acc 0.28125\n",
      "2017-04-03T19:20:14.231264: step 1199, loss 1.64923, acc 0.453125\n",
      "2017-04-03T19:20:14.430415: step 1200, loss 1.74651, acc 0.234375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:20:16.356535: step 1200, loss 1.88136, acc 0.31775\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-1200\n",
      "\n",
      "2017-04-03T19:20:16.705063: step 1201, loss 1.82153, acc 0.34375\n",
      "2017-04-03T19:20:16.905705: step 1202, loss 1.91843, acc 0.34375\n",
      "2017-04-03T19:20:17.112123: step 1203, loss 1.67084, acc 0.3125\n",
      "2017-04-03T19:20:17.308620: step 1204, loss 1.90277, acc 0.28125\n",
      "2017-04-03T19:20:17.509449: step 1205, loss 2.13848, acc 0.28125\n",
      "2017-04-03T19:20:17.705536: step 1206, loss 1.7051, acc 0.40625\n",
      "2017-04-03T19:20:17.908112: step 1207, loss 1.73842, acc 0.421875\n",
      "2017-04-03T19:20:18.103956: step 1208, loss 2.09733, acc 0.234375\n",
      "2017-04-03T19:20:18.311354: step 1209, loss 1.8421, acc 0.296875\n",
      "2017-04-03T19:20:18.505839: step 1210, loss 1.891, acc 0.296875\n",
      "2017-04-03T19:20:18.711320: step 1211, loss 1.93044, acc 0.390625\n",
      "2017-04-03T19:20:18.907401: step 1212, loss 1.8992, acc 0.3125\n",
      "2017-04-03T19:20:19.113399: step 1213, loss 1.96653, acc 0.296875\n",
      "2017-04-03T19:20:19.310656: step 1214, loss 1.66957, acc 0.359375\n",
      "2017-04-03T19:20:19.514563: step 1215, loss 1.92923, acc 0.3125\n",
      "2017-04-03T19:20:19.708131: step 1216, loss 1.81418, acc 0.265625\n",
      "2017-04-03T19:20:19.915816: step 1217, loss 1.84569, acc 0.390625\n",
      "2017-04-03T19:20:20.111507: step 1218, loss 1.87239, acc 0.390625\n",
      "2017-04-03T19:20:20.314274: step 1219, loss 1.90952, acc 0.328125\n",
      "2017-04-03T19:20:20.510097: step 1220, loss 1.87667, acc 0.3125\n",
      "2017-04-03T19:20:20.709083: step 1221, loss 1.93278, acc 0.296875\n",
      "2017-04-03T19:20:20.903226: step 1222, loss 1.97571, acc 0.3125\n",
      "2017-04-03T19:20:21.104108: step 1223, loss 1.87501, acc 0.390625\n",
      "2017-04-03T19:20:21.300610: step 1224, loss 1.87928, acc 0.3125\n",
      "2017-04-03T19:20:21.500820: step 1225, loss 1.99301, acc 0.328125\n",
      "2017-04-03T19:20:21.694302: step 1226, loss 1.88374, acc 0.3125\n",
      "2017-04-03T19:20:21.895936: step 1227, loss 1.91482, acc 0.296875\n",
      "2017-04-03T19:20:22.092879: step 1228, loss 1.77409, acc 0.34375\n",
      "2017-04-03T19:20:22.295641: step 1229, loss 1.81, acc 0.359375\n",
      "2017-04-03T19:20:22.492666: step 1230, loss 1.66398, acc 0.4375\n",
      "2017-04-03T19:20:22.694800: step 1231, loss 1.79744, acc 0.390625\n",
      "2017-04-03T19:20:22.892013: step 1232, loss 1.74356, acc 0.40625\n",
      "2017-04-03T19:20:23.095255: step 1233, loss 1.75821, acc 0.296875\n",
      "2017-04-03T19:20:23.290413: step 1234, loss 1.99956, acc 0.359375\n",
      "2017-04-03T19:20:23.496982: step 1235, loss 1.88567, acc 0.328125\n",
      "2017-04-03T19:20:23.696157: step 1236, loss 1.87177, acc 0.34375\n",
      "2017-04-03T19:20:23.896591: step 1237, loss 1.73428, acc 0.390625\n",
      "2017-04-03T19:20:24.092968: step 1238, loss 1.95009, acc 0.234375\n",
      "2017-04-03T19:20:24.296538: step 1239, loss 1.71034, acc 0.375\n",
      "2017-04-03T19:20:24.493719: step 1240, loss 2.07399, acc 0.171875\n",
      "2017-04-03T19:20:24.697236: step 1241, loss 1.86764, acc 0.359375\n",
      "2017-04-03T19:20:24.891524: step 1242, loss 1.62105, acc 0.3125\n",
      "2017-04-03T19:20:25.093320: step 1243, loss 1.70978, acc 0.375\n",
      "2017-04-03T19:20:25.289242: step 1244, loss 2.0454, acc 0.28125\n",
      "2017-04-03T19:20:25.488771: step 1245, loss 1.63874, acc 0.421875\n",
      "2017-04-03T19:20:25.687738: step 1246, loss 1.97801, acc 0.296875\n",
      "2017-04-03T19:20:25.892326: step 1247, loss 1.72218, acc 0.421875\n",
      "2017-04-03T19:20:26.090511: step 1248, loss 1.87297, acc 0.296875\n",
      "2017-04-03T19:20:26.292233: step 1249, loss 1.8436, acc 0.375\n",
      "2017-04-03T19:20:26.486712: step 1250, loss 1.86921, acc 0.34375\n",
      "2017-04-03T19:20:26.687953: step 1251, loss 2.05614, acc 0.28125\n",
      "2017-04-03T19:20:26.887589: step 1252, loss 1.90777, acc 0.3125\n",
      "2017-04-03T19:20:27.093259: step 1253, loss 1.93681, acc 0.3125\n",
      "2017-04-03T19:20:27.291152: step 1254, loss 1.95929, acc 0.328125\n",
      "2017-04-03T19:20:27.493679: step 1255, loss 1.84261, acc 0.28125\n",
      "2017-04-03T19:20:27.687440: step 1256, loss 1.96565, acc 0.25\n",
      "2017-04-03T19:20:27.889787: step 1257, loss 1.81769, acc 0.3125\n",
      "2017-04-03T19:20:28.086107: step 1258, loss 1.9707, acc 0.296875\n",
      "2017-04-03T19:20:28.287342: step 1259, loss 1.90926, acc 0.296875\n",
      "2017-04-03T19:20:28.482731: step 1260, loss 1.82133, acc 0.375\n",
      "2017-04-03T19:20:28.684406: step 1261, loss 1.72837, acc 0.40625\n",
      "2017-04-03T19:20:28.881668: step 1262, loss 1.82869, acc 0.34375\n",
      "2017-04-03T19:20:29.086962: step 1263, loss 1.65456, acc 0.515625\n",
      "2017-04-03T19:20:29.282097: step 1264, loss 1.99612, acc 0.34375\n",
      "2017-04-03T19:20:29.482605: step 1265, loss 1.87923, acc 0.3125\n",
      "2017-04-03T19:20:29.678154: step 1266, loss 1.65313, acc 0.4375\n",
      "2017-04-03T19:20:29.882215: step 1267, loss 1.87697, acc 0.359375\n",
      "2017-04-03T19:20:30.074023: step 1268, loss 1.77441, acc 0.34375\n",
      "2017-04-03T19:20:30.285952: step 1269, loss 1.88441, acc 0.21875\n",
      "2017-04-03T19:20:30.478049: step 1270, loss 1.78052, acc 0.34375\n",
      "2017-04-03T19:20:30.684689: step 1271, loss 1.76503, acc 0.328125\n",
      "2017-04-03T19:20:30.880100: step 1272, loss 1.82188, acc 0.421875\n",
      "2017-04-03T19:20:31.086026: step 1273, loss 1.81232, acc 0.328125\n",
      "2017-04-03T19:20:31.280046: step 1274, loss 1.97369, acc 0.25\n",
      "2017-04-03T19:20:31.483856: step 1275, loss 1.75186, acc 0.375\n",
      "2017-04-03T19:20:31.680592: step 1276, loss 1.91763, acc 0.265625\n",
      "2017-04-03T19:20:31.880121: step 1277, loss 1.83117, acc 0.3125\n",
      "2017-04-03T19:20:32.075448: step 1278, loss 1.95, acc 0.390625\n",
      "2017-04-03T19:20:32.278346: step 1279, loss 1.90416, acc 0.375\n",
      "2017-04-03T19:20:32.476571: step 1280, loss 2.07022, acc 0.3125\n",
      "2017-04-03T19:20:32.677525: step 1281, loss 1.97265, acc 0.3125\n",
      "2017-04-03T19:20:32.873454: step 1282, loss 1.67069, acc 0.421875\n",
      "2017-04-03T19:20:33.074959: step 1283, loss 1.75816, acc 0.3125\n",
      "2017-04-03T19:20:33.272324: step 1284, loss 1.8996, acc 0.3125\n",
      "2017-04-03T19:20:33.475062: step 1285, loss 1.89194, acc 0.25\n",
      "2017-04-03T19:20:33.671391: step 1286, loss 1.8399, acc 0.3125\n",
      "2017-04-03T19:20:33.872206: step 1287, loss 1.76857, acc 0.28125\n",
      "2017-04-03T19:20:34.066248: step 1288, loss 1.76613, acc 0.3125\n",
      "2017-04-03T19:20:34.264552: step 1289, loss 1.81899, acc 0.296875\n",
      "2017-04-03T19:20:34.464860: step 1290, loss 1.96549, acc 0.359375\n",
      "2017-04-03T19:20:34.666318: step 1291, loss 2.05787, acc 0.328125\n",
      "2017-04-03T19:20:34.861902: step 1292, loss 2.01176, acc 0.265625\n",
      "2017-04-03T19:20:35.063312: step 1293, loss 1.80779, acc 0.28125\n",
      "2017-04-03T19:20:35.260166: step 1294, loss 1.97011, acc 0.359375\n",
      "2017-04-03T19:20:35.458266: step 1295, loss 1.687, acc 0.390625\n",
      "2017-04-03T19:20:35.652680: step 1296, loss 1.99546, acc 0.328125\n",
      "2017-04-03T19:20:35.853343: step 1297, loss 1.95891, acc 0.296875\n",
      "2017-04-03T19:20:36.047045: step 1298, loss 1.76695, acc 0.40625\n",
      "2017-04-03T19:20:36.247510: step 1299, loss 1.97574, acc 0.25\n",
      "2017-04-03T19:20:36.443302: step 1300, loss 1.85339, acc 0.375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:20:38.371302: step 1300, loss 1.86856, acc 0.3225\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-1300\n",
      "\n",
      "2017-04-03T19:20:38.724548: step 1301, loss 1.82535, acc 0.265625\n",
      "2017-04-03T19:20:38.918119: step 1302, loss 1.86126, acc 0.3125\n",
      "2017-04-03T19:20:39.119241: step 1303, loss 2.06819, acc 0.296875\n",
      "2017-04-03T19:20:39.310997: step 1304, loss 1.90023, acc 0.3125\n",
      "2017-04-03T19:20:39.515310: step 1305, loss 1.92605, acc 0.328125\n",
      "2017-04-03T19:20:39.717864: step 1306, loss 1.65716, acc 0.359375\n",
      "2017-04-03T19:20:39.916772: step 1307, loss 1.72406, acc 0.34375\n",
      "2017-04-03T19:20:40.117007: step 1308, loss 1.88346, acc 0.21875\n",
      "2017-04-03T19:20:40.307112: step 1309, loss 1.69538, acc 0.4375\n",
      "2017-04-03T19:20:40.506737: step 1310, loss 1.99217, acc 0.21875\n",
      "2017-04-03T19:20:40.701671: step 1311, loss 1.78211, acc 0.40625\n",
      "2017-04-03T19:20:40.902848: step 1312, loss 1.98938, acc 0.296875\n",
      "2017-04-03T19:20:41.097226: step 1313, loss 1.76764, acc 0.4375\n",
      "2017-04-03T19:20:41.299895: step 1314, loss 1.72119, acc 0.4375\n",
      "2017-04-03T19:20:41.494910: step 1315, loss 1.91733, acc 0.375\n",
      "2017-04-03T19:20:41.697426: step 1316, loss 1.90601, acc 0.25\n",
      "2017-04-03T19:20:41.896212: step 1317, loss 2.17836, acc 0.25\n",
      "2017-04-03T19:20:42.097955: step 1318, loss 1.96081, acc 0.328125\n",
      "2017-04-03T19:20:42.295926: step 1319, loss 1.9639, acc 0.390625\n",
      "2017-04-03T19:20:42.496589: step 1320, loss 1.73578, acc 0.421875\n",
      "2017-04-03T19:20:42.692572: step 1321, loss 1.67043, acc 0.34375\n",
      "2017-04-03T19:20:42.891026: step 1322, loss 1.83316, acc 0.40625\n",
      "2017-04-03T19:20:43.087191: step 1323, loss 1.7699, acc 0.390625\n",
      "2017-04-03T19:20:43.289933: step 1324, loss 1.60103, acc 0.40625\n",
      "2017-04-03T19:20:43.482462: step 1325, loss 1.74684, acc 0.4375\n",
      "2017-04-03T19:20:43.680266: step 1326, loss 1.68628, acc 0.421875\n",
      "2017-04-03T19:20:43.875584: step 1327, loss 1.75584, acc 0.359375\n",
      "2017-04-03T19:20:44.076785: step 1328, loss 1.84842, acc 0.359375\n",
      "2017-04-03T19:20:44.269340: step 1329, loss 2.08115, acc 0.3125\n",
      "2017-04-03T19:20:44.471481: step 1330, loss 1.84842, acc 0.265625\n",
      "2017-04-03T19:20:44.669693: step 1331, loss 1.94526, acc 0.265625\n",
      "2017-04-03T19:20:44.870299: step 1332, loss 1.81374, acc 0.28125\n",
      "2017-04-03T19:20:45.061887: step 1333, loss 1.87149, acc 0.296875\n",
      "2017-04-03T19:20:45.262711: step 1334, loss 1.94088, acc 0.296875\n",
      "2017-04-03T19:20:45.460032: step 1335, loss 1.72308, acc 0.390625\n",
      "2017-04-03T19:20:45.664650: step 1336, loss 1.88416, acc 0.328125\n",
      "2017-04-03T19:20:45.855661: step 1337, loss 1.74788, acc 0.375\n",
      "2017-04-03T19:20:46.057447: step 1338, loss 2.15923, acc 0.28125\n",
      "2017-04-03T19:20:46.249951: step 1339, loss 1.57248, acc 0.40625\n",
      "2017-04-03T19:20:46.452313: step 1340, loss 1.79067, acc 0.3125\n",
      "2017-04-03T19:20:46.641778: step 1341, loss 1.7597, acc 0.390625\n",
      "2017-04-03T19:20:46.841785: step 1342, loss 1.83295, acc 0.40625\n",
      "2017-04-03T19:20:47.039683: step 1343, loss 1.95694, acc 0.296875\n",
      "2017-04-03T19:20:47.243574: step 1344, loss 1.68952, acc 0.3125\n",
      "2017-04-03T19:20:47.436811: step 1345, loss 1.64298, acc 0.40625\n",
      "2017-04-03T19:20:47.638554: step 1346, loss 1.82987, acc 0.28125\n",
      "2017-04-03T19:20:47.832901: step 1347, loss 1.88829, acc 0.34375\n",
      "2017-04-03T19:20:48.035478: step 1348, loss 1.90686, acc 0.296875\n",
      "2017-04-03T19:20:48.228544: step 1349, loss 1.96849, acc 0.3125\n",
      "2017-04-03T19:20:48.431888: step 1350, loss 1.72789, acc 0.359375\n",
      "2017-04-03T19:20:48.624463: step 1351, loss 1.71959, acc 0.359375\n",
      "2017-04-03T19:20:48.823982: step 1352, loss 1.64895, acc 0.328125\n",
      "2017-04-03T19:20:49.017558: step 1353, loss 1.81764, acc 0.390625\n",
      "2017-04-03T19:20:49.218150: step 1354, loss 1.93271, acc 0.296875\n",
      "2017-04-03T19:20:49.413755: step 1355, loss 1.88008, acc 0.34375\n",
      "2017-04-03T19:20:49.613570: step 1356, loss 1.82815, acc 0.34375\n",
      "2017-04-03T19:20:49.808098: step 1357, loss 1.8871, acc 0.234375\n",
      "2017-04-03T19:20:50.004660: step 1358, loss 2.00679, acc 0.265625\n",
      "2017-04-03T19:20:50.196455: step 1359, loss 1.73559, acc 0.3125\n",
      "2017-04-03T19:20:50.395357: step 1360, loss 1.73597, acc 0.375\n",
      "2017-04-03T19:20:50.587779: step 1361, loss 1.63944, acc 0.34375\n",
      "2017-04-03T19:20:50.794960: step 1362, loss 1.74313, acc 0.34375\n",
      "2017-04-03T19:20:50.985554: step 1363, loss 1.73487, acc 0.34375\n",
      "2017-04-03T19:20:51.183077: step 1364, loss 1.85552, acc 0.375\n",
      "2017-04-03T19:20:51.383260: step 1365, loss 1.88138, acc 0.21875\n",
      "2017-04-03T19:20:51.579063: step 1366, loss 1.72173, acc 0.328125\n",
      "2017-04-03T19:20:51.774246: step 1367, loss 1.98772, acc 0.28125\n",
      "2017-04-03T19:20:51.975279: step 1368, loss 1.83838, acc 0.40625\n",
      "2017-04-03T19:20:52.170243: step 1369, loss 1.78207, acc 0.421875\n",
      "2017-04-03T19:20:52.368510: step 1370, loss 1.74514, acc 0.40625\n",
      "2017-04-03T19:20:52.562547: step 1371, loss 1.9092, acc 0.359375\n",
      "2017-04-03T19:20:52.761104: step 1372, loss 1.90696, acc 0.296875\n",
      "2017-04-03T19:20:52.952440: step 1373, loss 1.74404, acc 0.375\n",
      "2017-04-03T19:20:53.156686: step 1374, loss 1.89402, acc 0.40625\n",
      "2017-04-03T19:20:53.352447: step 1375, loss 1.84965, acc 0.3125\n",
      "2017-04-03T19:20:53.551609: step 1376, loss 1.83008, acc 0.328125\n",
      "2017-04-03T19:20:53.747848: step 1377, loss 1.80467, acc 0.421875\n",
      "2017-04-03T19:20:53.948631: step 1378, loss 1.67248, acc 0.375\n",
      "2017-04-03T19:20:54.144399: step 1379, loss 1.98994, acc 0.28125\n",
      "2017-04-03T19:20:54.343886: step 1380, loss 1.86238, acc 0.4375\n",
      "2017-04-03T19:20:54.536063: step 1381, loss 1.88866, acc 0.28125\n",
      "2017-04-03T19:20:54.742938: step 1382, loss 2.01834, acc 0.296875\n",
      "2017-04-03T19:20:54.936758: step 1383, loss 1.88265, acc 0.359375\n",
      "2017-04-03T19:20:55.140530: step 1384, loss 1.77132, acc 0.453125\n",
      "2017-04-03T19:20:55.337385: step 1385, loss 1.96992, acc 0.359375\n",
      "2017-04-03T19:20:55.537882: step 1386, loss 1.71233, acc 0.375\n",
      "2017-04-03T19:20:55.731684: step 1387, loss 1.76789, acc 0.34375\n",
      "2017-04-03T19:20:55.935596: step 1388, loss 1.85927, acc 0.25\n",
      "2017-04-03T19:20:56.131433: step 1389, loss 1.70839, acc 0.375\n",
      "2017-04-03T19:20:56.330959: step 1390, loss 1.97617, acc 0.390625\n",
      "2017-04-03T19:20:56.524303: step 1391, loss 1.78457, acc 0.34375\n",
      "2017-04-03T19:20:56.727041: step 1392, loss 1.91084, acc 0.28125\n",
      "2017-04-03T19:20:56.917681: step 1393, loss 1.72115, acc 0.328125\n",
      "2017-04-03T19:20:57.115138: step 1394, loss 1.87456, acc 0.296875\n",
      "2017-04-03T19:20:57.309168: step 1395, loss 2.02334, acc 0.328125\n",
      "2017-04-03T19:20:57.511029: step 1396, loss 1.72965, acc 0.375\n",
      "2017-04-03T19:20:57.703737: step 1397, loss 1.91764, acc 0.375\n",
      "2017-04-03T19:20:57.905604: step 1398, loss 1.82863, acc 0.234375\n",
      "2017-04-03T19:20:58.099250: step 1399, loss 1.51485, acc 0.421875\n",
      "2017-04-03T19:20:58.296617: step 1400, loss 1.94244, acc 0.328125\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:21:00.228784: step 1400, loss 1.86979, acc 0.324\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-1400\n",
      "\n",
      "2017-04-03T19:21:00.611342: step 1401, loss 1.78606, acc 0.453125\n",
      "2017-04-03T19:21:00.807798: step 1402, loss 1.85922, acc 0.328125\n",
      "2017-04-03T19:21:01.009712: step 1403, loss 1.77608, acc 0.3125\n",
      "2017-04-03T19:21:01.202339: step 1404, loss 1.93126, acc 0.390625\n",
      "2017-04-03T19:21:01.399532: step 1405, loss 1.87829, acc 0.296875\n",
      "2017-04-03T19:21:01.592160: step 1406, loss 1.89689, acc 0.3125\n",
      "2017-04-03T19:21:01.794710: step 1407, loss 1.84114, acc 0.359375\n",
      "2017-04-03T19:21:01.986508: step 1408, loss 1.87287, acc 0.34375\n",
      "2017-04-03T19:21:02.185596: step 1409, loss 2.01997, acc 0.328125\n",
      "2017-04-03T19:21:02.374796: step 1410, loss 1.86521, acc 0.28125\n",
      "2017-04-03T19:21:02.575554: step 1411, loss 1.59852, acc 0.375\n",
      "2017-04-03T19:21:02.766964: step 1412, loss 1.97378, acc 0.296875\n",
      "2017-04-03T19:21:02.969887: step 1413, loss 1.7622, acc 0.359375\n",
      "2017-04-03T19:21:03.166212: step 1414, loss 1.82505, acc 0.328125\n",
      "2017-04-03T19:21:03.366285: step 1415, loss 1.82756, acc 0.3125\n",
      "2017-04-03T19:21:03.560760: step 1416, loss 1.7977, acc 0.359375\n",
      "2017-04-03T19:21:03.761427: step 1417, loss 1.85587, acc 0.3125\n",
      "2017-04-03T19:21:03.957442: step 1418, loss 1.89882, acc 0.234375\n",
      "2017-04-03T19:21:04.156117: step 1419, loss 1.72534, acc 0.40625\n",
      "2017-04-03T19:21:04.350029: step 1420, loss 1.85083, acc 0.34375\n",
      "2017-04-03T19:21:04.555547: step 1421, loss 1.79656, acc 0.296875\n",
      "2017-04-03T19:21:04.748249: step 1422, loss 1.86093, acc 0.328125\n",
      "2017-04-03T19:21:04.950463: step 1423, loss 1.79772, acc 0.421875\n",
      "2017-04-03T19:21:05.145073: step 1424, loss 1.8162, acc 0.359375\n",
      "2017-04-03T19:21:05.345666: step 1425, loss 1.86884, acc 0.28125\n",
      "2017-04-03T19:21:05.538948: step 1426, loss 2.00683, acc 0.265625\n",
      "2017-04-03T19:21:05.741256: step 1427, loss 1.86242, acc 0.3125\n",
      "2017-04-03T19:21:05.934474: step 1428, loss 1.97676, acc 0.265625\n",
      "2017-04-03T19:21:06.134698: step 1429, loss 1.84307, acc 0.328125\n",
      "2017-04-03T19:21:06.331933: step 1430, loss 1.92473, acc 0.296875\n",
      "2017-04-03T19:21:06.534633: step 1431, loss 1.84877, acc 0.25\n",
      "2017-04-03T19:21:06.729829: step 1432, loss 1.71685, acc 0.34375\n",
      "2017-04-03T19:21:06.934222: step 1433, loss 1.78596, acc 0.328125\n",
      "2017-04-03T19:21:07.127902: step 1434, loss 1.754, acc 0.421875\n",
      "2017-04-03T19:21:07.324787: step 1435, loss 1.65413, acc 0.375\n",
      "2017-04-03T19:21:07.518900: step 1436, loss 1.73181, acc 0.484375\n",
      "2017-04-03T19:21:07.719704: step 1437, loss 1.73138, acc 0.34375\n",
      "2017-04-03T19:21:07.913108: step 1438, loss 1.66643, acc 0.4375\n",
      "2017-04-03T19:21:08.107802: step 1439, loss 1.66114, acc 0.40625\n",
      "2017-04-03T19:21:08.307186: step 1440, loss 1.74779, acc 0.40625\n",
      "2017-04-03T19:21:08.507414: step 1441, loss 1.86188, acc 0.328125\n",
      "2017-04-03T19:21:08.702034: step 1442, loss 2.1571, acc 0.265625\n",
      "2017-04-03T19:21:08.902849: step 1443, loss 1.9392, acc 0.328125\n",
      "2017-04-03T19:21:09.097752: step 1444, loss 1.75294, acc 0.390625\n",
      "2017-04-03T19:21:09.296809: step 1445, loss 1.62896, acc 0.40625\n",
      "2017-04-03T19:21:09.496339: step 1446, loss 1.86486, acc 0.390625\n",
      "2017-04-03T19:21:09.698076: step 1447, loss 1.67603, acc 0.359375\n",
      "2017-04-03T19:21:09.892374: step 1448, loss 1.82208, acc 0.359375\n",
      "2017-04-03T19:21:10.099642: step 1449, loss 1.98391, acc 0.203125\n",
      "2017-04-03T19:21:10.295109: step 1450, loss 1.69126, acc 0.40625\n",
      "2017-04-03T19:21:10.504918: step 1451, loss 2.00754, acc 0.34375\n",
      "2017-04-03T19:21:10.704432: step 1452, loss 2.06203, acc 0.3125\n",
      "2017-04-03T19:21:10.910847: step 1453, loss 1.91841, acc 0.296875\n",
      "2017-04-03T19:21:11.104257: step 1454, loss 1.84914, acc 0.375\n",
      "2017-04-03T19:21:11.309620: step 1455, loss 1.90204, acc 0.21875\n",
      "2017-04-03T19:21:11.500429: step 1456, loss 2.02985, acc 0.328125\n",
      "2017-04-03T19:21:11.699354: step 1457, loss 1.74054, acc 0.421875\n",
      "2017-04-03T19:21:11.893599: step 1458, loss 1.91256, acc 0.265625\n",
      "2017-04-03T19:21:12.093002: step 1459, loss 1.94898, acc 0.390625\n",
      "2017-04-03T19:21:12.290595: step 1460, loss 1.82347, acc 0.296875\n",
      "2017-04-03T19:21:12.489591: step 1461, loss 1.885, acc 0.3125\n",
      "2017-04-03T19:21:12.681390: step 1462, loss 1.93812, acc 0.359375\n",
      "2017-04-03T19:21:12.883460: step 1463, loss 2.07577, acc 0.375\n",
      "2017-04-03T19:21:13.078120: step 1464, loss 1.97539, acc 0.265625\n",
      "2017-04-03T19:21:13.278352: step 1465, loss 2.04066, acc 0.25\n",
      "2017-04-03T19:21:13.472410: step 1466, loss 1.79686, acc 0.3125\n",
      "2017-04-03T19:21:13.673146: step 1467, loss 1.94873, acc 0.375\n",
      "2017-04-03T19:21:13.866625: step 1468, loss 2.0623, acc 0.28125\n",
      "2017-04-03T19:21:14.070057: step 1469, loss 1.61073, acc 0.421875\n",
      "2017-04-03T19:21:14.265148: step 1470, loss 2.10398, acc 0.234375\n",
      "2017-04-03T19:21:14.466835: step 1471, loss 1.86076, acc 0.390625\n",
      "2017-04-03T19:21:14.664741: step 1472, loss 1.92385, acc 0.234375\n",
      "2017-04-03T19:21:14.866840: step 1473, loss 2.00481, acc 0.28125\n",
      "2017-04-03T19:21:15.056997: step 1474, loss 1.84809, acc 0.359375\n",
      "2017-04-03T19:21:15.261194: step 1475, loss 1.84695, acc 0.296875\n",
      "2017-04-03T19:21:15.473036: step 1476, loss 1.72819, acc 0.4375\n",
      "2017-04-03T19:21:15.672238: step 1477, loss 1.80155, acc 0.375\n",
      "2017-04-03T19:21:15.874062: step 1478, loss 1.83092, acc 0.421875\n",
      "2017-04-03T19:21:16.068996: step 1479, loss 1.81719, acc 0.28125\n",
      "2017-04-03T19:21:16.273176: step 1480, loss 1.70115, acc 0.40625\n",
      "2017-04-03T19:21:16.470221: step 1481, loss 1.74662, acc 0.328125\n",
      "2017-04-03T19:21:16.672534: step 1482, loss 1.93064, acc 0.34375\n",
      "2017-04-03T19:21:16.866387: step 1483, loss 1.92826, acc 0.296875\n",
      "2017-04-03T19:21:17.066683: step 1484, loss 1.81967, acc 0.421875\n",
      "2017-04-03T19:21:17.261193: step 1485, loss 1.82471, acc 0.359375\n",
      "2017-04-03T19:21:17.462356: step 1486, loss 1.80899, acc 0.296875\n",
      "2017-04-03T19:21:17.657313: step 1487, loss 2.04745, acc 0.3125\n",
      "2017-04-03T19:21:17.859472: step 1488, loss 1.83913, acc 0.3125\n",
      "2017-04-03T19:21:18.054944: step 1489, loss 1.83078, acc 0.34375\n",
      "2017-04-03T19:21:18.258108: step 1490, loss 1.85048, acc 0.296875\n",
      "2017-04-03T19:21:18.452798: step 1491, loss 1.87978, acc 0.3125\n",
      "2017-04-03T19:21:18.654852: step 1492, loss 1.83484, acc 0.328125\n",
      "2017-04-03T19:21:18.852742: step 1493, loss 1.85406, acc 0.296875\n",
      "2017-04-03T19:21:19.050550: step 1494, loss 1.85414, acc 0.28125\n",
      "2017-04-03T19:21:19.245510: step 1495, loss 1.96333, acc 0.296875\n",
      "2017-04-03T19:21:19.447243: step 1496, loss 1.64644, acc 0.421875\n",
      "2017-04-03T19:21:19.637129: step 1497, loss 1.95163, acc 0.265625\n",
      "2017-04-03T19:21:19.838073: step 1498, loss 1.62849, acc 0.390625\n",
      "2017-04-03T19:21:20.029679: step 1499, loss 1.79602, acc 0.296875\n",
      "2017-04-03T19:21:20.229108: step 1500, loss 1.8023, acc 0.375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:21:22.222519: step 1500, loss 1.86484, acc 0.334\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-1500\n",
      "\n",
      "2017-04-03T19:21:22.566645: step 1501, loss 1.95003, acc 0.3125\n",
      "2017-04-03T19:21:22.759135: step 1502, loss 1.99832, acc 0.3125\n",
      "2017-04-03T19:21:22.959465: step 1503, loss 1.84828, acc 0.359375\n",
      "2017-04-03T19:21:23.152436: step 1504, loss 1.69527, acc 0.390625\n",
      "2017-04-03T19:21:23.353505: step 1505, loss 1.88676, acc 0.390625\n",
      "2017-04-03T19:21:23.548204: step 1506, loss 1.82258, acc 0.359375\n",
      "2017-04-03T19:21:23.746990: step 1507, loss 2.11646, acc 0.296875\n",
      "2017-04-03T19:21:23.945021: step 1508, loss 2.01863, acc 0.21875\n",
      "2017-04-03T19:21:24.148707: step 1509, loss 1.82223, acc 0.375\n",
      "2017-04-03T19:21:24.344958: step 1510, loss 1.72731, acc 0.390625\n",
      "2017-04-03T19:21:24.544700: step 1511, loss 1.91428, acc 0.359375\n",
      "2017-04-03T19:21:24.742630: step 1512, loss 1.82054, acc 0.328125\n",
      "2017-04-03T19:21:24.944171: step 1513, loss 1.678, acc 0.359375\n",
      "2017-04-03T19:21:25.137208: step 1514, loss 1.64708, acc 0.328125\n",
      "2017-04-03T19:21:25.339788: step 1515, loss 1.91057, acc 0.28125\n",
      "2017-04-03T19:21:25.532933: step 1516, loss 1.88678, acc 0.328125\n",
      "2017-04-03T19:21:25.733271: step 1517, loss 1.90003, acc 0.3125\n",
      "2017-04-03T19:21:25.927998: step 1518, loss 1.91733, acc 0.34375\n",
      "2017-04-03T19:21:26.127304: step 1519, loss 1.81696, acc 0.390625\n",
      "2017-04-03T19:21:26.322758: step 1520, loss 1.90744, acc 0.359375\n",
      "2017-04-03T19:21:26.523775: step 1521, loss 2.01128, acc 0.328125\n",
      "2017-04-03T19:21:26.719006: step 1522, loss 1.94693, acc 0.265625\n",
      "2017-04-03T19:21:26.922606: step 1523, loss 1.93646, acc 0.296875\n",
      "2017-04-03T19:21:27.118809: step 1524, loss 1.84728, acc 0.328125\n",
      "2017-04-03T19:21:27.321728: step 1525, loss 1.78903, acc 0.390625\n",
      "2017-04-03T19:21:27.518169: step 1526, loss 1.6655, acc 0.375\n",
      "2017-04-03T19:21:27.719333: step 1527, loss 1.81917, acc 0.328125\n",
      "2017-04-03T19:21:27.912892: step 1528, loss 1.89858, acc 0.3125\n",
      "2017-04-03T19:21:28.115367: step 1529, loss 1.84413, acc 0.390625\n",
      "2017-04-03T19:21:28.308352: step 1530, loss 1.87594, acc 0.296875\n",
      "2017-04-03T19:21:28.510261: step 1531, loss 1.76062, acc 0.375\n",
      "2017-04-03T19:21:28.705727: step 1532, loss 1.79672, acc 0.375\n",
      "2017-04-03T19:21:28.906548: step 1533, loss 1.83137, acc 0.265625\n",
      "2017-04-03T19:21:29.100598: step 1534, loss 1.93123, acc 0.28125\n",
      "2017-04-03T19:21:29.302814: step 1535, loss 1.87907, acc 0.3125\n",
      "2017-04-03T19:21:29.495446: step 1536, loss 1.85567, acc 0.3125\n",
      "2017-04-03T19:21:29.696733: step 1537, loss 1.72662, acc 0.40625\n",
      "2017-04-03T19:21:29.889446: step 1538, loss 1.80721, acc 0.328125\n",
      "2017-04-03T19:21:30.093704: step 1539, loss 1.77524, acc 0.375\n",
      "2017-04-03T19:21:30.290793: step 1540, loss 1.73288, acc 0.4375\n",
      "2017-04-03T19:21:30.492741: step 1541, loss 1.87563, acc 0.25\n",
      "2017-04-03T19:21:30.689124: step 1542, loss 1.78762, acc 0.390625\n",
      "2017-04-03T19:21:30.889473: step 1543, loss 1.75669, acc 0.375\n",
      "2017-04-03T19:21:31.082711: step 1544, loss 1.87818, acc 0.296875\n",
      "2017-04-03T19:21:31.285940: step 1545, loss 1.56767, acc 0.5\n",
      "2017-04-03T19:21:31.480332: step 1546, loss 1.93128, acc 0.296875\n",
      "2017-04-03T19:21:31.680949: step 1547, loss 1.89314, acc 0.28125\n",
      "2017-04-03T19:21:31.878725: step 1548, loss 1.85573, acc 0.34375\n",
      "2017-04-03T19:21:32.078561: step 1549, loss 1.84007, acc 0.234375\n",
      "2017-04-03T19:21:32.273360: step 1550, loss 1.83948, acc 0.40625\n",
      "2017-04-03T19:21:32.475637: step 1551, loss 1.86531, acc 0.28125\n",
      "2017-04-03T19:21:32.669516: step 1552, loss 1.87068, acc 0.359375\n",
      "2017-04-03T19:21:32.869239: step 1553, loss 1.60324, acc 0.4375\n",
      "2017-04-03T19:21:33.060394: step 1554, loss 1.7266, acc 0.3125\n",
      "2017-04-03T19:21:33.259163: step 1555, loss 1.73414, acc 0.34375\n",
      "2017-04-03T19:21:33.453669: step 1556, loss 1.69043, acc 0.40625\n",
      "2017-04-03T19:21:33.660664: step 1557, loss 1.9326, acc 0.328125\n",
      "2017-04-03T19:21:33.854237: step 1558, loss 1.76596, acc 0.40625\n",
      "2017-04-03T19:21:34.052605: step 1559, loss 1.9923, acc 0.21875\n",
      "2017-04-03T19:21:34.249648: step 1560, loss 2.0268, acc 0.359375\n",
      "2017-04-03T19:21:34.449218: step 1561, loss 1.85741, acc 0.34375\n",
      "2017-04-03T19:21:34.646185: step 1562, loss 1.83486, acc 0.359375\n",
      "2017-04-03T19:21:34.849097: step 1563, loss 1.82654, acc 0.359375\n",
      "2017-04-03T19:21:35.046304: step 1564, loss 1.77065, acc 0.390625\n",
      "2017-04-03T19:21:35.247709: step 1565, loss 1.80348, acc 0.390625\n",
      "2017-04-03T19:21:35.445879: step 1566, loss 1.79325, acc 0.3125\n",
      "2017-04-03T19:21:35.645579: step 1567, loss 1.78496, acc 0.375\n",
      "2017-04-03T19:21:35.840165: step 1568, loss 1.76895, acc 0.34375\n",
      "2017-04-03T19:21:36.042786: step 1569, loss 1.9638, acc 0.25\n",
      "2017-04-03T19:21:36.234943: step 1570, loss 1.95333, acc 0.25\n",
      "2017-04-03T19:21:36.439782: step 1571, loss 1.781, acc 0.296875\n",
      "2017-04-03T19:21:36.636371: step 1572, loss 1.77623, acc 0.328125\n",
      "2017-04-03T19:21:36.842239: step 1573, loss 1.87216, acc 0.4375\n",
      "2017-04-03T19:21:37.035492: step 1574, loss 2.03804, acc 0.265625\n",
      "2017-04-03T19:21:37.239061: step 1575, loss 1.91961, acc 0.359375\n",
      "2017-04-03T19:21:37.436759: step 1576, loss 1.83962, acc 0.40625\n",
      "2017-04-03T19:21:37.640124: step 1577, loss 1.85536, acc 0.296875\n",
      "2017-04-03T19:21:37.836814: step 1578, loss 1.94451, acc 0.390625\n",
      "2017-04-03T19:21:38.038878: step 1579, loss 1.7671, acc 0.375\n",
      "2017-04-03T19:21:38.236179: step 1580, loss 1.53826, acc 0.40625\n",
      "2017-04-03T19:21:38.439768: step 1581, loss 1.58791, acc 0.4375\n",
      "2017-04-03T19:21:38.635234: step 1582, loss 1.79889, acc 0.265625\n",
      "2017-04-03T19:21:38.835678: step 1583, loss 1.91536, acc 0.34375\n",
      "2017-04-03T19:21:39.033981: step 1584, loss 1.85653, acc 0.25\n",
      "2017-04-03T19:21:39.237688: step 1585, loss 1.65215, acc 0.375\n",
      "2017-04-03T19:21:39.436612: step 1586, loss 2.07439, acc 0.28125\n",
      "2017-04-03T19:21:39.640327: step 1587, loss 1.67677, acc 0.421875\n",
      "2017-04-03T19:21:39.832697: step 1588, loss 1.85729, acc 0.296875\n",
      "2017-04-03T19:21:40.034232: step 1589, loss 1.87602, acc 0.296875\n",
      "2017-04-03T19:21:40.229425: step 1590, loss 2.02661, acc 0.234375\n",
      "2017-04-03T19:21:40.431437: step 1591, loss 1.65022, acc 0.484375\n",
      "2017-04-03T19:21:40.628478: step 1592, loss 1.67589, acc 0.453125\n",
      "2017-04-03T19:21:40.825198: step 1593, loss 1.65574, acc 0.390625\n",
      "2017-04-03T19:21:41.025064: step 1594, loss 1.77411, acc 0.3125\n",
      "2017-04-03T19:21:41.221661: step 1595, loss 1.63856, acc 0.390625\n",
      "2017-04-03T19:21:41.415107: step 1596, loss 1.70106, acc 0.375\n",
      "2017-04-03T19:21:41.616550: step 1597, loss 1.94696, acc 0.28125\n",
      "2017-04-03T19:21:41.810769: step 1598, loss 1.8261, acc 0.328125\n",
      "2017-04-03T19:21:42.014129: step 1599, loss 1.86095, acc 0.28125\n",
      "2017-04-03T19:21:42.206188: step 1600, loss 2.00596, acc 0.359375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:21:44.193561: step 1600, loss 1.86591, acc 0.3315\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-1600\n",
      "\n",
      "2017-04-03T19:21:44.525401: step 1601, loss 1.77304, acc 0.4375\n",
      "2017-04-03T19:21:44.718332: step 1602, loss 1.92644, acc 0.34375\n",
      "2017-04-03T19:21:44.925366: step 1603, loss 2.11362, acc 0.25\n",
      "2017-04-03T19:21:45.118951: step 1604, loss 1.91091, acc 0.265625\n",
      "2017-04-03T19:21:45.323658: step 1605, loss 1.88269, acc 0.375\n",
      "2017-04-03T19:21:45.520558: step 1606, loss 1.81651, acc 0.296875\n",
      "2017-04-03T19:21:45.724204: step 1607, loss 1.8767, acc 0.3125\n",
      "2017-04-03T19:21:45.919767: step 1608, loss 1.79641, acc 0.3125\n",
      "2017-04-03T19:21:46.119238: step 1609, loss 2.04244, acc 0.203125\n",
      "2017-04-03T19:21:46.316395: step 1610, loss 1.85312, acc 0.375\n",
      "2017-04-03T19:21:46.517995: step 1611, loss 1.81802, acc 0.390625\n",
      "2017-04-03T19:21:46.713877: step 1612, loss 2.03684, acc 0.234375\n",
      "2017-04-03T19:21:46.918874: step 1613, loss 1.61344, acc 0.359375\n",
      "2017-04-03T19:21:47.113812: step 1614, loss 1.67786, acc 0.390625\n",
      "2017-04-03T19:21:47.314690: step 1615, loss 1.90668, acc 0.3125\n",
      "2017-04-03T19:21:47.511952: step 1616, loss 1.79353, acc 0.34375\n",
      "2017-04-03T19:21:47.715813: step 1617, loss 1.98275, acc 0.265625\n",
      "2017-04-03T19:21:47.912541: step 1618, loss 1.87131, acc 0.390625\n",
      "2017-04-03T19:21:48.114844: step 1619, loss 1.77436, acc 0.265625\n",
      "2017-04-03T19:21:48.311801: step 1620, loss 2.09124, acc 0.296875\n",
      "2017-04-03T19:21:48.517141: step 1621, loss 1.73703, acc 0.390625\n",
      "2017-04-03T19:21:48.715743: step 1622, loss 1.81487, acc 0.265625\n",
      "2017-04-03T19:21:48.917808: step 1623, loss 1.77619, acc 0.390625\n",
      "2017-04-03T19:21:49.116400: step 1624, loss 1.75171, acc 0.359375\n",
      "2017-04-03T19:21:49.315379: step 1625, loss 1.97246, acc 0.28125\n",
      "2017-04-03T19:21:49.513558: step 1626, loss 1.92158, acc 0.296875\n",
      "2017-04-03T19:21:49.711565: step 1627, loss 2.22881, acc 0.234375\n",
      "2017-04-03T19:21:49.908147: step 1628, loss 1.72553, acc 0.40625\n",
      "2017-04-03T19:21:50.110830: step 1629, loss 1.59837, acc 0.453125\n",
      "2017-04-03T19:21:50.304326: step 1630, loss 1.80923, acc 0.34375\n",
      "2017-04-03T19:21:50.506470: step 1631, loss 1.86794, acc 0.34375\n",
      "2017-04-03T19:21:50.706231: step 1632, loss 1.8401, acc 0.34375\n",
      "2017-04-03T19:21:50.907177: step 1633, loss 1.70465, acc 0.34375\n",
      "2017-04-03T19:21:51.105376: step 1634, loss 1.75298, acc 0.359375\n",
      "2017-04-03T19:21:51.306347: step 1635, loss 1.94441, acc 0.25\n",
      "2017-04-03T19:21:51.502144: step 1636, loss 1.82454, acc 0.390625\n",
      "2017-04-03T19:21:51.707467: step 1637, loss 1.73547, acc 0.359375\n",
      "2017-04-03T19:21:51.905525: step 1638, loss 1.91929, acc 0.359375\n",
      "2017-04-03T19:21:52.103704: step 1639, loss 1.99671, acc 0.328125\n",
      "2017-04-03T19:21:52.299470: step 1640, loss 1.80654, acc 0.3125\n",
      "2017-04-03T19:21:52.503897: step 1641, loss 1.74405, acc 0.359375\n",
      "2017-04-03T19:21:52.698369: step 1642, loss 1.82332, acc 0.34375\n",
      "2017-04-03T19:21:52.898497: step 1643, loss 1.85829, acc 0.28125\n",
      "2017-04-03T19:21:53.097760: step 1644, loss 1.84675, acc 0.390625\n",
      "2017-04-03T19:21:53.298371: step 1645, loss 1.84914, acc 0.359375\n",
      "2017-04-03T19:21:53.496062: step 1646, loss 1.81829, acc 0.359375\n",
      "2017-04-03T19:21:53.696999: step 1647, loss 1.92732, acc 0.28125\n",
      "2017-04-03T19:21:53.892960: step 1648, loss 1.74249, acc 0.375\n",
      "2017-04-03T19:21:54.093034: step 1649, loss 1.97636, acc 0.296875\n",
      "2017-04-03T19:21:54.293114: step 1650, loss 2.00429, acc 0.328125\n",
      "2017-04-03T19:21:54.495125: step 1651, loss 1.76438, acc 0.375\n",
      "2017-04-03T19:21:54.724284: step 1652, loss 1.88087, acc 0.3125\n",
      "2017-04-03T19:21:54.926639: step 1653, loss 1.78632, acc 0.3125\n",
      "2017-04-03T19:21:55.132172: step 1654, loss 1.94258, acc 0.34375\n",
      "2017-04-03T19:21:55.334528: step 1655, loss 2.01629, acc 0.21875\n",
      "2017-04-03T19:21:55.537318: step 1656, loss 1.61691, acc 0.4375\n",
      "2017-04-03T19:21:55.741186: step 1657, loss 1.84066, acc 0.40625\n",
      "2017-04-03T19:21:55.942866: step 1658, loss 1.8795, acc 0.34375\n",
      "2017-04-03T19:21:56.146127: step 1659, loss 1.61531, acc 0.453125\n",
      "2017-04-03T19:21:56.346701: step 1660, loss 2.11694, acc 0.28125\n",
      "2017-04-03T19:21:56.547754: step 1661, loss 1.81423, acc 0.296875\n",
      "2017-04-03T19:21:56.752942: step 1662, loss 1.64528, acc 0.4375\n",
      "2017-04-03T19:21:56.954100: step 1663, loss 1.70775, acc 0.453125\n",
      "2017-04-03T19:21:57.157709: step 1664, loss 1.94222, acc 0.296875\n",
      "2017-04-03T19:21:57.357701: step 1665, loss 1.54479, acc 0.4375\n",
      "2017-04-03T19:21:57.558753: step 1666, loss 1.79202, acc 0.375\n",
      "2017-04-03T19:21:57.758571: step 1667, loss 1.67376, acc 0.4375\n",
      "2017-04-03T19:21:57.958388: step 1668, loss 2.03313, acc 0.328125\n",
      "2017-04-03T19:21:58.157054: step 1669, loss 1.86988, acc 0.328125\n",
      "2017-04-03T19:21:58.359762: step 1670, loss 1.85857, acc 0.3125\n",
      "2017-04-03T19:21:58.556840: step 1671, loss 1.90264, acc 0.34375\n",
      "2017-04-03T19:21:58.761849: step 1672, loss 1.81683, acc 0.375\n",
      "2017-04-03T19:21:58.955469: step 1673, loss 1.97679, acc 0.328125\n",
      "2017-04-03T19:21:59.155919: step 1674, loss 1.66388, acc 0.328125\n",
      "2017-04-03T19:21:59.350924: step 1675, loss 1.73778, acc 0.40625\n",
      "2017-04-03T19:21:59.556260: step 1676, loss 1.72626, acc 0.328125\n",
      "2017-04-03T19:21:59.754073: step 1677, loss 1.67388, acc 0.375\n",
      "2017-04-03T19:21:59.955226: step 1678, loss 2.13977, acc 0.296875\n",
      "2017-04-03T19:22:00.151142: step 1679, loss 1.91968, acc 0.25\n",
      "2017-04-03T19:22:00.353256: step 1680, loss 1.98823, acc 0.25\n",
      "2017-04-03T19:22:00.546519: step 1681, loss 1.61256, acc 0.421875\n",
      "2017-04-03T19:22:00.753675: step 1682, loss 1.89987, acc 0.375\n",
      "2017-04-03T19:22:00.951045: step 1683, loss 1.69536, acc 0.34375\n",
      "2017-04-03T19:22:01.154736: step 1684, loss 1.84543, acc 0.40625\n",
      "2017-04-03T19:22:01.350015: step 1685, loss 1.69349, acc 0.40625\n",
      "2017-04-03T19:22:01.554814: step 1686, loss 1.78243, acc 0.3125\n",
      "2017-04-03T19:22:01.754893: step 1687, loss 1.89676, acc 0.390625\n",
      "2017-04-03T19:22:01.957409: step 1688, loss 1.95348, acc 0.34375\n",
      "2017-04-03T19:22:02.100612: step 1689, loss 1.6632, acc 0.34375\n",
      "2017-04-03T19:22:02.310197: step 1690, loss 1.59785, acc 0.4375\n",
      "2017-04-03T19:22:02.506933: step 1691, loss 1.67195, acc 0.4375\n",
      "2017-04-03T19:22:02.707442: step 1692, loss 1.68677, acc 0.34375\n",
      "2017-04-03T19:22:02.901058: step 1693, loss 1.82814, acc 0.28125\n",
      "2017-04-03T19:22:03.103890: step 1694, loss 1.68698, acc 0.390625\n",
      "2017-04-03T19:22:03.303282: step 1695, loss 1.60074, acc 0.453125\n",
      "2017-04-03T19:22:03.509121: step 1696, loss 1.72096, acc 0.40625\n",
      "2017-04-03T19:22:03.703102: step 1697, loss 1.89044, acc 0.3125\n",
      "2017-04-03T19:22:03.909355: step 1698, loss 1.80316, acc 0.359375\n",
      "2017-04-03T19:22:04.110778: step 1699, loss 1.67506, acc 0.46875\n",
      "2017-04-03T19:22:04.315305: step 1700, loss 1.55218, acc 0.390625\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:22:06.266864: step 1700, loss 1.86014, acc 0.32025\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-1700\n",
      "\n",
      "2017-04-03T19:22:06.592085: step 1701, loss 1.70366, acc 0.28125\n",
      "2017-04-03T19:22:06.789345: step 1702, loss 1.70378, acc 0.453125\n",
      "2017-04-03T19:22:06.999544: step 1703, loss 1.7667, acc 0.3125\n",
      "2017-04-03T19:22:07.198267: step 1704, loss 1.68485, acc 0.390625\n",
      "2017-04-03T19:22:07.401632: step 1705, loss 1.66518, acc 0.46875\n",
      "2017-04-03T19:22:07.594174: step 1706, loss 1.71441, acc 0.34375\n",
      "2017-04-03T19:22:07.793088: step 1707, loss 1.64637, acc 0.421875\n",
      "2017-04-03T19:22:07.992048: step 1708, loss 1.67456, acc 0.4375\n",
      "2017-04-03T19:22:08.193096: step 1709, loss 1.71745, acc 0.421875\n",
      "2017-04-03T19:22:08.383671: step 1710, loss 1.79074, acc 0.4375\n",
      "2017-04-03T19:22:08.593233: step 1711, loss 1.83855, acc 0.296875\n",
      "2017-04-03T19:22:08.789099: step 1712, loss 1.57776, acc 0.5\n",
      "2017-04-03T19:22:08.993345: step 1713, loss 1.85074, acc 0.28125\n",
      "2017-04-03T19:22:09.192376: step 1714, loss 1.65684, acc 0.390625\n",
      "2017-04-03T19:22:09.399599: step 1715, loss 1.77227, acc 0.328125\n",
      "2017-04-03T19:22:09.595289: step 1716, loss 1.69438, acc 0.40625\n",
      "2017-04-03T19:22:09.799387: step 1717, loss 1.58852, acc 0.484375\n",
      "2017-04-03T19:22:09.993463: step 1718, loss 1.49607, acc 0.53125\n",
      "2017-04-03T19:22:10.197978: step 1719, loss 1.74838, acc 0.421875\n",
      "2017-04-03T19:22:10.396665: step 1720, loss 1.57054, acc 0.390625\n",
      "2017-04-03T19:22:10.602144: step 1721, loss 1.97673, acc 0.359375\n",
      "2017-04-03T19:22:10.801510: step 1722, loss 1.68937, acc 0.375\n",
      "2017-04-03T19:22:11.012340: step 1723, loss 1.74592, acc 0.328125\n",
      "2017-04-03T19:22:11.206061: step 1724, loss 1.78687, acc 0.296875\n",
      "2017-04-03T19:22:11.412468: step 1725, loss 1.79445, acc 0.40625\n",
      "2017-04-03T19:22:11.608284: step 1726, loss 1.54205, acc 0.453125\n",
      "2017-04-03T19:22:11.811129: step 1727, loss 1.86764, acc 0.3125\n",
      "2017-04-03T19:22:12.006248: step 1728, loss 1.61076, acc 0.40625\n",
      "2017-04-03T19:22:12.213002: step 1729, loss 1.69135, acc 0.34375\n",
      "2017-04-03T19:22:12.413581: step 1730, loss 1.7779, acc 0.453125\n",
      "2017-04-03T19:22:12.616242: step 1731, loss 1.82321, acc 0.359375\n",
      "2017-04-03T19:22:12.813266: step 1732, loss 1.54383, acc 0.484375\n",
      "2017-04-03T19:22:13.020935: step 1733, loss 1.58826, acc 0.390625\n",
      "2017-04-03T19:22:13.214040: step 1734, loss 1.64008, acc 0.390625\n",
      "2017-04-03T19:22:13.420087: step 1735, loss 1.6984, acc 0.359375\n",
      "2017-04-03T19:22:13.615049: step 1736, loss 1.85204, acc 0.359375\n",
      "2017-04-03T19:22:13.818932: step 1737, loss 1.768, acc 0.484375\n",
      "2017-04-03T19:22:14.012823: step 1738, loss 1.65296, acc 0.34375\n",
      "2017-04-03T19:22:14.216903: step 1739, loss 1.80619, acc 0.40625\n",
      "2017-04-03T19:22:14.409529: step 1740, loss 1.59692, acc 0.390625\n",
      "2017-04-03T19:22:14.616164: step 1741, loss 2.01041, acc 0.3125\n",
      "2017-04-03T19:22:14.815712: step 1742, loss 1.61597, acc 0.40625\n",
      "2017-04-03T19:22:15.021902: step 1743, loss 1.81067, acc 0.375\n",
      "2017-04-03T19:22:15.218133: step 1744, loss 1.84636, acc 0.34375\n",
      "2017-04-03T19:22:15.422047: step 1745, loss 1.68196, acc 0.46875\n",
      "2017-04-03T19:22:15.618083: step 1746, loss 1.82529, acc 0.328125\n",
      "2017-04-03T19:22:15.822304: step 1747, loss 1.83442, acc 0.375\n",
      "2017-04-03T19:22:16.020140: step 1748, loss 1.65035, acc 0.4375\n",
      "2017-04-03T19:22:16.226627: step 1749, loss 1.74381, acc 0.375\n",
      "2017-04-03T19:22:16.424903: step 1750, loss 1.89196, acc 0.34375\n",
      "2017-04-03T19:22:16.630667: step 1751, loss 1.65334, acc 0.390625\n",
      "2017-04-03T19:22:16.828255: step 1752, loss 1.82042, acc 0.25\n",
      "2017-04-03T19:22:17.029359: step 1753, loss 1.68955, acc 0.359375\n",
      "2017-04-03T19:22:17.227055: step 1754, loss 1.60128, acc 0.5\n",
      "2017-04-03T19:22:17.435618: step 1755, loss 1.71714, acc 0.359375\n",
      "2017-04-03T19:22:17.634931: step 1756, loss 1.76997, acc 0.40625\n",
      "2017-04-03T19:22:17.838092: step 1757, loss 1.67365, acc 0.421875\n",
      "2017-04-03T19:22:18.034318: step 1758, loss 1.7296, acc 0.421875\n",
      "2017-04-03T19:22:18.232290: step 1759, loss 1.78485, acc 0.375\n",
      "2017-04-03T19:22:18.430619: step 1760, loss 1.87875, acc 0.359375\n",
      "2017-04-03T19:22:18.635371: step 1761, loss 1.74274, acc 0.375\n",
      "2017-04-03T19:22:18.828990: step 1762, loss 1.68697, acc 0.375\n",
      "2017-04-03T19:22:19.036252: step 1763, loss 1.55816, acc 0.484375\n",
      "2017-04-03T19:22:19.229962: step 1764, loss 1.62257, acc 0.4375\n",
      "2017-04-03T19:22:19.428404: step 1765, loss 1.68064, acc 0.359375\n",
      "2017-04-03T19:22:19.621804: step 1766, loss 1.80533, acc 0.28125\n",
      "2017-04-03T19:22:19.830494: step 1767, loss 1.66387, acc 0.40625\n",
      "2017-04-03T19:22:20.024806: step 1768, loss 1.72371, acc 0.375\n",
      "2017-04-03T19:22:20.230980: step 1769, loss 1.79447, acc 0.3125\n",
      "2017-04-03T19:22:20.425637: step 1770, loss 1.89852, acc 0.34375\n",
      "2017-04-03T19:22:20.629696: step 1771, loss 1.75882, acc 0.3125\n",
      "2017-04-03T19:22:20.829402: step 1772, loss 1.54847, acc 0.4375\n",
      "2017-04-03T19:22:21.034546: step 1773, loss 1.80428, acc 0.390625\n",
      "2017-04-03T19:22:21.230051: step 1774, loss 1.47792, acc 0.5\n",
      "2017-04-03T19:22:21.429431: step 1775, loss 1.84395, acc 0.359375\n",
      "2017-04-03T19:22:21.621407: step 1776, loss 1.72915, acc 0.421875\n",
      "2017-04-03T19:22:21.826464: step 1777, loss 1.68975, acc 0.453125\n",
      "2017-04-03T19:22:22.021904: step 1778, loss 1.74171, acc 0.28125\n",
      "2017-04-03T19:22:22.227280: step 1779, loss 1.76785, acc 0.421875\n",
      "2017-04-03T19:22:22.421599: step 1780, loss 1.80477, acc 0.3125\n",
      "2017-04-03T19:22:22.625229: step 1781, loss 1.89311, acc 0.3125\n",
      "2017-04-03T19:22:22.822709: step 1782, loss 1.83909, acc 0.25\n",
      "2017-04-03T19:22:23.027098: step 1783, loss 1.56488, acc 0.484375\n",
      "2017-04-03T19:22:23.222807: step 1784, loss 1.68673, acc 0.484375\n",
      "2017-04-03T19:22:23.429417: step 1785, loss 1.6692, acc 0.390625\n",
      "2017-04-03T19:22:23.623960: step 1786, loss 1.74375, acc 0.3125\n",
      "2017-04-03T19:22:23.831360: step 1787, loss 1.79478, acc 0.359375\n",
      "2017-04-03T19:22:24.028630: step 1788, loss 1.66868, acc 0.421875\n",
      "2017-04-03T19:22:24.229940: step 1789, loss 1.55085, acc 0.5\n",
      "2017-04-03T19:22:24.425692: step 1790, loss 1.70795, acc 0.375\n",
      "2017-04-03T19:22:24.633434: step 1791, loss 1.75299, acc 0.421875\n",
      "2017-04-03T19:22:24.829158: step 1792, loss 1.46525, acc 0.453125\n",
      "2017-04-03T19:22:25.034309: step 1793, loss 1.85002, acc 0.34375\n",
      "2017-04-03T19:22:25.233540: step 1794, loss 1.78396, acc 0.375\n",
      "2017-04-03T19:22:25.438295: step 1795, loss 1.69348, acc 0.34375\n",
      "2017-04-03T19:22:25.632541: step 1796, loss 1.52539, acc 0.46875\n",
      "2017-04-03T19:22:25.833242: step 1797, loss 1.7061, acc 0.359375\n",
      "2017-04-03T19:22:26.030022: step 1798, loss 1.81015, acc 0.359375\n",
      "2017-04-03T19:22:26.234875: step 1799, loss 1.78344, acc 0.296875\n",
      "2017-04-03T19:22:26.433570: step 1800, loss 1.64454, acc 0.4375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:22:28.404025: step 1800, loss 1.85739, acc 0.33775\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-1800\n",
      "\n",
      "2017-04-03T19:22:28.731854: step 1801, loss 1.8152, acc 0.4375\n",
      "2017-04-03T19:22:28.924994: step 1802, loss 1.72322, acc 0.328125\n",
      "2017-04-03T19:22:29.125988: step 1803, loss 1.80058, acc 0.375\n",
      "2017-04-03T19:22:29.321920: step 1804, loss 1.71932, acc 0.453125\n",
      "2017-04-03T19:22:29.525317: step 1805, loss 1.74677, acc 0.375\n",
      "2017-04-03T19:22:29.723434: step 1806, loss 1.6504, acc 0.375\n",
      "2017-04-03T19:22:29.928808: step 1807, loss 1.86931, acc 0.265625\n",
      "2017-04-03T19:22:30.125333: step 1808, loss 1.77809, acc 0.296875\n",
      "2017-04-03T19:22:30.325639: step 1809, loss 1.71297, acc 0.34375\n",
      "2017-04-03T19:22:30.519964: step 1810, loss 1.77285, acc 0.375\n",
      "2017-04-03T19:22:30.730396: step 1811, loss 1.54722, acc 0.484375\n",
      "2017-04-03T19:22:30.921757: step 1812, loss 1.62297, acc 0.4375\n",
      "2017-04-03T19:22:31.125683: step 1813, loss 1.63676, acc 0.4375\n",
      "2017-04-03T19:22:31.317282: step 1814, loss 1.75424, acc 0.359375\n",
      "2017-04-03T19:22:31.520825: step 1815, loss 1.79178, acc 0.40625\n",
      "2017-04-03T19:22:31.714624: step 1816, loss 1.89492, acc 0.328125\n",
      "2017-04-03T19:22:31.917697: step 1817, loss 1.78255, acc 0.359375\n",
      "2017-04-03T19:22:32.112488: step 1818, loss 1.85938, acc 0.3125\n",
      "2017-04-03T19:22:32.307115: step 1819, loss 1.62497, acc 0.4375\n",
      "2017-04-03T19:22:32.501764: step 1820, loss 1.58483, acc 0.484375\n",
      "2017-04-03T19:22:32.702555: step 1821, loss 1.92851, acc 0.328125\n",
      "2017-04-03T19:22:32.896400: step 1822, loss 1.60857, acc 0.390625\n",
      "2017-04-03T19:22:33.101147: step 1823, loss 1.74812, acc 0.359375\n",
      "2017-04-03T19:22:33.294243: step 1824, loss 1.73613, acc 0.328125\n",
      "2017-04-03T19:22:33.498870: step 1825, loss 1.69091, acc 0.3125\n",
      "2017-04-03T19:22:33.692999: step 1826, loss 1.78, acc 0.359375\n",
      "2017-04-03T19:22:33.899510: step 1827, loss 1.67324, acc 0.40625\n",
      "2017-04-03T19:22:34.095742: step 1828, loss 1.68037, acc 0.359375\n",
      "2017-04-03T19:22:34.300190: step 1829, loss 1.66748, acc 0.359375\n",
      "2017-04-03T19:22:34.497733: step 1830, loss 1.79169, acc 0.328125\n",
      "2017-04-03T19:22:34.699787: step 1831, loss 1.70161, acc 0.453125\n",
      "2017-04-03T19:22:34.892957: step 1832, loss 1.65801, acc 0.375\n",
      "2017-04-03T19:22:35.093974: step 1833, loss 1.8317, acc 0.375\n",
      "2017-04-03T19:22:35.292126: step 1834, loss 1.60934, acc 0.328125\n",
      "2017-04-03T19:22:35.494042: step 1835, loss 1.63853, acc 0.453125\n",
      "2017-04-03T19:22:35.688368: step 1836, loss 1.88724, acc 0.390625\n",
      "2017-04-03T19:22:35.892996: step 1837, loss 1.43009, acc 0.515625\n",
      "2017-04-03T19:22:36.088864: step 1838, loss 1.56322, acc 0.421875\n",
      "2017-04-03T19:22:36.289673: step 1839, loss 1.73132, acc 0.390625\n",
      "2017-04-03T19:22:36.485871: step 1840, loss 1.84856, acc 0.3125\n",
      "2017-04-03T19:22:36.692418: step 1841, loss 1.75918, acc 0.40625\n",
      "2017-04-03T19:22:36.888341: step 1842, loss 1.86456, acc 0.28125\n",
      "2017-04-03T19:22:37.093736: step 1843, loss 1.77883, acc 0.390625\n",
      "2017-04-03T19:22:37.289899: step 1844, loss 1.68318, acc 0.34375\n",
      "2017-04-03T19:22:37.496425: step 1845, loss 1.76394, acc 0.359375\n",
      "2017-04-03T19:22:37.688892: step 1846, loss 1.66954, acc 0.328125\n",
      "2017-04-03T19:22:37.889196: step 1847, loss 1.82239, acc 0.375\n",
      "2017-04-03T19:22:38.086040: step 1848, loss 1.7196, acc 0.375\n",
      "2017-04-03T19:22:38.288984: step 1849, loss 1.67043, acc 0.421875\n",
      "2017-04-03T19:22:38.485539: step 1850, loss 1.69178, acc 0.421875\n",
      "2017-04-03T19:22:38.689498: step 1851, loss 1.79619, acc 0.421875\n",
      "2017-04-03T19:22:38.888468: step 1852, loss 1.92498, acc 0.359375\n",
      "2017-04-03T19:22:39.089805: step 1853, loss 1.71769, acc 0.375\n",
      "2017-04-03T19:22:39.283200: step 1854, loss 1.71106, acc 0.5\n",
      "2017-04-03T19:22:39.485401: step 1855, loss 1.68528, acc 0.46875\n",
      "2017-04-03T19:22:39.675859: step 1856, loss 1.98174, acc 0.3125\n",
      "2017-04-03T19:22:39.881284: step 1857, loss 1.83322, acc 0.3125\n",
      "2017-04-03T19:22:40.077248: step 1858, loss 1.57255, acc 0.421875\n",
      "2017-04-03T19:22:40.279238: step 1859, loss 1.68459, acc 0.40625\n",
      "2017-04-03T19:22:40.470951: step 1860, loss 1.73028, acc 0.359375\n",
      "2017-04-03T19:22:40.674525: step 1861, loss 1.52368, acc 0.5\n",
      "2017-04-03T19:22:40.865797: step 1862, loss 1.95175, acc 0.328125\n",
      "2017-04-03T19:22:41.063605: step 1863, loss 1.84563, acc 0.328125\n",
      "2017-04-03T19:22:41.259204: step 1864, loss 1.77956, acc 0.4375\n",
      "2017-04-03T19:22:41.461297: step 1865, loss 1.85795, acc 0.40625\n",
      "2017-04-03T19:22:41.657839: step 1866, loss 1.91225, acc 0.34375\n",
      "2017-04-03T19:22:41.861007: step 1867, loss 1.72587, acc 0.359375\n",
      "2017-04-03T19:22:42.056514: step 1868, loss 1.88574, acc 0.28125\n",
      "2017-04-03T19:22:42.257217: step 1869, loss 1.87456, acc 0.3125\n",
      "2017-04-03T19:22:42.453149: step 1870, loss 1.69375, acc 0.390625\n",
      "2017-04-03T19:22:42.656647: step 1871, loss 1.56307, acc 0.4375\n",
      "2017-04-03T19:22:42.853338: step 1872, loss 1.90276, acc 0.3125\n",
      "2017-04-03T19:22:43.062809: step 1873, loss 1.68976, acc 0.34375\n",
      "2017-04-03T19:22:43.256319: step 1874, loss 1.64462, acc 0.390625\n",
      "2017-04-03T19:22:43.460798: step 1875, loss 1.77206, acc 0.34375\n",
      "2017-04-03T19:22:43.653330: step 1876, loss 1.70687, acc 0.359375\n",
      "2017-04-03T19:22:43.858732: step 1877, loss 1.93153, acc 0.25\n",
      "2017-04-03T19:22:44.056233: step 1878, loss 1.57067, acc 0.5\n",
      "2017-04-03T19:22:44.262175: step 1879, loss 1.68633, acc 0.5\n",
      "2017-04-03T19:22:44.454089: step 1880, loss 1.71865, acc 0.390625\n",
      "2017-04-03T19:22:44.657702: step 1881, loss 1.68831, acc 0.421875\n",
      "2017-04-03T19:22:44.852629: step 1882, loss 1.80152, acc 0.4375\n",
      "2017-04-03T19:22:45.052396: step 1883, loss 1.67565, acc 0.328125\n",
      "2017-04-03T19:22:45.245241: step 1884, loss 1.76173, acc 0.34375\n",
      "2017-04-03T19:22:45.449923: step 1885, loss 1.76901, acc 0.296875\n",
      "2017-04-03T19:22:45.642210: step 1886, loss 1.77286, acc 0.421875\n",
      "2017-04-03T19:22:45.845256: step 1887, loss 1.91583, acc 0.34375\n",
      "2017-04-03T19:22:46.037500: step 1888, loss 1.59793, acc 0.4375\n",
      "2017-04-03T19:22:46.240265: step 1889, loss 1.75818, acc 0.453125\n",
      "2017-04-03T19:22:46.433923: step 1890, loss 1.78328, acc 0.40625\n",
      "2017-04-03T19:22:46.637132: step 1891, loss 1.7067, acc 0.375\n",
      "2017-04-03T19:22:46.828757: step 1892, loss 1.71781, acc 0.4375\n",
      "2017-04-03T19:22:47.029435: step 1893, loss 1.53854, acc 0.390625\n",
      "2017-04-03T19:22:47.225901: step 1894, loss 1.81066, acc 0.296875\n",
      "2017-04-03T19:22:47.424764: step 1895, loss 1.66969, acc 0.4375\n",
      "2017-04-03T19:22:47.620598: step 1896, loss 1.55098, acc 0.4375\n",
      "2017-04-03T19:22:47.822347: step 1897, loss 1.76776, acc 0.328125\n",
      "2017-04-03T19:22:48.016678: step 1898, loss 1.78248, acc 0.421875\n",
      "2017-04-03T19:22:48.214862: step 1899, loss 1.63235, acc 0.390625\n",
      "2017-04-03T19:22:48.410516: step 1900, loss 1.56913, acc 0.484375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:22:50.346482: step 1900, loss 1.86364, acc 0.32925\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-1900\n",
      "\n",
      "2017-04-03T19:22:50.681968: step 1901, loss 2.04889, acc 0.3125\n",
      "2017-04-03T19:22:50.876470: step 1902, loss 2.02325, acc 0.34375\n",
      "2017-04-03T19:22:51.082726: step 1903, loss 1.7581, acc 0.40625\n",
      "2017-04-03T19:22:51.282542: step 1904, loss 1.77234, acc 0.390625\n",
      "2017-04-03T19:22:51.485694: step 1905, loss 1.72559, acc 0.390625\n",
      "2017-04-03T19:22:51.684901: step 1906, loss 1.8339, acc 0.328125\n",
      "2017-04-03T19:22:51.889492: step 1907, loss 1.77639, acc 0.390625\n",
      "2017-04-03T19:22:52.084317: step 1908, loss 1.67867, acc 0.453125\n",
      "2017-04-03T19:22:52.291915: step 1909, loss 1.65779, acc 0.453125\n",
      "2017-04-03T19:22:52.487645: step 1910, loss 1.66432, acc 0.4375\n",
      "2017-04-03T19:22:52.689043: step 1911, loss 1.76593, acc 0.4375\n",
      "2017-04-03T19:22:52.886613: step 1912, loss 1.90649, acc 0.375\n",
      "2017-04-03T19:22:53.089672: step 1913, loss 1.64307, acc 0.421875\n",
      "2017-04-03T19:22:53.283073: step 1914, loss 1.80457, acc 0.359375\n",
      "2017-04-03T19:22:53.488486: step 1915, loss 1.81296, acc 0.328125\n",
      "2017-04-03T19:22:53.676233: step 1916, loss 1.65536, acc 0.34375\n",
      "2017-04-03T19:22:53.877356: step 1917, loss 1.79246, acc 0.328125\n",
      "2017-04-03T19:22:54.073423: step 1918, loss 1.68072, acc 0.421875\n",
      "2017-04-03T19:22:54.272714: step 1919, loss 1.52363, acc 0.421875\n",
      "2017-04-03T19:22:54.466618: step 1920, loss 1.55649, acc 0.40625\n",
      "2017-04-03T19:22:54.670891: step 1921, loss 1.94572, acc 0.265625\n",
      "2017-04-03T19:22:54.870609: step 1922, loss 1.57259, acc 0.453125\n",
      "2017-04-03T19:22:55.070501: step 1923, loss 1.72009, acc 0.4375\n",
      "2017-04-03T19:22:55.262591: step 1924, loss 1.71592, acc 0.4375\n",
      "2017-04-03T19:22:55.466542: step 1925, loss 1.51077, acc 0.53125\n",
      "2017-04-03T19:22:55.658845: step 1926, loss 1.60976, acc 0.40625\n",
      "2017-04-03T19:22:55.859671: step 1927, loss 1.61936, acc 0.4375\n",
      "2017-04-03T19:22:56.054832: step 1928, loss 2.01486, acc 0.328125\n",
      "2017-04-03T19:22:56.256677: step 1929, loss 1.82232, acc 0.328125\n",
      "2017-04-03T19:22:56.448928: step 1930, loss 1.53612, acc 0.5\n",
      "2017-04-03T19:22:56.650324: step 1931, loss 1.69035, acc 0.40625\n",
      "2017-04-03T19:22:56.843476: step 1932, loss 1.72296, acc 0.421875\n",
      "2017-04-03T19:22:57.043717: step 1933, loss 1.58058, acc 0.484375\n",
      "2017-04-03T19:22:57.238180: step 1934, loss 1.63376, acc 0.40625\n",
      "2017-04-03T19:22:57.441486: step 1935, loss 1.80894, acc 0.296875\n",
      "2017-04-03T19:22:57.636370: step 1936, loss 2.03148, acc 0.3125\n",
      "2017-04-03T19:22:57.843728: step 1937, loss 1.79291, acc 0.390625\n",
      "2017-04-03T19:22:58.035221: step 1938, loss 1.70552, acc 0.359375\n",
      "2017-04-03T19:22:58.236340: step 1939, loss 1.81269, acc 0.328125\n",
      "2017-04-03T19:22:58.426887: step 1940, loss 1.71689, acc 0.421875\n",
      "2017-04-03T19:22:58.629407: step 1941, loss 1.75217, acc 0.375\n",
      "2017-04-03T19:22:58.823662: step 1942, loss 1.70804, acc 0.328125\n",
      "2017-04-03T19:22:59.028601: step 1943, loss 1.76809, acc 0.34375\n",
      "2017-04-03T19:22:59.222931: step 1944, loss 1.78503, acc 0.328125\n",
      "2017-04-03T19:22:59.425132: step 1945, loss 1.6302, acc 0.4375\n",
      "2017-04-03T19:22:59.621231: step 1946, loss 1.64227, acc 0.390625\n",
      "2017-04-03T19:22:59.829013: step 1947, loss 1.67715, acc 0.390625\n",
      "2017-04-03T19:23:00.025287: step 1948, loss 1.73219, acc 0.453125\n",
      "2017-04-03T19:23:00.226962: step 1949, loss 1.66024, acc 0.4375\n",
      "2017-04-03T19:23:00.420584: step 1950, loss 1.56935, acc 0.46875\n",
      "2017-04-03T19:23:00.622434: step 1951, loss 1.61578, acc 0.46875\n",
      "2017-04-03T19:23:00.820081: step 1952, loss 1.80825, acc 0.390625\n",
      "2017-04-03T19:23:01.025448: step 1953, loss 1.72065, acc 0.421875\n",
      "2017-04-03T19:23:01.216379: step 1954, loss 1.90786, acc 0.390625\n",
      "2017-04-03T19:23:01.420860: step 1955, loss 1.5992, acc 0.390625\n",
      "2017-04-03T19:23:01.619798: step 1956, loss 1.54809, acc 0.546875\n",
      "2017-04-03T19:23:01.820372: step 1957, loss 1.71646, acc 0.328125\n",
      "2017-04-03T19:23:02.013229: step 1958, loss 1.70941, acc 0.390625\n",
      "2017-04-03T19:23:02.214580: step 1959, loss 1.75541, acc 0.34375\n",
      "2017-04-03T19:23:02.412700: step 1960, loss 1.64261, acc 0.40625\n",
      "2017-04-03T19:23:02.614534: step 1961, loss 1.84747, acc 0.375\n",
      "2017-04-03T19:23:02.810697: step 1962, loss 1.70358, acc 0.4375\n",
      "2017-04-03T19:23:03.013722: step 1963, loss 1.77463, acc 0.375\n",
      "2017-04-03T19:23:03.209936: step 1964, loss 1.62901, acc 0.34375\n",
      "2017-04-03T19:23:03.413768: step 1965, loss 1.79237, acc 0.34375\n",
      "2017-04-03T19:23:03.608746: step 1966, loss 1.76284, acc 0.390625\n",
      "2017-04-03T19:23:03.810838: step 1967, loss 1.74908, acc 0.40625\n",
      "2017-04-03T19:23:04.004195: step 1968, loss 1.71626, acc 0.40625\n",
      "2017-04-03T19:23:04.207030: step 1969, loss 1.80273, acc 0.34375\n",
      "2017-04-03T19:23:04.400660: step 1970, loss 1.96524, acc 0.25\n",
      "2017-04-03T19:23:04.603665: step 1971, loss 1.51993, acc 0.40625\n",
      "2017-04-03T19:23:04.800003: step 1972, loss 1.75992, acc 0.359375\n",
      "2017-04-03T19:23:05.005057: step 1973, loss 2.05465, acc 0.265625\n",
      "2017-04-03T19:23:05.195481: step 1974, loss 1.58286, acc 0.453125\n",
      "2017-04-03T19:23:05.398439: step 1975, loss 1.69313, acc 0.40625\n",
      "2017-04-03T19:23:05.596550: step 1976, loss 1.72644, acc 0.421875\n",
      "2017-04-03T19:23:05.798556: step 1977, loss 1.94425, acc 0.296875\n",
      "2017-04-03T19:23:05.996725: step 1978, loss 1.50658, acc 0.484375\n",
      "2017-04-03T19:23:06.197124: step 1979, loss 1.78449, acc 0.375\n",
      "2017-04-03T19:23:06.388944: step 1980, loss 1.50074, acc 0.5\n",
      "2017-04-03T19:23:06.598008: step 1981, loss 1.91198, acc 0.34375\n",
      "2017-04-03T19:23:06.793291: step 1982, loss 1.78985, acc 0.296875\n",
      "2017-04-03T19:23:07.000013: step 1983, loss 1.58793, acc 0.484375\n",
      "2017-04-03T19:23:07.194577: step 1984, loss 1.66629, acc 0.40625\n",
      "2017-04-03T19:23:07.394479: step 1985, loss 1.86374, acc 0.296875\n",
      "2017-04-03T19:23:07.588942: step 1986, loss 1.72299, acc 0.390625\n",
      "2017-04-03T19:23:07.789040: step 1987, loss 1.83429, acc 0.328125\n",
      "2017-04-03T19:23:07.984360: step 1988, loss 1.62933, acc 0.453125\n",
      "2017-04-03T19:23:08.184110: step 1989, loss 1.48988, acc 0.453125\n",
      "2017-04-03T19:23:08.374322: step 1990, loss 1.55383, acc 0.390625\n",
      "2017-04-03T19:23:08.576920: step 1991, loss 1.47454, acc 0.5\n",
      "2017-04-03T19:23:08.771183: step 1992, loss 1.55001, acc 0.4375\n",
      "2017-04-03T19:23:08.973020: step 1993, loss 1.60942, acc 0.359375\n",
      "2017-04-03T19:23:09.169906: step 1994, loss 1.93413, acc 0.359375\n",
      "2017-04-03T19:23:09.371529: step 1995, loss 2.00434, acc 0.3125\n",
      "2017-04-03T19:23:09.566121: step 1996, loss 1.70249, acc 0.40625\n",
      "2017-04-03T19:23:09.770381: step 1997, loss 1.72497, acc 0.3125\n",
      "2017-04-03T19:23:09.964977: step 1998, loss 1.68577, acc 0.40625\n",
      "2017-04-03T19:23:10.169377: step 1999, loss 1.70296, acc 0.4375\n",
      "2017-04-03T19:23:10.365204: step 2000, loss 1.66418, acc 0.4375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:23:12.360977: step 2000, loss 1.86895, acc 0.31225\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-2000\n",
      "\n",
      "2017-04-03T19:23:12.697504: step 2001, loss 1.78089, acc 0.34375\n",
      "2017-04-03T19:23:12.891581: step 2002, loss 1.94192, acc 0.375\n",
      "2017-04-03T19:23:13.096810: step 2003, loss 1.86254, acc 0.328125\n",
      "2017-04-03T19:23:13.294293: step 2004, loss 1.73613, acc 0.34375\n",
      "2017-04-03T19:23:13.497215: step 2005, loss 1.4934, acc 0.453125\n",
      "2017-04-03T19:23:13.694944: step 2006, loss 1.80227, acc 0.390625\n",
      "2017-04-03T19:23:13.893541: step 2007, loss 1.64048, acc 0.484375\n",
      "2017-04-03T19:23:14.084641: step 2008, loss 1.74759, acc 0.40625\n",
      "2017-04-03T19:23:14.286288: step 2009, loss 1.80955, acc 0.3125\n",
      "2017-04-03T19:23:14.477728: step 2010, loss 1.67201, acc 0.390625\n",
      "2017-04-03T19:23:14.680323: step 2011, loss 1.73196, acc 0.40625\n",
      "2017-04-03T19:23:14.875123: step 2012, loss 1.72115, acc 0.34375\n",
      "2017-04-03T19:23:15.076638: step 2013, loss 1.72985, acc 0.421875\n",
      "2017-04-03T19:23:15.270375: step 2014, loss 1.78773, acc 0.328125\n",
      "2017-04-03T19:23:15.470711: step 2015, loss 1.80976, acc 0.359375\n",
      "2017-04-03T19:23:15.663882: step 2016, loss 1.90637, acc 0.359375\n",
      "2017-04-03T19:23:15.864284: step 2017, loss 1.86969, acc 0.28125\n",
      "2017-04-03T19:23:16.057121: step 2018, loss 1.59868, acc 0.375\n",
      "2017-04-03T19:23:16.261667: step 2019, loss 1.94644, acc 0.296875\n",
      "2017-04-03T19:23:16.453089: step 2020, loss 1.60842, acc 0.421875\n",
      "2017-04-03T19:23:16.652668: step 2021, loss 1.7205, acc 0.4375\n",
      "2017-04-03T19:23:16.848878: step 2022, loss 1.96088, acc 0.328125\n",
      "2017-04-03T19:23:17.051191: step 2023, loss 1.73122, acc 0.40625\n",
      "2017-04-03T19:23:17.249408: step 2024, loss 1.72916, acc 0.34375\n",
      "2017-04-03T19:23:17.453424: step 2025, loss 1.72632, acc 0.375\n",
      "2017-04-03T19:23:17.646722: step 2026, loss 1.80405, acc 0.28125\n",
      "2017-04-03T19:23:17.850522: step 2027, loss 1.81998, acc 0.34375\n",
      "2017-04-03T19:23:18.046020: step 2028, loss 1.64372, acc 0.4375\n",
      "2017-04-03T19:23:18.247265: step 2029, loss 1.78691, acc 0.328125\n",
      "2017-04-03T19:23:18.440571: step 2030, loss 1.73784, acc 0.375\n",
      "2017-04-03T19:23:18.643134: step 2031, loss 1.72754, acc 0.390625\n",
      "2017-04-03T19:23:18.833621: step 2032, loss 1.80223, acc 0.296875\n",
      "2017-04-03T19:23:19.035556: step 2033, loss 1.69432, acc 0.375\n",
      "2017-04-03T19:23:19.230532: step 2034, loss 1.54653, acc 0.453125\n",
      "2017-04-03T19:23:19.434408: step 2035, loss 1.7004, acc 0.453125\n",
      "2017-04-03T19:23:19.628662: step 2036, loss 1.60336, acc 0.40625\n",
      "2017-04-03T19:23:19.828960: step 2037, loss 1.66015, acc 0.421875\n",
      "2017-04-03T19:23:20.023856: step 2038, loss 1.60479, acc 0.40625\n",
      "2017-04-03T19:23:20.229726: step 2039, loss 1.64663, acc 0.40625\n",
      "2017-04-03T19:23:20.425276: step 2040, loss 1.60537, acc 0.4375\n",
      "2017-04-03T19:23:20.630290: step 2041, loss 1.8138, acc 0.296875\n",
      "2017-04-03T19:23:20.821048: step 2042, loss 1.6912, acc 0.421875\n",
      "2017-04-03T19:23:21.024050: step 2043, loss 1.71703, acc 0.375\n",
      "2017-04-03T19:23:21.215788: step 2044, loss 1.64633, acc 0.296875\n",
      "2017-04-03T19:23:21.415788: step 2045, loss 1.86946, acc 0.34375\n",
      "2017-04-03T19:23:21.613274: step 2046, loss 1.80286, acc 0.359375\n",
      "2017-04-03T19:23:21.818495: step 2047, loss 1.74956, acc 0.375\n",
      "2017-04-03T19:23:22.015076: step 2048, loss 1.83261, acc 0.375\n",
      "2017-04-03T19:23:22.220593: step 2049, loss 1.7613, acc 0.34375\n",
      "2017-04-03T19:23:22.415276: step 2050, loss 1.78366, acc 0.46875\n",
      "2017-04-03T19:23:22.619178: step 2051, loss 1.93294, acc 0.265625\n",
      "2017-04-03T19:23:22.812067: step 2052, loss 1.64779, acc 0.453125\n",
      "2017-04-03T19:23:23.012978: step 2053, loss 1.77053, acc 0.421875\n",
      "2017-04-03T19:23:23.206893: step 2054, loss 1.5737, acc 0.515625\n",
      "2017-04-03T19:23:23.410553: step 2055, loss 1.64903, acc 0.40625\n",
      "2017-04-03T19:23:23.602008: step 2056, loss 1.58453, acc 0.4375\n",
      "2017-04-03T19:23:23.804830: step 2057, loss 1.79354, acc 0.359375\n",
      "2017-04-03T19:23:24.004117: step 2058, loss 1.93477, acc 0.328125\n",
      "2017-04-03T19:23:24.206321: step 2059, loss 1.54038, acc 0.46875\n",
      "2017-04-03T19:23:24.402386: step 2060, loss 1.85161, acc 0.296875\n",
      "2017-04-03T19:23:24.605799: step 2061, loss 1.77388, acc 0.515625\n",
      "2017-04-03T19:23:24.803256: step 2062, loss 1.8395, acc 0.375\n",
      "2017-04-03T19:23:25.009525: step 2063, loss 1.69, acc 0.453125\n",
      "2017-04-03T19:23:25.203940: step 2064, loss 2.06643, acc 0.1875\n",
      "2017-04-03T19:23:25.410015: step 2065, loss 1.70053, acc 0.390625\n",
      "2017-04-03T19:23:25.602719: step 2066, loss 1.83789, acc 0.375\n",
      "2017-04-03T19:23:25.804030: step 2067, loss 1.84547, acc 0.359375\n",
      "2017-04-03T19:23:25.989995: step 2068, loss 1.63131, acc 0.3125\n",
      "2017-04-03T19:23:26.192248: step 2069, loss 1.80284, acc 0.359375\n",
      "2017-04-03T19:23:26.385444: step 2070, loss 1.91883, acc 0.3125\n",
      "2017-04-03T19:23:26.600972: step 2071, loss 1.57887, acc 0.46875\n",
      "2017-04-03T19:23:26.796939: step 2072, loss 1.72774, acc 0.34375\n",
      "2017-04-03T19:23:27.000749: step 2073, loss 1.69577, acc 0.390625\n",
      "2017-04-03T19:23:27.193691: step 2074, loss 1.76804, acc 0.3125\n",
      "2017-04-03T19:23:27.398731: step 2075, loss 1.93429, acc 0.296875\n",
      "2017-04-03T19:23:27.592678: step 2076, loss 1.6973, acc 0.375\n",
      "2017-04-03T19:23:27.794009: step 2077, loss 1.83178, acc 0.28125\n",
      "2017-04-03T19:23:27.989065: step 2078, loss 1.8387, acc 0.28125\n",
      "2017-04-03T19:23:28.188531: step 2079, loss 1.6986, acc 0.375\n",
      "2017-04-03T19:23:28.386518: step 2080, loss 1.57251, acc 0.46875\n",
      "2017-04-03T19:23:28.585917: step 2081, loss 1.90182, acc 0.3125\n",
      "2017-04-03T19:23:28.780192: step 2082, loss 1.80335, acc 0.40625\n",
      "2017-04-03T19:23:28.982936: step 2083, loss 1.85582, acc 0.34375\n",
      "2017-04-03T19:23:29.178138: step 2084, loss 1.66992, acc 0.390625\n",
      "2017-04-03T19:23:29.380669: step 2085, loss 1.82947, acc 0.390625\n",
      "2017-04-03T19:23:29.573182: step 2086, loss 1.70958, acc 0.453125\n",
      "2017-04-03T19:23:29.772494: step 2087, loss 1.55702, acc 0.34375\n",
      "2017-04-03T19:23:29.965619: step 2088, loss 1.61328, acc 0.40625\n",
      "2017-04-03T19:23:30.166679: step 2089, loss 1.60543, acc 0.375\n",
      "2017-04-03T19:23:30.359003: step 2090, loss 1.89278, acc 0.40625\n",
      "2017-04-03T19:23:30.564740: step 2091, loss 1.95164, acc 0.34375\n",
      "2017-04-03T19:23:30.763158: step 2092, loss 1.91112, acc 0.328125\n",
      "2017-04-03T19:23:30.968111: step 2093, loss 1.76051, acc 0.390625\n",
      "2017-04-03T19:23:31.166447: step 2094, loss 1.52057, acc 0.46875\n",
      "2017-04-03T19:23:31.368023: step 2095, loss 1.47041, acc 0.46875\n",
      "2017-04-03T19:23:31.563006: step 2096, loss 1.80809, acc 0.328125\n",
      "2017-04-03T19:23:31.765382: step 2097, loss 1.59575, acc 0.53125\n",
      "2017-04-03T19:23:31.961507: step 2098, loss 1.67667, acc 0.3125\n",
      "2017-04-03T19:23:32.159651: step 2099, loss 1.78119, acc 0.328125\n",
      "2017-04-03T19:23:32.353962: step 2100, loss 1.6872, acc 0.34375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:23:34.337732: step 2100, loss 1.85641, acc 0.32575\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-2100\n",
      "\n",
      "2017-04-03T19:23:34.681642: step 2101, loss 1.4657, acc 0.4375\n",
      "2017-04-03T19:23:34.876470: step 2102, loss 1.92886, acc 0.34375\n",
      "2017-04-03T19:23:35.080981: step 2103, loss 1.51546, acc 0.5\n",
      "2017-04-03T19:23:35.278182: step 2104, loss 1.97791, acc 0.265625\n",
      "2017-04-03T19:23:35.477556: step 2105, loss 1.70219, acc 0.421875\n",
      "2017-04-03T19:23:35.671922: step 2106, loss 1.83463, acc 0.359375\n",
      "2017-04-03T19:23:35.872340: step 2107, loss 1.62601, acc 0.40625\n",
      "2017-04-03T19:23:36.072761: step 2108, loss 1.885, acc 0.25\n",
      "2017-04-03T19:23:36.276935: step 2109, loss 1.75255, acc 0.421875\n",
      "2017-04-03T19:23:36.472457: step 2110, loss 2.06514, acc 0.296875\n",
      "2017-04-03T19:23:36.673228: step 2111, loss 1.78627, acc 0.34375\n",
      "2017-04-03T19:23:36.865391: step 2112, loss 1.9433, acc 0.34375\n",
      "2017-04-03T19:23:37.067450: step 2113, loss 1.72005, acc 0.328125\n",
      "2017-04-03T19:23:37.263755: step 2114, loss 1.68912, acc 0.328125\n",
      "2017-04-03T19:23:37.464471: step 2115, loss 1.62024, acc 0.421875\n",
      "2017-04-03T19:23:37.656779: step 2116, loss 1.69119, acc 0.40625\n",
      "2017-04-03T19:23:37.858782: step 2117, loss 1.41716, acc 0.453125\n",
      "2017-04-03T19:23:38.054796: step 2118, loss 1.78447, acc 0.4375\n",
      "2017-04-03T19:23:38.260442: step 2119, loss 1.93276, acc 0.34375\n",
      "2017-04-03T19:23:38.454676: step 2120, loss 1.67375, acc 0.46875\n",
      "2017-04-03T19:23:38.658526: step 2121, loss 1.82188, acc 0.359375\n",
      "2017-04-03T19:23:38.851563: step 2122, loss 1.8901, acc 0.25\n",
      "2017-04-03T19:23:39.053210: step 2123, loss 1.742, acc 0.375\n",
      "2017-04-03T19:23:39.243352: step 2124, loss 1.92292, acc 0.25\n",
      "2017-04-03T19:23:39.445798: step 2125, loss 1.80741, acc 0.34375\n",
      "2017-04-03T19:23:39.644435: step 2126, loss 1.63647, acc 0.484375\n",
      "2017-04-03T19:23:39.846621: step 2127, loss 1.93209, acc 0.265625\n",
      "2017-04-03T19:23:40.042414: step 2128, loss 1.74738, acc 0.34375\n",
      "2017-04-03T19:23:40.250227: step 2129, loss 1.80473, acc 0.296875\n",
      "2017-04-03T19:23:40.449058: step 2130, loss 1.95339, acc 0.3125\n",
      "2017-04-03T19:23:40.652637: step 2131, loss 1.71174, acc 0.34375\n",
      "2017-04-03T19:23:40.845923: step 2132, loss 1.81436, acc 0.359375\n",
      "2017-04-03T19:23:41.051751: step 2133, loss 1.55069, acc 0.515625\n",
      "2017-04-03T19:23:41.242946: step 2134, loss 1.68249, acc 0.34375\n",
      "2017-04-03T19:23:41.451553: step 2135, loss 1.97851, acc 0.3125\n",
      "2017-04-03T19:23:41.644672: step 2136, loss 1.83249, acc 0.296875\n",
      "2017-04-03T19:23:41.847872: step 2137, loss 1.71933, acc 0.34375\n",
      "2017-04-03T19:23:42.040843: step 2138, loss 1.64389, acc 0.390625\n",
      "2017-04-03T19:23:42.246322: step 2139, loss 1.76988, acc 0.328125\n",
      "2017-04-03T19:23:42.443557: step 2140, loss 1.88167, acc 0.25\n",
      "2017-04-03T19:23:42.648875: step 2141, loss 1.58472, acc 0.375\n",
      "2017-04-03T19:23:42.842244: step 2142, loss 1.82425, acc 0.375\n",
      "2017-04-03T19:23:43.045154: step 2143, loss 1.79116, acc 0.375\n",
      "2017-04-03T19:23:43.243486: step 2144, loss 1.65995, acc 0.359375\n",
      "2017-04-03T19:23:43.449788: step 2145, loss 1.66797, acc 0.421875\n",
      "2017-04-03T19:23:43.646621: step 2146, loss 1.77279, acc 0.28125\n",
      "2017-04-03T19:23:43.849878: step 2147, loss 1.68571, acc 0.359375\n",
      "2017-04-03T19:23:44.045406: step 2148, loss 1.69953, acc 0.421875\n",
      "2017-04-03T19:23:44.249101: step 2149, loss 1.64471, acc 0.46875\n",
      "2017-04-03T19:23:44.445026: step 2150, loss 1.68269, acc 0.421875\n",
      "2017-04-03T19:23:44.649449: step 2151, loss 1.66787, acc 0.46875\n",
      "2017-04-03T19:23:44.847947: step 2152, loss 1.65088, acc 0.4375\n",
      "2017-04-03T19:23:45.054524: step 2153, loss 1.49357, acc 0.359375\n",
      "2017-04-03T19:23:45.248627: step 2154, loss 1.70468, acc 0.375\n",
      "2017-04-03T19:23:45.453856: step 2155, loss 1.54061, acc 0.40625\n",
      "2017-04-03T19:23:45.650372: step 2156, loss 1.71692, acc 0.359375\n",
      "2017-04-03T19:23:45.853451: step 2157, loss 1.75306, acc 0.34375\n",
      "2017-04-03T19:23:46.049515: step 2158, loss 1.81294, acc 0.34375\n",
      "2017-04-03T19:23:46.255645: step 2159, loss 1.59704, acc 0.40625\n",
      "2017-04-03T19:23:46.451026: step 2160, loss 1.68118, acc 0.40625\n",
      "2017-04-03T19:23:46.656226: step 2161, loss 1.58913, acc 0.375\n",
      "2017-04-03T19:23:46.846804: step 2162, loss 1.86928, acc 0.421875\n",
      "2017-04-03T19:23:47.049329: step 2163, loss 1.60401, acc 0.40625\n",
      "2017-04-03T19:23:47.245016: step 2164, loss 1.67669, acc 0.40625\n",
      "2017-04-03T19:23:47.448833: step 2165, loss 1.70779, acc 0.421875\n",
      "2017-04-03T19:23:47.641226: step 2166, loss 1.79631, acc 0.40625\n",
      "2017-04-03T19:23:47.850008: step 2167, loss 1.5241, acc 0.421875\n",
      "2017-04-03T19:23:48.045986: step 2168, loss 1.70906, acc 0.328125\n",
      "2017-04-03T19:23:48.251492: step 2169, loss 1.80882, acc 0.328125\n",
      "2017-04-03T19:23:48.443764: step 2170, loss 1.90507, acc 0.359375\n",
      "2017-04-03T19:23:48.645833: step 2171, loss 1.63833, acc 0.390625\n",
      "2017-04-03T19:23:48.840062: step 2172, loss 1.78381, acc 0.296875\n",
      "2017-04-03T19:23:49.043684: step 2173, loss 1.71645, acc 0.390625\n",
      "2017-04-03T19:23:49.237313: step 2174, loss 1.58978, acc 0.359375\n",
      "2017-04-03T19:23:49.439138: step 2175, loss 1.71161, acc 0.375\n",
      "2017-04-03T19:23:49.633094: step 2176, loss 1.86539, acc 0.296875\n",
      "2017-04-03T19:23:49.837978: step 2177, loss 1.89346, acc 0.421875\n",
      "2017-04-03T19:23:50.033057: step 2178, loss 1.80143, acc 0.34375\n",
      "2017-04-03T19:23:50.241784: step 2179, loss 1.60078, acc 0.453125\n",
      "2017-04-03T19:23:50.439562: step 2180, loss 1.9073, acc 0.34375\n",
      "2017-04-03T19:23:50.645515: step 2181, loss 1.61781, acc 0.421875\n",
      "2017-04-03T19:23:50.841220: step 2182, loss 1.63404, acc 0.40625\n",
      "2017-04-03T19:23:51.049580: step 2183, loss 1.70698, acc 0.390625\n",
      "2017-04-03T19:23:51.244697: step 2184, loss 1.79634, acc 0.4375\n",
      "2017-04-03T19:23:51.451408: step 2185, loss 1.75262, acc 0.3125\n",
      "2017-04-03T19:23:51.648345: step 2186, loss 1.96582, acc 0.328125\n",
      "2017-04-03T19:23:51.853287: step 2187, loss 1.64319, acc 0.359375\n",
      "2017-04-03T19:23:52.054764: step 2188, loss 1.70213, acc 0.46875\n",
      "2017-04-03T19:23:52.260340: step 2189, loss 1.94645, acc 0.265625\n",
      "2017-04-03T19:23:52.464144: step 2190, loss 1.7195, acc 0.390625\n",
      "2017-04-03T19:23:52.666727: step 2191, loss 1.69582, acc 0.390625\n",
      "2017-04-03T19:23:52.871745: step 2192, loss 1.66313, acc 0.40625\n",
      "2017-04-03T19:23:53.074619: step 2193, loss 1.82717, acc 0.28125\n",
      "2017-04-03T19:23:53.282957: step 2194, loss 1.74743, acc 0.34375\n",
      "2017-04-03T19:23:53.487645: step 2195, loss 1.61768, acc 0.375\n",
      "2017-04-03T19:23:53.688777: step 2196, loss 1.43995, acc 0.453125\n",
      "2017-04-03T19:23:53.891361: step 2197, loss 1.84407, acc 0.296875\n",
      "2017-04-03T19:23:54.098041: step 2198, loss 1.90013, acc 0.328125\n",
      "2017-04-03T19:23:54.299190: step 2199, loss 1.72726, acc 0.421875\n",
      "2017-04-03T19:23:54.506703: step 2200, loss 1.74504, acc 0.40625\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:23:56.438243: step 2200, loss 1.84201, acc 0.33775\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-2200\n",
      "\n",
      "2017-04-03T19:23:56.781778: step 2201, loss 1.70966, acc 0.390625\n",
      "2017-04-03T19:23:56.980527: step 2202, loss 1.76679, acc 0.390625\n",
      "2017-04-03T19:23:57.185012: step 2203, loss 1.74222, acc 0.375\n",
      "2017-04-03T19:23:57.382689: step 2204, loss 1.70484, acc 0.46875\n",
      "2017-04-03T19:23:57.586406: step 2205, loss 1.77894, acc 0.328125\n",
      "2017-04-03T19:23:57.786873: step 2206, loss 1.75735, acc 0.421875\n",
      "2017-04-03T19:23:57.993704: step 2207, loss 1.71895, acc 0.390625\n",
      "2017-04-03T19:23:58.191040: step 2208, loss 1.95139, acc 0.265625\n",
      "2017-04-03T19:23:58.392660: step 2209, loss 1.71116, acc 0.328125\n",
      "2017-04-03T19:23:58.588942: step 2210, loss 1.65005, acc 0.390625\n",
      "2017-04-03T19:23:58.795190: step 2211, loss 1.89522, acc 0.296875\n",
      "2017-04-03T19:23:58.991326: step 2212, loss 1.84464, acc 0.375\n",
      "2017-04-03T19:23:59.200974: step 2213, loss 1.53758, acc 0.46875\n",
      "2017-04-03T19:23:59.413293: step 2214, loss 1.8028, acc 0.375\n",
      "2017-04-03T19:23:59.618743: step 2215, loss 1.46342, acc 0.546875\n",
      "2017-04-03T19:23:59.822535: step 2216, loss 1.66401, acc 0.390625\n",
      "2017-04-03T19:24:00.026907: step 2217, loss 1.772, acc 0.390625\n",
      "2017-04-03T19:24:00.234037: step 2218, loss 1.63911, acc 0.359375\n",
      "2017-04-03T19:24:00.442614: step 2219, loss 1.69573, acc 0.453125\n",
      "2017-04-03T19:24:00.645793: step 2220, loss 1.89092, acc 0.328125\n",
      "2017-04-03T19:24:00.849746: step 2221, loss 1.71953, acc 0.359375\n",
      "2017-04-03T19:24:01.053111: step 2222, loss 1.81668, acc 0.328125\n",
      "2017-04-03T19:24:01.259391: step 2223, loss 1.6901, acc 0.546875\n",
      "2017-04-03T19:24:01.466554: step 2224, loss 1.60672, acc 0.4375\n",
      "2017-04-03T19:24:01.665364: step 2225, loss 1.81875, acc 0.328125\n",
      "2017-04-03T19:24:01.868855: step 2226, loss 1.64596, acc 0.328125\n",
      "2017-04-03T19:24:02.063928: step 2227, loss 1.81183, acc 0.4375\n",
      "2017-04-03T19:24:02.271239: step 2228, loss 1.64188, acc 0.375\n",
      "2017-04-03T19:24:02.471788: step 2229, loss 1.67484, acc 0.515625\n",
      "2017-04-03T19:24:02.675608: step 2230, loss 1.85024, acc 0.328125\n",
      "2017-04-03T19:24:02.876269: step 2231, loss 1.79348, acc 0.3125\n",
      "2017-04-03T19:24:03.081723: step 2232, loss 1.65743, acc 0.375\n",
      "2017-04-03T19:24:03.283449: step 2233, loss 1.69841, acc 0.375\n",
      "2017-04-03T19:24:03.491672: step 2234, loss 1.83918, acc 0.34375\n",
      "2017-04-03T19:24:03.696713: step 2235, loss 1.73897, acc 0.421875\n",
      "2017-04-03T19:24:03.901866: step 2236, loss 1.77971, acc 0.359375\n",
      "2017-04-03T19:24:04.106837: step 2237, loss 1.53496, acc 0.546875\n",
      "2017-04-03T19:24:04.311038: step 2238, loss 1.77577, acc 0.375\n",
      "2017-04-03T19:24:04.511797: step 2239, loss 1.60663, acc 0.484375\n",
      "2017-04-03T19:24:04.718473: step 2240, loss 1.69282, acc 0.390625\n",
      "2017-04-03T19:24:04.927823: step 2241, loss 2.01902, acc 0.375\n",
      "2017-04-03T19:24:05.134418: step 2242, loss 1.66636, acc 0.40625\n",
      "2017-04-03T19:24:05.336911: step 2243, loss 1.86323, acc 0.359375\n",
      "2017-04-03T19:24:05.541922: step 2244, loss 1.8975, acc 0.359375\n",
      "2017-04-03T19:24:05.751159: step 2245, loss 1.93738, acc 0.328125\n",
      "2017-04-03T19:24:05.953152: step 2246, loss 1.58525, acc 0.421875\n",
      "2017-04-03T19:24:06.158938: step 2247, loss 1.56962, acc 0.421875\n",
      "2017-04-03T19:24:06.360480: step 2248, loss 1.75424, acc 0.359375\n",
      "2017-04-03T19:24:06.567125: step 2249, loss 1.73515, acc 0.4375\n",
      "2017-04-03T19:24:06.777569: step 2250, loss 1.68988, acc 0.34375\n",
      "2017-04-03T19:24:06.992243: step 2251, loss 1.70999, acc 0.4375\n",
      "2017-04-03T19:24:07.142981: step 2252, loss 1.6081, acc 0.40625\n",
      "2017-04-03T19:24:07.350880: step 2253, loss 1.43031, acc 0.53125\n",
      "2017-04-03T19:24:07.550232: step 2254, loss 1.59358, acc 0.421875\n",
      "2017-04-03T19:24:07.756805: step 2255, loss 1.6357, acc 0.40625\n",
      "2017-04-03T19:24:07.953824: step 2256, loss 1.47118, acc 0.5625\n",
      "2017-04-03T19:24:08.160542: step 2257, loss 1.69163, acc 0.375\n",
      "2017-04-03T19:24:08.362492: step 2258, loss 1.72697, acc 0.453125\n",
      "2017-04-03T19:24:08.568434: step 2259, loss 1.70245, acc 0.34375\n",
      "2017-04-03T19:24:08.770558: step 2260, loss 1.51842, acc 0.484375\n",
      "2017-04-03T19:24:08.977317: step 2261, loss 1.81084, acc 0.375\n",
      "2017-04-03T19:24:09.186843: step 2262, loss 1.52847, acc 0.421875\n",
      "2017-04-03T19:24:09.388481: step 2263, loss 1.69117, acc 0.390625\n",
      "2017-04-03T19:24:09.591837: step 2264, loss 1.45078, acc 0.515625\n",
      "2017-04-03T19:24:09.796362: step 2265, loss 1.49549, acc 0.484375\n",
      "2017-04-03T19:24:10.002275: step 2266, loss 1.50325, acc 0.484375\n",
      "2017-04-03T19:24:10.206578: step 2267, loss 1.53373, acc 0.40625\n",
      "2017-04-03T19:24:10.415856: step 2268, loss 1.58902, acc 0.46875\n",
      "2017-04-03T19:24:10.617315: step 2269, loss 1.47275, acc 0.5\n",
      "2017-04-03T19:24:10.820328: step 2270, loss 1.51886, acc 0.53125\n",
      "2017-04-03T19:24:11.023953: step 2271, loss 1.55087, acc 0.46875\n",
      "2017-04-03T19:24:11.232104: step 2272, loss 1.51954, acc 0.46875\n",
      "2017-04-03T19:24:11.435276: step 2273, loss 1.62197, acc 0.375\n",
      "2017-04-03T19:24:11.647766: step 2274, loss 1.63349, acc 0.4375\n",
      "2017-04-03T19:24:11.856662: step 2275, loss 1.61175, acc 0.390625\n",
      "2017-04-03T19:24:12.064059: step 2276, loss 1.63318, acc 0.390625\n",
      "2017-04-03T19:24:12.268194: step 2277, loss 1.447, acc 0.546875\n",
      "2017-04-03T19:24:12.470068: step 2278, loss 1.58264, acc 0.421875\n",
      "2017-04-03T19:24:12.674938: step 2279, loss 1.53606, acc 0.453125\n",
      "2017-04-03T19:24:12.889449: step 2280, loss 1.34994, acc 0.5625\n",
      "2017-04-03T19:24:13.095043: step 2281, loss 1.42513, acc 0.484375\n",
      "2017-04-03T19:24:13.297452: step 2282, loss 1.48603, acc 0.421875\n",
      "2017-04-03T19:24:13.499543: step 2283, loss 1.60022, acc 0.421875\n",
      "2017-04-03T19:24:13.703049: step 2284, loss 1.62596, acc 0.421875\n",
      "2017-04-03T19:24:13.908748: step 2285, loss 1.49853, acc 0.484375\n",
      "2017-04-03T19:24:14.112616: step 2286, loss 1.63836, acc 0.390625\n",
      "2017-04-03T19:24:14.318266: step 2287, loss 1.64993, acc 0.40625\n",
      "2017-04-03T19:24:14.526605: step 2288, loss 1.65884, acc 0.4375\n",
      "2017-04-03T19:24:14.736548: step 2289, loss 1.72284, acc 0.5\n",
      "2017-04-03T19:24:14.940177: step 2290, loss 1.73539, acc 0.375\n",
      "2017-04-03T19:24:15.151662: step 2291, loss 1.5941, acc 0.375\n",
      "2017-04-03T19:24:15.354016: step 2292, loss 1.6294, acc 0.46875\n",
      "2017-04-03T19:24:15.557292: step 2293, loss 1.67079, acc 0.359375\n",
      "2017-04-03T19:24:15.761065: step 2294, loss 1.56259, acc 0.5\n",
      "2017-04-03T19:24:15.970543: step 2295, loss 1.53942, acc 0.53125\n",
      "2017-04-03T19:24:16.174514: step 2296, loss 1.48838, acc 0.453125\n",
      "2017-04-03T19:24:16.379160: step 2297, loss 1.5099, acc 0.40625\n",
      "2017-04-03T19:24:16.583606: step 2298, loss 1.63689, acc 0.40625\n",
      "2017-04-03T19:24:16.785318: step 2299, loss 1.85095, acc 0.375\n",
      "2017-04-03T19:24:16.990938: step 2300, loss 1.29568, acc 0.546875\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:24:18.932910: step 2300, loss 1.83174, acc 0.344\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-2300\n",
      "\n",
      "2017-04-03T19:24:19.270876: step 2301, loss 1.47699, acc 0.40625\n",
      "2017-04-03T19:24:19.465032: step 2302, loss 1.47615, acc 0.53125\n",
      "2017-04-03T19:24:19.674527: step 2303, loss 1.42842, acc 0.484375\n",
      "2017-04-03T19:24:19.870656: step 2304, loss 1.62086, acc 0.359375\n",
      "2017-04-03T19:24:20.076722: step 2305, loss 1.63903, acc 0.515625\n",
      "2017-04-03T19:24:20.274905: step 2306, loss 1.55612, acc 0.453125\n",
      "2017-04-03T19:24:20.479511: step 2307, loss 1.62654, acc 0.46875\n",
      "2017-04-03T19:24:20.679590: step 2308, loss 1.52554, acc 0.453125\n",
      "2017-04-03T19:24:20.887797: step 2309, loss 1.75983, acc 0.328125\n",
      "2017-04-03T19:24:21.085310: step 2310, loss 1.51914, acc 0.484375\n",
      "2017-04-03T19:24:21.293837: step 2311, loss 1.50786, acc 0.390625\n",
      "2017-04-03T19:24:21.485373: step 2312, loss 1.42695, acc 0.515625\n",
      "2017-04-03T19:24:21.691562: step 2313, loss 1.61144, acc 0.4375\n",
      "2017-04-03T19:24:21.888810: step 2314, loss 1.55913, acc 0.4375\n",
      "2017-04-03T19:24:22.093118: step 2315, loss 1.73719, acc 0.34375\n",
      "2017-04-03T19:24:22.293186: step 2316, loss 1.65246, acc 0.46875\n",
      "2017-04-03T19:24:22.498381: step 2317, loss 1.78279, acc 0.375\n",
      "2017-04-03T19:24:22.690141: step 2318, loss 1.51389, acc 0.484375\n",
      "2017-04-03T19:24:22.895754: step 2319, loss 1.56831, acc 0.4375\n",
      "2017-04-03T19:24:23.092831: step 2320, loss 1.32992, acc 0.609375\n",
      "2017-04-03T19:24:23.298955: step 2321, loss 1.76294, acc 0.359375\n",
      "2017-04-03T19:24:23.491641: step 2322, loss 1.68582, acc 0.40625\n",
      "2017-04-03T19:24:23.697468: step 2323, loss 1.74191, acc 0.359375\n",
      "2017-04-03T19:24:23.894899: step 2324, loss 1.66712, acc 0.390625\n",
      "2017-04-03T19:24:24.094951: step 2325, loss 1.43466, acc 0.46875\n",
      "2017-04-03T19:24:24.292635: step 2326, loss 1.70764, acc 0.40625\n",
      "2017-04-03T19:24:24.500056: step 2327, loss 1.62699, acc 0.46875\n",
      "2017-04-03T19:24:24.693847: step 2328, loss 1.51124, acc 0.421875\n",
      "2017-04-03T19:24:24.901035: step 2329, loss 1.37822, acc 0.484375\n",
      "2017-04-03T19:24:25.101340: step 2330, loss 1.63316, acc 0.40625\n",
      "2017-04-03T19:24:25.312375: step 2331, loss 1.64332, acc 0.359375\n",
      "2017-04-03T19:24:25.512476: step 2332, loss 1.47018, acc 0.53125\n",
      "2017-04-03T19:24:25.713812: step 2333, loss 1.6002, acc 0.5\n",
      "2017-04-03T19:24:25.909887: step 2334, loss 1.50469, acc 0.4375\n",
      "2017-04-03T19:24:26.111774: step 2335, loss 1.55713, acc 0.453125\n",
      "2017-04-03T19:24:26.308793: step 2336, loss 1.70685, acc 0.421875\n",
      "2017-04-03T19:24:26.513674: step 2337, loss 1.54066, acc 0.421875\n",
      "2017-04-03T19:24:26.713738: step 2338, loss 1.5468, acc 0.453125\n",
      "2017-04-03T19:24:26.926932: step 2339, loss 1.82651, acc 0.40625\n",
      "2017-04-03T19:24:27.121015: step 2340, loss 1.58871, acc 0.40625\n",
      "2017-04-03T19:24:27.327040: step 2341, loss 1.4232, acc 0.59375\n",
      "2017-04-03T19:24:27.524432: step 2342, loss 1.54662, acc 0.390625\n",
      "2017-04-03T19:24:27.729234: step 2343, loss 1.36648, acc 0.484375\n",
      "2017-04-03T19:24:27.927067: step 2344, loss 1.50077, acc 0.4375\n",
      "2017-04-03T19:24:28.132562: step 2345, loss 1.56958, acc 0.46875\n",
      "2017-04-03T19:24:28.333033: step 2346, loss 1.4946, acc 0.4375\n",
      "2017-04-03T19:24:28.536336: step 2347, loss 1.45888, acc 0.453125\n",
      "2017-04-03T19:24:28.734410: step 2348, loss 1.5566, acc 0.390625\n",
      "2017-04-03T19:24:28.937885: step 2349, loss 1.93751, acc 0.375\n",
      "2017-04-03T19:24:29.132127: step 2350, loss 1.45387, acc 0.484375\n",
      "2017-04-03T19:24:29.341927: step 2351, loss 1.70937, acc 0.375\n",
      "2017-04-03T19:24:29.537666: step 2352, loss 1.77754, acc 0.421875\n",
      "2017-04-03T19:24:29.744153: step 2353, loss 1.53293, acc 0.421875\n",
      "2017-04-03T19:24:29.943445: step 2354, loss 1.6001, acc 0.4375\n",
      "2017-04-03T19:24:30.150941: step 2355, loss 1.73588, acc 0.390625\n",
      "2017-04-03T19:24:30.347547: step 2356, loss 1.58067, acc 0.46875\n",
      "2017-04-03T19:24:30.554514: step 2357, loss 1.85872, acc 0.328125\n",
      "2017-04-03T19:24:30.755810: step 2358, loss 1.59986, acc 0.40625\n",
      "2017-04-03T19:24:30.960115: step 2359, loss 1.64011, acc 0.375\n",
      "2017-04-03T19:24:31.164639: step 2360, loss 1.68489, acc 0.421875\n",
      "2017-04-03T19:24:31.368405: step 2361, loss 1.63833, acc 0.328125\n",
      "2017-04-03T19:24:31.574086: step 2362, loss 1.50772, acc 0.5\n",
      "2017-04-03T19:24:31.778176: step 2363, loss 1.49314, acc 0.5\n",
      "2017-04-03T19:24:31.987530: step 2364, loss 1.65507, acc 0.40625\n",
      "2017-04-03T19:24:32.189347: step 2365, loss 1.52045, acc 0.484375\n",
      "2017-04-03T19:24:32.394303: step 2366, loss 1.39412, acc 0.484375\n",
      "2017-04-03T19:24:32.598159: step 2367, loss 1.57158, acc 0.421875\n",
      "2017-04-03T19:24:32.799422: step 2368, loss 1.69652, acc 0.375\n",
      "2017-04-03T19:24:33.003948: step 2369, loss 1.55148, acc 0.453125\n",
      "2017-04-03T19:24:33.213951: step 2370, loss 1.84956, acc 0.359375\n",
      "2017-04-03T19:24:33.415012: step 2371, loss 1.5318, acc 0.4375\n",
      "2017-04-03T19:24:33.623671: step 2372, loss 1.51658, acc 0.421875\n",
      "2017-04-03T19:24:33.826608: step 2373, loss 1.61171, acc 0.40625\n",
      "2017-04-03T19:24:34.028805: step 2374, loss 1.3514, acc 0.546875\n",
      "2017-04-03T19:24:34.231123: step 2375, loss 1.5302, acc 0.484375\n",
      "2017-04-03T19:24:34.432394: step 2376, loss 1.49947, acc 0.46875\n",
      "2017-04-03T19:24:34.641152: step 2377, loss 1.42082, acc 0.46875\n",
      "2017-04-03T19:24:34.842977: step 2378, loss 1.55246, acc 0.4375\n",
      "2017-04-03T19:24:35.040367: step 2379, loss 1.74803, acc 0.296875\n",
      "2017-04-03T19:24:35.245624: step 2380, loss 1.42917, acc 0.46875\n",
      "2017-04-03T19:24:35.442165: step 2381, loss 1.51971, acc 0.484375\n",
      "2017-04-03T19:24:35.650284: step 2382, loss 1.66952, acc 0.421875\n",
      "2017-04-03T19:24:35.846043: step 2383, loss 1.46362, acc 0.515625\n",
      "2017-04-03T19:24:36.049613: step 2384, loss 1.42306, acc 0.53125\n",
      "2017-04-03T19:24:36.247439: step 2385, loss 1.75609, acc 0.359375\n",
      "2017-04-03T19:24:36.450797: step 2386, loss 1.63387, acc 0.375\n",
      "2017-04-03T19:24:36.649328: step 2387, loss 1.71551, acc 0.328125\n",
      "2017-04-03T19:24:36.856935: step 2388, loss 1.33361, acc 0.5\n",
      "2017-04-03T19:24:37.054340: step 2389, loss 1.55023, acc 0.4375\n",
      "2017-04-03T19:24:37.257459: step 2390, loss 1.71475, acc 0.421875\n",
      "2017-04-03T19:24:37.453625: step 2391, loss 1.58259, acc 0.4375\n",
      "2017-04-03T19:24:37.656988: step 2392, loss 1.54457, acc 0.5\n",
      "2017-04-03T19:24:37.850327: step 2393, loss 1.77444, acc 0.328125\n",
      "2017-04-03T19:24:38.056358: step 2394, loss 1.67345, acc 0.359375\n",
      "2017-04-03T19:24:38.250255: step 2395, loss 1.38997, acc 0.484375\n",
      "2017-04-03T19:24:38.456211: step 2396, loss 1.43118, acc 0.515625\n",
      "2017-04-03T19:24:38.649482: step 2397, loss 1.69513, acc 0.453125\n",
      "2017-04-03T19:24:38.852699: step 2398, loss 1.60773, acc 0.4375\n",
      "2017-04-03T19:24:39.046694: step 2399, loss 1.57808, acc 0.453125\n",
      "2017-04-03T19:24:39.250837: step 2400, loss 1.59476, acc 0.390625\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:24:41.282246: step 2400, loss 1.843, acc 0.34725\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-2400\n",
      "\n",
      "2017-04-03T19:24:41.635225: step 2401, loss 1.50905, acc 0.515625\n",
      "2017-04-03T19:24:41.829676: step 2402, loss 1.81753, acc 0.390625\n",
      "2017-04-03T19:24:42.035619: step 2403, loss 1.85358, acc 0.328125\n",
      "2017-04-03T19:24:42.231777: step 2404, loss 1.45845, acc 0.46875\n",
      "2017-04-03T19:24:42.439540: step 2405, loss 1.50044, acc 0.46875\n",
      "2017-04-03T19:24:42.634229: step 2406, loss 1.73168, acc 0.359375\n",
      "2017-04-03T19:24:42.840994: step 2407, loss 1.55307, acc 0.515625\n",
      "2017-04-03T19:24:43.034025: step 2408, loss 1.58632, acc 0.421875\n",
      "2017-04-03T19:24:43.239335: step 2409, loss 1.42493, acc 0.46875\n",
      "2017-04-03T19:24:43.436026: step 2410, loss 1.77192, acc 0.34375\n",
      "2017-04-03T19:24:43.644378: step 2411, loss 1.43041, acc 0.484375\n",
      "2017-04-03T19:24:43.840540: step 2412, loss 1.50263, acc 0.515625\n",
      "2017-04-03T19:24:44.045242: step 2413, loss 1.54875, acc 0.40625\n",
      "2017-04-03T19:24:44.240198: step 2414, loss 1.56346, acc 0.484375\n",
      "2017-04-03T19:24:44.445759: step 2415, loss 1.5981, acc 0.484375\n",
      "2017-04-03T19:24:44.638634: step 2416, loss 1.74215, acc 0.359375\n",
      "2017-04-03T19:24:44.843972: step 2417, loss 1.60212, acc 0.421875\n",
      "2017-04-03T19:24:45.034129: step 2418, loss 1.6648, acc 0.46875\n",
      "2017-04-03T19:24:45.237848: step 2419, loss 1.47456, acc 0.375\n",
      "2017-04-03T19:24:45.435083: step 2420, loss 1.72539, acc 0.359375\n",
      "2017-04-03T19:24:45.638328: step 2421, loss 1.53632, acc 0.4375\n",
      "2017-04-03T19:24:45.831294: step 2422, loss 1.71764, acc 0.375\n",
      "2017-04-03T19:24:46.035934: step 2423, loss 1.50088, acc 0.390625\n",
      "2017-04-03T19:24:46.230517: step 2424, loss 1.59851, acc 0.375\n",
      "2017-04-03T19:24:46.434965: step 2425, loss 1.75776, acc 0.34375\n",
      "2017-04-03T19:24:46.627200: step 2426, loss 1.41262, acc 0.5\n",
      "2017-04-03T19:24:46.833772: step 2427, loss 1.72225, acc 0.40625\n",
      "2017-04-03T19:24:47.030697: step 2428, loss 1.59027, acc 0.421875\n",
      "2017-04-03T19:24:47.234919: step 2429, loss 1.47203, acc 0.453125\n",
      "2017-04-03T19:24:47.425728: step 2430, loss 1.69727, acc 0.390625\n",
      "2017-04-03T19:24:47.629907: step 2431, loss 1.52138, acc 0.4375\n",
      "2017-04-03T19:24:47.825779: step 2432, loss 1.75412, acc 0.375\n",
      "2017-04-03T19:24:48.032195: step 2433, loss 1.63453, acc 0.4375\n",
      "2017-04-03T19:24:48.234790: step 2434, loss 1.6715, acc 0.453125\n",
      "2017-04-03T19:24:48.439452: step 2435, loss 1.56521, acc 0.421875\n",
      "2017-04-03T19:24:48.647068: step 2436, loss 1.5545, acc 0.46875\n",
      "2017-04-03T19:24:48.854357: step 2437, loss 1.72853, acc 0.390625\n",
      "2017-04-03T19:24:49.061437: step 2438, loss 1.60396, acc 0.328125\n",
      "2017-04-03T19:24:49.260207: step 2439, loss 1.4783, acc 0.4375\n",
      "2017-04-03T19:24:49.461898: step 2440, loss 1.565, acc 0.390625\n",
      "2017-04-03T19:24:49.654149: step 2441, loss 1.70716, acc 0.390625\n",
      "2017-04-03T19:24:49.858339: step 2442, loss 1.66252, acc 0.359375\n",
      "2017-04-03T19:24:50.056929: step 2443, loss 1.56528, acc 0.484375\n",
      "2017-04-03T19:24:50.262574: step 2444, loss 1.53488, acc 0.484375\n",
      "2017-04-03T19:24:50.453329: step 2445, loss 1.49625, acc 0.375\n",
      "2017-04-03T19:24:50.657448: step 2446, loss 1.50584, acc 0.421875\n",
      "2017-04-03T19:24:50.853610: step 2447, loss 1.69905, acc 0.421875\n",
      "2017-04-03T19:24:51.052496: step 2448, loss 1.56929, acc 0.484375\n",
      "2017-04-03T19:24:51.249349: step 2449, loss 1.84542, acc 0.296875\n",
      "2017-04-03T19:24:51.455771: step 2450, loss 1.64587, acc 0.4375\n",
      "2017-04-03T19:24:51.651706: step 2451, loss 1.93703, acc 0.34375\n",
      "2017-04-03T19:24:51.861224: step 2452, loss 1.7209, acc 0.375\n",
      "2017-04-03T19:24:52.058741: step 2453, loss 1.47118, acc 0.5\n",
      "2017-04-03T19:24:52.269722: step 2454, loss 1.39112, acc 0.53125\n",
      "2017-04-03T19:24:52.466599: step 2455, loss 1.45511, acc 0.46875\n",
      "2017-04-03T19:24:52.672448: step 2456, loss 1.65593, acc 0.421875\n",
      "2017-04-03T19:24:52.868001: step 2457, loss 1.51871, acc 0.484375\n",
      "2017-04-03T19:24:53.076114: step 2458, loss 1.34549, acc 0.59375\n",
      "2017-04-03T19:24:53.276843: step 2459, loss 1.75566, acc 0.3125\n",
      "2017-04-03T19:24:53.487125: step 2460, loss 1.59063, acc 0.390625\n",
      "2017-04-03T19:24:53.693652: step 2461, loss 1.56831, acc 0.421875\n",
      "2017-04-03T19:24:53.900979: step 2462, loss 1.6989, acc 0.3125\n",
      "2017-04-03T19:24:54.102593: step 2463, loss 1.37171, acc 0.515625\n",
      "2017-04-03T19:24:54.307837: step 2464, loss 1.70266, acc 0.40625\n",
      "2017-04-03T19:24:54.518746: step 2465, loss 1.51259, acc 0.453125\n",
      "2017-04-03T19:24:54.718937: step 2466, loss 1.51668, acc 0.4375\n",
      "2017-04-03T19:24:54.924123: step 2467, loss 1.69424, acc 0.453125\n",
      "2017-04-03T19:24:55.128015: step 2468, loss 1.47067, acc 0.5\n",
      "2017-04-03T19:24:55.332264: step 2469, loss 1.64233, acc 0.390625\n",
      "2017-04-03T19:24:55.538761: step 2470, loss 1.56689, acc 0.359375\n",
      "2017-04-03T19:24:55.745075: step 2471, loss 1.41932, acc 0.421875\n",
      "2017-04-03T19:24:55.949253: step 2472, loss 1.46003, acc 0.46875\n",
      "2017-04-03T19:24:56.153780: step 2473, loss 1.58379, acc 0.359375\n",
      "2017-04-03T19:24:56.356354: step 2474, loss 1.68408, acc 0.5\n",
      "2017-04-03T19:24:56.568518: step 2475, loss 1.52779, acc 0.5\n",
      "2017-04-03T19:24:56.775799: step 2476, loss 1.51394, acc 0.390625\n",
      "2017-04-03T19:24:56.979854: step 2477, loss 1.46644, acc 0.515625\n",
      "2017-04-03T19:24:57.187289: step 2478, loss 1.62356, acc 0.4375\n",
      "2017-04-03T19:24:57.394652: step 2479, loss 1.37446, acc 0.5\n",
      "2017-04-03T19:24:57.603370: step 2480, loss 1.80932, acc 0.421875\n",
      "2017-04-03T19:24:57.805206: step 2481, loss 1.75346, acc 0.34375\n",
      "2017-04-03T19:24:58.010496: step 2482, loss 1.60289, acc 0.484375\n",
      "2017-04-03T19:24:58.213272: step 2483, loss 1.52649, acc 0.5\n",
      "2017-04-03T19:24:58.420705: step 2484, loss 1.76336, acc 0.515625\n",
      "2017-04-03T19:24:58.626575: step 2485, loss 1.56759, acc 0.40625\n",
      "2017-04-03T19:24:58.830909: step 2486, loss 1.81058, acc 0.421875\n",
      "2017-04-03T19:24:59.034389: step 2487, loss 1.69591, acc 0.375\n",
      "2017-04-03T19:24:59.241945: step 2488, loss 1.55675, acc 0.484375\n",
      "2017-04-03T19:24:59.448846: step 2489, loss 1.51601, acc 0.5\n",
      "2017-04-03T19:24:59.655301: step 2490, loss 1.60292, acc 0.4375\n",
      "2017-04-03T19:24:59.861638: step 2491, loss 1.43845, acc 0.484375\n",
      "2017-04-03T19:25:00.075694: step 2492, loss 1.60909, acc 0.34375\n",
      "2017-04-03T19:25:00.282068: step 2493, loss 1.51816, acc 0.5\n",
      "2017-04-03T19:25:00.492743: step 2494, loss 1.42736, acc 0.515625\n",
      "2017-04-03T19:25:00.699422: step 2495, loss 1.76233, acc 0.359375\n",
      "2017-04-03T19:25:00.909424: step 2496, loss 1.61875, acc 0.421875\n",
      "2017-04-03T19:25:01.115417: step 2497, loss 1.42286, acc 0.515625\n",
      "2017-04-03T19:25:01.332387: step 2498, loss 1.73482, acc 0.40625\n",
      "2017-04-03T19:25:01.548371: step 2499, loss 1.43125, acc 0.546875\n",
      "2017-04-03T19:25:01.758719: step 2500, loss 1.58845, acc 0.421875\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:25:03.813262: step 2500, loss 1.83965, acc 0.3435\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-2500\n",
      "\n",
      "2017-04-03T19:25:04.146798: step 2501, loss 1.54559, acc 0.421875\n",
      "2017-04-03T19:25:04.340574: step 2502, loss 1.4907, acc 0.515625\n",
      "2017-04-03T19:25:04.543150: step 2503, loss 1.44954, acc 0.453125\n",
      "2017-04-03T19:25:04.735874: step 2504, loss 1.62666, acc 0.390625\n",
      "2017-04-03T19:25:04.937582: step 2505, loss 1.61664, acc 0.375\n",
      "2017-04-03T19:25:05.127782: step 2506, loss 1.61867, acc 0.40625\n",
      "2017-04-03T19:25:05.326852: step 2507, loss 1.56623, acc 0.46875\n",
      "2017-04-03T19:25:05.519561: step 2508, loss 1.67163, acc 0.34375\n",
      "2017-04-03T19:25:05.721111: step 2509, loss 1.54595, acc 0.515625\n",
      "2017-04-03T19:25:05.908808: step 2510, loss 1.60602, acc 0.484375\n",
      "2017-04-03T19:25:06.109850: step 2511, loss 1.59981, acc 0.4375\n",
      "2017-04-03T19:25:06.303803: step 2512, loss 1.58978, acc 0.46875\n",
      "2017-04-03T19:25:06.501795: step 2513, loss 1.49089, acc 0.484375\n",
      "2017-04-03T19:25:06.696403: step 2514, loss 1.9276, acc 0.375\n",
      "2017-04-03T19:25:06.899689: step 2515, loss 1.47806, acc 0.546875\n",
      "2017-04-03T19:25:07.095518: step 2516, loss 1.59062, acc 0.421875\n",
      "2017-04-03T19:25:07.297475: step 2517, loss 1.46365, acc 0.421875\n",
      "2017-04-03T19:25:07.489086: step 2518, loss 1.69643, acc 0.421875\n",
      "2017-04-03T19:25:07.693209: step 2519, loss 2.02066, acc 0.28125\n",
      "2017-04-03T19:25:07.888264: step 2520, loss 1.32905, acc 0.625\n",
      "2017-04-03T19:25:08.094788: step 2521, loss 1.81113, acc 0.46875\n",
      "2017-04-03T19:25:08.285860: step 2522, loss 1.58881, acc 0.4375\n",
      "2017-04-03T19:25:08.486782: step 2523, loss 1.71063, acc 0.484375\n",
      "2017-04-03T19:25:08.681073: step 2524, loss 1.55804, acc 0.421875\n",
      "2017-04-03T19:25:08.885849: step 2525, loss 1.51791, acc 0.421875\n",
      "2017-04-03T19:25:09.081834: step 2526, loss 1.59814, acc 0.359375\n",
      "2017-04-03T19:25:09.283864: step 2527, loss 1.44764, acc 0.53125\n",
      "2017-04-03T19:25:09.478785: step 2528, loss 1.72394, acc 0.375\n",
      "2017-04-03T19:25:09.681032: step 2529, loss 1.56431, acc 0.390625\n",
      "2017-04-03T19:25:09.876969: step 2530, loss 1.53325, acc 0.4375\n",
      "2017-04-03T19:25:10.077453: step 2531, loss 1.51118, acc 0.484375\n",
      "2017-04-03T19:25:10.266928: step 2532, loss 1.91554, acc 0.390625\n",
      "2017-04-03T19:25:10.480980: step 2533, loss 1.55457, acc 0.421875\n",
      "2017-04-03T19:25:10.676629: step 2534, loss 1.52241, acc 0.40625\n",
      "2017-04-03T19:25:10.880093: step 2535, loss 1.53243, acc 0.421875\n",
      "2017-04-03T19:25:11.075336: step 2536, loss 1.54009, acc 0.421875\n",
      "2017-04-03T19:25:11.281250: step 2537, loss 1.43986, acc 0.5\n",
      "2017-04-03T19:25:11.474188: step 2538, loss 1.86899, acc 0.359375\n",
      "2017-04-03T19:25:11.677566: step 2539, loss 1.66297, acc 0.46875\n",
      "2017-04-03T19:25:11.868087: step 2540, loss 1.45333, acc 0.53125\n",
      "2017-04-03T19:25:12.071767: step 2541, loss 1.53924, acc 0.4375\n",
      "2017-04-03T19:25:12.264173: step 2542, loss 1.44704, acc 0.453125\n",
      "2017-04-03T19:25:12.465150: step 2543, loss 1.45788, acc 0.453125\n",
      "2017-04-03T19:25:12.660343: step 2544, loss 1.53308, acc 0.484375\n",
      "2017-04-03T19:25:12.864199: step 2545, loss 1.62731, acc 0.453125\n",
      "2017-04-03T19:25:13.057189: step 2546, loss 1.53956, acc 0.46875\n",
      "2017-04-03T19:25:13.255271: step 2547, loss 1.77014, acc 0.328125\n",
      "2017-04-03T19:25:13.446487: step 2548, loss 1.48184, acc 0.421875\n",
      "2017-04-03T19:25:13.647484: step 2549, loss 1.80495, acc 0.421875\n",
      "2017-04-03T19:25:13.836536: step 2550, loss 1.39837, acc 0.484375\n",
      "2017-04-03T19:25:14.034493: step 2551, loss 1.56904, acc 0.34375\n",
      "2017-04-03T19:25:14.229813: step 2552, loss 1.55738, acc 0.453125\n",
      "2017-04-03T19:25:14.427632: step 2553, loss 1.43168, acc 0.484375\n",
      "2017-04-03T19:25:14.617736: step 2554, loss 1.58729, acc 0.40625\n",
      "2017-04-03T19:25:14.819356: step 2555, loss 1.70179, acc 0.375\n",
      "2017-04-03T19:25:15.012211: step 2556, loss 1.51227, acc 0.484375\n",
      "2017-04-03T19:25:15.216582: step 2557, loss 1.71171, acc 0.375\n",
      "2017-04-03T19:25:15.412504: step 2558, loss 1.80625, acc 0.359375\n",
      "2017-04-03T19:25:15.612187: step 2559, loss 1.82284, acc 0.328125\n",
      "2017-04-03T19:25:15.803663: step 2560, loss 1.59569, acc 0.4375\n",
      "2017-04-03T19:25:16.001896: step 2561, loss 1.43297, acc 0.5\n",
      "2017-04-03T19:25:16.189727: step 2562, loss 1.54582, acc 0.4375\n",
      "2017-04-03T19:25:16.393225: step 2563, loss 1.64299, acc 0.421875\n",
      "2017-04-03T19:25:16.584323: step 2564, loss 1.46686, acc 0.46875\n",
      "2017-04-03T19:25:16.785158: step 2565, loss 1.63206, acc 0.40625\n",
      "2017-04-03T19:25:16.979376: step 2566, loss 1.43188, acc 0.5\n",
      "2017-04-03T19:25:17.183909: step 2567, loss 1.68525, acc 0.4375\n",
      "2017-04-03T19:25:17.378153: step 2568, loss 1.7326, acc 0.359375\n",
      "2017-04-03T19:25:17.579200: step 2569, loss 1.64924, acc 0.296875\n",
      "2017-04-03T19:25:17.769888: step 2570, loss 1.6043, acc 0.40625\n",
      "2017-04-03T19:25:17.973109: step 2571, loss 1.66385, acc 0.5\n",
      "2017-04-03T19:25:18.165666: step 2572, loss 1.61481, acc 0.40625\n",
      "2017-04-03T19:25:18.364831: step 2573, loss 1.61823, acc 0.453125\n",
      "2017-04-03T19:25:18.557837: step 2574, loss 1.55507, acc 0.390625\n",
      "2017-04-03T19:25:18.765587: step 2575, loss 1.40709, acc 0.5625\n",
      "2017-04-03T19:25:18.955344: step 2576, loss 1.41879, acc 0.5\n",
      "2017-04-03T19:25:19.156648: step 2577, loss 1.80098, acc 0.25\n",
      "2017-04-03T19:25:19.351850: step 2578, loss 1.54679, acc 0.4375\n",
      "2017-04-03T19:25:19.552921: step 2579, loss 1.40302, acc 0.46875\n",
      "2017-04-03T19:25:19.745413: step 2580, loss 1.90179, acc 0.28125\n",
      "2017-04-03T19:25:19.949514: step 2581, loss 1.82437, acc 0.4375\n",
      "2017-04-03T19:25:20.138299: step 2582, loss 1.54008, acc 0.515625\n",
      "2017-04-03T19:25:20.342901: step 2583, loss 1.80422, acc 0.328125\n",
      "2017-04-03T19:25:20.536493: step 2584, loss 1.55331, acc 0.484375\n",
      "2017-04-03T19:25:20.742752: step 2585, loss 1.67876, acc 0.375\n",
      "2017-04-03T19:25:20.937123: step 2586, loss 1.66531, acc 0.375\n",
      "2017-04-03T19:25:21.137696: step 2587, loss 1.65978, acc 0.515625\n",
      "2017-04-03T19:25:21.328595: step 2588, loss 1.68585, acc 0.4375\n",
      "2017-04-03T19:25:21.533975: step 2589, loss 1.50266, acc 0.5625\n",
      "2017-04-03T19:25:21.725161: step 2590, loss 1.66402, acc 0.421875\n",
      "2017-04-03T19:25:21.929141: step 2591, loss 1.81621, acc 0.375\n",
      "2017-04-03T19:25:22.119534: step 2592, loss 1.56547, acc 0.484375\n",
      "2017-04-03T19:25:22.325259: step 2593, loss 1.43354, acc 0.375\n",
      "2017-04-03T19:25:22.516322: step 2594, loss 1.83157, acc 0.375\n",
      "2017-04-03T19:25:22.719147: step 2595, loss 2.00152, acc 0.3125\n",
      "2017-04-03T19:25:22.907761: step 2596, loss 1.66488, acc 0.375\n",
      "2017-04-03T19:25:23.104839: step 2597, loss 1.52013, acc 0.53125\n",
      "2017-04-03T19:25:23.296976: step 2598, loss 1.62062, acc 0.421875\n",
      "2017-04-03T19:25:23.493247: step 2599, loss 1.61264, acc 0.40625\n",
      "2017-04-03T19:25:23.684232: step 2600, loss 1.57421, acc 0.453125\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:25:25.643672: step 2600, loss 1.85404, acc 0.33725\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-2600\n",
      "\n",
      "2017-04-03T19:25:25.983218: step 2601, loss 1.58439, acc 0.484375\n",
      "2017-04-03T19:25:26.176635: step 2602, loss 1.74479, acc 0.40625\n",
      "2017-04-03T19:25:26.381246: step 2603, loss 1.86308, acc 0.40625\n",
      "2017-04-03T19:25:26.574932: step 2604, loss 1.61953, acc 0.40625\n",
      "2017-04-03T19:25:26.776880: step 2605, loss 1.42895, acc 0.46875\n",
      "2017-04-03T19:25:26.971468: step 2606, loss 1.59255, acc 0.484375\n",
      "2017-04-03T19:25:27.172404: step 2607, loss 1.75636, acc 0.390625\n",
      "2017-04-03T19:25:27.364311: step 2608, loss 1.82336, acc 0.515625\n",
      "2017-04-03T19:25:27.566802: step 2609, loss 1.68277, acc 0.40625\n",
      "2017-04-03T19:25:27.761838: step 2610, loss 1.75211, acc 0.359375\n",
      "2017-04-03T19:25:27.963605: step 2611, loss 1.62013, acc 0.375\n",
      "2017-04-03T19:25:28.154630: step 2612, loss 1.53152, acc 0.40625\n",
      "2017-04-03T19:25:28.358683: step 2613, loss 1.55444, acc 0.453125\n",
      "2017-04-03T19:25:28.553440: step 2614, loss 1.39965, acc 0.453125\n",
      "2017-04-03T19:25:28.767314: step 2615, loss 1.61736, acc 0.453125\n",
      "2017-04-03T19:25:28.961013: step 2616, loss 1.46382, acc 0.421875\n",
      "2017-04-03T19:25:29.163879: step 2617, loss 1.3121, acc 0.453125\n",
      "2017-04-03T19:25:29.357922: step 2618, loss 1.39691, acc 0.453125\n",
      "2017-04-03T19:25:29.561475: step 2619, loss 1.77133, acc 0.375\n",
      "2017-04-03T19:25:29.755453: step 2620, loss 1.57829, acc 0.484375\n",
      "2017-04-03T19:25:29.958011: step 2621, loss 1.5818, acc 0.40625\n",
      "2017-04-03T19:25:30.150328: step 2622, loss 1.6938, acc 0.359375\n",
      "2017-04-03T19:25:30.350944: step 2623, loss 1.56968, acc 0.46875\n",
      "2017-04-03T19:25:30.542393: step 2624, loss 1.63077, acc 0.359375\n",
      "2017-04-03T19:25:30.756882: step 2625, loss 1.51313, acc 0.484375\n",
      "2017-04-03T19:25:30.950037: step 2626, loss 1.77169, acc 0.40625\n",
      "2017-04-03T19:25:31.157074: step 2627, loss 1.80736, acc 0.359375\n",
      "2017-04-03T19:25:31.350042: step 2628, loss 1.6882, acc 0.40625\n",
      "2017-04-03T19:25:31.553981: step 2629, loss 1.65729, acc 0.390625\n",
      "2017-04-03T19:25:31.748995: step 2630, loss 1.53876, acc 0.375\n",
      "2017-04-03T19:25:31.954194: step 2631, loss 1.35709, acc 0.40625\n",
      "2017-04-03T19:25:32.145598: step 2632, loss 1.54326, acc 0.421875\n",
      "2017-04-03T19:25:32.354131: step 2633, loss 1.72501, acc 0.34375\n",
      "2017-04-03T19:25:32.545473: step 2634, loss 1.64177, acc 0.359375\n",
      "2017-04-03T19:25:32.750850: step 2635, loss 1.57117, acc 0.46875\n",
      "2017-04-03T19:25:32.941174: step 2636, loss 1.62734, acc 0.359375\n",
      "2017-04-03T19:25:33.148543: step 2637, loss 1.70531, acc 0.359375\n",
      "2017-04-03T19:25:33.342941: step 2638, loss 1.52317, acc 0.515625\n",
      "2017-04-03T19:25:33.547132: step 2639, loss 1.41374, acc 0.40625\n",
      "2017-04-03T19:25:33.740922: step 2640, loss 1.8239, acc 0.328125\n",
      "2017-04-03T19:25:33.945538: step 2641, loss 1.60868, acc 0.46875\n",
      "2017-04-03T19:25:34.135991: step 2642, loss 1.54952, acc 0.5\n",
      "2017-04-03T19:25:34.341384: step 2643, loss 1.39231, acc 0.546875\n",
      "2017-04-03T19:25:34.533314: step 2644, loss 1.64139, acc 0.453125\n",
      "2017-04-03T19:25:34.737637: step 2645, loss 1.7011, acc 0.453125\n",
      "2017-04-03T19:25:34.930363: step 2646, loss 1.53629, acc 0.5\n",
      "2017-04-03T19:25:35.135419: step 2647, loss 1.88285, acc 0.359375\n",
      "2017-04-03T19:25:35.328386: step 2648, loss 1.3516, acc 0.5625\n",
      "2017-04-03T19:25:35.528114: step 2649, loss 1.72955, acc 0.390625\n",
      "2017-04-03T19:25:35.722360: step 2650, loss 1.55617, acc 0.4375\n",
      "2017-04-03T19:25:35.925718: step 2651, loss 1.52147, acc 0.484375\n",
      "2017-04-03T19:25:36.120049: step 2652, loss 1.65419, acc 0.4375\n",
      "2017-04-03T19:25:36.325870: step 2653, loss 1.48069, acc 0.453125\n",
      "2017-04-03T19:25:36.518030: step 2654, loss 1.68551, acc 0.328125\n",
      "2017-04-03T19:25:36.726094: step 2655, loss 1.5849, acc 0.34375\n",
      "2017-04-03T19:25:36.916950: step 2656, loss 1.33113, acc 0.5625\n",
      "2017-04-03T19:25:37.126688: step 2657, loss 1.58917, acc 0.453125\n",
      "2017-04-03T19:25:37.320106: step 2658, loss 1.42285, acc 0.5\n",
      "2017-04-03T19:25:37.519642: step 2659, loss 1.55898, acc 0.375\n",
      "2017-04-03T19:25:37.714410: step 2660, loss 1.69421, acc 0.375\n",
      "2017-04-03T19:25:37.916744: step 2661, loss 1.50548, acc 0.5625\n",
      "2017-04-03T19:25:38.106855: step 2662, loss 1.72033, acc 0.421875\n",
      "2017-04-03T19:25:38.310888: step 2663, loss 1.86798, acc 0.453125\n",
      "2017-04-03T19:25:38.505977: step 2664, loss 1.43559, acc 0.515625\n",
      "2017-04-03T19:25:38.710194: step 2665, loss 1.61681, acc 0.421875\n",
      "2017-04-03T19:25:38.903822: step 2666, loss 1.46221, acc 0.5\n",
      "2017-04-03T19:25:39.106850: step 2667, loss 1.64756, acc 0.40625\n",
      "2017-04-03T19:25:39.297305: step 2668, loss 1.69498, acc 0.390625\n",
      "2017-04-03T19:25:39.500105: step 2669, loss 1.53868, acc 0.421875\n",
      "2017-04-03T19:25:39.695209: step 2670, loss 1.52232, acc 0.421875\n",
      "2017-04-03T19:25:39.897719: step 2671, loss 1.71657, acc 0.46875\n",
      "2017-04-03T19:25:40.088859: step 2672, loss 1.66805, acc 0.375\n",
      "2017-04-03T19:25:40.290759: step 2673, loss 1.84638, acc 0.40625\n",
      "2017-04-03T19:25:40.483342: step 2674, loss 1.6837, acc 0.359375\n",
      "2017-04-03T19:25:40.686129: step 2675, loss 1.64041, acc 0.46875\n",
      "2017-04-03T19:25:40.877418: step 2676, loss 1.63885, acc 0.453125\n",
      "2017-04-03T19:25:41.083010: step 2677, loss 1.4985, acc 0.4375\n",
      "2017-04-03T19:25:41.272966: step 2678, loss 1.85296, acc 0.34375\n",
      "2017-04-03T19:25:41.475924: step 2679, loss 1.56146, acc 0.453125\n",
      "2017-04-03T19:25:41.671614: step 2680, loss 1.75308, acc 0.453125\n",
      "2017-04-03T19:25:41.877699: step 2681, loss 1.55787, acc 0.4375\n",
      "2017-04-03T19:25:42.074220: step 2682, loss 1.29214, acc 0.625\n",
      "2017-04-03T19:25:42.279286: step 2683, loss 1.62799, acc 0.390625\n",
      "2017-04-03T19:25:42.475153: step 2684, loss 1.50239, acc 0.515625\n",
      "2017-04-03T19:25:42.677747: step 2685, loss 1.47729, acc 0.59375\n",
      "2017-04-03T19:25:42.867303: step 2686, loss 1.66816, acc 0.453125\n",
      "2017-04-03T19:25:43.072799: step 2687, loss 1.86347, acc 0.375\n",
      "2017-04-03T19:25:43.265625: step 2688, loss 1.77432, acc 0.375\n",
      "2017-04-03T19:25:43.471460: step 2689, loss 1.56907, acc 0.40625\n",
      "2017-04-03T19:25:43.669482: step 2690, loss 1.66175, acc 0.484375\n",
      "2017-04-03T19:25:43.866575: step 2691, loss 1.62912, acc 0.453125\n",
      "2017-04-03T19:25:44.055362: step 2692, loss 1.68276, acc 0.40625\n",
      "2017-04-03T19:25:44.256424: step 2693, loss 1.67571, acc 0.359375\n",
      "2017-04-03T19:25:44.447903: step 2694, loss 1.71347, acc 0.328125\n",
      "2017-04-03T19:25:44.653471: step 2695, loss 1.84807, acc 0.390625\n",
      "2017-04-03T19:25:44.845435: step 2696, loss 1.80279, acc 0.4375\n",
      "2017-04-03T19:25:45.049085: step 2697, loss 1.49264, acc 0.421875\n",
      "2017-04-03T19:25:45.243247: step 2698, loss 1.65916, acc 0.453125\n",
      "2017-04-03T19:25:45.451149: step 2699, loss 1.57451, acc 0.421875\n",
      "2017-04-03T19:25:45.644312: step 2700, loss 1.73768, acc 0.328125\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:25:47.571339: step 2700, loss 1.84944, acc 0.34625\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-2700\n",
      "\n",
      "2017-04-03T19:25:47.896697: step 2701, loss 1.65112, acc 0.46875\n",
      "2017-04-03T19:25:48.090084: step 2702, loss 1.70016, acc 0.375\n",
      "2017-04-03T19:25:48.293973: step 2703, loss 1.69241, acc 0.40625\n",
      "2017-04-03T19:25:48.485867: step 2704, loss 1.66491, acc 0.40625\n",
      "2017-04-03T19:25:48.691441: step 2705, loss 1.63931, acc 0.46875\n",
      "2017-04-03T19:25:48.886800: step 2706, loss 1.72526, acc 0.34375\n",
      "2017-04-03T19:25:49.086668: step 2707, loss 1.78512, acc 0.3125\n",
      "2017-04-03T19:25:49.281164: step 2708, loss 1.65801, acc 0.46875\n",
      "2017-04-03T19:25:49.489056: step 2709, loss 1.56516, acc 0.4375\n",
      "2017-04-03T19:25:49.684032: step 2710, loss 1.66684, acc 0.40625\n",
      "2017-04-03T19:25:49.884364: step 2711, loss 1.55916, acc 0.4375\n",
      "2017-04-03T19:25:50.071761: step 2712, loss 1.6324, acc 0.484375\n",
      "2017-04-03T19:25:50.271554: step 2713, loss 1.75218, acc 0.453125\n",
      "2017-04-03T19:25:50.467356: step 2714, loss 1.61598, acc 0.53125\n",
      "2017-04-03T19:25:50.671676: step 2715, loss 1.85844, acc 0.359375\n",
      "2017-04-03T19:25:50.865055: step 2716, loss 1.68504, acc 0.375\n",
      "2017-04-03T19:25:51.069288: step 2717, loss 1.52246, acc 0.53125\n",
      "2017-04-03T19:25:51.260483: step 2718, loss 1.55169, acc 0.46875\n",
      "2017-04-03T19:25:51.461126: step 2719, loss 1.64904, acc 0.484375\n",
      "2017-04-03T19:25:51.654809: step 2720, loss 1.65747, acc 0.34375\n",
      "2017-04-03T19:25:51.858610: step 2721, loss 1.72098, acc 0.359375\n",
      "2017-04-03T19:25:52.053389: step 2722, loss 1.82586, acc 0.375\n",
      "2017-04-03T19:25:52.259792: step 2723, loss 1.87781, acc 0.390625\n",
      "2017-04-03T19:25:52.451869: step 2724, loss 1.66464, acc 0.453125\n",
      "2017-04-03T19:25:52.655464: step 2725, loss 1.8835, acc 0.390625\n",
      "2017-04-03T19:25:52.854400: step 2726, loss 1.88531, acc 0.296875\n",
      "2017-04-03T19:25:53.065137: step 2727, loss 1.56118, acc 0.484375\n",
      "2017-04-03T19:25:53.257612: step 2728, loss 1.53986, acc 0.515625\n",
      "2017-04-03T19:25:53.464340: step 2729, loss 1.64097, acc 0.34375\n",
      "2017-04-03T19:25:53.660212: step 2730, loss 1.43914, acc 0.484375\n",
      "2017-04-03T19:25:53.865375: step 2731, loss 1.58115, acc 0.46875\n",
      "2017-04-03T19:25:54.060790: step 2732, loss 1.63013, acc 0.34375\n",
      "2017-04-03T19:25:54.265881: step 2733, loss 1.67926, acc 0.421875\n",
      "2017-04-03T19:25:54.461412: step 2734, loss 1.5191, acc 0.421875\n",
      "2017-04-03T19:25:54.664656: step 2735, loss 1.64888, acc 0.421875\n",
      "2017-04-03T19:25:54.859480: step 2736, loss 1.64916, acc 0.5\n",
      "2017-04-03T19:25:55.062130: step 2737, loss 1.4469, acc 0.5\n",
      "2017-04-03T19:25:55.255459: step 2738, loss 1.69656, acc 0.421875\n",
      "2017-04-03T19:25:55.459019: step 2739, loss 1.42406, acc 0.5\n",
      "2017-04-03T19:25:55.650301: step 2740, loss 1.52175, acc 0.4375\n",
      "2017-04-03T19:25:55.855852: step 2741, loss 1.85502, acc 0.453125\n",
      "2017-04-03T19:25:56.052697: step 2742, loss 1.818, acc 0.40625\n",
      "2017-04-03T19:25:56.254228: step 2743, loss 1.6837, acc 0.359375\n",
      "2017-04-03T19:25:56.447581: step 2744, loss 1.56594, acc 0.484375\n",
      "2017-04-03T19:25:56.654246: step 2745, loss 1.46531, acc 0.46875\n",
      "2017-04-03T19:25:56.850774: step 2746, loss 1.72774, acc 0.296875\n",
      "2017-04-03T19:25:57.059706: step 2747, loss 1.47564, acc 0.484375\n",
      "2017-04-03T19:25:57.255924: step 2748, loss 1.63142, acc 0.421875\n",
      "2017-04-03T19:25:57.461456: step 2749, loss 1.82576, acc 0.359375\n",
      "2017-04-03T19:25:57.654648: step 2750, loss 1.44101, acc 0.5625\n",
      "2017-04-03T19:25:57.861806: step 2751, loss 1.56669, acc 0.4375\n",
      "2017-04-03T19:25:58.056188: step 2752, loss 1.64623, acc 0.421875\n",
      "2017-04-03T19:25:58.264850: step 2753, loss 1.66266, acc 0.4375\n",
      "2017-04-03T19:25:58.458200: step 2754, loss 1.65654, acc 0.515625\n",
      "2017-04-03T19:25:58.658641: step 2755, loss 1.44369, acc 0.53125\n",
      "2017-04-03T19:25:58.853896: step 2756, loss 1.56282, acc 0.421875\n",
      "2017-04-03T19:25:59.059459: step 2757, loss 1.44471, acc 0.515625\n",
      "2017-04-03T19:25:59.256335: step 2758, loss 1.52884, acc 0.484375\n",
      "2017-04-03T19:25:59.456665: step 2759, loss 1.56832, acc 0.40625\n",
      "2017-04-03T19:25:59.648070: step 2760, loss 1.68331, acc 0.4375\n",
      "2017-04-03T19:25:59.855284: step 2761, loss 1.59762, acc 0.40625\n",
      "2017-04-03T19:26:00.047956: step 2762, loss 1.51566, acc 0.390625\n",
      "2017-04-03T19:26:00.254963: step 2763, loss 1.43574, acc 0.484375\n",
      "2017-04-03T19:26:00.447496: step 2764, loss 1.48094, acc 0.46875\n",
      "2017-04-03T19:26:00.656405: step 2765, loss 1.52852, acc 0.453125\n",
      "2017-04-03T19:26:00.848824: step 2766, loss 1.50745, acc 0.375\n",
      "2017-04-03T19:26:01.052568: step 2767, loss 1.64052, acc 0.484375\n",
      "2017-04-03T19:26:01.244856: step 2768, loss 1.50792, acc 0.40625\n",
      "2017-04-03T19:26:01.454167: step 2769, loss 1.6472, acc 0.40625\n",
      "2017-04-03T19:26:01.653689: step 2770, loss 1.71783, acc 0.34375\n",
      "2017-04-03T19:26:01.854189: step 2771, loss 1.73768, acc 0.359375\n",
      "2017-04-03T19:26:02.049308: step 2772, loss 1.62472, acc 0.328125\n",
      "2017-04-03T19:26:02.254883: step 2773, loss 1.96569, acc 0.296875\n",
      "2017-04-03T19:26:02.444932: step 2774, loss 1.93358, acc 0.265625\n",
      "2017-04-03T19:26:02.649873: step 2775, loss 1.76307, acc 0.34375\n",
      "2017-04-03T19:26:02.843618: step 2776, loss 1.70177, acc 0.375\n",
      "2017-04-03T19:26:03.046094: step 2777, loss 1.44245, acc 0.515625\n",
      "2017-04-03T19:26:03.239449: step 2778, loss 1.52273, acc 0.453125\n",
      "2017-04-03T19:26:03.442336: step 2779, loss 1.56807, acc 0.453125\n",
      "2017-04-03T19:26:03.638586: step 2780, loss 1.68253, acc 0.453125\n",
      "2017-04-03T19:26:03.841065: step 2781, loss 1.54247, acc 0.53125\n",
      "2017-04-03T19:26:04.037440: step 2782, loss 1.70401, acc 0.390625\n",
      "2017-04-03T19:26:04.244696: step 2783, loss 1.49029, acc 0.515625\n",
      "2017-04-03T19:26:04.442052: step 2784, loss 1.60097, acc 0.390625\n",
      "2017-04-03T19:26:04.647713: step 2785, loss 1.80446, acc 0.34375\n",
      "2017-04-03T19:26:04.843970: step 2786, loss 1.59939, acc 0.390625\n",
      "2017-04-03T19:26:05.050684: step 2787, loss 1.6174, acc 0.421875\n",
      "2017-04-03T19:26:05.241432: step 2788, loss 1.42527, acc 0.5\n",
      "2017-04-03T19:26:05.444448: step 2789, loss 1.57062, acc 0.4375\n",
      "2017-04-03T19:26:05.637709: step 2790, loss 1.91881, acc 0.40625\n",
      "2017-04-03T19:26:05.841822: step 2791, loss 1.66148, acc 0.375\n",
      "2017-04-03T19:26:06.041005: step 2792, loss 1.73574, acc 0.421875\n",
      "2017-04-03T19:26:06.245696: step 2793, loss 1.74961, acc 0.328125\n",
      "2017-04-03T19:26:06.440403: step 2794, loss 1.60289, acc 0.4375\n",
      "2017-04-03T19:26:06.651010: step 2795, loss 1.55196, acc 0.453125\n",
      "2017-04-03T19:26:06.845577: step 2796, loss 1.3507, acc 0.53125\n",
      "2017-04-03T19:26:07.046065: step 2797, loss 1.56045, acc 0.453125\n",
      "2017-04-03T19:26:07.240094: step 2798, loss 1.52995, acc 0.5\n",
      "2017-04-03T19:26:07.445122: step 2799, loss 1.4695, acc 0.515625\n",
      "2017-04-03T19:26:07.637844: step 2800, loss 1.40385, acc 0.59375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:26:09.602560: step 2800, loss 1.85254, acc 0.3415\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-2800\n",
      "\n",
      "2017-04-03T19:26:09.934974: step 2801, loss 1.63451, acc 0.484375\n",
      "2017-04-03T19:26:10.131477: step 2802, loss 1.55194, acc 0.484375\n",
      "2017-04-03T19:26:10.336072: step 2803, loss 1.70359, acc 0.34375\n",
      "2017-04-03T19:26:10.528857: step 2804, loss 1.53147, acc 0.4375\n",
      "2017-04-03T19:26:10.736737: step 2805, loss 1.50799, acc 0.484375\n",
      "2017-04-03T19:26:10.935197: step 2806, loss 1.71589, acc 0.359375\n",
      "2017-04-03T19:26:11.146847: step 2807, loss 1.79548, acc 0.40625\n",
      "2017-04-03T19:26:11.341107: step 2808, loss 1.83911, acc 0.359375\n",
      "2017-04-03T19:26:11.546722: step 2809, loss 1.54022, acc 0.390625\n",
      "2017-04-03T19:26:11.742878: step 2810, loss 1.66458, acc 0.359375\n",
      "2017-04-03T19:26:11.946876: step 2811, loss 1.532, acc 0.515625\n",
      "2017-04-03T19:26:12.141127: step 2812, loss 1.6588, acc 0.4375\n",
      "2017-04-03T19:26:12.350670: step 2813, loss 1.67684, acc 0.515625\n",
      "2017-04-03T19:26:12.548214: step 2814, loss 1.81454, acc 0.34375\n",
      "2017-04-03T19:26:12.701450: step 2815, loss 1.70122, acc 0.375\n",
      "2017-04-03T19:26:12.898923: step 2816, loss 1.39349, acc 0.515625\n",
      "2017-04-03T19:26:13.098914: step 2817, loss 1.25739, acc 0.578125\n",
      "2017-04-03T19:26:13.293965: step 2818, loss 1.35839, acc 0.53125\n",
      "2017-04-03T19:26:13.495243: step 2819, loss 1.57598, acc 0.359375\n",
      "2017-04-03T19:26:13.692396: step 2820, loss 1.48406, acc 0.46875\n",
      "2017-04-03T19:26:13.894938: step 2821, loss 1.56567, acc 0.453125\n",
      "2017-04-03T19:26:14.089686: step 2822, loss 1.36464, acc 0.578125\n",
      "2017-04-03T19:26:14.296596: step 2823, loss 1.46784, acc 0.453125\n",
      "2017-04-03T19:26:14.491791: step 2824, loss 1.39541, acc 0.5\n",
      "2017-04-03T19:26:14.697279: step 2825, loss 1.5658, acc 0.484375\n",
      "2017-04-03T19:26:14.892184: step 2826, loss 1.33994, acc 0.5625\n",
      "2017-04-03T19:26:15.098804: step 2827, loss 1.59419, acc 0.4375\n",
      "2017-04-03T19:26:15.291400: step 2828, loss 1.56098, acc 0.484375\n",
      "2017-04-03T19:26:15.497995: step 2829, loss 1.28424, acc 0.59375\n",
      "2017-04-03T19:26:15.688756: step 2830, loss 1.41158, acc 0.515625\n",
      "2017-04-03T19:26:15.893189: step 2831, loss 1.28165, acc 0.546875\n",
      "2017-04-03T19:26:16.087182: step 2832, loss 1.43202, acc 0.515625\n",
      "2017-04-03T19:26:16.298129: step 2833, loss 1.59122, acc 0.421875\n",
      "2017-04-03T19:26:16.486695: step 2834, loss 1.28229, acc 0.59375\n",
      "2017-04-03T19:26:16.687363: step 2835, loss 1.39766, acc 0.515625\n",
      "2017-04-03T19:26:16.884216: step 2836, loss 1.67224, acc 0.390625\n",
      "2017-04-03T19:26:17.086610: step 2837, loss 1.31374, acc 0.546875\n",
      "2017-04-03T19:26:17.280731: step 2838, loss 1.25822, acc 0.546875\n",
      "2017-04-03T19:26:17.485161: step 2839, loss 1.49865, acc 0.5\n",
      "2017-04-03T19:26:17.682396: step 2840, loss 1.26021, acc 0.546875\n",
      "2017-04-03T19:26:17.894307: step 2841, loss 1.25063, acc 0.546875\n",
      "2017-04-03T19:26:18.090808: step 2842, loss 1.48522, acc 0.40625\n",
      "2017-04-03T19:26:18.294677: step 2843, loss 1.56924, acc 0.484375\n",
      "2017-04-03T19:26:18.490458: step 2844, loss 1.59225, acc 0.421875\n",
      "2017-04-03T19:26:18.692440: step 2845, loss 1.42961, acc 0.46875\n",
      "2017-04-03T19:26:18.883923: step 2846, loss 1.50395, acc 0.5\n",
      "2017-04-03T19:26:19.088200: step 2847, loss 1.33928, acc 0.546875\n",
      "2017-04-03T19:26:19.282996: step 2848, loss 1.32894, acc 0.484375\n",
      "2017-04-03T19:26:19.496758: step 2849, loss 1.31102, acc 0.5625\n",
      "2017-04-03T19:26:19.692577: step 2850, loss 1.50528, acc 0.453125\n",
      "2017-04-03T19:26:19.897979: step 2851, loss 1.39323, acc 0.484375\n",
      "2017-04-03T19:26:20.095896: step 2852, loss 1.35075, acc 0.53125\n",
      "2017-04-03T19:26:20.301867: step 2853, loss 1.51303, acc 0.484375\n",
      "2017-04-03T19:26:20.496674: step 2854, loss 1.55911, acc 0.484375\n",
      "2017-04-03T19:26:20.701979: step 2855, loss 1.49694, acc 0.453125\n",
      "2017-04-03T19:26:20.898590: step 2856, loss 1.37333, acc 0.59375\n",
      "2017-04-03T19:26:21.106675: step 2857, loss 1.55967, acc 0.484375\n",
      "2017-04-03T19:26:21.297731: step 2858, loss 1.34281, acc 0.484375\n",
      "2017-04-03T19:26:21.505755: step 2859, loss 1.41319, acc 0.546875\n",
      "2017-04-03T19:26:21.705129: step 2860, loss 1.49827, acc 0.46875\n",
      "2017-04-03T19:26:21.910961: step 2861, loss 1.45788, acc 0.515625\n",
      "2017-04-03T19:26:22.106284: step 2862, loss 1.46124, acc 0.484375\n",
      "2017-04-03T19:26:22.317289: step 2863, loss 1.30436, acc 0.5625\n",
      "2017-04-03T19:26:22.513036: step 2864, loss 1.37745, acc 0.546875\n",
      "2017-04-03T19:26:22.717002: step 2865, loss 1.47605, acc 0.484375\n",
      "2017-04-03T19:26:22.912166: step 2866, loss 1.44337, acc 0.515625\n",
      "2017-04-03T19:26:23.117811: step 2867, loss 1.28742, acc 0.546875\n",
      "2017-04-03T19:26:23.312031: step 2868, loss 1.48017, acc 0.5\n",
      "2017-04-03T19:26:23.517907: step 2869, loss 1.29777, acc 0.546875\n",
      "2017-04-03T19:26:23.709907: step 2870, loss 1.60737, acc 0.359375\n",
      "2017-04-03T19:26:23.910989: step 2871, loss 1.31566, acc 0.5\n",
      "2017-04-03T19:26:24.105779: step 2872, loss 1.55023, acc 0.46875\n",
      "2017-04-03T19:26:24.308203: step 2873, loss 1.41603, acc 0.546875\n",
      "2017-04-03T19:26:24.503134: step 2874, loss 1.41268, acc 0.515625\n",
      "2017-04-03T19:26:24.706151: step 2875, loss 1.46792, acc 0.421875\n",
      "2017-04-03T19:26:24.899707: step 2876, loss 1.32019, acc 0.5625\n",
      "2017-04-03T19:26:25.105334: step 2877, loss 1.50746, acc 0.421875\n",
      "2017-04-03T19:26:25.295963: step 2878, loss 1.37057, acc 0.515625\n",
      "2017-04-03T19:26:25.500372: step 2879, loss 1.28607, acc 0.53125\n",
      "2017-04-03T19:26:25.691259: step 2880, loss 1.39037, acc 0.5\n",
      "2017-04-03T19:26:25.898561: step 2881, loss 1.27534, acc 0.65625\n",
      "2017-04-03T19:26:26.095314: step 2882, loss 1.39926, acc 0.53125\n",
      "2017-04-03T19:26:26.302287: step 2883, loss 1.54606, acc 0.546875\n",
      "2017-04-03T19:26:26.497104: step 2884, loss 1.33532, acc 0.546875\n",
      "2017-04-03T19:26:26.707090: step 2885, loss 1.55116, acc 0.484375\n",
      "2017-04-03T19:26:26.900933: step 2886, loss 1.18018, acc 0.578125\n",
      "2017-04-03T19:26:27.106187: step 2887, loss 1.51728, acc 0.546875\n",
      "2017-04-03T19:26:27.304864: step 2888, loss 1.31982, acc 0.5\n",
      "2017-04-03T19:26:27.507052: step 2889, loss 1.54789, acc 0.46875\n",
      "2017-04-03T19:26:27.703493: step 2890, loss 1.23857, acc 0.53125\n",
      "2017-04-03T19:26:27.909682: step 2891, loss 1.3661, acc 0.5\n",
      "2017-04-03T19:26:28.105161: step 2892, loss 1.40127, acc 0.546875\n",
      "2017-04-03T19:26:28.313592: step 2893, loss 1.41939, acc 0.453125\n",
      "2017-04-03T19:26:28.508684: step 2894, loss 1.4523, acc 0.46875\n",
      "2017-04-03T19:26:28.710074: step 2895, loss 1.56574, acc 0.453125\n",
      "2017-04-03T19:26:28.905234: step 2896, loss 1.44496, acc 0.515625\n",
      "2017-04-03T19:26:29.108300: step 2897, loss 1.4837, acc 0.5\n",
      "2017-04-03T19:26:29.300870: step 2898, loss 1.53214, acc 0.46875\n",
      "2017-04-03T19:26:29.514139: step 2899, loss 1.15502, acc 0.5625\n",
      "2017-04-03T19:26:29.707165: step 2900, loss 1.5836, acc 0.421875\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:26:31.674541: step 2900, loss 1.85467, acc 0.3445\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-2900\n",
      "\n",
      "2017-04-03T19:26:32.012698: step 2901, loss 1.62691, acc 0.421875\n",
      "2017-04-03T19:26:32.206660: step 2902, loss 1.26173, acc 0.59375\n",
      "2017-04-03T19:26:32.410075: step 2903, loss 1.38404, acc 0.484375\n",
      "2017-04-03T19:26:32.597074: step 2904, loss 1.39552, acc 0.5\n",
      "2017-04-03T19:26:32.807960: step 2905, loss 1.62592, acc 0.421875\n",
      "2017-04-03T19:26:33.003895: step 2906, loss 1.46345, acc 0.484375\n",
      "2017-04-03T19:26:33.204984: step 2907, loss 1.39758, acc 0.53125\n",
      "2017-04-03T19:26:33.402038: step 2908, loss 1.41938, acc 0.5\n",
      "2017-04-03T19:26:33.607767: step 2909, loss 1.38244, acc 0.578125\n",
      "2017-04-03T19:26:33.803866: step 2910, loss 1.34442, acc 0.46875\n",
      "2017-04-03T19:26:34.009093: step 2911, loss 1.57675, acc 0.46875\n",
      "2017-04-03T19:26:34.206156: step 2912, loss 1.56008, acc 0.390625\n",
      "2017-04-03T19:26:34.410148: step 2913, loss 1.68738, acc 0.46875\n",
      "2017-04-03T19:26:34.608637: step 2914, loss 1.42925, acc 0.515625\n",
      "2017-04-03T19:26:34.809399: step 2915, loss 1.56364, acc 0.4375\n",
      "2017-04-03T19:26:35.004365: step 2916, loss 1.61247, acc 0.40625\n",
      "2017-04-03T19:26:35.206098: step 2917, loss 1.77425, acc 0.359375\n",
      "2017-04-03T19:26:35.401393: step 2918, loss 1.48929, acc 0.421875\n",
      "2017-04-03T19:26:35.608649: step 2919, loss 1.28439, acc 0.5625\n",
      "2017-04-03T19:26:35.803549: step 2920, loss 1.5234, acc 0.484375\n",
      "2017-04-03T19:26:36.005972: step 2921, loss 1.2897, acc 0.5\n",
      "2017-04-03T19:26:36.195001: step 2922, loss 1.23612, acc 0.609375\n",
      "2017-04-03T19:26:36.398320: step 2923, loss 1.7504, acc 0.4375\n",
      "2017-04-03T19:26:36.591872: step 2924, loss 1.32051, acc 0.53125\n",
      "2017-04-03T19:26:36.799614: step 2925, loss 1.63974, acc 0.34375\n",
      "2017-04-03T19:26:36.991441: step 2926, loss 1.56782, acc 0.46875\n",
      "2017-04-03T19:26:37.191971: step 2927, loss 1.53821, acc 0.484375\n",
      "2017-04-03T19:26:37.385421: step 2928, loss 1.37817, acc 0.453125\n",
      "2017-04-03T19:26:37.587955: step 2929, loss 1.56071, acc 0.515625\n",
      "2017-04-03T19:26:37.784356: step 2930, loss 1.41376, acc 0.515625\n",
      "2017-04-03T19:26:37.986580: step 2931, loss 1.38673, acc 0.5625\n",
      "2017-04-03T19:26:38.182663: step 2932, loss 1.52094, acc 0.4375\n",
      "2017-04-03T19:26:38.382258: step 2933, loss 1.18872, acc 0.625\n",
      "2017-04-03T19:26:38.573125: step 2934, loss 1.52154, acc 0.40625\n",
      "2017-04-03T19:26:38.777463: step 2935, loss 1.63148, acc 0.375\n",
      "2017-04-03T19:26:38.970099: step 2936, loss 1.72307, acc 0.5\n",
      "2017-04-03T19:26:39.178397: step 2937, loss 1.47576, acc 0.53125\n",
      "2017-04-03T19:26:39.371760: step 2938, loss 1.50201, acc 0.421875\n",
      "2017-04-03T19:26:39.579562: step 2939, loss 1.41446, acc 0.4375\n",
      "2017-04-03T19:26:39.767557: step 2940, loss 1.37471, acc 0.53125\n",
      "2017-04-03T19:26:39.968861: step 2941, loss 1.50568, acc 0.421875\n",
      "2017-04-03T19:26:40.164294: step 2942, loss 1.51636, acc 0.484375\n",
      "2017-04-03T19:26:40.546254: step 2943, loss 1.38607, acc 0.578125\n",
      "2017-04-03T19:26:40.738455: step 2944, loss 1.33019, acc 0.609375\n",
      "2017-04-03T19:26:40.949159: step 2945, loss 1.5282, acc 0.4375\n",
      "2017-04-03T19:26:41.141902: step 2946, loss 1.46737, acc 0.5\n",
      "2017-04-03T19:26:41.345605: step 2947, loss 1.22008, acc 0.609375\n",
      "2017-04-03T19:26:41.542838: step 2948, loss 1.32649, acc 0.5625\n",
      "2017-04-03T19:26:41.743221: step 2949, loss 1.50012, acc 0.421875\n",
      "2017-04-03T19:26:41.940542: step 2950, loss 1.50789, acc 0.453125\n",
      "2017-04-03T19:26:42.144402: step 2951, loss 1.19375, acc 0.578125\n",
      "2017-04-03T19:26:42.338722: step 2952, loss 1.4104, acc 0.484375\n",
      "2017-04-03T19:26:42.543615: step 2953, loss 1.31058, acc 0.46875\n",
      "2017-04-03T19:26:42.739966: step 2954, loss 1.39771, acc 0.5\n",
      "2017-04-03T19:26:42.943751: step 2955, loss 1.38762, acc 0.5\n",
      "2017-04-03T19:26:43.135321: step 2956, loss 1.27793, acc 0.515625\n",
      "2017-04-03T19:26:43.338035: step 2957, loss 1.0747, acc 0.6875\n",
      "2017-04-03T19:26:43.531117: step 2958, loss 1.46028, acc 0.46875\n",
      "2017-04-03T19:26:43.735659: step 2959, loss 1.52623, acc 0.4375\n",
      "2017-04-03T19:26:43.931517: step 2960, loss 1.36915, acc 0.421875\n",
      "2017-04-03T19:26:44.132999: step 2961, loss 1.40066, acc 0.546875\n",
      "2017-04-03T19:26:44.325630: step 2962, loss 1.29572, acc 0.53125\n",
      "2017-04-03T19:26:44.529984: step 2963, loss 1.57905, acc 0.4375\n",
      "2017-04-03T19:26:44.721417: step 2964, loss 1.35693, acc 0.515625\n",
      "2017-04-03T19:26:44.934284: step 2965, loss 1.38325, acc 0.515625\n",
      "2017-04-03T19:26:45.126204: step 2966, loss 1.35408, acc 0.5\n",
      "2017-04-03T19:26:45.331166: step 2967, loss 1.36997, acc 0.484375\n",
      "2017-04-03T19:26:45.523418: step 2968, loss 1.35615, acc 0.546875\n",
      "2017-04-03T19:26:45.727249: step 2969, loss 1.47549, acc 0.390625\n",
      "2017-04-03T19:26:45.920480: step 2970, loss 1.35099, acc 0.5625\n",
      "2017-04-03T19:26:46.128825: step 2971, loss 1.3588, acc 0.46875\n",
      "2017-04-03T19:26:46.324362: step 2972, loss 1.34834, acc 0.5625\n",
      "2017-04-03T19:26:46.526362: step 2973, loss 1.5759, acc 0.390625\n",
      "2017-04-03T19:26:46.716513: step 2974, loss 1.44118, acc 0.453125\n",
      "2017-04-03T19:26:46.919211: step 2975, loss 1.38015, acc 0.5\n",
      "2017-04-03T19:26:47.114129: step 2976, loss 1.55661, acc 0.46875\n",
      "2017-04-03T19:26:47.324369: step 2977, loss 1.42751, acc 0.4375\n",
      "2017-04-03T19:26:47.518491: step 2978, loss 1.45861, acc 0.453125\n",
      "2017-04-03T19:26:47.721220: step 2979, loss 1.23972, acc 0.546875\n",
      "2017-04-03T19:26:47.913425: step 2980, loss 1.5643, acc 0.40625\n",
      "2017-04-03T19:26:48.121462: step 2981, loss 1.48332, acc 0.453125\n",
      "2017-04-03T19:26:48.311674: step 2982, loss 1.28901, acc 0.53125\n",
      "2017-04-03T19:26:48.512158: step 2983, loss 1.34716, acc 0.484375\n",
      "2017-04-03T19:26:48.704287: step 2984, loss 1.52556, acc 0.546875\n",
      "2017-04-03T19:26:48.907914: step 2985, loss 1.44547, acc 0.53125\n",
      "2017-04-03T19:26:49.099926: step 2986, loss 1.49221, acc 0.4375\n",
      "2017-04-03T19:26:49.303450: step 2987, loss 1.19587, acc 0.578125\n",
      "2017-04-03T19:26:49.495818: step 2988, loss 1.42297, acc 0.46875\n",
      "2017-04-03T19:26:49.698287: step 2989, loss 1.36378, acc 0.5\n",
      "2017-04-03T19:26:49.893893: step 2990, loss 1.58179, acc 0.453125\n",
      "2017-04-03T19:26:50.096393: step 2991, loss 1.45049, acc 0.421875\n",
      "2017-04-03T19:26:50.288682: step 2992, loss 1.06759, acc 0.65625\n",
      "2017-04-03T19:26:50.496976: step 2993, loss 1.20174, acc 0.578125\n",
      "2017-04-03T19:26:50.689049: step 2994, loss 1.50871, acc 0.453125\n",
      "2017-04-03T19:26:50.893205: step 2995, loss 1.30136, acc 0.515625\n",
      "2017-04-03T19:26:51.087273: step 2996, loss 1.4052, acc 0.59375\n",
      "2017-04-03T19:26:51.287613: step 2997, loss 1.33054, acc 0.515625\n",
      "2017-04-03T19:26:51.479178: step 2998, loss 1.45719, acc 0.484375\n",
      "2017-04-03T19:26:51.679242: step 2999, loss 1.28425, acc 0.625\n",
      "2017-04-03T19:26:51.871913: step 3000, loss 1.34298, acc 0.515625\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:26:53.833926: step 3000, loss 1.87424, acc 0.34675\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-3000\n",
      "\n",
      "2017-04-03T19:26:54.160908: step 3001, loss 1.35568, acc 0.5625\n",
      "2017-04-03T19:26:54.352290: step 3002, loss 1.27169, acc 0.640625\n",
      "2017-04-03T19:26:54.553602: step 3003, loss 1.5783, acc 0.390625\n",
      "2017-04-03T19:26:54.751450: step 3004, loss 1.54807, acc 0.4375\n",
      "2017-04-03T19:26:54.955265: step 3005, loss 1.13277, acc 0.609375\n",
      "2017-04-03T19:26:55.147668: step 3006, loss 1.40408, acc 0.515625\n",
      "2017-04-03T19:26:55.350137: step 3007, loss 1.62262, acc 0.4375\n",
      "2017-04-03T19:26:55.540789: step 3008, loss 1.42098, acc 0.53125\n",
      "2017-04-03T19:26:55.743432: step 3009, loss 1.51259, acc 0.390625\n",
      "2017-04-03T19:26:55.935295: step 3010, loss 1.48811, acc 0.515625\n",
      "2017-04-03T19:26:56.141942: step 3011, loss 1.29732, acc 0.53125\n",
      "2017-04-03T19:26:56.334146: step 3012, loss 1.32971, acc 0.578125\n",
      "2017-04-03T19:26:56.538765: step 3013, loss 1.60566, acc 0.46875\n",
      "2017-04-03T19:26:56.727719: step 3014, loss 1.33254, acc 0.46875\n",
      "2017-04-03T19:26:56.934334: step 3015, loss 1.34271, acc 0.546875\n",
      "2017-04-03T19:26:57.128125: step 3016, loss 1.52269, acc 0.40625\n",
      "2017-04-03T19:26:57.327165: step 3017, loss 1.67523, acc 0.375\n",
      "2017-04-03T19:26:57.519966: step 3018, loss 1.70597, acc 0.484375\n",
      "2017-04-03T19:26:57.724488: step 3019, loss 1.45226, acc 0.53125\n",
      "2017-04-03T19:26:57.918989: step 3020, loss 1.70746, acc 0.46875\n",
      "2017-04-03T19:26:58.124651: step 3021, loss 1.3548, acc 0.5\n",
      "2017-04-03T19:26:58.315213: step 3022, loss 1.42163, acc 0.53125\n",
      "2017-04-03T19:26:58.521402: step 3023, loss 1.63361, acc 0.546875\n",
      "2017-04-03T19:26:58.717322: step 3024, loss 1.33171, acc 0.5625\n",
      "2017-04-03T19:26:58.922087: step 3025, loss 1.69914, acc 0.421875\n",
      "2017-04-03T19:26:59.112657: step 3026, loss 1.37733, acc 0.515625\n",
      "2017-04-03T19:26:59.311777: step 3027, loss 1.44537, acc 0.546875\n",
      "2017-04-03T19:26:59.508556: step 3028, loss 1.42907, acc 0.53125\n",
      "2017-04-03T19:26:59.720217: step 3029, loss 1.34434, acc 0.578125\n",
      "2017-04-03T19:26:59.918520: step 3030, loss 1.69683, acc 0.40625\n",
      "2017-04-03T19:27:00.121765: step 3031, loss 1.51062, acc 0.484375\n",
      "2017-04-03T19:27:00.312493: step 3032, loss 1.31328, acc 0.515625\n",
      "2017-04-03T19:27:00.511766: step 3033, loss 1.49943, acc 0.4375\n",
      "2017-04-03T19:27:00.704071: step 3034, loss 1.65177, acc 0.4375\n",
      "2017-04-03T19:27:00.906530: step 3035, loss 1.48218, acc 0.359375\n",
      "2017-04-03T19:27:01.102236: step 3036, loss 1.41969, acc 0.515625\n",
      "2017-04-03T19:27:01.300473: step 3037, loss 1.49423, acc 0.46875\n",
      "2017-04-03T19:27:01.493113: step 3038, loss 1.29389, acc 0.578125\n",
      "2017-04-03T19:27:01.697205: step 3039, loss 1.29856, acc 0.53125\n",
      "2017-04-03T19:27:01.888361: step 3040, loss 1.44953, acc 0.5625\n",
      "2017-04-03T19:27:02.087100: step 3041, loss 1.38345, acc 0.46875\n",
      "2017-04-03T19:27:02.281092: step 3042, loss 1.72864, acc 0.390625\n",
      "2017-04-03T19:27:02.482709: step 3043, loss 1.35602, acc 0.5625\n",
      "2017-04-03T19:27:02.676758: step 3044, loss 1.31842, acc 0.53125\n",
      "2017-04-03T19:27:02.879111: step 3045, loss 1.3099, acc 0.578125\n",
      "2017-04-03T19:27:03.069042: step 3046, loss 1.44, acc 0.46875\n",
      "2017-04-03T19:27:03.279493: step 3047, loss 1.43011, acc 0.53125\n",
      "2017-04-03T19:27:03.473388: step 3048, loss 1.50139, acc 0.515625\n",
      "2017-04-03T19:27:03.671356: step 3049, loss 1.22982, acc 0.640625\n",
      "2017-04-03T19:27:03.865219: step 3050, loss 1.30228, acc 0.578125\n",
      "2017-04-03T19:27:04.069034: step 3051, loss 1.81743, acc 0.375\n",
      "2017-04-03T19:27:04.263145: step 3052, loss 1.407, acc 0.484375\n",
      "2017-04-03T19:27:04.461725: step 3053, loss 1.20166, acc 0.59375\n",
      "2017-04-03T19:27:04.654674: step 3054, loss 1.5924, acc 0.484375\n",
      "2017-04-03T19:27:04.854184: step 3055, loss 1.47954, acc 0.5\n",
      "2017-04-03T19:27:05.045570: step 3056, loss 1.26476, acc 0.59375\n",
      "2017-04-03T19:27:05.245299: step 3057, loss 1.42276, acc 0.453125\n",
      "2017-04-03T19:27:05.440530: step 3058, loss 1.29587, acc 0.515625\n",
      "2017-04-03T19:27:05.642328: step 3059, loss 1.53293, acc 0.4375\n",
      "2017-04-03T19:27:05.832532: step 3060, loss 1.50091, acc 0.46875\n",
      "2017-04-03T19:27:06.032645: step 3061, loss 1.2644, acc 0.578125\n",
      "2017-04-03T19:27:06.224424: step 3062, loss 1.40586, acc 0.46875\n",
      "2017-04-03T19:27:06.423865: step 3063, loss 1.42624, acc 0.53125\n",
      "2017-04-03T19:27:06.614480: step 3064, loss 1.43593, acc 0.515625\n",
      "2017-04-03T19:27:06.813675: step 3065, loss 1.57164, acc 0.46875\n",
      "2017-04-03T19:27:07.007208: step 3066, loss 1.30942, acc 0.578125\n",
      "2017-04-03T19:27:07.206127: step 3067, loss 1.32595, acc 0.5625\n",
      "2017-04-03T19:27:07.396766: step 3068, loss 1.35787, acc 0.515625\n",
      "2017-04-03T19:27:07.602276: step 3069, loss 1.3091, acc 0.546875\n",
      "2017-04-03T19:27:07.794309: step 3070, loss 1.52022, acc 0.4375\n",
      "2017-04-03T19:27:07.992997: step 3071, loss 1.48713, acc 0.390625\n",
      "2017-04-03T19:27:08.184945: step 3072, loss 1.42659, acc 0.40625\n",
      "2017-04-03T19:27:08.386154: step 3073, loss 1.38963, acc 0.484375\n",
      "2017-04-03T19:27:08.579595: step 3074, loss 1.24244, acc 0.484375\n",
      "2017-04-03T19:27:08.782103: step 3075, loss 1.4005, acc 0.578125\n",
      "2017-04-03T19:27:08.975589: step 3076, loss 1.27297, acc 0.515625\n",
      "2017-04-03T19:27:09.176468: step 3077, loss 1.34709, acc 0.53125\n",
      "2017-04-03T19:27:09.368119: step 3078, loss 1.51179, acc 0.546875\n",
      "2017-04-03T19:27:09.574227: step 3079, loss 1.20837, acc 0.625\n",
      "2017-04-03T19:27:09.765072: step 3080, loss 1.37207, acc 0.546875\n",
      "2017-04-03T19:27:09.972842: step 3081, loss 1.48533, acc 0.5\n",
      "2017-04-03T19:27:10.168205: step 3082, loss 1.31195, acc 0.5625\n",
      "2017-04-03T19:27:10.381014: step 3083, loss 1.42679, acc 0.46875\n",
      "2017-04-03T19:27:10.583335: step 3084, loss 1.34893, acc 0.53125\n",
      "2017-04-03T19:27:10.797086: step 3085, loss 1.42311, acc 0.53125\n",
      "2017-04-03T19:27:10.998957: step 3086, loss 1.30314, acc 0.53125\n",
      "2017-04-03T19:27:11.201979: step 3087, loss 1.44737, acc 0.5625\n",
      "2017-04-03T19:27:11.398453: step 3088, loss 1.62934, acc 0.421875\n",
      "2017-04-03T19:27:11.598609: step 3089, loss 1.60636, acc 0.453125\n",
      "2017-04-03T19:27:11.792739: step 3090, loss 1.35368, acc 0.515625\n",
      "2017-04-03T19:27:11.997376: step 3091, loss 1.42706, acc 0.5\n",
      "2017-04-03T19:27:12.191040: step 3092, loss 1.47248, acc 0.453125\n",
      "2017-04-03T19:27:12.393567: step 3093, loss 1.30582, acc 0.640625\n",
      "2017-04-03T19:27:12.586123: step 3094, loss 1.34521, acc 0.546875\n",
      "2017-04-03T19:27:12.787671: step 3095, loss 1.62231, acc 0.453125\n",
      "2017-04-03T19:27:12.987012: step 3096, loss 1.468, acc 0.390625\n",
      "2017-04-03T19:27:13.191331: step 3097, loss 1.56533, acc 0.4375\n",
      "2017-04-03T19:27:13.381014: step 3098, loss 1.42553, acc 0.5\n",
      "2017-04-03T19:27:13.583994: step 3099, loss 1.47094, acc 0.46875\n",
      "2017-04-03T19:27:13.782232: step 3100, loss 1.46547, acc 0.453125\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:27:15.776091: step 3100, loss 1.87398, acc 0.34775\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-3100\n",
      "\n",
      "2017-04-03T19:27:16.107675: step 3101, loss 1.29914, acc 0.484375\n",
      "2017-04-03T19:27:16.299136: step 3102, loss 1.54525, acc 0.46875\n",
      "2017-04-03T19:27:16.501556: step 3103, loss 1.45184, acc 0.453125\n",
      "2017-04-03T19:27:16.690564: step 3104, loss 1.2637, acc 0.578125\n",
      "2017-04-03T19:27:16.893764: step 3105, loss 1.5909, acc 0.4375\n",
      "2017-04-03T19:27:17.082510: step 3106, loss 1.22179, acc 0.46875\n",
      "2017-04-03T19:27:17.283247: step 3107, loss 1.31825, acc 0.5\n",
      "2017-04-03T19:27:17.470190: step 3108, loss 1.30225, acc 0.453125\n",
      "2017-04-03T19:27:17.675924: step 3109, loss 1.60167, acc 0.484375\n",
      "2017-04-03T19:27:17.872759: step 3110, loss 1.75901, acc 0.34375\n",
      "2017-04-03T19:27:18.071265: step 3111, loss 1.415, acc 0.5625\n",
      "2017-04-03T19:27:18.264780: step 3112, loss 1.32641, acc 0.578125\n",
      "2017-04-03T19:27:18.465610: step 3113, loss 1.55464, acc 0.4375\n",
      "2017-04-03T19:27:18.656735: step 3114, loss 1.26007, acc 0.53125\n",
      "2017-04-03T19:27:18.856985: step 3115, loss 1.59858, acc 0.453125\n",
      "2017-04-03T19:27:19.049156: step 3116, loss 1.36042, acc 0.625\n",
      "2017-04-03T19:27:19.251023: step 3117, loss 1.70571, acc 0.390625\n",
      "2017-04-03T19:27:19.443904: step 3118, loss 1.36297, acc 0.484375\n",
      "2017-04-03T19:27:19.648044: step 3119, loss 1.31266, acc 0.546875\n",
      "2017-04-03T19:27:19.839254: step 3120, loss 1.39403, acc 0.53125\n",
      "2017-04-03T19:27:20.037890: step 3121, loss 1.55036, acc 0.484375\n",
      "2017-04-03T19:27:20.230069: step 3122, loss 1.52287, acc 0.4375\n",
      "2017-04-03T19:27:20.433782: step 3123, loss 1.46295, acc 0.484375\n",
      "2017-04-03T19:27:20.620815: step 3124, loss 1.34496, acc 0.578125\n",
      "2017-04-03T19:27:20.825474: step 3125, loss 1.51477, acc 0.484375\n",
      "2017-04-03T19:27:21.017553: step 3126, loss 1.55641, acc 0.46875\n",
      "2017-04-03T19:27:21.217300: step 3127, loss 1.43149, acc 0.46875\n",
      "2017-04-03T19:27:21.411589: step 3128, loss 1.4135, acc 0.453125\n",
      "2017-04-03T19:27:21.612126: step 3129, loss 1.35055, acc 0.578125\n",
      "2017-04-03T19:27:21.800709: step 3130, loss 1.39201, acc 0.546875\n",
      "2017-04-03T19:27:22.008333: step 3131, loss 1.26804, acc 0.546875\n",
      "2017-04-03T19:27:22.201817: step 3132, loss 1.62908, acc 0.40625\n",
      "2017-04-03T19:27:22.398883: step 3133, loss 1.31475, acc 0.46875\n",
      "2017-04-03T19:27:22.590687: step 3134, loss 1.42125, acc 0.53125\n",
      "2017-04-03T19:27:22.790958: step 3135, loss 1.49888, acc 0.46875\n",
      "2017-04-03T19:27:22.982749: step 3136, loss 1.39416, acc 0.4375\n",
      "2017-04-03T19:27:23.185406: step 3137, loss 1.51612, acc 0.515625\n",
      "2017-04-03T19:27:23.375372: step 3138, loss 1.32981, acc 0.546875\n",
      "2017-04-03T19:27:23.576138: step 3139, loss 1.44547, acc 0.484375\n",
      "2017-04-03T19:27:23.763519: step 3140, loss 1.32951, acc 0.5625\n",
      "2017-04-03T19:27:23.964863: step 3141, loss 1.23514, acc 0.484375\n",
      "2017-04-03T19:27:24.154815: step 3142, loss 1.26904, acc 0.515625\n",
      "2017-04-03T19:27:24.356809: step 3143, loss 1.45057, acc 0.5\n",
      "2017-04-03T19:27:24.549010: step 3144, loss 1.47413, acc 0.46875\n",
      "2017-04-03T19:27:24.754602: step 3145, loss 1.3599, acc 0.53125\n",
      "2017-04-03T19:27:24.945932: step 3146, loss 1.38354, acc 0.484375\n",
      "2017-04-03T19:27:25.149246: step 3147, loss 1.48658, acc 0.453125\n",
      "2017-04-03T19:27:25.339644: step 3148, loss 1.30718, acc 0.53125\n",
      "2017-04-03T19:27:25.543602: step 3149, loss 1.41938, acc 0.40625\n",
      "2017-04-03T19:27:25.733988: step 3150, loss 1.26418, acc 0.46875\n",
      "2017-04-03T19:27:25.936723: step 3151, loss 1.27948, acc 0.53125\n",
      "2017-04-03T19:27:26.130849: step 3152, loss 1.54479, acc 0.46875\n",
      "2017-04-03T19:27:26.335953: step 3153, loss 1.29283, acc 0.515625\n",
      "2017-04-03T19:27:26.527175: step 3154, loss 1.70305, acc 0.375\n",
      "2017-04-03T19:27:26.727863: step 3155, loss 1.67885, acc 0.421875\n",
      "2017-04-03T19:27:26.918447: step 3156, loss 1.32514, acc 0.546875\n",
      "2017-04-03T19:27:27.121875: step 3157, loss 1.49868, acc 0.546875\n",
      "2017-04-03T19:27:27.315115: step 3158, loss 1.52822, acc 0.421875\n",
      "2017-04-03T19:27:27.521558: step 3159, loss 1.58136, acc 0.421875\n",
      "2017-04-03T19:27:27.709478: step 3160, loss 1.48295, acc 0.515625\n",
      "2017-04-03T19:27:27.909094: step 3161, loss 1.82652, acc 0.390625\n",
      "2017-04-03T19:27:28.100816: step 3162, loss 1.3752, acc 0.46875\n",
      "2017-04-03T19:27:28.306801: step 3163, loss 1.56022, acc 0.453125\n",
      "2017-04-03T19:27:28.496606: step 3164, loss 1.53896, acc 0.4375\n",
      "2017-04-03T19:27:28.696730: step 3165, loss 1.53137, acc 0.46875\n",
      "2017-04-03T19:27:28.888415: step 3166, loss 1.84236, acc 0.359375\n",
      "2017-04-03T19:27:29.090847: step 3167, loss 1.47398, acc 0.546875\n",
      "2017-04-03T19:27:29.285582: step 3168, loss 1.59213, acc 0.375\n",
      "2017-04-03T19:27:29.486507: step 3169, loss 1.5668, acc 0.4375\n",
      "2017-04-03T19:27:29.675859: step 3170, loss 1.60937, acc 0.5\n",
      "2017-04-03T19:27:29.869519: step 3171, loss 1.48747, acc 0.5\n",
      "2017-04-03T19:27:30.058043: step 3172, loss 1.21853, acc 0.5625\n",
      "2017-04-03T19:27:30.260480: step 3173, loss 1.39254, acc 0.5625\n",
      "2017-04-03T19:27:30.447837: step 3174, loss 1.21945, acc 0.609375\n",
      "2017-04-03T19:27:30.646581: step 3175, loss 1.40283, acc 0.484375\n",
      "2017-04-03T19:27:30.839974: step 3176, loss 1.50508, acc 0.453125\n",
      "2017-04-03T19:27:31.044431: step 3177, loss 1.4994, acc 0.46875\n",
      "2017-04-03T19:27:31.232757: step 3178, loss 1.47904, acc 0.46875\n",
      "2017-04-03T19:27:31.433452: step 3179, loss 1.34245, acc 0.46875\n",
      "2017-04-03T19:27:31.626631: step 3180, loss 1.38697, acc 0.53125\n",
      "2017-04-03T19:27:31.827833: step 3181, loss 1.4052, acc 0.46875\n",
      "2017-04-03T19:27:32.018886: step 3182, loss 1.51381, acc 0.390625\n",
      "2017-04-03T19:27:32.220122: step 3183, loss 1.64131, acc 0.390625\n",
      "2017-04-03T19:27:32.415551: step 3184, loss 1.48757, acc 0.484375\n",
      "2017-04-03T19:27:32.618190: step 3185, loss 1.23391, acc 0.625\n",
      "2017-04-03T19:27:32.809916: step 3186, loss 1.53134, acc 0.4375\n",
      "2017-04-03T19:27:33.012645: step 3187, loss 1.32445, acc 0.5625\n",
      "2017-04-03T19:27:33.202926: step 3188, loss 1.5794, acc 0.46875\n",
      "2017-04-03T19:27:33.403508: step 3189, loss 1.39978, acc 0.46875\n",
      "2017-04-03T19:27:33.598573: step 3190, loss 1.50485, acc 0.484375\n",
      "2017-04-03T19:27:33.804796: step 3191, loss 1.21306, acc 0.53125\n",
      "2017-04-03T19:27:33.992426: step 3192, loss 1.57694, acc 0.4375\n",
      "2017-04-03T19:27:34.194761: step 3193, loss 1.63866, acc 0.390625\n",
      "2017-04-03T19:27:34.385349: step 3194, loss 1.42452, acc 0.484375\n",
      "2017-04-03T19:27:34.587897: step 3195, loss 1.54975, acc 0.421875\n",
      "2017-04-03T19:27:34.782189: step 3196, loss 1.41119, acc 0.375\n",
      "2017-04-03T19:27:34.985006: step 3197, loss 1.30524, acc 0.5625\n",
      "2017-04-03T19:27:35.177782: step 3198, loss 1.35934, acc 0.578125\n",
      "2017-04-03T19:27:35.379106: step 3199, loss 1.37606, acc 0.515625\n",
      "2017-04-03T19:27:35.572080: step 3200, loss 1.54104, acc 0.46875\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:27:37.520774: step 3200, loss 1.8794, acc 0.347\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-3200\n",
      "\n",
      "2017-04-03T19:27:37.846176: step 3201, loss 1.31115, acc 0.5625\n",
      "2017-04-03T19:27:38.039567: step 3202, loss 1.46394, acc 0.453125\n",
      "2017-04-03T19:27:38.244931: step 3203, loss 1.45805, acc 0.421875\n",
      "2017-04-03T19:27:38.439786: step 3204, loss 1.48995, acc 0.484375\n",
      "2017-04-03T19:27:38.643637: step 3205, loss 1.10362, acc 0.59375\n",
      "2017-04-03T19:27:38.840128: step 3206, loss 1.37301, acc 0.46875\n",
      "2017-04-03T19:27:39.047101: step 3207, loss 1.57677, acc 0.375\n",
      "2017-04-03T19:27:39.245880: step 3208, loss 1.7303, acc 0.40625\n",
      "2017-04-03T19:27:39.452318: step 3209, loss 1.34048, acc 0.53125\n",
      "2017-04-03T19:27:39.644218: step 3210, loss 1.51547, acc 0.484375\n",
      "2017-04-03T19:27:39.844676: step 3211, loss 1.26314, acc 0.5625\n",
      "2017-04-03T19:27:40.037971: step 3212, loss 1.50673, acc 0.5\n",
      "2017-04-03T19:27:40.240975: step 3213, loss 1.44974, acc 0.484375\n",
      "2017-04-03T19:27:40.439117: step 3214, loss 1.49479, acc 0.453125\n",
      "2017-04-03T19:27:40.645109: step 3215, loss 1.49599, acc 0.578125\n",
      "2017-04-03T19:27:40.838559: step 3216, loss 1.47864, acc 0.46875\n",
      "2017-04-03T19:27:41.044603: step 3217, loss 1.66092, acc 0.390625\n",
      "2017-04-03T19:27:41.237885: step 3218, loss 1.61847, acc 0.34375\n",
      "2017-04-03T19:27:41.436288: step 3219, loss 1.52384, acc 0.5\n",
      "2017-04-03T19:27:41.631768: step 3220, loss 1.55678, acc 0.40625\n",
      "2017-04-03T19:27:41.835248: step 3221, loss 1.34021, acc 0.4375\n",
      "2017-04-03T19:27:42.023349: step 3222, loss 1.64099, acc 0.390625\n",
      "2017-04-03T19:27:42.232341: step 3223, loss 1.46231, acc 0.46875\n",
      "2017-04-03T19:27:42.424454: step 3224, loss 1.2376, acc 0.53125\n",
      "2017-04-03T19:27:42.623872: step 3225, loss 1.57643, acc 0.390625\n",
      "2017-04-03T19:27:42.814874: step 3226, loss 1.28224, acc 0.59375\n",
      "2017-04-03T19:27:43.017144: step 3227, loss 1.5328, acc 0.5\n",
      "2017-04-03T19:27:43.210217: step 3228, loss 1.72705, acc 0.484375\n",
      "2017-04-03T19:27:43.414211: step 3229, loss 1.44404, acc 0.5\n",
      "2017-04-03T19:27:43.607264: step 3230, loss 1.48145, acc 0.46875\n",
      "2017-04-03T19:27:43.816672: step 3231, loss 1.59456, acc 0.390625\n",
      "2017-04-03T19:27:44.009062: step 3232, loss 1.34933, acc 0.46875\n",
      "2017-04-03T19:27:44.214085: step 3233, loss 1.59818, acc 0.484375\n",
      "2017-04-03T19:27:44.410141: step 3234, loss 1.46564, acc 0.546875\n",
      "2017-04-03T19:27:44.612879: step 3235, loss 1.55721, acc 0.40625\n",
      "2017-04-03T19:27:44.803236: step 3236, loss 1.66332, acc 0.46875\n",
      "2017-04-03T19:27:44.999739: step 3237, loss 1.40624, acc 0.515625\n",
      "2017-04-03T19:27:45.194840: step 3238, loss 1.47278, acc 0.453125\n",
      "2017-04-03T19:27:45.395041: step 3239, loss 1.521, acc 0.515625\n",
      "2017-04-03T19:27:45.588596: step 3240, loss 1.71136, acc 0.4375\n",
      "2017-04-03T19:27:45.798541: step 3241, loss 1.26299, acc 0.515625\n",
      "2017-04-03T19:27:45.989711: step 3242, loss 1.23501, acc 0.53125\n",
      "2017-04-03T19:27:46.193431: step 3243, loss 1.65912, acc 0.390625\n",
      "2017-04-03T19:27:46.388677: step 3244, loss 1.4023, acc 0.484375\n",
      "2017-04-03T19:27:46.597169: step 3245, loss 1.48246, acc 0.5625\n",
      "2017-04-03T19:27:46.791936: step 3246, loss 1.41635, acc 0.484375\n",
      "2017-04-03T19:27:46.994959: step 3247, loss 1.47471, acc 0.53125\n",
      "2017-04-03T19:27:47.188619: step 3248, loss 1.46072, acc 0.53125\n",
      "2017-04-03T19:27:47.390651: step 3249, loss 1.42182, acc 0.515625\n",
      "2017-04-03T19:27:47.581481: step 3250, loss 1.3917, acc 0.484375\n",
      "2017-04-03T19:27:47.791712: step 3251, loss 1.362, acc 0.484375\n",
      "2017-04-03T19:27:47.985611: step 3252, loss 1.73778, acc 0.359375\n",
      "2017-04-03T19:27:48.192690: step 3253, loss 1.46272, acc 0.484375\n",
      "2017-04-03T19:27:48.385108: step 3254, loss 1.49752, acc 0.5\n",
      "2017-04-03T19:27:48.584736: step 3255, loss 1.72715, acc 0.453125\n",
      "2017-04-03T19:27:48.776589: step 3256, loss 1.56892, acc 0.4375\n",
      "2017-04-03T19:27:48.976647: step 3257, loss 1.37412, acc 0.53125\n",
      "2017-04-03T19:27:49.168345: step 3258, loss 1.48437, acc 0.484375\n",
      "2017-04-03T19:27:49.371175: step 3259, loss 1.57522, acc 0.375\n",
      "2017-04-03T19:27:49.560581: step 3260, loss 1.44527, acc 0.484375\n",
      "2017-04-03T19:27:49.760284: step 3261, loss 1.32086, acc 0.5\n",
      "2017-04-03T19:27:49.954321: step 3262, loss 1.38515, acc 0.4375\n",
      "2017-04-03T19:27:50.164927: step 3263, loss 1.32179, acc 0.515625\n",
      "2017-04-03T19:27:50.363173: step 3264, loss 1.46029, acc 0.453125\n",
      "2017-04-03T19:27:50.565517: step 3265, loss 1.48476, acc 0.53125\n",
      "2017-04-03T19:27:50.759728: step 3266, loss 1.58318, acc 0.4375\n",
      "2017-04-03T19:27:50.963626: step 3267, loss 1.2347, acc 0.609375\n",
      "2017-04-03T19:27:51.158527: step 3268, loss 1.57562, acc 0.390625\n",
      "2017-04-03T19:27:51.364672: step 3269, loss 1.44546, acc 0.546875\n",
      "2017-04-03T19:27:51.560721: step 3270, loss 1.41628, acc 0.390625\n",
      "2017-04-03T19:27:51.765117: step 3271, loss 1.57736, acc 0.421875\n",
      "2017-04-03T19:27:51.956257: step 3272, loss 1.46912, acc 0.453125\n",
      "2017-04-03T19:27:52.158451: step 3273, loss 1.46806, acc 0.484375\n",
      "2017-04-03T19:27:52.350812: step 3274, loss 1.44535, acc 0.421875\n",
      "2017-04-03T19:27:52.552991: step 3275, loss 1.34961, acc 0.5\n",
      "2017-04-03T19:27:52.742904: step 3276, loss 1.51686, acc 0.46875\n",
      "2017-04-03T19:27:52.948729: step 3277, loss 1.54416, acc 0.453125\n",
      "2017-04-03T19:27:53.140184: step 3278, loss 1.70396, acc 0.375\n",
      "2017-04-03T19:27:53.338213: step 3279, loss 1.44615, acc 0.453125\n",
      "2017-04-03T19:27:53.532825: step 3280, loss 1.59408, acc 0.46875\n",
      "2017-04-03T19:27:53.732852: step 3281, loss 1.33852, acc 0.53125\n",
      "2017-04-03T19:27:53.924082: step 3282, loss 1.49508, acc 0.5\n",
      "2017-04-03T19:27:54.127858: step 3283, loss 1.63435, acc 0.421875\n",
      "2017-04-03T19:27:54.322030: step 3284, loss 1.39708, acc 0.46875\n",
      "2017-04-03T19:27:54.527725: step 3285, loss 1.59714, acc 0.421875\n",
      "2017-04-03T19:27:54.721887: step 3286, loss 1.56216, acc 0.515625\n",
      "2017-04-03T19:27:54.927773: step 3287, loss 1.62983, acc 0.453125\n",
      "2017-04-03T19:27:55.122800: step 3288, loss 1.25302, acc 0.609375\n",
      "2017-04-03T19:27:55.329340: step 3289, loss 1.5404, acc 0.484375\n",
      "2017-04-03T19:27:55.525786: step 3290, loss 1.5401, acc 0.484375\n",
      "2017-04-03T19:27:55.738576: step 3291, loss 1.45821, acc 0.453125\n",
      "2017-04-03T19:27:55.931750: step 3292, loss 1.48739, acc 0.5\n",
      "2017-04-03T19:27:56.134435: step 3293, loss 1.37313, acc 0.53125\n",
      "2017-04-03T19:27:56.326892: step 3294, loss 1.35265, acc 0.5\n",
      "2017-04-03T19:27:56.529966: step 3295, loss 1.46128, acc 0.5\n",
      "2017-04-03T19:27:56.723524: step 3296, loss 1.54875, acc 0.46875\n",
      "2017-04-03T19:27:56.925531: step 3297, loss 1.58089, acc 0.46875\n",
      "2017-04-03T19:27:57.118572: step 3298, loss 1.51589, acc 0.453125\n",
      "2017-04-03T19:27:57.332505: step 3299, loss 1.66245, acc 0.453125\n",
      "2017-04-03T19:27:57.522931: step 3300, loss 1.49464, acc 0.4375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:27:59.467568: step 3300, loss 1.88594, acc 0.34775\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-3300\n",
      "\n",
      "2017-04-03T19:27:59.826738: step 3301, loss 1.42229, acc 0.484375\n",
      "2017-04-03T19:28:00.018068: step 3302, loss 1.51054, acc 0.5\n",
      "2017-04-03T19:28:00.221773: step 3303, loss 1.39316, acc 0.46875\n",
      "2017-04-03T19:28:00.415320: step 3304, loss 1.58322, acc 0.46875\n",
      "2017-04-03T19:28:00.615920: step 3305, loss 1.28512, acc 0.53125\n",
      "2017-04-03T19:28:00.810690: step 3306, loss 1.39229, acc 0.5625\n",
      "2017-04-03T19:28:01.015267: step 3307, loss 1.37554, acc 0.578125\n",
      "2017-04-03T19:28:01.211421: step 3308, loss 1.58333, acc 0.4375\n",
      "2017-04-03T19:28:01.416799: step 3309, loss 1.34118, acc 0.5\n",
      "2017-04-03T19:28:01.608076: step 3310, loss 1.27866, acc 0.5625\n",
      "2017-04-03T19:28:01.838423: step 3311, loss 1.65581, acc 0.421875\n",
      "2017-04-03T19:28:02.032046: step 3312, loss 1.44326, acc 0.484375\n",
      "2017-04-03T19:28:02.235181: step 3313, loss 1.27674, acc 0.546875\n",
      "2017-04-03T19:28:02.427386: step 3314, loss 1.49706, acc 0.46875\n",
      "2017-04-03T19:28:02.636037: step 3315, loss 1.61752, acc 0.34375\n",
      "2017-04-03T19:28:02.831087: step 3316, loss 1.64037, acc 0.453125\n",
      "2017-04-03T19:28:03.030891: step 3317, loss 1.69767, acc 0.359375\n",
      "2017-04-03T19:28:03.224945: step 3318, loss 1.31223, acc 0.53125\n",
      "2017-04-03T19:28:03.430777: step 3319, loss 1.5958, acc 0.484375\n",
      "2017-04-03T19:28:03.625648: step 3320, loss 1.49883, acc 0.5\n",
      "2017-04-03T19:28:03.824752: step 3321, loss 1.64334, acc 0.484375\n",
      "2017-04-03T19:28:04.016550: step 3322, loss 1.3377, acc 0.59375\n",
      "2017-04-03T19:28:04.218277: step 3323, loss 1.51156, acc 0.421875\n",
      "2017-04-03T19:28:04.412040: step 3324, loss 1.39994, acc 0.453125\n",
      "2017-04-03T19:28:04.607669: step 3325, loss 1.47537, acc 0.421875\n",
      "2017-04-03T19:28:04.801899: step 3326, loss 1.70718, acc 0.4375\n",
      "2017-04-03T19:28:05.003461: step 3327, loss 1.77238, acc 0.390625\n",
      "2017-04-03T19:28:05.200603: step 3328, loss 1.6071, acc 0.328125\n",
      "2017-04-03T19:28:05.430243: step 3329, loss 1.34389, acc 0.53125\n",
      "2017-04-03T19:28:05.623873: step 3330, loss 1.53166, acc 0.453125\n",
      "2017-04-03T19:28:05.825966: step 3331, loss 1.64493, acc 0.4375\n",
      "2017-04-03T19:28:06.018167: step 3332, loss 1.36213, acc 0.53125\n",
      "2017-04-03T19:28:06.227488: step 3333, loss 1.43217, acc 0.484375\n",
      "2017-04-03T19:28:06.423978: step 3334, loss 1.65241, acc 0.484375\n",
      "2017-04-03T19:28:06.627019: step 3335, loss 1.52749, acc 0.40625\n",
      "2017-04-03T19:28:06.822386: step 3336, loss 1.7466, acc 0.359375\n",
      "2017-04-03T19:28:07.023075: step 3337, loss 1.5076, acc 0.453125\n",
      "2017-04-03T19:28:07.215994: step 3338, loss 1.5318, acc 0.515625\n",
      "2017-04-03T19:28:07.413478: step 3339, loss 1.33046, acc 0.5625\n",
      "2017-04-03T19:28:07.607447: step 3340, loss 1.47798, acc 0.453125\n",
      "2017-04-03T19:28:07.804672: step 3341, loss 1.55401, acc 0.484375\n",
      "2017-04-03T19:28:07.997106: step 3342, loss 1.41053, acc 0.546875\n",
      "2017-04-03T19:28:08.205089: step 3343, loss 1.28759, acc 0.5\n",
      "2017-04-03T19:28:08.401576: step 3344, loss 1.67295, acc 0.34375\n",
      "2017-04-03T19:28:08.601971: step 3345, loss 1.55523, acc 0.421875\n",
      "2017-04-03T19:28:08.797688: step 3346, loss 1.34457, acc 0.546875\n",
      "2017-04-03T19:28:09.000341: step 3347, loss 1.40468, acc 0.40625\n",
      "2017-04-03T19:28:09.195176: step 3348, loss 1.58489, acc 0.359375\n",
      "2017-04-03T19:28:09.396169: step 3349, loss 1.29599, acc 0.546875\n",
      "2017-04-03T19:28:09.591429: step 3350, loss 1.74497, acc 0.4375\n",
      "2017-04-03T19:28:09.796097: step 3351, loss 1.52436, acc 0.4375\n",
      "2017-04-03T19:28:09.989208: step 3352, loss 1.39619, acc 0.453125\n",
      "2017-04-03T19:28:10.195126: step 3353, loss 1.53575, acc 0.4375\n",
      "2017-04-03T19:28:10.387873: step 3354, loss 1.36511, acc 0.515625\n",
      "2017-04-03T19:28:10.616868: step 3355, loss 1.56064, acc 0.328125\n",
      "2017-04-03T19:28:10.810476: step 3356, loss 1.56022, acc 0.515625\n",
      "2017-04-03T19:28:11.017111: step 3357, loss 1.46954, acc 0.5625\n",
      "2017-04-03T19:28:11.213411: step 3358, loss 1.45163, acc 0.4375\n",
      "2017-04-03T19:28:11.424155: step 3359, loss 1.53392, acc 0.453125\n",
      "2017-04-03T19:28:11.618033: step 3360, loss 1.45142, acc 0.421875\n",
      "2017-04-03T19:28:11.823321: step 3361, loss 1.23998, acc 0.59375\n",
      "2017-04-03T19:28:12.017981: step 3362, loss 1.51506, acc 0.359375\n",
      "2017-04-03T19:28:12.221637: step 3363, loss 1.35826, acc 0.484375\n",
      "2017-04-03T19:28:12.415207: step 3364, loss 1.38848, acc 0.5625\n",
      "2017-04-03T19:28:12.625644: step 3365, loss 1.49023, acc 0.453125\n",
      "2017-04-03T19:28:12.818229: step 3366, loss 1.59995, acc 0.4375\n",
      "2017-04-03T19:28:13.046455: step 3367, loss 1.44579, acc 0.5625\n",
      "2017-04-03T19:28:13.242233: step 3368, loss 1.2566, acc 0.546875\n",
      "2017-04-03T19:28:13.446649: step 3369, loss 1.322, acc 0.5625\n",
      "2017-04-03T19:28:13.644331: step 3370, loss 1.56053, acc 0.5\n",
      "2017-04-03T19:28:13.848013: step 3371, loss 1.24658, acc 0.609375\n",
      "2017-04-03T19:28:14.039599: step 3372, loss 1.41581, acc 0.5625\n",
      "2017-04-03T19:28:14.247903: step 3373, loss 1.63614, acc 0.453125\n",
      "2017-04-03T19:28:14.441868: step 3374, loss 1.35724, acc 0.46875\n",
      "2017-04-03T19:28:14.673157: step 3375, loss 1.51836, acc 0.46875\n",
      "2017-04-03T19:28:14.869655: step 3376, loss 1.53771, acc 0.453125\n",
      "2017-04-03T19:28:15.071852: step 3377, loss 1.34674, acc 0.453125\n",
      "2017-04-03T19:28:15.220374: step 3378, loss 1.58899, acc 0.375\n",
      "2017-04-03T19:28:15.427902: step 3379, loss 1.13556, acc 0.59375\n",
      "2017-04-03T19:28:15.622743: step 3380, loss 1.13392, acc 0.609375\n",
      "2017-04-03T19:28:15.834814: step 3381, loss 1.2782, acc 0.609375\n",
      "2017-04-03T19:28:16.028731: step 3382, loss 1.05923, acc 0.671875\n",
      "2017-04-03T19:28:16.227728: step 3383, loss 1.37299, acc 0.515625\n",
      "2017-04-03T19:28:16.427482: step 3384, loss 1.2772, acc 0.609375\n",
      "2017-04-03T19:28:16.629734: step 3385, loss 1.43429, acc 0.578125\n",
      "2017-04-03T19:28:16.831282: step 3386, loss 1.0973, acc 0.59375\n",
      "2017-04-03T19:28:17.030838: step 3387, loss 1.24392, acc 0.625\n",
      "2017-04-03T19:28:17.234046: step 3388, loss 1.17503, acc 0.609375\n",
      "2017-04-03T19:28:17.430617: step 3389, loss 1.20979, acc 0.609375\n",
      "2017-04-03T19:28:17.627047: step 3390, loss 1.15372, acc 0.546875\n",
      "2017-04-03T19:28:17.825351: step 3391, loss 1.20876, acc 0.609375\n",
      "2017-04-03T19:28:18.027587: step 3392, loss 1.15544, acc 0.578125\n",
      "2017-04-03T19:28:18.220382: step 3393, loss 1.58123, acc 0.421875\n",
      "2017-04-03T19:28:18.418436: step 3394, loss 1.4203, acc 0.484375\n",
      "2017-04-03T19:28:18.610770: step 3395, loss 1.15158, acc 0.578125\n",
      "2017-04-03T19:28:18.816673: step 3396, loss 1.12145, acc 0.625\n",
      "2017-04-03T19:28:19.008091: step 3397, loss 1.12876, acc 0.671875\n",
      "2017-04-03T19:28:19.208941: step 3398, loss 1.23289, acc 0.578125\n",
      "2017-04-03T19:28:19.405551: step 3399, loss 1.15583, acc 0.65625\n",
      "2017-04-03T19:28:19.610423: step 3400, loss 1.21433, acc 0.65625\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:28:21.538599: step 3400, loss 1.89175, acc 0.346\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-3400\n",
      "\n",
      "2017-04-03T19:28:21.919044: step 3401, loss 1.21096, acc 0.546875\n",
      "2017-04-03T19:28:22.111525: step 3402, loss 1.22442, acc 0.578125\n",
      "2017-04-03T19:28:22.324383: step 3403, loss 1.31205, acc 0.5625\n",
      "2017-04-03T19:28:22.520851: step 3404, loss 1.14596, acc 0.625\n",
      "2017-04-03T19:28:22.721476: step 3405, loss 1.18027, acc 0.640625\n",
      "2017-04-03T19:28:22.914086: step 3406, loss 1.09674, acc 0.640625\n",
      "2017-04-03T19:28:23.114549: step 3407, loss 1.18123, acc 0.59375\n",
      "2017-04-03T19:28:23.312420: step 3408, loss 1.53958, acc 0.4375\n",
      "2017-04-03T19:28:23.513381: step 3409, loss 1.24414, acc 0.625\n",
      "2017-04-03T19:28:23.709651: step 3410, loss 1.23454, acc 0.5625\n",
      "2017-04-03T19:28:23.912138: step 3411, loss 1.31003, acc 0.46875\n",
      "2017-04-03T19:28:24.104545: step 3412, loss 1.29069, acc 0.625\n",
      "2017-04-03T19:28:24.305958: step 3413, loss 1.09005, acc 0.546875\n",
      "2017-04-03T19:28:24.499286: step 3414, loss 1.1605, acc 0.546875\n",
      "2017-04-03T19:28:24.702140: step 3415, loss 1.29799, acc 0.5\n",
      "2017-04-03T19:28:24.897658: step 3416, loss 1.21507, acc 0.640625\n",
      "2017-04-03T19:28:25.099443: step 3417, loss 1.19025, acc 0.578125\n",
      "2017-04-03T19:28:25.295209: step 3418, loss 1.34973, acc 0.546875\n",
      "2017-04-03T19:28:25.500983: step 3419, loss 1.19416, acc 0.59375\n",
      "2017-04-03T19:28:25.697310: step 3420, loss 1.49702, acc 0.46875\n",
      "2017-04-03T19:28:25.901895: step 3421, loss 1.11816, acc 0.5625\n",
      "2017-04-03T19:28:26.097036: step 3422, loss 1.33991, acc 0.5625\n",
      "2017-04-03T19:28:26.295297: step 3423, loss 1.17095, acc 0.609375\n",
      "2017-04-03T19:28:26.484706: step 3424, loss 1.2584, acc 0.5625\n",
      "2017-04-03T19:28:26.684829: step 3425, loss 1.44441, acc 0.5\n",
      "2017-04-03T19:28:26.880994: step 3426, loss 1.23822, acc 0.5625\n",
      "2017-04-03T19:28:27.077751: step 3427, loss 1.26325, acc 0.546875\n",
      "2017-04-03T19:28:27.276802: step 3428, loss 1.2057, acc 0.5625\n",
      "2017-04-03T19:28:27.476912: step 3429, loss 1.14497, acc 0.5625\n",
      "2017-04-03T19:28:27.671262: step 3430, loss 1.3248, acc 0.53125\n",
      "2017-04-03T19:28:27.870066: step 3431, loss 1.46217, acc 0.5\n",
      "2017-04-03T19:28:28.067542: step 3432, loss 1.09522, acc 0.609375\n",
      "2017-04-03T19:28:28.274080: step 3433, loss 1.2749, acc 0.5625\n",
      "2017-04-03T19:28:28.470798: step 3434, loss 1.21005, acc 0.546875\n",
      "2017-04-03T19:28:28.681033: step 3435, loss 1.17983, acc 0.53125\n",
      "2017-04-03T19:28:28.875886: step 3436, loss 1.12191, acc 0.625\n",
      "2017-04-03T19:28:29.076664: step 3437, loss 1.3051, acc 0.5625\n",
      "2017-04-03T19:28:29.271545: step 3438, loss 1.08015, acc 0.625\n",
      "2017-04-03T19:28:29.482641: step 3439, loss 1.03153, acc 0.640625\n",
      "2017-04-03T19:28:29.674296: step 3440, loss 1.12023, acc 0.609375\n",
      "2017-04-03T19:28:29.877429: step 3441, loss 1.40564, acc 0.546875\n",
      "2017-04-03T19:28:30.075295: step 3442, loss 1.26951, acc 0.578125\n",
      "2017-04-03T19:28:30.281254: step 3443, loss 1.30042, acc 0.546875\n",
      "2017-04-03T19:28:30.469755: step 3444, loss 1.09614, acc 0.578125\n",
      "2017-04-03T19:28:30.677996: step 3445, loss 0.911197, acc 0.65625\n",
      "2017-04-03T19:28:30.877046: step 3446, loss 1.23212, acc 0.53125\n",
      "2017-04-03T19:28:31.078862: step 3447, loss 1.12657, acc 0.65625\n",
      "2017-04-03T19:28:31.275391: step 3448, loss 1.39964, acc 0.515625\n",
      "2017-04-03T19:28:31.482184: step 3449, loss 1.18802, acc 0.59375\n",
      "2017-04-03T19:28:31.677176: step 3450, loss 0.930137, acc 0.71875\n",
      "2017-04-03T19:28:31.881489: step 3451, loss 1.16353, acc 0.65625\n",
      "2017-04-03T19:28:32.080583: step 3452, loss 1.32072, acc 0.5625\n",
      "2017-04-03T19:28:32.283181: step 3453, loss 1.40143, acc 0.515625\n",
      "2017-04-03T19:28:32.479126: step 3454, loss 1.32566, acc 0.515625\n",
      "2017-04-03T19:28:32.687499: step 3455, loss 1.42153, acc 0.46875\n",
      "2017-04-03T19:28:32.880092: step 3456, loss 1.19667, acc 0.578125\n",
      "2017-04-03T19:28:33.080176: step 3457, loss 1.10801, acc 0.625\n",
      "2017-04-03T19:28:33.272648: step 3458, loss 1.38968, acc 0.546875\n",
      "2017-04-03T19:28:33.499038: step 3459, loss 1.10482, acc 0.65625\n",
      "2017-04-03T19:28:33.690837: step 3460, loss 1.2366, acc 0.59375\n",
      "2017-04-03T19:28:33.889444: step 3461, loss 1.255, acc 0.578125\n",
      "2017-04-03T19:28:34.087429: step 3462, loss 1.34658, acc 0.578125\n",
      "2017-04-03T19:28:34.289133: step 3463, loss 1.31473, acc 0.515625\n",
      "2017-04-03T19:28:34.484819: step 3464, loss 1.21691, acc 0.671875\n",
      "2017-04-03T19:28:34.685049: step 3465, loss 1.27896, acc 0.5625\n",
      "2017-04-03T19:28:34.881888: step 3466, loss 1.15276, acc 0.609375\n",
      "2017-04-03T19:28:35.082172: step 3467, loss 1.14744, acc 0.59375\n",
      "2017-04-03T19:28:35.275908: step 3468, loss 1.1692, acc 0.578125\n",
      "2017-04-03T19:28:35.514968: step 3469, loss 1.18928, acc 0.609375\n",
      "2017-04-03T19:28:35.712670: step 3470, loss 1.23227, acc 0.546875\n",
      "2017-04-03T19:28:35.921687: step 3471, loss 1.38082, acc 0.5\n",
      "2017-04-03T19:28:36.113981: step 3472, loss 1.24025, acc 0.609375\n",
      "2017-04-03T19:28:36.340408: step 3473, loss 1.16812, acc 0.609375\n",
      "2017-04-03T19:28:36.538864: step 3474, loss 1.15046, acc 0.65625\n",
      "2017-04-03T19:28:36.740669: step 3475, loss 1.1008, acc 0.65625\n",
      "2017-04-03T19:28:36.937750: step 3476, loss 1.26993, acc 0.5\n",
      "2017-04-03T19:28:37.139839: step 3477, loss 1.4966, acc 0.53125\n",
      "2017-04-03T19:28:37.335968: step 3478, loss 1.26278, acc 0.5625\n",
      "2017-04-03T19:28:37.536898: step 3479, loss 1.26377, acc 0.46875\n",
      "2017-04-03T19:28:37.732870: step 3480, loss 1.40503, acc 0.4375\n",
      "2017-04-03T19:28:37.937338: step 3481, loss 1.29287, acc 0.5\n",
      "2017-04-03T19:28:38.131121: step 3482, loss 1.21076, acc 0.65625\n",
      "2017-04-03T19:28:38.333852: step 3483, loss 1.17449, acc 0.5625\n",
      "2017-04-03T19:28:38.527380: step 3484, loss 1.27195, acc 0.578125\n",
      "2017-04-03T19:28:38.732916: step 3485, loss 1.11591, acc 0.65625\n",
      "2017-04-03T19:28:38.927088: step 3486, loss 1.02676, acc 0.625\n",
      "2017-04-03T19:28:39.128833: step 3487, loss 1.203, acc 0.546875\n",
      "2017-04-03T19:28:39.325129: step 3488, loss 1.16872, acc 0.609375\n",
      "2017-04-03T19:28:39.527202: step 3489, loss 1.30958, acc 0.578125\n",
      "2017-04-03T19:28:39.716712: step 3490, loss 1.35529, acc 0.53125\n",
      "2017-04-03T19:28:39.919366: step 3491, loss 1.28871, acc 0.546875\n",
      "2017-04-03T19:28:40.112958: step 3492, loss 1.308, acc 0.5625\n",
      "2017-04-03T19:28:40.316033: step 3493, loss 1.30922, acc 0.515625\n",
      "2017-04-03T19:28:40.511960: step 3494, loss 1.12602, acc 0.59375\n",
      "2017-04-03T19:28:40.713787: step 3495, loss 1.0494, acc 0.734375\n",
      "2017-04-03T19:28:40.906540: step 3496, loss 1.35061, acc 0.484375\n",
      "2017-04-03T19:28:41.108610: step 3497, loss 1.21438, acc 0.609375\n",
      "2017-04-03T19:28:41.301782: step 3498, loss 1.15489, acc 0.625\n",
      "2017-04-03T19:28:41.534981: step 3499, loss 1.36961, acc 0.515625\n",
      "2017-04-03T19:28:41.729736: step 3500, loss 1.46735, acc 0.375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:28:43.669370: step 3500, loss 1.95259, acc 0.33475\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-3500\n",
      "\n",
      "2017-04-03T19:28:43.996334: step 3501, loss 1.20428, acc 0.578125\n",
      "2017-04-03T19:28:44.194916: step 3502, loss 1.25419, acc 0.546875\n",
      "2017-04-03T19:28:44.394784: step 3503, loss 1.50038, acc 0.484375\n",
      "2017-04-03T19:28:44.588316: step 3504, loss 1.21632, acc 0.625\n",
      "2017-04-03T19:28:44.817728: step 3505, loss 1.30369, acc 0.53125\n",
      "2017-04-03T19:28:45.012233: step 3506, loss 1.16307, acc 0.578125\n",
      "2017-04-03T19:28:45.215537: step 3507, loss 1.27305, acc 0.53125\n",
      "2017-04-03T19:28:45.407173: step 3508, loss 1.02571, acc 0.671875\n",
      "2017-04-03T19:28:45.611067: step 3509, loss 1.32611, acc 0.515625\n",
      "2017-04-03T19:28:45.805367: step 3510, loss 1.49789, acc 0.484375\n",
      "2017-04-03T19:28:46.008484: step 3511, loss 1.26293, acc 0.609375\n",
      "2017-04-03T19:28:46.203570: step 3512, loss 1.33123, acc 0.46875\n",
      "2017-04-03T19:28:46.403652: step 3513, loss 1.19566, acc 0.640625\n",
      "2017-04-03T19:28:46.597239: step 3514, loss 1.01191, acc 0.734375\n",
      "2017-04-03T19:28:46.798599: step 3515, loss 1.254, acc 0.578125\n",
      "2017-04-03T19:28:46.994470: step 3516, loss 1.10818, acc 0.640625\n",
      "2017-04-03T19:28:47.192669: step 3517, loss 1.19059, acc 0.5625\n",
      "2017-04-03T19:28:47.382522: step 3518, loss 1.09093, acc 0.640625\n",
      "2017-04-03T19:28:47.613697: step 3519, loss 1.31125, acc 0.515625\n",
      "2017-04-03T19:28:47.810571: step 3520, loss 1.3995, acc 0.46875\n",
      "2017-04-03T19:28:48.011466: step 3521, loss 1.22853, acc 0.609375\n",
      "2017-04-03T19:28:48.201539: step 3522, loss 1.42514, acc 0.46875\n",
      "2017-04-03T19:28:48.405451: step 3523, loss 1.24791, acc 0.5\n",
      "2017-04-03T19:28:48.597399: step 3524, loss 1.00118, acc 0.640625\n",
      "2017-04-03T19:28:48.799529: step 3525, loss 1.26831, acc 0.546875\n",
      "2017-04-03T19:28:48.991974: step 3526, loss 1.40725, acc 0.546875\n",
      "2017-04-03T19:28:49.196691: step 3527, loss 1.21897, acc 0.578125\n",
      "2017-04-03T19:28:49.386630: step 3528, loss 1.37923, acc 0.46875\n",
      "2017-04-03T19:28:49.586523: step 3529, loss 1.41934, acc 0.53125\n",
      "2017-04-03T19:28:49.778927: step 3530, loss 1.35579, acc 0.578125\n",
      "2017-04-03T19:28:49.985701: step 3531, loss 1.23431, acc 0.578125\n",
      "2017-04-03T19:28:50.181416: step 3532, loss 1.26394, acc 0.546875\n",
      "2017-04-03T19:28:50.378581: step 3533, loss 1.27388, acc 0.5\n",
      "2017-04-03T19:28:50.570918: step 3534, loss 1.15968, acc 0.515625\n",
      "2017-04-03T19:28:50.771179: step 3535, loss 1.15166, acc 0.5625\n",
      "2017-04-03T19:28:50.962540: step 3536, loss 1.2472, acc 0.53125\n",
      "2017-04-03T19:28:51.168098: step 3537, loss 1.13239, acc 0.578125\n",
      "2017-04-03T19:28:51.359523: step 3538, loss 1.14337, acc 0.609375\n",
      "2017-04-03T19:28:51.559589: step 3539, loss 1.13175, acc 0.671875\n",
      "2017-04-03T19:28:51.751251: step 3540, loss 1.11236, acc 0.65625\n",
      "2017-04-03T19:28:51.949677: step 3541, loss 1.12431, acc 0.640625\n",
      "2017-04-03T19:28:52.139882: step 3542, loss 1.22809, acc 0.515625\n",
      "2017-04-03T19:28:52.343142: step 3543, loss 1.10455, acc 0.65625\n",
      "2017-04-03T19:28:52.534457: step 3544, loss 1.24736, acc 0.5625\n",
      "2017-04-03T19:28:52.733167: step 3545, loss 1.07582, acc 0.625\n",
      "2017-04-03T19:28:52.926622: step 3546, loss 1.17125, acc 0.5625\n",
      "2017-04-03T19:28:53.127706: step 3547, loss 1.15757, acc 0.609375\n",
      "2017-04-03T19:28:53.320833: step 3548, loss 1.40973, acc 0.5\n",
      "2017-04-03T19:28:53.521744: step 3549, loss 1.28772, acc 0.546875\n",
      "2017-04-03T19:28:53.715998: step 3550, loss 1.3187, acc 0.546875\n",
      "2017-04-03T19:28:53.918017: step 3551, loss 1.21574, acc 0.625\n",
      "2017-04-03T19:28:54.110854: step 3552, loss 1.29048, acc 0.515625\n",
      "2017-04-03T19:28:54.308832: step 3553, loss 1.20628, acc 0.609375\n",
      "2017-04-03T19:28:54.502917: step 3554, loss 1.26122, acc 0.578125\n",
      "2017-04-03T19:28:54.703045: step 3555, loss 1.11733, acc 0.625\n",
      "2017-04-03T19:28:54.894224: step 3556, loss 1.19361, acc 0.625\n",
      "2017-04-03T19:28:55.094260: step 3557, loss 1.25816, acc 0.515625\n",
      "2017-04-03T19:28:55.286590: step 3558, loss 1.08555, acc 0.609375\n",
      "2017-04-03T19:28:55.492348: step 3559, loss 1.36238, acc 0.546875\n",
      "2017-04-03T19:28:55.684972: step 3560, loss 1.28923, acc 0.546875\n",
      "2017-04-03T19:28:55.891218: step 3561, loss 1.32851, acc 0.609375\n",
      "2017-04-03T19:28:56.085556: step 3562, loss 1.25382, acc 0.59375\n",
      "2017-04-03T19:28:56.285464: step 3563, loss 1.36934, acc 0.46875\n",
      "2017-04-03T19:28:56.479368: step 3564, loss 1.17698, acc 0.625\n",
      "2017-04-03T19:28:56.682330: step 3565, loss 1.24156, acc 0.546875\n",
      "2017-04-03T19:28:56.876481: step 3566, loss 1.65239, acc 0.421875\n",
      "2017-04-03T19:28:57.079469: step 3567, loss 1.33468, acc 0.5\n",
      "2017-04-03T19:28:57.271964: step 3568, loss 1.21458, acc 0.625\n",
      "2017-04-03T19:28:57.478322: step 3569, loss 1.06957, acc 0.578125\n",
      "2017-04-03T19:28:57.672656: step 3570, loss 1.20422, acc 0.5\n",
      "2017-04-03T19:28:57.874161: step 3571, loss 1.12021, acc 0.609375\n",
      "2017-04-03T19:28:58.069344: step 3572, loss 1.32783, acc 0.5625\n",
      "2017-04-03T19:28:58.270629: step 3573, loss 1.20156, acc 0.5625\n",
      "2017-04-03T19:28:58.465686: step 3574, loss 1.11166, acc 0.59375\n",
      "2017-04-03T19:28:58.663162: step 3575, loss 1.36328, acc 0.453125\n",
      "2017-04-03T19:28:58.857546: step 3576, loss 1.25266, acc 0.5625\n",
      "2017-04-03T19:28:59.072885: step 3577, loss 1.50594, acc 0.5\n",
      "2017-04-03T19:28:59.265352: step 3578, loss 1.2242, acc 0.609375\n",
      "2017-04-03T19:28:59.463214: step 3579, loss 1.16929, acc 0.671875\n",
      "2017-04-03T19:28:59.658746: step 3580, loss 1.15138, acc 0.578125\n",
      "2017-04-03T19:28:59.859073: step 3581, loss 1.04977, acc 0.703125\n",
      "2017-04-03T19:29:00.053991: step 3582, loss 1.2803, acc 0.59375\n",
      "2017-04-03T19:29:00.283603: step 3583, loss 1.21624, acc 0.578125\n",
      "2017-04-03T19:29:00.476855: step 3584, loss 1.3267, acc 0.578125\n",
      "2017-04-03T19:29:00.680637: step 3585, loss 1.23157, acc 0.53125\n",
      "2017-04-03T19:29:00.874297: step 3586, loss 1.20979, acc 0.59375\n",
      "2017-04-03T19:29:01.074734: step 3587, loss 1.03686, acc 0.65625\n",
      "2017-04-03T19:29:01.267539: step 3588, loss 1.33568, acc 0.421875\n",
      "2017-04-03T19:29:01.472612: step 3589, loss 1.18983, acc 0.59375\n",
      "2017-04-03T19:29:01.672000: step 3590, loss 1.27198, acc 0.59375\n",
      "2017-04-03T19:29:01.875411: step 3591, loss 1.21218, acc 0.578125\n",
      "2017-04-03T19:29:02.064243: step 3592, loss 1.30795, acc 0.578125\n",
      "2017-04-03T19:29:02.262009: step 3593, loss 1.47979, acc 0.4375\n",
      "2017-04-03T19:29:02.454272: step 3594, loss 1.32797, acc 0.53125\n",
      "2017-04-03T19:29:02.655182: step 3595, loss 1.11793, acc 0.5625\n",
      "2017-04-03T19:29:02.848548: step 3596, loss 1.10922, acc 0.671875\n",
      "2017-04-03T19:29:03.047327: step 3597, loss 1.16223, acc 0.53125\n",
      "2017-04-03T19:29:03.238718: step 3598, loss 1.3782, acc 0.578125\n",
      "2017-04-03T19:29:03.436159: step 3599, loss 1.29335, acc 0.59375\n",
      "2017-04-03T19:29:03.628210: step 3600, loss 1.38565, acc 0.5\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:29:05.558932: step 3600, loss 1.93334, acc 0.3465\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-3600\n",
      "\n",
      "2017-04-03T19:29:05.890635: step 3601, loss 1.40055, acc 0.5\n",
      "2017-04-03T19:29:06.088536: step 3602, loss 1.38838, acc 0.578125\n",
      "2017-04-03T19:29:06.291460: step 3603, loss 1.46147, acc 0.515625\n",
      "2017-04-03T19:29:06.485289: step 3604, loss 1.38986, acc 0.484375\n",
      "2017-04-03T19:29:06.681262: step 3605, loss 1.24728, acc 0.546875\n",
      "2017-04-03T19:29:06.873741: step 3606, loss 1.28176, acc 0.515625\n",
      "2017-04-03T19:29:07.095425: step 3607, loss 1.29506, acc 0.546875\n",
      "2017-04-03T19:29:07.287787: step 3608, loss 1.17692, acc 0.578125\n",
      "2017-04-03T19:29:07.489502: step 3609, loss 1.18171, acc 0.640625\n",
      "2017-04-03T19:29:07.678526: step 3610, loss 1.18615, acc 0.59375\n",
      "2017-04-03T19:29:07.912508: step 3611, loss 1.26081, acc 0.515625\n",
      "2017-04-03T19:29:08.105230: step 3612, loss 1.32426, acc 0.46875\n",
      "2017-04-03T19:29:08.308216: step 3613, loss 1.44331, acc 0.4375\n",
      "2017-04-03T19:29:08.499518: step 3614, loss 1.25566, acc 0.578125\n",
      "2017-04-03T19:29:08.700338: step 3615, loss 1.29238, acc 0.546875\n",
      "2017-04-03T19:29:08.892693: step 3616, loss 1.24126, acc 0.5\n",
      "2017-04-03T19:29:09.089688: step 3617, loss 1.24695, acc 0.5\n",
      "2017-04-03T19:29:09.280219: step 3618, loss 1.19375, acc 0.53125\n",
      "2017-04-03T19:29:09.480237: step 3619, loss 1.31183, acc 0.5\n",
      "2017-04-03T19:29:09.673946: step 3620, loss 1.3777, acc 0.546875\n",
      "2017-04-03T19:29:09.875305: step 3621, loss 1.05354, acc 0.609375\n",
      "2017-04-03T19:29:10.067443: step 3622, loss 1.13408, acc 0.609375\n",
      "2017-04-03T19:29:10.301240: step 3623, loss 1.24892, acc 0.609375\n",
      "2017-04-03T19:29:10.498618: step 3624, loss 1.38343, acc 0.453125\n",
      "2017-04-03T19:29:10.699072: step 3625, loss 1.27389, acc 0.53125\n",
      "2017-04-03T19:29:10.895837: step 3626, loss 1.3758, acc 0.546875\n",
      "2017-04-03T19:29:11.098478: step 3627, loss 1.0523, acc 0.671875\n",
      "2017-04-03T19:29:11.294438: step 3628, loss 1.37476, acc 0.484375\n",
      "2017-04-03T19:29:11.500420: step 3629, loss 1.3922, acc 0.515625\n",
      "2017-04-03T19:29:11.691652: step 3630, loss 1.09391, acc 0.640625\n",
      "2017-04-03T19:29:11.891616: step 3631, loss 1.38939, acc 0.578125\n",
      "2017-04-03T19:29:12.082424: step 3632, loss 1.27225, acc 0.609375\n",
      "2017-04-03T19:29:12.285199: step 3633, loss 1.16588, acc 0.5\n",
      "2017-04-03T19:29:12.475905: step 3634, loss 1.33655, acc 0.546875\n",
      "2017-04-03T19:29:12.682575: step 3635, loss 0.954076, acc 0.6875\n",
      "2017-04-03T19:29:12.880488: step 3636, loss 1.42754, acc 0.484375\n",
      "2017-04-03T19:29:13.083614: step 3637, loss 1.21116, acc 0.625\n",
      "2017-04-03T19:29:13.275811: step 3638, loss 1.26037, acc 0.546875\n",
      "2017-04-03T19:29:13.473645: step 3639, loss 1.0435, acc 0.65625\n",
      "2017-04-03T19:29:13.667880: step 3640, loss 1.30066, acc 0.5625\n",
      "2017-04-03T19:29:13.900319: step 3641, loss 1.01896, acc 0.625\n",
      "2017-04-03T19:29:14.090500: step 3642, loss 1.14041, acc 0.546875\n",
      "2017-04-03T19:29:14.292975: step 3643, loss 1.27756, acc 0.484375\n",
      "2017-04-03T19:29:14.484858: step 3644, loss 1.11348, acc 0.625\n",
      "2017-04-03T19:29:14.687373: step 3645, loss 1.23866, acc 0.59375\n",
      "2017-04-03T19:29:14.878561: step 3646, loss 1.32447, acc 0.59375\n",
      "2017-04-03T19:29:15.085505: step 3647, loss 1.41214, acc 0.5\n",
      "2017-04-03T19:29:15.277159: step 3648, loss 1.37286, acc 0.453125\n",
      "2017-04-03T19:29:15.511943: step 3649, loss 1.13798, acc 0.5625\n",
      "2017-04-03T19:29:15.704748: step 3650, loss 1.13544, acc 0.640625\n",
      "2017-04-03T19:29:15.908465: step 3651, loss 1.33293, acc 0.46875\n",
      "2017-04-03T19:29:16.098419: step 3652, loss 1.02973, acc 0.59375\n",
      "2017-04-03T19:29:16.297243: step 3653, loss 1.30981, acc 0.609375\n",
      "2017-04-03T19:29:16.489179: step 3654, loss 1.36096, acc 0.390625\n",
      "2017-04-03T19:29:16.693594: step 3655, loss 1.27065, acc 0.578125\n",
      "2017-04-03T19:29:16.885151: step 3656, loss 1.27143, acc 0.578125\n",
      "2017-04-03T19:29:17.087190: step 3657, loss 1.12361, acc 0.640625\n",
      "2017-04-03T19:29:17.281182: step 3658, loss 1.01799, acc 0.609375\n",
      "2017-04-03T19:29:17.480333: step 3659, loss 1.05797, acc 0.671875\n",
      "2017-04-03T19:29:17.672054: step 3660, loss 1.45913, acc 0.453125\n",
      "2017-04-03T19:29:17.873514: step 3661, loss 1.07239, acc 0.671875\n",
      "2017-04-03T19:29:18.068398: step 3662, loss 0.914641, acc 0.6875\n",
      "2017-04-03T19:29:18.271958: step 3663, loss 1.41332, acc 0.484375\n",
      "2017-04-03T19:29:18.462941: step 3664, loss 1.20555, acc 0.59375\n",
      "2017-04-03T19:29:18.700547: step 3665, loss 1.21528, acc 0.5625\n",
      "2017-04-03T19:29:18.889887: step 3666, loss 1.3433, acc 0.5625\n",
      "2017-04-03T19:29:19.092083: step 3667, loss 1.26171, acc 0.578125\n",
      "2017-04-03T19:29:19.281445: step 3668, loss 1.18824, acc 0.578125\n",
      "2017-04-03T19:29:19.481250: step 3669, loss 1.13425, acc 0.5625\n",
      "2017-04-03T19:29:19.673567: step 3670, loss 1.34144, acc 0.546875\n",
      "2017-04-03T19:29:19.873810: step 3671, loss 1.36805, acc 0.578125\n",
      "2017-04-03T19:29:20.066650: step 3672, loss 1.19121, acc 0.578125\n",
      "2017-04-03T19:29:20.264262: step 3673, loss 1.14954, acc 0.671875\n",
      "2017-04-03T19:29:20.458872: step 3674, loss 1.14545, acc 0.671875\n",
      "2017-04-03T19:29:20.656150: step 3675, loss 1.25508, acc 0.625\n",
      "2017-04-03T19:29:20.848858: step 3676, loss 1.16841, acc 0.625\n",
      "2017-04-03T19:29:21.055459: step 3677, loss 1.24197, acc 0.546875\n",
      "2017-04-03T19:29:21.245713: step 3678, loss 1.26836, acc 0.484375\n",
      "2017-04-03T19:29:21.444798: step 3679, loss 1.38947, acc 0.5625\n",
      "2017-04-03T19:29:21.641388: step 3680, loss 1.23651, acc 0.5\n",
      "2017-04-03T19:29:21.845172: step 3681, loss 1.35805, acc 0.5\n",
      "2017-04-03T19:29:22.039338: step 3682, loss 1.34684, acc 0.59375\n",
      "2017-04-03T19:29:22.239505: step 3683, loss 1.10202, acc 0.6875\n",
      "2017-04-03T19:29:22.437218: step 3684, loss 1.13196, acc 0.578125\n",
      "2017-04-03T19:29:22.638359: step 3685, loss 1.28195, acc 0.484375\n",
      "2017-04-03T19:29:22.835125: step 3686, loss 1.23633, acc 0.5\n",
      "2017-04-03T19:29:23.034612: step 3687, loss 1.41981, acc 0.453125\n",
      "2017-04-03T19:29:23.223776: step 3688, loss 1.70083, acc 0.390625\n",
      "2017-04-03T19:29:23.425337: step 3689, loss 1.14577, acc 0.609375\n",
      "2017-04-03T19:29:23.618498: step 3690, loss 1.16661, acc 0.578125\n",
      "2017-04-03T19:29:23.819304: step 3691, loss 1.04702, acc 0.671875\n",
      "2017-04-03T19:29:24.014816: step 3692, loss 1.33709, acc 0.515625\n",
      "2017-04-03T19:29:24.216062: step 3693, loss 1.22877, acc 0.5625\n",
      "2017-04-03T19:29:24.408400: step 3694, loss 1.40096, acc 0.453125\n",
      "2017-04-03T19:29:24.612633: step 3695, loss 1.25795, acc 0.59375\n",
      "2017-04-03T19:29:24.806596: step 3696, loss 1.44472, acc 0.546875\n",
      "2017-04-03T19:29:25.006856: step 3697, loss 1.27074, acc 0.515625\n",
      "2017-04-03T19:29:25.198624: step 3698, loss 1.43153, acc 0.578125\n",
      "2017-04-03T19:29:25.401452: step 3699, loss 1.27688, acc 0.59375\n",
      "2017-04-03T19:29:25.591636: step 3700, loss 1.35152, acc 0.53125\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:29:27.530492: step 3700, loss 1.95225, acc 0.34275\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-3700\n",
      "\n",
      "2017-04-03T19:29:27.854899: step 3701, loss 1.52602, acc 0.484375\n",
      "2017-04-03T19:29:28.052778: step 3702, loss 1.19492, acc 0.578125\n",
      "2017-04-03T19:29:28.252208: step 3703, loss 1.14762, acc 0.5625\n",
      "2017-04-03T19:29:28.444927: step 3704, loss 1.20555, acc 0.546875\n",
      "2017-04-03T19:29:28.646601: step 3705, loss 1.14811, acc 0.640625\n",
      "2017-04-03T19:29:28.838412: step 3706, loss 1.15997, acc 0.578125\n",
      "2017-04-03T19:29:29.039222: step 3707, loss 1.4014, acc 0.5\n",
      "2017-04-03T19:29:29.235344: step 3708, loss 1.30659, acc 0.5\n",
      "2017-04-03T19:29:29.439491: step 3709, loss 1.22506, acc 0.609375\n",
      "2017-04-03T19:29:29.633206: step 3710, loss 1.21284, acc 0.578125\n",
      "2017-04-03T19:29:29.839108: step 3711, loss 1.16514, acc 0.609375\n",
      "2017-04-03T19:29:30.032561: step 3712, loss 1.277, acc 0.5625\n",
      "2017-04-03T19:29:30.266340: step 3713, loss 1.16809, acc 0.59375\n",
      "2017-04-03T19:29:30.456574: step 3714, loss 1.41555, acc 0.515625\n",
      "2017-04-03T19:29:30.654702: step 3715, loss 1.36655, acc 0.53125\n",
      "2017-04-03T19:29:30.848708: step 3716, loss 1.11815, acc 0.625\n",
      "2017-04-03T19:29:31.051349: step 3717, loss 1.35179, acc 0.453125\n",
      "2017-04-03T19:29:31.240763: step 3718, loss 1.05341, acc 0.609375\n",
      "2017-04-03T19:29:31.443717: step 3719, loss 1.33031, acc 0.515625\n",
      "2017-04-03T19:29:31.638547: step 3720, loss 1.27383, acc 0.53125\n",
      "2017-04-03T19:29:31.840089: step 3721, loss 1.47741, acc 0.484375\n",
      "2017-04-03T19:29:32.030436: step 3722, loss 1.19395, acc 0.640625\n",
      "2017-04-03T19:29:32.228706: step 3723, loss 1.20313, acc 0.640625\n",
      "2017-04-03T19:29:32.424523: step 3724, loss 1.33662, acc 0.53125\n",
      "2017-04-03T19:29:32.624400: step 3725, loss 1.2818, acc 0.515625\n",
      "2017-04-03T19:29:32.817210: step 3726, loss 1.28357, acc 0.5625\n",
      "2017-04-03T19:29:33.015898: step 3727, loss 1.15878, acc 0.5\n",
      "2017-04-03T19:29:33.209205: step 3728, loss 1.34294, acc 0.515625\n",
      "2017-04-03T19:29:33.413583: step 3729, loss 1.46543, acc 0.421875\n",
      "2017-04-03T19:29:33.608214: step 3730, loss 1.29185, acc 0.578125\n",
      "2017-04-03T19:29:33.812572: step 3731, loss 1.35234, acc 0.546875\n",
      "2017-04-03T19:29:34.005114: step 3732, loss 1.29032, acc 0.5625\n",
      "2017-04-03T19:29:34.207861: step 3733, loss 1.01093, acc 0.703125\n",
      "2017-04-03T19:29:34.396889: step 3734, loss 1.33142, acc 0.546875\n",
      "2017-04-03T19:29:34.601114: step 3735, loss 1.2325, acc 0.578125\n",
      "2017-04-03T19:29:34.796009: step 3736, loss 1.18777, acc 0.59375\n",
      "2017-04-03T19:29:34.995077: step 3737, loss 1.30566, acc 0.53125\n",
      "2017-04-03T19:29:35.187635: step 3738, loss 1.36044, acc 0.515625\n",
      "2017-04-03T19:29:35.391296: step 3739, loss 1.27306, acc 0.59375\n",
      "2017-04-03T19:29:35.583583: step 3740, loss 1.24978, acc 0.5625\n",
      "2017-04-03T19:29:35.784713: step 3741, loss 1.34924, acc 0.515625\n",
      "2017-04-03T19:29:35.980616: step 3742, loss 1.27759, acc 0.59375\n",
      "2017-04-03T19:29:36.182224: step 3743, loss 1.45668, acc 0.53125\n",
      "2017-04-03T19:29:36.374427: step 3744, loss 1.45327, acc 0.421875\n",
      "2017-04-03T19:29:36.572368: step 3745, loss 1.47293, acc 0.421875\n",
      "2017-04-03T19:29:36.762687: step 3746, loss 1.18059, acc 0.640625\n",
      "2017-04-03T19:29:36.969835: step 3747, loss 1.16656, acc 0.5625\n",
      "2017-04-03T19:29:37.162718: step 3748, loss 1.33762, acc 0.578125\n",
      "2017-04-03T19:29:37.363114: step 3749, loss 1.23245, acc 0.625\n",
      "2017-04-03T19:29:37.553424: step 3750, loss 1.36982, acc 0.515625\n",
      "2017-04-03T19:29:37.753037: step 3751, loss 1.19879, acc 0.59375\n",
      "2017-04-03T19:29:37.945479: step 3752, loss 1.08226, acc 0.625\n",
      "2017-04-03T19:29:38.182569: step 3753, loss 1.22125, acc 0.59375\n",
      "2017-04-03T19:29:38.376833: step 3754, loss 1.27834, acc 0.53125\n",
      "2017-04-03T19:29:38.577895: step 3755, loss 0.975932, acc 0.671875\n",
      "2017-04-03T19:29:38.771509: step 3756, loss 1.45391, acc 0.453125\n",
      "2017-04-03T19:29:38.971552: step 3757, loss 1.26563, acc 0.625\n",
      "2017-04-03T19:29:39.165295: step 3758, loss 1.17593, acc 0.609375\n",
      "2017-04-03T19:29:39.366023: step 3759, loss 1.38112, acc 0.546875\n",
      "2017-04-03T19:29:39.559915: step 3760, loss 1.38866, acc 0.5\n",
      "2017-04-03T19:29:39.767309: step 3761, loss 1.32711, acc 0.578125\n",
      "2017-04-03T19:29:39.959228: step 3762, loss 1.35656, acc 0.59375\n",
      "2017-04-03T19:29:40.160332: step 3763, loss 1.25199, acc 0.625\n",
      "2017-04-03T19:29:40.348482: step 3764, loss 1.36679, acc 0.453125\n",
      "2017-04-03T19:29:40.551245: step 3765, loss 1.30255, acc 0.515625\n",
      "2017-04-03T19:29:40.743760: step 3766, loss 1.34902, acc 0.46875\n",
      "2017-04-03T19:29:40.945489: step 3767, loss 1.16481, acc 0.578125\n",
      "2017-04-03T19:29:41.139792: step 3768, loss 1.28805, acc 0.5625\n",
      "2017-04-03T19:29:41.341105: step 3769, loss 1.32564, acc 0.4375\n",
      "2017-04-03T19:29:41.535214: step 3770, loss 1.24913, acc 0.578125\n",
      "2017-04-03T19:29:41.733865: step 3771, loss 1.40219, acc 0.4375\n",
      "2017-04-03T19:29:41.923116: step 3772, loss 1.05596, acc 0.640625\n",
      "2017-04-03T19:29:42.151874: step 3773, loss 1.37784, acc 0.4375\n",
      "2017-04-03T19:29:42.338115: step 3774, loss 1.42373, acc 0.484375\n",
      "2017-04-03T19:29:42.575981: step 3775, loss 1.20864, acc 0.515625\n",
      "2017-04-03T19:29:42.768326: step 3776, loss 1.20835, acc 0.578125\n",
      "2017-04-03T19:29:42.969514: step 3777, loss 1.26101, acc 0.546875\n",
      "2017-04-03T19:29:43.167720: step 3778, loss 1.13266, acc 0.640625\n",
      "2017-04-03T19:29:43.367908: step 3779, loss 1.30266, acc 0.546875\n",
      "2017-04-03T19:29:43.559805: step 3780, loss 1.69784, acc 0.5\n",
      "2017-04-03T19:29:43.761148: step 3781, loss 1.03692, acc 0.734375\n",
      "2017-04-03T19:29:43.953157: step 3782, loss 1.21583, acc 0.578125\n",
      "2017-04-03T19:29:44.161747: step 3783, loss 1.11813, acc 0.65625\n",
      "2017-04-03T19:29:44.358002: step 3784, loss 1.35494, acc 0.5\n",
      "2017-04-03T19:29:44.559266: step 3785, loss 1.20997, acc 0.484375\n",
      "2017-04-03T19:29:44.751455: step 3786, loss 1.68238, acc 0.421875\n",
      "2017-04-03T19:29:44.950954: step 3787, loss 1.08839, acc 0.703125\n",
      "2017-04-03T19:29:45.145139: step 3788, loss 1.16903, acc 0.625\n",
      "2017-04-03T19:29:45.348268: step 3789, loss 1.34, acc 0.53125\n",
      "2017-04-03T19:29:45.537923: step 3790, loss 1.21257, acc 0.59375\n",
      "2017-04-03T19:29:45.741999: step 3791, loss 1.3456, acc 0.5\n",
      "2017-04-03T19:29:45.932077: step 3792, loss 1.1317, acc 0.625\n",
      "2017-04-03T19:29:46.132786: step 3793, loss 1.26617, acc 0.5625\n",
      "2017-04-03T19:29:46.328425: step 3794, loss 1.33601, acc 0.484375\n",
      "2017-04-03T19:29:46.529880: step 3795, loss 1.31649, acc 0.546875\n",
      "2017-04-03T19:29:46.721429: step 3796, loss 1.21944, acc 0.53125\n",
      "2017-04-03T19:29:46.922718: step 3797, loss 1.48979, acc 0.46875\n",
      "2017-04-03T19:29:47.118005: step 3798, loss 1.22017, acc 0.546875\n",
      "2017-04-03T19:29:47.315948: step 3799, loss 1.37132, acc 0.484375\n",
      "2017-04-03T19:29:47.513305: step 3800, loss 1.2892, acc 0.546875\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:29:49.474629: step 3800, loss 1.95958, acc 0.344\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-3800\n",
      "\n",
      "2017-04-03T19:29:49.804232: step 3801, loss 1.05321, acc 0.703125\n",
      "2017-04-03T19:29:49.999140: step 3802, loss 1.32073, acc 0.546875\n",
      "2017-04-03T19:29:50.199697: step 3803, loss 1.55768, acc 0.359375\n",
      "2017-04-03T19:29:50.388797: step 3804, loss 1.6689, acc 0.5\n",
      "2017-04-03T19:29:50.592791: step 3805, loss 1.45294, acc 0.515625\n",
      "2017-04-03T19:29:50.789611: step 3806, loss 1.34646, acc 0.5\n",
      "2017-04-03T19:29:50.991190: step 3807, loss 1.41837, acc 0.484375\n",
      "2017-04-03T19:29:51.183906: step 3808, loss 1.27192, acc 0.5\n",
      "2017-04-03T19:29:51.383123: step 3809, loss 1.29922, acc 0.546875\n",
      "2017-04-03T19:29:51.574485: step 3810, loss 1.39544, acc 0.484375\n",
      "2017-04-03T19:29:51.777569: step 3811, loss 1.08994, acc 0.59375\n",
      "2017-04-03T19:29:51.970122: step 3812, loss 1.47773, acc 0.53125\n",
      "2017-04-03T19:29:52.212084: step 3813, loss 1.24734, acc 0.546875\n",
      "2017-04-03T19:29:52.403513: step 3814, loss 1.38546, acc 0.46875\n",
      "2017-04-03T19:29:52.604836: step 3815, loss 1.56403, acc 0.484375\n",
      "2017-04-03T19:29:52.798741: step 3816, loss 1.18443, acc 0.578125\n",
      "2017-04-03T19:29:52.999078: step 3817, loss 1.25635, acc 0.515625\n",
      "2017-04-03T19:29:53.189726: step 3818, loss 1.26827, acc 0.625\n",
      "2017-04-03T19:29:53.388825: step 3819, loss 1.48197, acc 0.453125\n",
      "2017-04-03T19:29:53.581427: step 3820, loss 1.40517, acc 0.5\n",
      "2017-04-03T19:29:53.782559: step 3821, loss 1.35098, acc 0.53125\n",
      "2017-04-03T19:29:53.976934: step 3822, loss 1.27414, acc 0.515625\n",
      "2017-04-03T19:29:54.178483: step 3823, loss 1.16677, acc 0.640625\n",
      "2017-04-03T19:29:54.368957: step 3824, loss 1.30941, acc 0.59375\n",
      "2017-04-03T19:29:54.572689: step 3825, loss 1.30262, acc 0.484375\n",
      "2017-04-03T19:29:54.765123: step 3826, loss 1.03268, acc 0.609375\n",
      "2017-04-03T19:29:54.966931: step 3827, loss 1.36182, acc 0.609375\n",
      "2017-04-03T19:29:55.161284: step 3828, loss 1.11662, acc 0.59375\n",
      "2017-04-03T19:29:55.365904: step 3829, loss 1.11266, acc 0.625\n",
      "2017-04-03T19:29:55.560763: step 3830, loss 1.37203, acc 0.5625\n",
      "2017-04-03T19:29:55.760803: step 3831, loss 1.45015, acc 0.53125\n",
      "2017-04-03T19:29:55.954890: step 3832, loss 1.3413, acc 0.53125\n",
      "2017-04-03T19:29:56.155411: step 3833, loss 1.28126, acc 0.5625\n",
      "2017-04-03T19:29:56.346167: step 3834, loss 1.33381, acc 0.46875\n",
      "2017-04-03T19:29:56.547738: step 3835, loss 1.09628, acc 0.640625\n",
      "2017-04-03T19:29:56.740035: step 3836, loss 1.32561, acc 0.546875\n",
      "2017-04-03T19:29:56.942400: step 3837, loss 1.19086, acc 0.546875\n",
      "2017-04-03T19:29:57.132734: step 3838, loss 1.4158, acc 0.53125\n",
      "2017-04-03T19:29:57.329879: step 3839, loss 1.18856, acc 0.625\n",
      "2017-04-03T19:29:57.522588: step 3840, loss 1.03087, acc 0.5625\n",
      "2017-04-03T19:29:57.721490: step 3841, loss 1.26084, acc 0.59375\n",
      "2017-04-03T19:29:57.912783: step 3842, loss 1.24744, acc 0.578125\n",
      "2017-04-03T19:29:58.115735: step 3843, loss 1.37874, acc 0.5\n",
      "2017-04-03T19:29:58.308005: step 3844, loss 1.30414, acc 0.578125\n",
      "2017-04-03T19:29:58.507097: step 3845, loss 1.23811, acc 0.53125\n",
      "2017-04-03T19:29:58.698750: step 3846, loss 1.66845, acc 0.40625\n",
      "2017-04-03T19:29:58.897523: step 3847, loss 1.52, acc 0.46875\n",
      "2017-04-03T19:29:59.087400: step 3848, loss 1.26275, acc 0.53125\n",
      "2017-04-03T19:29:59.288922: step 3849, loss 1.20275, acc 0.515625\n",
      "2017-04-03T19:29:59.480447: step 3850, loss 0.991488, acc 0.640625\n",
      "2017-04-03T19:29:59.704717: step 3851, loss 1.31712, acc 0.578125\n",
      "2017-04-03T19:29:59.900393: step 3852, loss 1.12181, acc 0.625\n",
      "2017-04-03T19:30:00.103453: step 3853, loss 1.19805, acc 0.578125\n",
      "2017-04-03T19:30:00.300432: step 3854, loss 1.13414, acc 0.65625\n",
      "2017-04-03T19:30:00.536207: step 3855, loss 1.5538, acc 0.5\n",
      "2017-04-03T19:30:00.728554: step 3856, loss 1.37729, acc 0.578125\n",
      "2017-04-03T19:30:00.958916: step 3857, loss 1.39731, acc 0.515625\n",
      "2017-04-03T19:30:01.148927: step 3858, loss 1.85194, acc 0.359375\n",
      "2017-04-03T19:30:01.385031: step 3859, loss 1.49582, acc 0.453125\n",
      "2017-04-03T19:30:01.578752: step 3860, loss 1.27664, acc 0.578125\n",
      "2017-04-03T19:30:01.778355: step 3861, loss 1.36045, acc 0.53125\n",
      "2017-04-03T19:30:01.973157: step 3862, loss 1.24293, acc 0.59375\n",
      "2017-04-03T19:30:02.176239: step 3863, loss 1.3512, acc 0.5625\n",
      "2017-04-03T19:30:02.364559: step 3864, loss 1.34, acc 0.5\n",
      "2017-04-03T19:30:02.566650: step 3865, loss 1.13485, acc 0.578125\n",
      "2017-04-03T19:30:02.760049: step 3866, loss 1.12597, acc 0.640625\n",
      "2017-04-03T19:30:02.959895: step 3867, loss 1.57906, acc 0.546875\n",
      "2017-04-03T19:30:03.153686: step 3868, loss 1.37075, acc 0.546875\n",
      "2017-04-03T19:30:03.362938: step 3869, loss 1.33959, acc 0.5625\n",
      "2017-04-03T19:30:03.557797: step 3870, loss 1.43919, acc 0.484375\n",
      "2017-04-03T19:30:03.760346: step 3871, loss 1.33958, acc 0.59375\n",
      "2017-04-03T19:30:03.951540: step 3872, loss 1.44246, acc 0.5\n",
      "2017-04-03T19:30:04.189256: step 3873, loss 1.29589, acc 0.515625\n",
      "2017-04-03T19:30:04.383561: step 3874, loss 1.21118, acc 0.5625\n",
      "2017-04-03T19:30:04.621255: step 3875, loss 1.58929, acc 0.34375\n",
      "2017-04-03T19:30:04.813174: step 3876, loss 1.33276, acc 0.484375\n",
      "2017-04-03T19:30:05.015539: step 3877, loss 1.2068, acc 0.5625\n",
      "2017-04-03T19:30:05.207656: step 3878, loss 1.30418, acc 0.59375\n",
      "2017-04-03T19:30:05.408299: step 3879, loss 1.31215, acc 0.578125\n",
      "2017-04-03T19:30:05.599637: step 3880, loss 1.22267, acc 0.5625\n",
      "2017-04-03T19:30:05.803344: step 3881, loss 1.42996, acc 0.515625\n",
      "2017-04-03T19:30:05.994122: step 3882, loss 1.41646, acc 0.46875\n",
      "2017-04-03T19:30:06.237601: step 3883, loss 1.46418, acc 0.40625\n",
      "2017-04-03T19:30:06.429960: step 3884, loss 1.21767, acc 0.625\n",
      "2017-04-03T19:30:06.672337: step 3885, loss 1.54545, acc 0.46875\n",
      "2017-04-03T19:30:06.866357: step 3886, loss 1.46597, acc 0.515625\n",
      "2017-04-03T19:30:07.073871: step 3887, loss 1.15977, acc 0.53125\n",
      "2017-04-03T19:30:07.268792: step 3888, loss 1.37533, acc 0.5\n",
      "2017-04-03T19:30:07.468104: step 3889, loss 1.5075, acc 0.453125\n",
      "2017-04-03T19:30:07.661254: step 3890, loss 1.3567, acc 0.59375\n",
      "2017-04-03T19:30:07.904580: step 3891, loss 1.1889, acc 0.546875\n",
      "2017-04-03T19:30:08.098207: step 3892, loss 1.14631, acc 0.609375\n",
      "2017-04-03T19:30:08.302068: step 3893, loss 1.21237, acc 0.53125\n",
      "2017-04-03T19:30:08.492389: step 3894, loss 1.42344, acc 0.53125\n",
      "2017-04-03T19:30:08.695845: step 3895, loss 1.30623, acc 0.4375\n",
      "2017-04-03T19:30:08.890663: step 3896, loss 1.16908, acc 0.5625\n",
      "2017-04-03T19:30:09.095286: step 3897, loss 1.36057, acc 0.53125\n",
      "2017-04-03T19:30:09.292725: step 3898, loss 1.37829, acc 0.5625\n",
      "2017-04-03T19:30:09.495638: step 3899, loss 1.21633, acc 0.625\n",
      "2017-04-03T19:30:09.693637: step 3900, loss 1.46925, acc 0.4375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:30:11.638928: step 3900, loss 1.99468, acc 0.33775\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-3900\n",
      "\n",
      "2017-04-03T19:30:11.960599: step 3901, loss 1.4273, acc 0.5625\n",
      "2017-04-03T19:30:12.156980: step 3902, loss 1.40775, acc 0.546875\n",
      "2017-04-03T19:30:12.360437: step 3903, loss 1.34466, acc 0.484375\n",
      "2017-04-03T19:30:12.558437: step 3904, loss 1.19222, acc 0.59375\n",
      "2017-04-03T19:30:12.761044: step 3905, loss 1.34472, acc 0.53125\n",
      "2017-04-03T19:30:12.953198: step 3906, loss 1.4968, acc 0.40625\n",
      "2017-04-03T19:30:13.152160: step 3907, loss 1.31615, acc 0.53125\n",
      "2017-04-03T19:30:13.346684: step 3908, loss 1.26299, acc 0.59375\n",
      "2017-04-03T19:30:13.548876: step 3909, loss 1.41353, acc 0.546875\n",
      "2017-04-03T19:30:13.745705: step 3910, loss 1.39213, acc 0.515625\n",
      "2017-04-03T19:30:13.943578: step 3911, loss 1.67609, acc 0.40625\n",
      "2017-04-03T19:30:14.137110: step 3912, loss 1.30186, acc 0.59375\n",
      "2017-04-03T19:30:14.344157: step 3913, loss 1.22964, acc 0.578125\n",
      "2017-04-03T19:30:14.538752: step 3914, loss 1.20545, acc 0.546875\n",
      "2017-04-03T19:30:14.744970: step 3915, loss 1.33225, acc 0.53125\n",
      "2017-04-03T19:30:14.937986: step 3916, loss 1.50064, acc 0.46875\n",
      "2017-04-03T19:30:15.133798: step 3917, loss 1.27216, acc 0.46875\n",
      "2017-04-03T19:30:15.325670: step 3918, loss 1.52002, acc 0.484375\n",
      "2017-04-03T19:30:15.527146: step 3919, loss 1.39178, acc 0.53125\n",
      "2017-04-03T19:30:15.723619: step 3920, loss 1.11875, acc 0.609375\n",
      "2017-04-03T19:30:15.925848: step 3921, loss 1.37652, acc 0.546875\n",
      "2017-04-03T19:30:16.119198: step 3922, loss 1.5006, acc 0.453125\n",
      "2017-04-03T19:30:16.318529: step 3923, loss 1.51302, acc 0.484375\n",
      "2017-04-03T19:30:16.512260: step 3924, loss 1.345, acc 0.59375\n",
      "2017-04-03T19:30:16.715319: step 3925, loss 1.48614, acc 0.484375\n",
      "2017-04-03T19:30:16.912201: step 3926, loss 1.3005, acc 0.53125\n",
      "2017-04-03T19:30:17.115821: step 3927, loss 1.44247, acc 0.515625\n",
      "2017-04-03T19:30:17.311920: step 3928, loss 1.28701, acc 0.546875\n",
      "2017-04-03T19:30:17.510701: step 3929, loss 1.18558, acc 0.578125\n",
      "2017-04-03T19:30:17.707686: step 3930, loss 1.37288, acc 0.5625\n",
      "2017-04-03T19:30:17.917380: step 3931, loss 1.32414, acc 0.59375\n",
      "2017-04-03T19:30:18.108355: step 3932, loss 1.42589, acc 0.5\n",
      "2017-04-03T19:30:18.316320: step 3933, loss 1.29057, acc 0.59375\n",
      "2017-04-03T19:30:18.510865: step 3934, loss 1.33068, acc 0.515625\n",
      "2017-04-03T19:30:18.713507: step 3935, loss 1.04138, acc 0.6875\n",
      "2017-04-03T19:30:18.912647: step 3936, loss 1.18405, acc 0.59375\n",
      "2017-04-03T19:30:19.131181: step 3937, loss 1.2006, acc 0.5625\n",
      "2017-04-03T19:30:19.326545: step 3938, loss 1.33647, acc 0.5625\n",
      "2017-04-03T19:30:19.531963: step 3939, loss 1.25199, acc 0.515625\n",
      "2017-04-03T19:30:19.726632: step 3940, loss 1.42435, acc 0.5\n",
      "2017-04-03T19:30:19.878240: step 3941, loss 1.4904, acc 0.4375\n",
      "2017-04-03T19:30:20.075755: step 3942, loss 1.29838, acc 0.5\n",
      "2017-04-03T19:30:20.277907: step 3943, loss 1.05413, acc 0.65625\n",
      "2017-04-03T19:30:20.479449: step 3944, loss 1.05175, acc 0.671875\n",
      "2017-04-03T19:30:20.690692: step 3945, loss 0.96022, acc 0.671875\n",
      "2017-04-03T19:30:20.930882: step 3946, loss 1.05887, acc 0.625\n",
      "2017-04-03T19:30:21.145355: step 3947, loss 1.07824, acc 0.625\n",
      "2017-04-03T19:30:21.360956: step 3948, loss 1.05217, acc 0.640625\n",
      "2017-04-03T19:30:21.563922: step 3949, loss 1.03457, acc 0.671875\n",
      "2017-04-03T19:30:21.763838: step 3950, loss 0.90372, acc 0.78125\n",
      "2017-04-03T19:30:21.965527: step 3951, loss 1.10551, acc 0.578125\n",
      "2017-04-03T19:30:22.159720: step 3952, loss 1.19003, acc 0.5625\n",
      "2017-04-03T19:30:22.400948: step 3953, loss 1.04915, acc 0.640625\n",
      "2017-04-03T19:30:22.607328: step 3954, loss 1.11793, acc 0.609375\n",
      "2017-04-03T19:30:22.807664: step 3955, loss 1.15536, acc 0.625\n",
      "2017-04-03T19:30:23.009681: step 3956, loss 0.948203, acc 0.671875\n",
      "2017-04-03T19:30:23.199324: step 3957, loss 0.964192, acc 0.640625\n",
      "2017-04-03T19:30:23.442551: step 3958, loss 1.05692, acc 0.640625\n",
      "2017-04-03T19:30:23.633028: step 3959, loss 1.12649, acc 0.609375\n",
      "2017-04-03T19:30:23.839084: step 3960, loss 1.22573, acc 0.53125\n",
      "2017-04-03T19:30:24.033098: step 3961, loss 1.14988, acc 0.59375\n",
      "2017-04-03T19:30:24.255208: step 3962, loss 1.05939, acc 0.609375\n",
      "2017-04-03T19:30:24.446095: step 3963, loss 1.13305, acc 0.59375\n",
      "2017-04-03T19:30:24.645480: step 3964, loss 0.95175, acc 0.65625\n",
      "2017-04-03T19:30:24.839934: step 3965, loss 1.08525, acc 0.734375\n",
      "2017-04-03T19:30:25.046352: step 3966, loss 1.08918, acc 0.640625\n",
      "2017-04-03T19:30:25.242355: step 3967, loss 1.16349, acc 0.703125\n",
      "2017-04-03T19:30:25.443361: step 3968, loss 1.30834, acc 0.640625\n",
      "2017-04-03T19:30:25.638915: step 3969, loss 0.801648, acc 0.75\n",
      "2017-04-03T19:30:25.838305: step 3970, loss 1.09286, acc 0.625\n",
      "2017-04-03T19:30:26.030037: step 3971, loss 1.12924, acc 0.640625\n",
      "2017-04-03T19:30:26.234489: step 3972, loss 0.850004, acc 0.71875\n",
      "2017-04-03T19:30:26.429383: step 3973, loss 0.850067, acc 0.6875\n",
      "2017-04-03T19:30:26.634704: step 3974, loss 1.03018, acc 0.6875\n",
      "2017-04-03T19:30:26.830170: step 3975, loss 0.929087, acc 0.671875\n",
      "2017-04-03T19:30:27.037226: step 3976, loss 0.906651, acc 0.734375\n",
      "2017-04-03T19:30:27.237176: step 3977, loss 1.12607, acc 0.578125\n",
      "2017-04-03T19:30:27.436317: step 3978, loss 1.01195, acc 0.640625\n",
      "2017-04-03T19:30:27.628752: step 3979, loss 1.05391, acc 0.6875\n",
      "2017-04-03T19:30:27.830575: step 3980, loss 0.980212, acc 0.71875\n",
      "2017-04-03T19:30:28.022793: step 3981, loss 0.781352, acc 0.71875\n",
      "2017-04-03T19:30:28.228253: step 3982, loss 0.871481, acc 0.75\n",
      "2017-04-03T19:30:28.421352: step 3983, loss 0.841339, acc 0.734375\n",
      "2017-04-03T19:30:28.665100: step 3984, loss 0.819601, acc 0.75\n",
      "2017-04-03T19:30:28.859185: step 3985, loss 1.04741, acc 0.640625\n",
      "2017-04-03T19:30:29.059278: step 3986, loss 1.03442, acc 0.640625\n",
      "2017-04-03T19:30:29.253381: step 3987, loss 1.07058, acc 0.609375\n",
      "2017-04-03T19:30:29.455695: step 3988, loss 1.04101, acc 0.75\n",
      "2017-04-03T19:30:29.650047: step 3989, loss 1.22105, acc 0.53125\n",
      "2017-04-03T19:30:29.896289: step 3990, loss 1.28803, acc 0.53125\n",
      "2017-04-03T19:30:30.089690: step 3991, loss 1.13245, acc 0.5625\n",
      "2017-04-03T19:30:30.331434: step 3992, loss 1.01185, acc 0.640625\n",
      "2017-04-03T19:30:30.529069: step 3993, loss 1.00728, acc 0.5625\n",
      "2017-04-03T19:30:30.728934: step 3994, loss 1.00967, acc 0.6875\n",
      "2017-04-03T19:30:30.920670: step 3995, loss 0.987548, acc 0.75\n",
      "2017-04-03T19:30:31.120965: step 3996, loss 0.986282, acc 0.671875\n",
      "2017-04-03T19:30:31.315800: step 3997, loss 0.918849, acc 0.671875\n",
      "2017-04-03T19:30:31.518619: step 3998, loss 1.30307, acc 0.578125\n",
      "2017-04-03T19:30:31.712270: step 3999, loss 0.846472, acc 0.75\n",
      "2017-04-03T19:30:31.912720: step 4000, loss 0.844958, acc 0.75\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:30:33.845089: step 4000, loss 1.98582, acc 0.33775\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-4000\n",
      "\n",
      "2017-04-03T19:30:34.172835: step 4001, loss 0.88591, acc 0.703125\n",
      "2017-04-03T19:30:34.368547: step 4002, loss 0.700396, acc 0.765625\n",
      "2017-04-03T19:30:34.574021: step 4003, loss 1.08524, acc 0.609375\n",
      "2017-04-03T19:30:34.768904: step 4004, loss 1.12378, acc 0.65625\n",
      "2017-04-03T19:30:34.970464: step 4005, loss 1.05381, acc 0.703125\n",
      "2017-04-03T19:30:35.162535: step 4006, loss 1.13722, acc 0.65625\n",
      "2017-04-03T19:30:35.363126: step 4007, loss 1.03654, acc 0.609375\n",
      "2017-04-03T19:30:35.556089: step 4008, loss 0.944086, acc 0.65625\n",
      "2017-04-03T19:30:35.758279: step 4009, loss 1.0058, acc 0.625\n",
      "2017-04-03T19:30:35.952678: step 4010, loss 1.12534, acc 0.609375\n",
      "2017-04-03T19:30:36.155169: step 4011, loss 1.15904, acc 0.65625\n",
      "2017-04-03T19:30:36.347958: step 4012, loss 1.22385, acc 0.625\n",
      "2017-04-03T19:30:36.552908: step 4013, loss 1.2141, acc 0.578125\n",
      "2017-04-03T19:30:36.747768: step 4014, loss 1.10034, acc 0.59375\n",
      "2017-04-03T19:30:36.955201: step 4015, loss 1.09673, acc 0.578125\n",
      "2017-04-03T19:30:37.149851: step 4016, loss 1.16776, acc 0.5625\n",
      "2017-04-03T19:30:37.351907: step 4017, loss 1.10762, acc 0.609375\n",
      "2017-04-03T19:30:37.548128: step 4018, loss 1.07993, acc 0.640625\n",
      "2017-04-03T19:30:37.752999: step 4019, loss 1.15395, acc 0.6875\n",
      "2017-04-03T19:30:37.948400: step 4020, loss 0.890429, acc 0.71875\n",
      "2017-04-03T19:30:38.149366: step 4021, loss 0.820188, acc 0.78125\n",
      "2017-04-03T19:30:38.346571: step 4022, loss 0.805758, acc 0.765625\n",
      "2017-04-03T19:30:38.548127: step 4023, loss 0.948063, acc 0.671875\n",
      "2017-04-03T19:30:38.742110: step 4024, loss 1.11005, acc 0.609375\n",
      "2017-04-03T19:30:38.945010: step 4025, loss 1.04465, acc 0.609375\n",
      "2017-04-03T19:30:39.138431: step 4026, loss 0.943135, acc 0.703125\n",
      "2017-04-03T19:30:39.342424: step 4027, loss 1.20303, acc 0.515625\n",
      "2017-04-03T19:30:39.541753: step 4028, loss 1.20009, acc 0.640625\n",
      "2017-04-03T19:30:39.753309: step 4029, loss 0.793908, acc 0.765625\n",
      "2017-04-03T19:30:39.947591: step 4030, loss 0.938779, acc 0.75\n",
      "2017-04-03T19:30:40.193306: step 4031, loss 1.15101, acc 0.625\n",
      "2017-04-03T19:30:40.389437: step 4032, loss 0.903029, acc 0.75\n",
      "2017-04-03T19:30:40.593714: step 4033, loss 1.13152, acc 0.515625\n",
      "2017-04-03T19:30:40.786613: step 4034, loss 0.976392, acc 0.703125\n",
      "2017-04-03T19:30:40.986239: step 4035, loss 1.20483, acc 0.5625\n",
      "2017-04-03T19:30:41.182307: step 4036, loss 1.08473, acc 0.703125\n",
      "2017-04-03T19:30:41.388573: step 4037, loss 0.942329, acc 0.703125\n",
      "2017-04-03T19:30:41.588479: step 4038, loss 0.998467, acc 0.671875\n",
      "2017-04-03T19:30:41.788291: step 4039, loss 0.916744, acc 0.734375\n",
      "2017-04-03T19:30:41.983120: step 4040, loss 0.904422, acc 0.734375\n",
      "2017-04-03T19:30:42.184104: step 4041, loss 1.03184, acc 0.640625\n",
      "2017-04-03T19:30:42.380315: step 4042, loss 1.25036, acc 0.5625\n",
      "2017-04-03T19:30:42.586647: step 4043, loss 1.1762, acc 0.609375\n",
      "2017-04-03T19:30:42.780817: step 4044, loss 1.06174, acc 0.640625\n",
      "2017-04-03T19:30:42.981722: step 4045, loss 1.05834, acc 0.671875\n",
      "2017-04-03T19:30:43.179445: step 4046, loss 0.983893, acc 0.640625\n",
      "2017-04-03T19:30:43.395658: step 4047, loss 1.17819, acc 0.59375\n",
      "2017-04-03T19:30:43.588967: step 4048, loss 1.11664, acc 0.578125\n",
      "2017-04-03T19:30:43.830152: step 4049, loss 1.14102, acc 0.5625\n",
      "2017-04-03T19:30:44.022098: step 4050, loss 0.93882, acc 0.625\n",
      "2017-04-03T19:30:44.226544: step 4051, loss 1.04596, acc 0.640625\n",
      "2017-04-03T19:30:44.420492: step 4052, loss 1.30648, acc 0.53125\n",
      "2017-04-03T19:30:44.624444: step 4053, loss 1.14488, acc 0.578125\n",
      "2017-04-03T19:30:44.818175: step 4054, loss 0.947594, acc 0.671875\n",
      "2017-04-03T19:30:45.021085: step 4055, loss 1.14402, acc 0.59375\n",
      "2017-04-03T19:30:45.213333: step 4056, loss 1.10195, acc 0.59375\n",
      "2017-04-03T19:30:45.413576: step 4057, loss 1.33806, acc 0.515625\n",
      "2017-04-03T19:30:45.613362: step 4058, loss 0.995421, acc 0.6875\n",
      "2017-04-03T19:30:45.820971: step 4059, loss 1.05284, acc 0.703125\n",
      "2017-04-03T19:30:46.015516: step 4060, loss 0.945246, acc 0.6875\n",
      "2017-04-03T19:30:46.216515: step 4061, loss 0.950187, acc 0.703125\n",
      "2017-04-03T19:30:46.412513: step 4062, loss 1.26118, acc 0.546875\n",
      "2017-04-03T19:30:46.613236: step 4063, loss 0.927505, acc 0.71875\n",
      "2017-04-03T19:30:46.808203: step 4064, loss 0.958245, acc 0.6875\n",
      "2017-04-03T19:30:47.007790: step 4065, loss 0.994868, acc 0.671875\n",
      "2017-04-03T19:30:47.201748: step 4066, loss 1.10237, acc 0.625\n",
      "2017-04-03T19:30:47.403660: step 4067, loss 1.17765, acc 0.5625\n",
      "2017-04-03T19:30:47.597458: step 4068, loss 1.0438, acc 0.671875\n",
      "2017-04-03T19:30:47.802066: step 4069, loss 0.920778, acc 0.65625\n",
      "2017-04-03T19:30:47.996156: step 4070, loss 1.02402, acc 0.640625\n",
      "2017-04-03T19:30:48.199556: step 4071, loss 1.16862, acc 0.625\n",
      "2017-04-03T19:30:48.393046: step 4072, loss 0.987291, acc 0.640625\n",
      "2017-04-03T19:30:48.593335: step 4073, loss 1.14658, acc 0.640625\n",
      "2017-04-03T19:30:48.785092: step 4074, loss 1.16466, acc 0.625\n",
      "2017-04-03T19:30:48.992682: step 4075, loss 1.06241, acc 0.640625\n",
      "2017-04-03T19:30:49.187318: step 4076, loss 0.97738, acc 0.671875\n",
      "2017-04-03T19:30:49.389100: step 4077, loss 0.880537, acc 0.65625\n",
      "2017-04-03T19:30:49.584949: step 4078, loss 1.01916, acc 0.609375\n",
      "2017-04-03T19:30:49.791857: step 4079, loss 0.989009, acc 0.65625\n",
      "2017-04-03T19:30:49.982563: step 4080, loss 1.06565, acc 0.578125\n",
      "2017-04-03T19:30:50.182180: step 4081, loss 1.03366, acc 0.703125\n",
      "2017-04-03T19:30:50.374117: step 4082, loss 1.10204, acc 0.578125\n",
      "2017-04-03T19:30:50.574999: step 4083, loss 1.38062, acc 0.59375\n",
      "2017-04-03T19:30:50.767185: step 4084, loss 1.03568, acc 0.5625\n",
      "2017-04-03T19:30:50.968427: step 4085, loss 1.04022, acc 0.671875\n",
      "2017-04-03T19:30:51.161097: step 4086, loss 1.00547, acc 0.671875\n",
      "2017-04-03T19:30:51.363506: step 4087, loss 0.997239, acc 0.609375\n",
      "2017-04-03T19:30:51.556101: step 4088, loss 1.15743, acc 0.609375\n",
      "2017-04-03T19:30:51.760467: step 4089, loss 1.10457, acc 0.625\n",
      "2017-04-03T19:30:51.951034: step 4090, loss 1.09856, acc 0.578125\n",
      "2017-04-03T19:30:52.152520: step 4091, loss 0.981775, acc 0.6875\n",
      "2017-04-03T19:30:52.347098: step 4092, loss 1.23339, acc 0.578125\n",
      "2017-04-03T19:30:52.549421: step 4093, loss 0.988424, acc 0.703125\n",
      "2017-04-03T19:30:52.743668: step 4094, loss 1.11559, acc 0.59375\n",
      "2017-04-03T19:30:52.945406: step 4095, loss 0.997165, acc 0.734375\n",
      "2017-04-03T19:30:53.137383: step 4096, loss 0.971704, acc 0.734375\n",
      "2017-04-03T19:30:53.340382: step 4097, loss 1.007, acc 0.703125\n",
      "2017-04-03T19:30:53.533614: step 4098, loss 0.862468, acc 0.6875\n",
      "2017-04-03T19:30:53.736401: step 4099, loss 1.06475, acc 0.65625\n",
      "2017-04-03T19:30:53.931504: step 4100, loss 1.06879, acc 0.65625\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:30:55.858246: step 4100, loss 2.01827, acc 0.3435\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-4100\n",
      "\n",
      "2017-04-03T19:30:56.190975: step 4101, loss 1.08957, acc 0.65625\n",
      "2017-04-03T19:30:56.388648: step 4102, loss 0.987262, acc 0.5625\n",
      "2017-04-03T19:30:56.588604: step 4103, loss 1.19604, acc 0.578125\n",
      "2017-04-03T19:30:56.777037: step 4104, loss 1.2261, acc 0.53125\n",
      "2017-04-03T19:30:56.978926: step 4105, loss 1.11577, acc 0.609375\n",
      "2017-04-03T19:30:57.172683: step 4106, loss 1.09846, acc 0.6875\n",
      "2017-04-03T19:30:57.371242: step 4107, loss 1.00316, acc 0.625\n",
      "2017-04-03T19:30:57.566748: step 4108, loss 1.17972, acc 0.609375\n",
      "2017-04-03T19:30:57.765636: step 4109, loss 0.733974, acc 0.796875\n",
      "2017-04-03T19:30:57.957515: step 4110, loss 0.869851, acc 0.6875\n",
      "2017-04-03T19:30:58.159908: step 4111, loss 1.29583, acc 0.5625\n",
      "2017-04-03T19:30:58.354361: step 4112, loss 0.960268, acc 0.65625\n",
      "2017-04-03T19:30:58.593769: step 4113, loss 1.05138, acc 0.640625\n",
      "2017-04-03T19:30:58.788806: step 4114, loss 1.01381, acc 0.609375\n",
      "2017-04-03T19:30:58.986723: step 4115, loss 0.967829, acc 0.734375\n",
      "2017-04-03T19:30:59.183021: step 4116, loss 0.818907, acc 0.71875\n",
      "2017-04-03T19:30:59.383320: step 4117, loss 1.18188, acc 0.625\n",
      "2017-04-03T19:30:59.575390: step 4118, loss 1.13995, acc 0.625\n",
      "2017-04-03T19:30:59.786120: step 4119, loss 0.992115, acc 0.65625\n",
      "2017-04-03T19:30:59.977866: step 4120, loss 1.33109, acc 0.515625\n",
      "2017-04-03T19:31:00.185157: step 4121, loss 1.05111, acc 0.703125\n",
      "2017-04-03T19:31:00.380155: step 4122, loss 0.900617, acc 0.671875\n",
      "2017-04-03T19:31:00.600913: step 4123, loss 0.999337, acc 0.609375\n",
      "2017-04-03T19:31:00.797140: step 4124, loss 1.17789, acc 0.609375\n",
      "2017-04-03T19:31:00.999520: step 4125, loss 1.01233, acc 0.625\n",
      "2017-04-03T19:31:01.195211: step 4126, loss 1.15909, acc 0.5625\n",
      "2017-04-03T19:31:01.398617: step 4127, loss 1.12774, acc 0.609375\n",
      "2017-04-03T19:31:01.586555: step 4128, loss 1.07696, acc 0.625\n",
      "2017-04-03T19:31:01.786220: step 4129, loss 0.997866, acc 0.65625\n",
      "2017-04-03T19:31:01.979287: step 4130, loss 0.975048, acc 0.65625\n",
      "2017-04-03T19:31:02.182584: step 4131, loss 1.14123, acc 0.578125\n",
      "2017-04-03T19:31:02.374650: step 4132, loss 1.04147, acc 0.65625\n",
      "2017-04-03T19:31:02.576199: step 4133, loss 0.942971, acc 0.625\n",
      "2017-04-03T19:31:02.772557: step 4134, loss 1.09217, acc 0.625\n",
      "2017-04-03T19:31:02.979803: step 4135, loss 0.9103, acc 0.640625\n",
      "2017-04-03T19:31:03.170688: step 4136, loss 1.07463, acc 0.625\n",
      "2017-04-03T19:31:03.370842: step 4137, loss 1.01054, acc 0.625\n",
      "2017-04-03T19:31:03.562341: step 4138, loss 1.02506, acc 0.640625\n",
      "2017-04-03T19:31:03.763443: step 4139, loss 1.07811, acc 0.59375\n",
      "2017-04-03T19:31:03.961362: step 4140, loss 1.08501, acc 0.6875\n",
      "2017-04-03T19:31:04.164978: step 4141, loss 1.0124, acc 0.59375\n",
      "2017-04-03T19:31:04.358276: step 4142, loss 1.10288, acc 0.609375\n",
      "2017-04-03T19:31:04.558518: step 4143, loss 1.13214, acc 0.625\n",
      "2017-04-03T19:31:04.752590: step 4144, loss 0.960776, acc 0.609375\n",
      "2017-04-03T19:31:04.949762: step 4145, loss 0.994778, acc 0.625\n",
      "2017-04-03T19:31:05.140594: step 4146, loss 0.889025, acc 0.734375\n",
      "2017-04-03T19:31:05.346053: step 4147, loss 1.26028, acc 0.578125\n",
      "2017-04-03T19:31:05.543949: step 4148, loss 1.16235, acc 0.546875\n",
      "2017-04-03T19:31:05.742016: step 4149, loss 1.01773, acc 0.5625\n",
      "2017-04-03T19:31:05.932342: step 4150, loss 1.1143, acc 0.671875\n",
      "2017-04-03T19:31:06.134922: step 4151, loss 1.09436, acc 0.625\n",
      "2017-04-03T19:31:06.328121: step 4152, loss 0.95544, acc 0.71875\n",
      "2017-04-03T19:31:06.529588: step 4153, loss 1.10547, acc 0.625\n",
      "2017-04-03T19:31:06.721640: step 4154, loss 1.14979, acc 0.5625\n",
      "2017-04-03T19:31:06.920890: step 4155, loss 1.04303, acc 0.578125\n",
      "2017-04-03T19:31:07.114813: step 4156, loss 1.2159, acc 0.546875\n",
      "2017-04-03T19:31:07.319989: step 4157, loss 1.07929, acc 0.59375\n",
      "2017-04-03T19:31:07.514146: step 4158, loss 1.02981, acc 0.6875\n",
      "2017-04-03T19:31:07.715863: step 4159, loss 0.875848, acc 0.640625\n",
      "2017-04-03T19:31:07.908147: step 4160, loss 0.922522, acc 0.703125\n",
      "2017-04-03T19:31:08.110345: step 4161, loss 1.04204, acc 0.734375\n",
      "2017-04-03T19:31:08.302957: step 4162, loss 1.12754, acc 0.578125\n",
      "2017-04-03T19:31:08.506973: step 4163, loss 1.03046, acc 0.5625\n",
      "2017-04-03T19:31:08.696364: step 4164, loss 1.29585, acc 0.609375\n",
      "2017-04-03T19:31:08.897003: step 4165, loss 1.28778, acc 0.578125\n",
      "2017-04-03T19:31:09.092816: step 4166, loss 1.06481, acc 0.625\n",
      "2017-04-03T19:31:09.292406: step 4167, loss 1.12833, acc 0.5625\n",
      "2017-04-03T19:31:09.486952: step 4168, loss 1.30321, acc 0.609375\n",
      "2017-04-03T19:31:09.687797: step 4169, loss 1.1095, acc 0.609375\n",
      "2017-04-03T19:31:09.880747: step 4170, loss 0.908544, acc 0.734375\n",
      "2017-04-03T19:31:10.086470: step 4171, loss 0.974466, acc 0.671875\n",
      "2017-04-03T19:31:10.276542: step 4172, loss 1.12507, acc 0.578125\n",
      "2017-04-03T19:31:10.476477: step 4173, loss 1.00357, acc 0.671875\n",
      "2017-04-03T19:31:10.673972: step 4174, loss 0.98453, acc 0.578125\n",
      "2017-04-03T19:31:10.877964: step 4175, loss 1.1461, acc 0.5625\n",
      "2017-04-03T19:31:11.077682: step 4176, loss 1.00491, acc 0.671875\n",
      "2017-04-03T19:31:11.285309: step 4177, loss 1.13633, acc 0.609375\n",
      "2017-04-03T19:31:11.477436: step 4178, loss 0.799824, acc 0.703125\n",
      "2017-04-03T19:31:11.681280: step 4179, loss 1.01044, acc 0.71875\n",
      "2017-04-03T19:31:11.873611: step 4180, loss 1.02946, acc 0.734375\n",
      "2017-04-03T19:31:12.073891: step 4181, loss 1.14461, acc 0.59375\n",
      "2017-04-03T19:31:12.264934: step 4182, loss 1.22243, acc 0.609375\n",
      "2017-04-03T19:31:12.467498: step 4183, loss 1.12702, acc 0.671875\n",
      "2017-04-03T19:31:12.658560: step 4184, loss 0.990251, acc 0.578125\n",
      "2017-04-03T19:31:12.900424: step 4185, loss 1.28012, acc 0.515625\n",
      "2017-04-03T19:31:13.102222: step 4186, loss 1.01557, acc 0.625\n",
      "2017-04-03T19:31:13.302911: step 4187, loss 0.991421, acc 0.640625\n",
      "2017-04-03T19:31:13.502748: step 4188, loss 1.14411, acc 0.5\n",
      "2017-04-03T19:31:13.703253: step 4189, loss 1.1525, acc 0.625\n",
      "2017-04-03T19:31:13.903050: step 4190, loss 1.08865, acc 0.5625\n",
      "2017-04-03T19:31:14.104419: step 4191, loss 1.09206, acc 0.625\n",
      "2017-04-03T19:31:14.294499: step 4192, loss 1.2349, acc 0.59375\n",
      "2017-04-03T19:31:14.494158: step 4193, loss 1.08225, acc 0.625\n",
      "2017-04-03T19:31:14.688243: step 4194, loss 1.19904, acc 0.5625\n",
      "2017-04-03T19:31:14.890720: step 4195, loss 1.02999, acc 0.765625\n",
      "2017-04-03T19:31:15.083634: step 4196, loss 1.13823, acc 0.625\n",
      "2017-04-03T19:31:15.288051: step 4197, loss 1.10027, acc 0.609375\n",
      "2017-04-03T19:31:15.480933: step 4198, loss 1.18138, acc 0.578125\n",
      "2017-04-03T19:31:15.680130: step 4199, loss 1.16005, acc 0.65625\n",
      "2017-04-03T19:31:15.877815: step 4200, loss 1.08815, acc 0.6875\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:31:17.888853: step 4200, loss 2.05051, acc 0.33475\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-4200\n",
      "\n",
      "2017-04-03T19:31:18.216268: step 4201, loss 1.16773, acc 0.609375\n",
      "2017-04-03T19:31:18.417134: step 4202, loss 1.11567, acc 0.625\n",
      "2017-04-03T19:31:18.616269: step 4203, loss 0.909844, acc 0.671875\n",
      "2017-04-03T19:31:18.863461: step 4204, loss 1.10963, acc 0.640625\n",
      "2017-04-03T19:31:19.058089: step 4205, loss 1.15469, acc 0.640625\n",
      "2017-04-03T19:31:19.255239: step 4206, loss 1.20667, acc 0.59375\n",
      "2017-04-03T19:31:19.448364: step 4207, loss 0.946668, acc 0.65625\n",
      "2017-04-03T19:31:19.650069: step 4208, loss 1.03194, acc 0.625\n",
      "2017-04-03T19:31:19.839582: step 4209, loss 0.978474, acc 0.640625\n",
      "2017-04-03T19:31:20.037961: step 4210, loss 1.34277, acc 0.609375\n",
      "2017-04-03T19:31:20.230767: step 4211, loss 1.3056, acc 0.609375\n",
      "2017-04-03T19:31:20.434197: step 4212, loss 0.910553, acc 0.75\n",
      "2017-04-03T19:31:20.625731: step 4213, loss 1.10313, acc 0.578125\n",
      "2017-04-03T19:31:20.829657: step 4214, loss 1.13341, acc 0.609375\n",
      "2017-04-03T19:31:21.019348: step 4215, loss 1.11447, acc 0.625\n",
      "2017-04-03T19:31:21.219861: step 4216, loss 1.25626, acc 0.546875\n",
      "2017-04-03T19:31:21.411385: step 4217, loss 1.16944, acc 0.578125\n",
      "2017-04-03T19:31:21.611809: step 4218, loss 0.986411, acc 0.6875\n",
      "2017-04-03T19:31:21.802418: step 4219, loss 1.45113, acc 0.5\n",
      "2017-04-03T19:31:22.003204: step 4220, loss 0.97992, acc 0.609375\n",
      "2017-04-03T19:31:22.193733: step 4221, loss 1.10952, acc 0.59375\n",
      "2017-04-03T19:31:22.391441: step 4222, loss 1.05371, acc 0.6875\n",
      "2017-04-03T19:31:22.585010: step 4223, loss 1.27314, acc 0.609375\n",
      "2017-04-03T19:31:22.785425: step 4224, loss 0.950434, acc 0.625\n",
      "2017-04-03T19:31:22.978727: step 4225, loss 0.856035, acc 0.78125\n",
      "2017-04-03T19:31:23.178197: step 4226, loss 1.02743, acc 0.59375\n",
      "2017-04-03T19:31:23.369528: step 4227, loss 1.34322, acc 0.59375\n",
      "2017-04-03T19:31:23.570409: step 4228, loss 1.16496, acc 0.609375\n",
      "2017-04-03T19:31:23.761471: step 4229, loss 1.25041, acc 0.546875\n",
      "2017-04-03T19:31:23.959658: step 4230, loss 1.14711, acc 0.578125\n",
      "2017-04-03T19:31:24.149147: step 4231, loss 0.981542, acc 0.6875\n",
      "2017-04-03T19:31:24.347424: step 4232, loss 1.16732, acc 0.59375\n",
      "2017-04-03T19:31:24.544675: step 4233, loss 0.99929, acc 0.625\n",
      "2017-04-03T19:31:24.744417: step 4234, loss 0.888726, acc 0.625\n",
      "2017-04-03T19:31:24.937901: step 4235, loss 0.950217, acc 0.6875\n",
      "2017-04-03T19:31:25.142620: step 4236, loss 0.934061, acc 0.65625\n",
      "2017-04-03T19:31:25.340421: step 4237, loss 1.18701, acc 0.59375\n",
      "2017-04-03T19:31:25.540665: step 4238, loss 1.07861, acc 0.65625\n",
      "2017-04-03T19:31:25.737803: step 4239, loss 1.14619, acc 0.59375\n",
      "2017-04-03T19:31:25.975866: step 4240, loss 1.21761, acc 0.5625\n",
      "2017-04-03T19:31:26.167043: step 4241, loss 1.17402, acc 0.609375\n",
      "2017-04-03T19:31:26.370282: step 4242, loss 0.870275, acc 0.703125\n",
      "2017-04-03T19:31:26.565540: step 4243, loss 1.1428, acc 0.5625\n",
      "2017-04-03T19:31:26.763625: step 4244, loss 1.23123, acc 0.5625\n",
      "2017-04-03T19:31:26.954526: step 4245, loss 1.18521, acc 0.5625\n",
      "2017-04-03T19:31:27.157888: step 4246, loss 1.05031, acc 0.59375\n",
      "2017-04-03T19:31:27.350198: step 4247, loss 1.34203, acc 0.578125\n",
      "2017-04-03T19:31:27.549653: step 4248, loss 0.998959, acc 0.640625\n",
      "2017-04-03T19:31:27.740466: step 4249, loss 0.951659, acc 0.734375\n",
      "2017-04-03T19:31:27.938998: step 4250, loss 0.930588, acc 0.6875\n",
      "2017-04-03T19:31:28.129999: step 4251, loss 1.13357, acc 0.546875\n",
      "2017-04-03T19:31:28.336356: step 4252, loss 0.960997, acc 0.65625\n",
      "2017-04-03T19:31:28.528640: step 4253, loss 1.13052, acc 0.65625\n",
      "2017-04-03T19:31:28.729725: step 4254, loss 1.11973, acc 0.546875\n",
      "2017-04-03T19:31:28.925366: step 4255, loss 1.03101, acc 0.625\n",
      "2017-04-03T19:31:29.167408: step 4256, loss 1.05235, acc 0.609375\n",
      "2017-04-03T19:31:29.358906: step 4257, loss 1.10157, acc 0.578125\n",
      "2017-04-03T19:31:29.563077: step 4258, loss 0.853926, acc 0.65625\n",
      "2017-04-03T19:31:29.757264: step 4259, loss 1.24377, acc 0.578125\n",
      "2017-04-03T19:31:29.996099: step 4260, loss 1.01987, acc 0.6875\n",
      "2017-04-03T19:31:30.190755: step 4261, loss 1.13087, acc 0.609375\n",
      "2017-04-03T19:31:30.388577: step 4262, loss 0.888842, acc 0.65625\n",
      "2017-04-03T19:31:30.582888: step 4263, loss 0.955908, acc 0.6875\n",
      "2017-04-03T19:31:30.783971: step 4264, loss 0.912409, acc 0.703125\n",
      "2017-04-03T19:31:30.976430: step 4265, loss 1.17974, acc 0.59375\n",
      "2017-04-03T19:31:31.214957: step 4266, loss 0.859222, acc 0.75\n",
      "2017-04-03T19:31:31.408999: step 4267, loss 0.871348, acc 0.765625\n",
      "2017-04-03T19:31:31.610232: step 4268, loss 1.05238, acc 0.609375\n",
      "2017-04-03T19:31:31.807306: step 4269, loss 1.21423, acc 0.5625\n",
      "2017-04-03T19:31:32.013137: step 4270, loss 1.10584, acc 0.59375\n",
      "2017-04-03T19:31:32.205420: step 4271, loss 1.10772, acc 0.625\n",
      "2017-04-03T19:31:32.407949: step 4272, loss 1.16084, acc 0.515625\n",
      "2017-04-03T19:31:32.602522: step 4273, loss 0.888377, acc 0.6875\n",
      "2017-04-03T19:31:32.807096: step 4274, loss 1.28831, acc 0.578125\n",
      "2017-04-03T19:31:33.000817: step 4275, loss 1.15334, acc 0.59375\n",
      "2017-04-03T19:31:33.200962: step 4276, loss 1.15321, acc 0.546875\n",
      "2017-04-03T19:31:33.399548: step 4277, loss 1.0286, acc 0.71875\n",
      "2017-04-03T19:31:33.598987: step 4278, loss 0.959691, acc 0.6875\n",
      "2017-04-03T19:31:33.793344: step 4279, loss 0.983654, acc 0.6875\n",
      "2017-04-03T19:31:33.994739: step 4280, loss 0.963402, acc 0.703125\n",
      "2017-04-03T19:31:34.186883: step 4281, loss 1.1413, acc 0.65625\n",
      "2017-04-03T19:31:34.385250: step 4282, loss 0.993384, acc 0.703125\n",
      "2017-04-03T19:31:34.579877: step 4283, loss 1.02002, acc 0.71875\n",
      "2017-04-03T19:31:34.781578: step 4284, loss 1.18474, acc 0.65625\n",
      "2017-04-03T19:31:34.972768: step 4285, loss 0.971837, acc 0.71875\n",
      "2017-04-03T19:31:35.175280: step 4286, loss 1.16134, acc 0.65625\n",
      "2017-04-03T19:31:35.367301: step 4287, loss 1.22043, acc 0.609375\n",
      "2017-04-03T19:31:35.566859: step 4288, loss 1.27179, acc 0.578125\n",
      "2017-04-03T19:31:35.758506: step 4289, loss 1.11373, acc 0.640625\n",
      "2017-04-03T19:31:35.964926: step 4290, loss 1.23164, acc 0.5625\n",
      "2017-04-03T19:31:36.157644: step 4291, loss 1.13618, acc 0.578125\n",
      "2017-04-03T19:31:36.355887: step 4292, loss 1.03318, acc 0.5625\n",
      "2017-04-03T19:31:36.550569: step 4293, loss 1.26866, acc 0.625\n",
      "2017-04-03T19:31:36.751715: step 4294, loss 1.07117, acc 0.65625\n",
      "2017-04-03T19:31:36.946241: step 4295, loss 0.928334, acc 0.6875\n",
      "2017-04-03T19:31:37.148528: step 4296, loss 1.21117, acc 0.5625\n",
      "2017-04-03T19:31:37.340133: step 4297, loss 1.06097, acc 0.609375\n",
      "2017-04-03T19:31:37.541016: step 4298, loss 1.07326, acc 0.5625\n",
      "2017-04-03T19:31:37.733899: step 4299, loss 1.1007, acc 0.5625\n",
      "2017-04-03T19:31:37.935448: step 4300, loss 0.958452, acc 0.671875\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:31:39.902445: step 4300, loss 2.06064, acc 0.33775\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-4300\n",
      "\n",
      "2017-04-03T19:31:40.231690: step 4301, loss 1.06139, acc 0.65625\n",
      "2017-04-03T19:31:40.433955: step 4302, loss 1.13192, acc 0.59375\n",
      "2017-04-03T19:31:40.632820: step 4303, loss 0.938206, acc 0.640625\n",
      "2017-04-03T19:31:40.833642: step 4304, loss 1.10322, acc 0.640625\n",
      "2017-04-03T19:31:41.029200: step 4305, loss 1.24022, acc 0.578125\n",
      "2017-04-03T19:31:41.229619: step 4306, loss 0.834672, acc 0.71875\n",
      "2017-04-03T19:31:41.421782: step 4307, loss 1.33012, acc 0.484375\n",
      "2017-04-03T19:31:41.626937: step 4308, loss 1.011, acc 0.625\n",
      "2017-04-03T19:31:41.820751: step 4309, loss 1.18493, acc 0.609375\n",
      "2017-04-03T19:31:42.023482: step 4310, loss 1.19324, acc 0.578125\n",
      "2017-04-03T19:31:42.217758: step 4311, loss 1.11219, acc 0.65625\n",
      "2017-04-03T19:31:42.418480: step 4312, loss 1.20918, acc 0.578125\n",
      "2017-04-03T19:31:42.613415: step 4313, loss 1.2662, acc 0.59375\n",
      "2017-04-03T19:31:42.815073: step 4314, loss 1.33207, acc 0.5\n",
      "2017-04-03T19:31:43.010329: step 4315, loss 1.10097, acc 0.65625\n",
      "2017-04-03T19:31:43.211778: step 4316, loss 1.11045, acc 0.65625\n",
      "2017-04-03T19:31:43.403691: step 4317, loss 1.01238, acc 0.578125\n",
      "2017-04-03T19:31:43.605185: step 4318, loss 1.34512, acc 0.484375\n",
      "2017-04-03T19:31:43.798933: step 4319, loss 1.09477, acc 0.578125\n",
      "2017-04-03T19:31:43.997454: step 4320, loss 1.25286, acc 0.59375\n",
      "2017-04-03T19:31:44.190446: step 4321, loss 1.10334, acc 0.65625\n",
      "2017-04-03T19:31:44.396303: step 4322, loss 1.02869, acc 0.53125\n",
      "2017-04-03T19:31:44.586102: step 4323, loss 1.14682, acc 0.625\n",
      "2017-04-03T19:31:44.791832: step 4324, loss 1.02205, acc 0.703125\n",
      "2017-04-03T19:31:44.982480: step 4325, loss 1.28859, acc 0.59375\n",
      "2017-04-03T19:31:45.183616: step 4326, loss 1.0956, acc 0.625\n",
      "2017-04-03T19:31:45.379961: step 4327, loss 1.09979, acc 0.640625\n",
      "2017-04-03T19:31:45.625778: step 4328, loss 1.15864, acc 0.5625\n",
      "2017-04-03T19:31:45.816215: step 4329, loss 1.16969, acc 0.59375\n",
      "2017-04-03T19:31:46.015538: step 4330, loss 1.02507, acc 0.59375\n",
      "2017-04-03T19:31:46.212969: step 4331, loss 1.0538, acc 0.65625\n",
      "2017-04-03T19:31:46.412607: step 4332, loss 1.20737, acc 0.5625\n",
      "2017-04-03T19:31:46.603668: step 4333, loss 0.933936, acc 0.65625\n",
      "2017-04-03T19:31:46.804655: step 4334, loss 1.07039, acc 0.640625\n",
      "2017-04-03T19:31:46.993411: step 4335, loss 1.31447, acc 0.5\n",
      "2017-04-03T19:31:47.200458: step 4336, loss 0.996, acc 0.625\n",
      "2017-04-03T19:31:47.393802: step 4337, loss 1.0502, acc 0.6875\n",
      "2017-04-03T19:31:47.596437: step 4338, loss 0.960556, acc 0.65625\n",
      "2017-04-03T19:31:47.788418: step 4339, loss 1.10884, acc 0.625\n",
      "2017-04-03T19:31:47.987224: step 4340, loss 0.864842, acc 0.6875\n",
      "2017-04-03T19:31:48.186082: step 4341, loss 1.02502, acc 0.671875\n",
      "2017-04-03T19:31:48.385711: step 4342, loss 0.971786, acc 0.671875\n",
      "2017-04-03T19:31:48.579599: step 4343, loss 1.0712, acc 0.671875\n",
      "2017-04-03T19:31:48.778925: step 4344, loss 1.18, acc 0.65625\n",
      "2017-04-03T19:31:48.973982: step 4345, loss 1.03311, acc 0.6875\n",
      "2017-04-03T19:31:49.175670: step 4346, loss 1.19025, acc 0.515625\n",
      "2017-04-03T19:31:49.368652: step 4347, loss 1.12075, acc 0.640625\n",
      "2017-04-03T19:31:49.569440: step 4348, loss 1.19437, acc 0.515625\n",
      "2017-04-03T19:31:49.768552: step 4349, loss 1.05496, acc 0.65625\n",
      "2017-04-03T19:31:49.972171: step 4350, loss 1.25628, acc 0.578125\n",
      "2017-04-03T19:31:50.168553: step 4351, loss 0.878223, acc 0.71875\n",
      "2017-04-03T19:31:50.361923: step 4352, loss 1.16008, acc 0.546875\n",
      "2017-04-03T19:31:50.559539: step 4353, loss 1.07856, acc 0.59375\n",
      "2017-04-03T19:31:50.761108: step 4354, loss 1.18775, acc 0.609375\n",
      "2017-04-03T19:31:50.952301: step 4355, loss 0.954703, acc 0.671875\n",
      "2017-04-03T19:31:51.150568: step 4356, loss 1.31584, acc 0.46875\n",
      "2017-04-03T19:31:51.346154: step 4357, loss 0.883617, acc 0.65625\n",
      "2017-04-03T19:31:51.548446: step 4358, loss 1.12687, acc 0.609375\n",
      "2017-04-03T19:31:51.742415: step 4359, loss 1.07837, acc 0.6875\n",
      "2017-04-03T19:31:51.946933: step 4360, loss 1.23693, acc 0.609375\n",
      "2017-04-03T19:31:52.141362: step 4361, loss 1.11531, acc 0.65625\n",
      "2017-04-03T19:31:52.343090: step 4362, loss 1.08194, acc 0.578125\n",
      "2017-04-03T19:31:52.538842: step 4363, loss 1.17956, acc 0.625\n",
      "2017-04-03T19:31:52.734576: step 4364, loss 1.24178, acc 0.53125\n",
      "2017-04-03T19:31:52.933172: step 4365, loss 1.09966, acc 0.671875\n",
      "2017-04-03T19:31:53.176682: step 4366, loss 0.991363, acc 0.609375\n",
      "2017-04-03T19:31:53.373163: step 4367, loss 0.932872, acc 0.671875\n",
      "2017-04-03T19:31:53.574097: step 4368, loss 0.970214, acc 0.6875\n",
      "2017-04-03T19:31:53.765666: step 4369, loss 1.06057, acc 0.59375\n",
      "2017-04-03T19:31:53.969368: step 4370, loss 1.33187, acc 0.5625\n",
      "2017-04-03T19:31:54.162835: step 4371, loss 1.42248, acc 0.5\n",
      "2017-04-03T19:31:54.365552: step 4372, loss 1.14952, acc 0.640625\n",
      "2017-04-03T19:31:54.562176: step 4373, loss 1.23518, acc 0.578125\n",
      "2017-04-03T19:31:54.764267: step 4374, loss 1.05345, acc 0.609375\n",
      "2017-04-03T19:31:54.959991: step 4375, loss 1.01994, acc 0.640625\n",
      "2017-04-03T19:31:55.163470: step 4376, loss 0.979544, acc 0.6875\n",
      "2017-04-03T19:31:55.354204: step 4377, loss 1.15209, acc 0.59375\n",
      "2017-04-03T19:31:55.599935: step 4378, loss 1.19402, acc 0.65625\n",
      "2017-04-03T19:31:55.792217: step 4379, loss 0.917002, acc 0.671875\n",
      "2017-04-03T19:31:55.989487: step 4380, loss 0.98778, acc 0.578125\n",
      "2017-04-03T19:31:56.182989: step 4381, loss 1.15919, acc 0.5625\n",
      "2017-04-03T19:31:56.379439: step 4382, loss 0.808187, acc 0.75\n",
      "2017-04-03T19:31:56.576261: step 4383, loss 1.05766, acc 0.625\n",
      "2017-04-03T19:31:56.776431: step 4384, loss 1.2657, acc 0.5625\n",
      "2017-04-03T19:31:56.973107: step 4385, loss 1.11394, acc 0.6875\n",
      "2017-04-03T19:31:57.172539: step 4386, loss 1.05604, acc 0.578125\n",
      "2017-04-03T19:31:57.370388: step 4387, loss 1.08921, acc 0.640625\n",
      "2017-04-03T19:31:57.570508: step 4388, loss 1.20062, acc 0.5625\n",
      "2017-04-03T19:31:57.767692: step 4389, loss 1.25438, acc 0.453125\n",
      "2017-04-03T19:31:57.974629: step 4390, loss 1.22282, acc 0.625\n",
      "2017-04-03T19:31:58.165606: step 4391, loss 1.0708, acc 0.6875\n",
      "2017-04-03T19:31:58.366232: step 4392, loss 1.05503, acc 0.546875\n",
      "2017-04-03T19:31:58.563518: step 4393, loss 0.74524, acc 0.71875\n",
      "2017-04-03T19:31:58.761061: step 4394, loss 1.05764, acc 0.703125\n",
      "2017-04-03T19:31:58.953079: step 4395, loss 1.1656, acc 0.609375\n",
      "2017-04-03T19:31:59.148889: step 4396, loss 1.20358, acc 0.5625\n",
      "2017-04-03T19:31:59.342986: step 4397, loss 1.28803, acc 0.578125\n",
      "2017-04-03T19:31:59.543273: step 4398, loss 1.26968, acc 0.5625\n",
      "2017-04-03T19:31:59.737865: step 4399, loss 0.909877, acc 0.671875\n",
      "2017-04-03T19:31:59.938416: step 4400, loss 1.15112, acc 0.671875\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:32:01.921767: step 4400, loss 2.09163, acc 0.3335\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-4400\n",
      "\n",
      "2017-04-03T19:32:02.246904: step 4401, loss 0.980732, acc 0.640625\n",
      "2017-04-03T19:32:02.449421: step 4402, loss 1.18811, acc 0.640625\n",
      "2017-04-03T19:32:02.647448: step 4403, loss 1.00363, acc 0.625\n",
      "2017-04-03T19:32:02.854000: step 4404, loss 0.876101, acc 0.703125\n",
      "2017-04-03T19:32:03.045421: step 4405, loss 1.30672, acc 0.53125\n",
      "2017-04-03T19:32:03.246290: step 4406, loss 0.765414, acc 0.734375\n",
      "2017-04-03T19:32:03.441066: step 4407, loss 1.14534, acc 0.578125\n",
      "2017-04-03T19:32:03.644606: step 4408, loss 1.21395, acc 0.625\n",
      "2017-04-03T19:32:03.840594: step 4409, loss 1.04744, acc 0.625\n",
      "2017-04-03T19:32:04.047794: step 4410, loss 1.18777, acc 0.578125\n",
      "2017-04-03T19:32:04.242413: step 4411, loss 1.1756, acc 0.609375\n",
      "2017-04-03T19:32:04.443430: step 4412, loss 1.23114, acc 0.5625\n",
      "2017-04-03T19:32:04.634624: step 4413, loss 1.19563, acc 0.625\n",
      "2017-04-03T19:32:04.834804: step 4414, loss 1.03259, acc 0.640625\n",
      "2017-04-03T19:32:05.032029: step 4415, loss 1.09341, acc 0.640625\n",
      "2017-04-03T19:32:05.240445: step 4416, loss 0.953575, acc 0.671875\n",
      "2017-04-03T19:32:05.431384: step 4417, loss 1.01807, acc 0.671875\n",
      "2017-04-03T19:32:05.632559: step 4418, loss 1.34818, acc 0.59375\n",
      "2017-04-03T19:32:05.825496: step 4419, loss 1.10388, acc 0.6875\n",
      "2017-04-03T19:32:06.027690: step 4420, loss 1.19599, acc 0.59375\n",
      "2017-04-03T19:32:06.222552: step 4421, loss 1.10708, acc 0.5625\n",
      "2017-04-03T19:32:06.423813: step 4422, loss 1.21339, acc 0.546875\n",
      "2017-04-03T19:32:06.622053: step 4423, loss 1.1966, acc 0.53125\n",
      "2017-04-03T19:32:06.823697: step 4424, loss 0.958511, acc 0.671875\n",
      "2017-04-03T19:32:07.019164: step 4425, loss 1.3205, acc 0.484375\n",
      "2017-04-03T19:32:07.229030: step 4426, loss 1.37708, acc 0.578125\n",
      "2017-04-03T19:32:07.421236: step 4427, loss 1.17416, acc 0.5625\n",
      "2017-04-03T19:32:07.624672: step 4428, loss 1.09285, acc 0.609375\n",
      "2017-04-03T19:32:07.819919: step 4429, loss 1.14552, acc 0.546875\n",
      "2017-04-03T19:32:08.021585: step 4430, loss 1.17254, acc 0.609375\n",
      "2017-04-03T19:32:08.216916: step 4431, loss 1.29917, acc 0.5\n",
      "2017-04-03T19:32:08.422187: step 4432, loss 1.17892, acc 0.6875\n",
      "2017-04-03T19:32:08.615924: step 4433, loss 1.13613, acc 0.625\n",
      "2017-04-03T19:32:08.815571: step 4434, loss 1.06926, acc 0.609375\n",
      "2017-04-03T19:32:09.009283: step 4435, loss 1.24459, acc 0.578125\n",
      "2017-04-03T19:32:09.213476: step 4436, loss 1.01474, acc 0.640625\n",
      "2017-04-03T19:32:09.410315: step 4437, loss 1.11432, acc 0.609375\n",
      "2017-04-03T19:32:09.612712: step 4438, loss 1.16715, acc 0.65625\n",
      "2017-04-03T19:32:09.807718: step 4439, loss 1.08305, acc 0.578125\n",
      "2017-04-03T19:32:10.009049: step 4440, loss 1.03342, acc 0.609375\n",
      "2017-04-03T19:32:10.205773: step 4441, loss 1.03165, acc 0.609375\n",
      "2017-04-03T19:32:10.407382: step 4442, loss 0.891225, acc 0.640625\n",
      "2017-04-03T19:32:10.598470: step 4443, loss 1.32049, acc 0.546875\n",
      "2017-04-03T19:32:10.799783: step 4444, loss 1.40345, acc 0.515625\n",
      "2017-04-03T19:32:10.994057: step 4445, loss 1.51643, acc 0.5625\n",
      "2017-04-03T19:32:11.194482: step 4446, loss 1.33855, acc 0.578125\n",
      "2017-04-03T19:32:11.387306: step 4447, loss 1.05478, acc 0.609375\n",
      "2017-04-03T19:32:11.636721: step 4448, loss 1.34431, acc 0.546875\n",
      "2017-04-03T19:32:11.829207: step 4449, loss 1.00961, acc 0.65625\n",
      "2017-04-03T19:32:12.037979: step 4450, loss 0.96683, acc 0.625\n",
      "2017-04-03T19:32:12.232916: step 4451, loss 1.14139, acc 0.625\n",
      "2017-04-03T19:32:12.431510: step 4452, loss 1.10234, acc 0.640625\n",
      "2017-04-03T19:32:12.625078: step 4453, loss 1.27489, acc 0.578125\n",
      "2017-04-03T19:32:12.827328: step 4454, loss 1.09282, acc 0.671875\n",
      "2017-04-03T19:32:13.022955: step 4455, loss 1.37301, acc 0.53125\n",
      "2017-04-03T19:32:13.225432: step 4456, loss 1.04245, acc 0.625\n",
      "2017-04-03T19:32:13.420707: step 4457, loss 1.08956, acc 0.625\n",
      "2017-04-03T19:32:13.623882: step 4458, loss 1.22052, acc 0.59375\n",
      "2017-04-03T19:32:13.817288: step 4459, loss 1.20512, acc 0.5625\n",
      "2017-04-03T19:32:14.017963: step 4460, loss 1.13964, acc 0.625\n",
      "2017-04-03T19:32:14.212153: step 4461, loss 0.943186, acc 0.625\n",
      "2017-04-03T19:32:14.419573: step 4462, loss 1.08701, acc 0.703125\n",
      "2017-04-03T19:32:14.614426: step 4463, loss 1.00389, acc 0.65625\n",
      "2017-04-03T19:32:14.818248: step 4464, loss 0.968094, acc 0.6875\n",
      "2017-04-03T19:32:15.012384: step 4465, loss 1.02041, acc 0.6875\n",
      "2017-04-03T19:32:15.218403: step 4466, loss 1.07131, acc 0.671875\n",
      "2017-04-03T19:32:15.413245: step 4467, loss 1.19989, acc 0.5625\n",
      "2017-04-03T19:32:15.612814: step 4468, loss 1.04862, acc 0.625\n",
      "2017-04-03T19:32:15.808405: step 4469, loss 1.03093, acc 0.640625\n",
      "2017-04-03T19:32:16.009304: step 4470, loss 0.929379, acc 0.671875\n",
      "2017-04-03T19:32:16.207778: step 4471, loss 1.17153, acc 0.59375\n",
      "2017-04-03T19:32:16.410840: step 4472, loss 1.01553, acc 0.625\n",
      "2017-04-03T19:32:16.612689: step 4473, loss 1.04913, acc 0.625\n",
      "2017-04-03T19:32:16.818980: step 4474, loss 1.08499, acc 0.65625\n",
      "2017-04-03T19:32:17.027562: step 4475, loss 1.71976, acc 0.46875\n",
      "2017-04-03T19:32:17.231983: step 4476, loss 1.11269, acc 0.59375\n",
      "2017-04-03T19:32:17.434068: step 4477, loss 1.12984, acc 0.5625\n",
      "2017-04-03T19:32:17.638589: step 4478, loss 1.24133, acc 0.53125\n",
      "2017-04-03T19:32:17.840164: step 4479, loss 1.05782, acc 0.578125\n",
      "2017-04-03T19:32:18.051306: step 4480, loss 1.25383, acc 0.609375\n",
      "2017-04-03T19:32:18.252890: step 4481, loss 1.40966, acc 0.5625\n",
      "2017-04-03T19:32:18.458015: step 4482, loss 1.17597, acc 0.5625\n",
      "2017-04-03T19:32:18.658734: step 4483, loss 0.970064, acc 0.65625\n",
      "2017-04-03T19:32:18.857626: step 4484, loss 1.15927, acc 0.578125\n",
      "2017-04-03T19:32:19.056829: step 4485, loss 1.06257, acc 0.59375\n",
      "2017-04-03T19:32:19.253779: step 4486, loss 0.904134, acc 0.640625\n",
      "2017-04-03T19:32:19.451000: step 4487, loss 0.994512, acc 0.671875\n",
      "2017-04-03T19:32:19.648006: step 4488, loss 0.951737, acc 0.625\n",
      "2017-04-03T19:32:19.845464: step 4489, loss 0.975113, acc 0.609375\n",
      "2017-04-03T19:32:20.052932: step 4490, loss 1.08185, acc 0.640625\n",
      "2017-04-03T19:32:20.249758: step 4491, loss 1.03998, acc 0.625\n",
      "2017-04-03T19:32:20.452893: step 4492, loss 1.01375, acc 0.65625\n",
      "2017-04-03T19:32:20.649293: step 4493, loss 1.09877, acc 0.640625\n",
      "2017-04-03T19:32:20.851482: step 4494, loss 0.874599, acc 0.71875\n",
      "2017-04-03T19:32:21.041544: step 4495, loss 1.40905, acc 0.453125\n",
      "2017-04-03T19:32:21.241441: step 4496, loss 1.25996, acc 0.5625\n",
      "2017-04-03T19:32:21.440003: step 4497, loss 1.21623, acc 0.546875\n",
      "2017-04-03T19:32:21.639269: step 4498, loss 1.01226, acc 0.640625\n",
      "2017-04-03T19:32:21.838004: step 4499, loss 1.07832, acc 0.59375\n",
      "2017-04-03T19:32:22.042487: step 4500, loss 1.25081, acc 0.546875\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:32:24.017457: step 4500, loss 2.11491, acc 0.33575\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-4500\n",
      "\n",
      "2017-04-03T19:32:24.356904: step 4501, loss 0.934363, acc 0.671875\n",
      "2017-04-03T19:32:24.559021: step 4502, loss 1.29867, acc 0.5625\n",
      "2017-04-03T19:32:24.758074: step 4503, loss 1.23313, acc 0.5625\n",
      "2017-04-03T19:32:24.907091: step 4504, loss 1.07046, acc 0.625\n",
      "2017-04-03T19:32:25.112844: step 4505, loss 0.918291, acc 0.671875\n",
      "2017-04-03T19:32:25.316692: step 4506, loss 0.985332, acc 0.65625\n",
      "2017-04-03T19:32:25.518960: step 4507, loss 0.743296, acc 0.78125\n",
      "2017-04-03T19:32:25.718864: step 4508, loss 1.02089, acc 0.625\n",
      "2017-04-03T19:32:25.974712: step 4509, loss 0.7476, acc 0.78125\n",
      "2017-04-03T19:32:26.171757: step 4510, loss 1.05987, acc 0.640625\n",
      "2017-04-03T19:32:26.378921: step 4511, loss 0.875307, acc 0.71875\n",
      "2017-04-03T19:32:26.578265: step 4512, loss 0.77472, acc 0.796875\n",
      "2017-04-03T19:32:26.779540: step 4513, loss 0.701741, acc 0.765625\n",
      "2017-04-03T19:32:26.975411: step 4514, loss 0.861293, acc 0.78125\n",
      "2017-04-03T19:32:27.179844: step 4515, loss 0.91302, acc 0.734375\n",
      "2017-04-03T19:32:27.377855: step 4516, loss 0.8985, acc 0.6875\n",
      "2017-04-03T19:32:27.579277: step 4517, loss 0.951766, acc 0.6875\n",
      "2017-04-03T19:32:27.774664: step 4518, loss 0.681901, acc 0.796875\n",
      "2017-04-03T19:32:27.980568: step 4519, loss 0.917347, acc 0.671875\n",
      "2017-04-03T19:32:28.176005: step 4520, loss 0.997588, acc 0.6875\n",
      "2017-04-03T19:32:28.375781: step 4521, loss 1.01282, acc 0.6875\n",
      "2017-04-03T19:32:28.572615: step 4522, loss 0.932856, acc 0.6875\n",
      "2017-04-03T19:32:28.775912: step 4523, loss 0.866158, acc 0.734375\n",
      "2017-04-03T19:32:28.972076: step 4524, loss 0.905916, acc 0.6875\n",
      "2017-04-03T19:32:29.172065: step 4525, loss 0.817498, acc 0.75\n",
      "2017-04-03T19:32:29.372630: step 4526, loss 0.778146, acc 0.8125\n",
      "2017-04-03T19:32:29.573681: step 4527, loss 0.724134, acc 0.796875\n",
      "2017-04-03T19:32:29.776252: step 4528, loss 0.897434, acc 0.75\n",
      "2017-04-03T19:32:29.985352: step 4529, loss 0.873372, acc 0.65625\n",
      "2017-04-03T19:32:30.202374: step 4530, loss 0.764385, acc 0.71875\n",
      "2017-04-03T19:32:30.405634: step 4531, loss 0.811676, acc 0.765625\n",
      "2017-04-03T19:32:30.610052: step 4532, loss 0.858403, acc 0.765625\n",
      "2017-04-03T19:32:30.821924: step 4533, loss 0.718177, acc 0.734375\n",
      "2017-04-03T19:32:31.023151: step 4534, loss 0.861015, acc 0.71875\n",
      "2017-04-03T19:32:31.223791: step 4535, loss 0.727095, acc 0.8125\n",
      "2017-04-03T19:32:31.428516: step 4536, loss 0.871167, acc 0.703125\n",
      "2017-04-03T19:32:31.626463: step 4537, loss 0.730026, acc 0.71875\n",
      "2017-04-03T19:32:31.870274: step 4538, loss 0.865619, acc 0.6875\n",
      "2017-04-03T19:32:32.071164: step 4539, loss 0.691421, acc 0.875\n",
      "2017-04-03T19:32:32.279101: step 4540, loss 0.90946, acc 0.609375\n",
      "2017-04-03T19:32:32.483091: step 4541, loss 0.79807, acc 0.75\n",
      "2017-04-03T19:32:32.693989: step 4542, loss 0.815931, acc 0.765625\n",
      "2017-04-03T19:32:32.904216: step 4543, loss 0.808002, acc 0.8125\n",
      "2017-04-03T19:32:33.112204: step 4544, loss 1.02455, acc 0.671875\n",
      "2017-04-03T19:32:33.317514: step 4545, loss 0.797988, acc 0.734375\n",
      "2017-04-03T19:32:33.529490: step 4546, loss 0.74391, acc 0.75\n",
      "2017-04-03T19:32:33.747529: step 4547, loss 0.869529, acc 0.71875\n",
      "2017-04-03T19:32:33.953003: step 4548, loss 1.14155, acc 0.625\n",
      "2017-04-03T19:32:34.152949: step 4549, loss 0.979049, acc 0.671875\n",
      "2017-04-03T19:32:34.358046: step 4550, loss 0.651024, acc 0.796875\n",
      "2017-04-03T19:32:34.555082: step 4551, loss 0.784308, acc 0.71875\n",
      "2017-04-03T19:32:34.763438: step 4552, loss 0.857966, acc 0.734375\n",
      "2017-04-03T19:32:34.962725: step 4553, loss 0.985014, acc 0.6875\n",
      "2017-04-03T19:32:35.167083: step 4554, loss 0.835279, acc 0.765625\n",
      "2017-04-03T19:32:35.361907: step 4555, loss 0.714722, acc 0.8125\n",
      "2017-04-03T19:32:35.564068: step 4556, loss 0.873654, acc 0.6875\n",
      "2017-04-03T19:32:35.764485: step 4557, loss 0.82292, acc 0.71875\n",
      "2017-04-03T19:32:35.966446: step 4558, loss 0.726156, acc 0.765625\n",
      "2017-04-03T19:32:36.161015: step 4559, loss 0.795519, acc 0.734375\n",
      "2017-04-03T19:32:36.363130: step 4560, loss 0.727624, acc 0.796875\n",
      "2017-04-03T19:32:36.564074: step 4561, loss 0.735617, acc 0.703125\n",
      "2017-04-03T19:32:36.773812: step 4562, loss 0.872277, acc 0.75\n",
      "2017-04-03T19:32:36.977624: step 4563, loss 0.832554, acc 0.703125\n",
      "2017-04-03T19:32:37.224736: step 4564, loss 0.706475, acc 0.71875\n",
      "2017-04-03T19:32:37.427696: step 4565, loss 1.02362, acc 0.65625\n",
      "2017-04-03T19:32:37.631393: step 4566, loss 0.979071, acc 0.65625\n",
      "2017-04-03T19:32:37.836384: step 4567, loss 0.868261, acc 0.703125\n",
      "2017-04-03T19:32:38.043468: step 4568, loss 0.813044, acc 0.703125\n",
      "2017-04-03T19:32:38.250163: step 4569, loss 1.0648, acc 0.65625\n",
      "2017-04-03T19:32:38.465582: step 4570, loss 0.888826, acc 0.6875\n",
      "2017-04-03T19:32:38.674616: step 4571, loss 0.970871, acc 0.6875\n",
      "2017-04-03T19:32:38.917134: step 4572, loss 0.85391, acc 0.71875\n",
      "2017-04-03T19:32:39.129660: step 4573, loss 0.886728, acc 0.703125\n",
      "2017-04-03T19:32:39.334672: step 4574, loss 1.06073, acc 0.578125\n",
      "2017-04-03T19:32:39.540119: step 4575, loss 0.730778, acc 0.71875\n",
      "2017-04-03T19:32:39.748564: step 4576, loss 0.991156, acc 0.59375\n",
      "2017-04-03T19:32:39.953686: step 4577, loss 0.964194, acc 0.65625\n",
      "2017-04-03T19:32:40.154205: step 4578, loss 0.798912, acc 0.75\n",
      "2017-04-03T19:32:40.402843: step 4579, loss 0.993727, acc 0.625\n",
      "2017-04-03T19:32:40.609961: step 4580, loss 0.819487, acc 0.765625\n",
      "2017-04-03T19:32:40.814377: step 4581, loss 0.798162, acc 0.765625\n",
      "2017-04-03T19:32:41.012954: step 4582, loss 0.694803, acc 0.75\n",
      "2017-04-03T19:32:41.220579: step 4583, loss 0.757208, acc 0.75\n",
      "2017-04-03T19:32:41.429054: step 4584, loss 0.788086, acc 0.703125\n",
      "2017-04-03T19:32:41.674378: step 4585, loss 0.87601, acc 0.734375\n",
      "2017-04-03T19:32:41.877752: step 4586, loss 0.823851, acc 0.75\n",
      "2017-04-03T19:32:42.085226: step 4587, loss 0.808257, acc 0.671875\n",
      "2017-04-03T19:32:42.286420: step 4588, loss 0.75456, acc 0.734375\n",
      "2017-04-03T19:32:42.488249: step 4589, loss 0.997684, acc 0.71875\n",
      "2017-04-03T19:32:42.692417: step 4590, loss 0.847929, acc 0.71875\n",
      "2017-04-03T19:32:42.937896: step 4591, loss 0.687357, acc 0.8125\n",
      "2017-04-03T19:32:43.146571: step 4592, loss 1.0095, acc 0.671875\n",
      "2017-04-03T19:32:43.353317: step 4593, loss 0.929875, acc 0.703125\n",
      "2017-04-03T19:32:43.579186: step 4594, loss 0.698361, acc 0.765625\n",
      "2017-04-03T19:32:43.793703: step 4595, loss 0.831855, acc 0.71875\n",
      "2017-04-03T19:32:43.999347: step 4596, loss 0.859016, acc 0.6875\n",
      "2017-04-03T19:32:44.204117: step 4597, loss 0.712105, acc 0.765625\n",
      "2017-04-03T19:32:44.407190: step 4598, loss 0.899323, acc 0.625\n",
      "2017-04-03T19:32:44.612160: step 4599, loss 0.861963, acc 0.703125\n",
      "2017-04-03T19:32:44.862297: step 4600, loss 0.830045, acc 0.71875\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:32:46.916010: step 4600, loss 2.15958, acc 0.33825\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-4600\n",
      "\n",
      "2017-04-03T19:32:47.293841: step 4601, loss 0.936202, acc 0.671875\n",
      "2017-04-03T19:32:47.494871: step 4602, loss 0.812738, acc 0.734375\n",
      "2017-04-03T19:32:47.695676: step 4603, loss 0.842919, acc 0.734375\n",
      "2017-04-03T19:32:47.897937: step 4604, loss 0.788334, acc 0.8125\n",
      "2017-04-03T19:32:48.144736: step 4605, loss 0.514334, acc 0.875\n",
      "2017-04-03T19:32:48.350264: step 4606, loss 1.12094, acc 0.640625\n",
      "2017-04-03T19:32:48.558719: step 4607, loss 0.726428, acc 0.75\n",
      "2017-04-03T19:32:48.763850: step 4608, loss 0.911762, acc 0.65625\n",
      "2017-04-03T19:32:48.964406: step 4609, loss 1.155, acc 0.625\n",
      "2017-04-03T19:32:49.167085: step 4610, loss 1.05841, acc 0.625\n",
      "2017-04-03T19:32:49.373063: step 4611, loss 0.726335, acc 0.796875\n",
      "2017-04-03T19:32:49.576813: step 4612, loss 0.894451, acc 0.765625\n",
      "2017-04-03T19:32:49.819226: step 4613, loss 0.995046, acc 0.703125\n",
      "2017-04-03T19:32:50.027256: step 4614, loss 0.833629, acc 0.703125\n",
      "2017-04-03T19:32:50.230009: step 4615, loss 0.737943, acc 0.75\n",
      "2017-04-03T19:32:50.430721: step 4616, loss 0.833984, acc 0.640625\n",
      "2017-04-03T19:32:50.633584: step 4617, loss 0.999456, acc 0.65625\n",
      "2017-04-03T19:32:50.839430: step 4618, loss 0.735577, acc 0.765625\n",
      "2017-04-03T19:32:51.089375: step 4619, loss 0.920985, acc 0.6875\n",
      "2017-04-03T19:32:51.294574: step 4620, loss 0.936897, acc 0.671875\n",
      "2017-04-03T19:32:51.495382: step 4621, loss 0.727837, acc 0.75\n",
      "2017-04-03T19:32:51.698723: step 4622, loss 1.02166, acc 0.65625\n",
      "2017-04-03T19:32:51.900471: step 4623, loss 0.93434, acc 0.65625\n",
      "2017-04-03T19:32:52.100076: step 4624, loss 0.76418, acc 0.734375\n",
      "2017-04-03T19:32:52.339420: step 4625, loss 0.751022, acc 0.765625\n",
      "2017-04-03T19:32:52.542081: step 4626, loss 0.835578, acc 0.703125\n",
      "2017-04-03T19:32:52.743532: step 4627, loss 1.16046, acc 0.640625\n",
      "2017-04-03T19:32:52.944423: step 4628, loss 0.936999, acc 0.703125\n",
      "2017-04-03T19:32:53.146477: step 4629, loss 0.743429, acc 0.75\n",
      "2017-04-03T19:32:53.353689: step 4630, loss 1.03888, acc 0.59375\n",
      "2017-04-03T19:32:53.559789: step 4631, loss 1.00072, acc 0.65625\n",
      "2017-04-03T19:32:53.775534: step 4632, loss 0.824141, acc 0.734375\n",
      "2017-04-03T19:32:53.993975: step 4633, loss 1.00041, acc 0.65625\n",
      "2017-04-03T19:32:54.194640: step 4634, loss 0.964183, acc 0.640625\n",
      "2017-04-03T19:32:54.398562: step 4635, loss 0.853722, acc 0.71875\n",
      "2017-04-03T19:32:54.595705: step 4636, loss 0.913263, acc 0.703125\n",
      "2017-04-03T19:32:54.797118: step 4637, loss 0.677924, acc 0.765625\n",
      "2017-04-03T19:32:54.997407: step 4638, loss 1.02571, acc 0.6875\n",
      "2017-04-03T19:32:55.200235: step 4639, loss 1.00797, acc 0.6875\n",
      "2017-04-03T19:32:55.394457: step 4640, loss 0.793954, acc 0.6875\n",
      "2017-04-03T19:32:55.596498: step 4641, loss 0.795431, acc 0.75\n",
      "2017-04-03T19:32:55.789501: step 4642, loss 0.899453, acc 0.6875\n",
      "2017-04-03T19:32:55.998250: step 4643, loss 0.633888, acc 0.8125\n",
      "2017-04-03T19:32:56.190457: step 4644, loss 0.807924, acc 0.734375\n",
      "2017-04-03T19:32:56.393952: step 4645, loss 0.896914, acc 0.6875\n",
      "2017-04-03T19:32:56.595323: step 4646, loss 1.11171, acc 0.65625\n",
      "2017-04-03T19:32:56.811310: step 4647, loss 0.838823, acc 0.75\n",
      "2017-04-03T19:32:57.012268: step 4648, loss 1.05753, acc 0.65625\n",
      "2017-04-03T19:32:57.221630: step 4649, loss 0.926056, acc 0.65625\n",
      "2017-04-03T19:32:57.426530: step 4650, loss 0.729413, acc 0.703125\n",
      "2017-04-03T19:32:57.627249: step 4651, loss 1.34688, acc 0.546875\n",
      "2017-04-03T19:32:57.827456: step 4652, loss 0.961536, acc 0.59375\n",
      "2017-04-03T19:32:58.032943: step 4653, loss 0.936301, acc 0.640625\n",
      "2017-04-03T19:32:58.232448: step 4654, loss 0.89272, acc 0.703125\n",
      "2017-04-03T19:32:58.434215: step 4655, loss 0.815508, acc 0.703125\n",
      "2017-04-03T19:32:58.630518: step 4656, loss 0.981991, acc 0.65625\n",
      "2017-04-03T19:32:58.843106: step 4657, loss 0.853493, acc 0.765625\n",
      "2017-04-03T19:32:59.038426: step 4658, loss 0.928819, acc 0.671875\n",
      "2017-04-03T19:32:59.238270: step 4659, loss 0.870533, acc 0.796875\n",
      "2017-04-03T19:32:59.435628: step 4660, loss 1.0601, acc 0.625\n",
      "2017-04-03T19:32:59.680756: step 4661, loss 0.792678, acc 0.75\n",
      "2017-04-03T19:32:59.877959: step 4662, loss 0.826148, acc 0.6875\n",
      "2017-04-03T19:33:00.081381: step 4663, loss 0.918667, acc 0.6875\n",
      "2017-04-03T19:33:00.276352: step 4664, loss 0.949787, acc 0.6875\n",
      "2017-04-03T19:33:00.485789: step 4665, loss 1.07863, acc 0.671875\n",
      "2017-04-03T19:33:00.678582: step 4666, loss 0.694708, acc 0.71875\n",
      "2017-04-03T19:33:00.878645: step 4667, loss 0.784018, acc 0.765625\n",
      "2017-04-03T19:33:01.076553: step 4668, loss 0.785388, acc 0.765625\n",
      "2017-04-03T19:33:01.279151: step 4669, loss 0.801188, acc 0.703125\n",
      "2017-04-03T19:33:01.474382: step 4670, loss 0.98482, acc 0.6875\n",
      "2017-04-03T19:33:01.674894: step 4671, loss 0.9975, acc 0.6875\n",
      "2017-04-03T19:33:01.873426: step 4672, loss 0.930995, acc 0.640625\n",
      "2017-04-03T19:33:02.073413: step 4673, loss 0.929354, acc 0.6875\n",
      "2017-04-03T19:33:02.271473: step 4674, loss 0.809929, acc 0.65625\n",
      "2017-04-03T19:33:02.472091: step 4675, loss 1.03227, acc 0.640625\n",
      "2017-04-03T19:33:02.671163: step 4676, loss 0.853362, acc 0.734375\n",
      "2017-04-03T19:33:02.872108: step 4677, loss 0.968475, acc 0.71875\n",
      "2017-04-03T19:33:03.071444: step 4678, loss 0.784443, acc 0.734375\n",
      "2017-04-03T19:33:03.279053: step 4679, loss 0.920556, acc 0.703125\n",
      "2017-04-03T19:33:03.473262: step 4680, loss 0.803153, acc 0.734375\n",
      "2017-04-03T19:33:03.673076: step 4681, loss 0.899136, acc 0.65625\n",
      "2017-04-03T19:33:03.871753: step 4682, loss 0.963634, acc 0.625\n",
      "2017-04-03T19:33:04.076782: step 4683, loss 0.971186, acc 0.640625\n",
      "2017-04-03T19:33:04.272268: step 4684, loss 0.908029, acc 0.6875\n",
      "2017-04-03T19:33:04.515577: step 4685, loss 0.833589, acc 0.703125\n",
      "2017-04-03T19:33:04.711622: step 4686, loss 0.945053, acc 0.71875\n",
      "2017-04-03T19:33:04.916319: step 4687, loss 0.948412, acc 0.671875\n",
      "2017-04-03T19:33:05.112598: step 4688, loss 0.959252, acc 0.640625\n",
      "2017-04-03T19:33:05.355676: step 4689, loss 0.912339, acc 0.671875\n",
      "2017-04-03T19:33:05.550956: step 4690, loss 0.873929, acc 0.6875\n",
      "2017-04-03T19:33:05.749266: step 4691, loss 0.907272, acc 0.625\n",
      "2017-04-03T19:33:05.944725: step 4692, loss 0.997099, acc 0.703125\n",
      "2017-04-03T19:33:06.148627: step 4693, loss 0.852654, acc 0.65625\n",
      "2017-04-03T19:33:06.349665: step 4694, loss 1.0463, acc 0.59375\n",
      "2017-04-03T19:33:06.553173: step 4695, loss 1.02356, acc 0.65625\n",
      "2017-04-03T19:33:06.755908: step 4696, loss 0.893381, acc 0.6875\n",
      "2017-04-03T19:33:06.958937: step 4697, loss 0.783921, acc 0.71875\n",
      "2017-04-03T19:33:07.204144: step 4698, loss 0.925518, acc 0.6875\n",
      "2017-04-03T19:33:07.402673: step 4699, loss 0.814724, acc 0.78125\n",
      "2017-04-03T19:33:07.630603: step 4700, loss 1.00649, acc 0.671875\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:33:09.587807: step 4700, loss 2.164, acc 0.329\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-4700\n",
      "\n",
      "2017-04-03T19:33:09.913769: step 4701, loss 0.822424, acc 0.71875\n",
      "2017-04-03T19:33:10.117055: step 4702, loss 0.733933, acc 0.75\n",
      "2017-04-03T19:33:10.331536: step 4703, loss 0.942828, acc 0.625\n",
      "2017-04-03T19:33:10.532978: step 4704, loss 0.972747, acc 0.625\n",
      "2017-04-03T19:33:10.738541: step 4705, loss 0.934206, acc 0.6875\n",
      "2017-04-03T19:33:10.939637: step 4706, loss 0.815022, acc 0.703125\n",
      "2017-04-03T19:33:11.139069: step 4707, loss 0.706205, acc 0.734375\n",
      "2017-04-03T19:33:11.343335: step 4708, loss 0.623599, acc 0.828125\n",
      "2017-04-03T19:33:11.544543: step 4709, loss 1.0125, acc 0.640625\n",
      "2017-04-03T19:33:11.748403: step 4710, loss 0.84322, acc 0.703125\n",
      "2017-04-03T19:33:11.945404: step 4711, loss 0.853948, acc 0.765625\n",
      "2017-04-03T19:33:12.147335: step 4712, loss 0.944712, acc 0.703125\n",
      "2017-04-03T19:33:12.345894: step 4713, loss 1.09824, acc 0.59375\n",
      "2017-04-03T19:33:12.544007: step 4714, loss 0.997444, acc 0.640625\n",
      "2017-04-03T19:33:12.743142: step 4715, loss 1.06357, acc 0.5625\n",
      "2017-04-03T19:33:12.944532: step 4716, loss 0.954313, acc 0.71875\n",
      "2017-04-03T19:33:13.140801: step 4717, loss 0.93034, acc 0.6875\n",
      "2017-04-03T19:33:13.345121: step 4718, loss 0.936548, acc 0.625\n",
      "2017-04-03T19:33:13.535661: step 4719, loss 1.05697, acc 0.703125\n",
      "2017-04-03T19:33:13.737109: step 4720, loss 0.995382, acc 0.734375\n",
      "2017-04-03T19:33:13.938025: step 4721, loss 1.03233, acc 0.59375\n",
      "2017-04-03T19:33:14.140076: step 4722, loss 1.15486, acc 0.609375\n",
      "2017-04-03T19:33:14.342236: step 4723, loss 0.707567, acc 0.765625\n",
      "2017-04-03T19:33:14.546840: step 4724, loss 0.637977, acc 0.8125\n",
      "2017-04-03T19:33:14.792561: step 4725, loss 0.757694, acc 0.75\n",
      "2017-04-03T19:33:14.998323: step 4726, loss 0.995241, acc 0.640625\n",
      "2017-04-03T19:33:15.200066: step 4727, loss 1.21197, acc 0.515625\n",
      "2017-04-03T19:33:15.400076: step 4728, loss 0.845818, acc 0.703125\n",
      "2017-04-03T19:33:15.606430: step 4729, loss 0.802057, acc 0.6875\n",
      "2017-04-03T19:33:15.806050: step 4730, loss 0.897566, acc 0.6875\n",
      "2017-04-03T19:33:16.004966: step 4731, loss 0.837535, acc 0.734375\n",
      "2017-04-03T19:33:16.201705: step 4732, loss 0.680779, acc 0.828125\n",
      "2017-04-03T19:33:16.402959: step 4733, loss 0.904339, acc 0.703125\n",
      "2017-04-03T19:33:16.604003: step 4734, loss 0.847778, acc 0.765625\n",
      "2017-04-03T19:33:16.803291: step 4735, loss 0.971975, acc 0.65625\n",
      "2017-04-03T19:33:17.003200: step 4736, loss 0.928043, acc 0.6875\n",
      "2017-04-03T19:33:17.201444: step 4737, loss 0.954679, acc 0.625\n",
      "2017-04-03T19:33:17.402046: step 4738, loss 0.906416, acc 0.671875\n",
      "2017-04-03T19:33:17.596862: step 4739, loss 0.81213, acc 0.703125\n",
      "2017-04-03T19:33:17.804864: step 4740, loss 0.788512, acc 0.734375\n",
      "2017-04-03T19:33:17.993710: step 4741, loss 0.868468, acc 0.703125\n",
      "2017-04-03T19:33:18.198423: step 4742, loss 0.920088, acc 0.640625\n",
      "2017-04-03T19:33:18.388396: step 4743, loss 0.812066, acc 0.6875\n",
      "2017-04-03T19:33:18.600258: step 4744, loss 0.831662, acc 0.71875\n",
      "2017-04-03T19:33:18.795303: step 4745, loss 0.791127, acc 0.703125\n",
      "2017-04-03T19:33:18.995642: step 4746, loss 0.727735, acc 0.734375\n",
      "2017-04-03T19:33:19.189358: step 4747, loss 1.21049, acc 0.59375\n",
      "2017-04-03T19:33:19.391512: step 4748, loss 0.685843, acc 0.78125\n",
      "2017-04-03T19:33:19.587293: step 4749, loss 0.784699, acc 0.734375\n",
      "2017-04-03T19:33:19.789689: step 4750, loss 1.17937, acc 0.59375\n",
      "2017-04-03T19:33:19.984367: step 4751, loss 0.993735, acc 0.6875\n",
      "2017-04-03T19:33:20.181496: step 4752, loss 0.73121, acc 0.8125\n",
      "2017-04-03T19:33:20.375199: step 4753, loss 0.967464, acc 0.625\n",
      "2017-04-03T19:33:20.575676: step 4754, loss 0.963815, acc 0.765625\n",
      "2017-04-03T19:33:20.773045: step 4755, loss 1.00386, acc 0.6875\n",
      "2017-04-03T19:33:20.973987: step 4756, loss 0.802148, acc 0.703125\n",
      "2017-04-03T19:33:21.170682: step 4757, loss 0.970207, acc 0.703125\n",
      "2017-04-03T19:33:21.378776: step 4758, loss 0.839226, acc 0.765625\n",
      "2017-04-03T19:33:21.572383: step 4759, loss 0.973625, acc 0.6875\n",
      "2017-04-03T19:33:21.771456: step 4760, loss 0.994067, acc 0.6875\n",
      "2017-04-03T19:33:21.968001: step 4761, loss 1.00844, acc 0.59375\n",
      "2017-04-03T19:33:22.170014: step 4762, loss 1.08582, acc 0.671875\n",
      "2017-04-03T19:33:22.371630: step 4763, loss 0.595493, acc 0.84375\n",
      "2017-04-03T19:33:22.570623: step 4764, loss 0.793718, acc 0.6875\n",
      "2017-04-03T19:33:22.776298: step 4765, loss 0.710235, acc 0.78125\n",
      "2017-04-03T19:33:22.976112: step 4766, loss 0.863998, acc 0.703125\n",
      "2017-04-03T19:33:23.175862: step 4767, loss 0.744404, acc 0.78125\n",
      "2017-04-03T19:33:23.367231: step 4768, loss 0.849443, acc 0.75\n",
      "2017-04-03T19:33:23.567285: step 4769, loss 0.995849, acc 0.6875\n",
      "2017-04-03T19:33:23.763861: step 4770, loss 0.78864, acc 0.765625\n",
      "2017-04-03T19:33:23.962633: step 4771, loss 0.8706, acc 0.765625\n",
      "2017-04-03T19:33:24.158284: step 4772, loss 1.01532, acc 0.609375\n",
      "2017-04-03T19:33:24.355371: step 4773, loss 0.90479, acc 0.71875\n",
      "2017-04-03T19:33:24.549610: step 4774, loss 1.08726, acc 0.625\n",
      "2017-04-03T19:33:24.750267: step 4775, loss 0.941529, acc 0.6875\n",
      "2017-04-03T19:33:24.948269: step 4776, loss 0.946615, acc 0.65625\n",
      "2017-04-03T19:33:25.149531: step 4777, loss 0.678913, acc 0.765625\n",
      "2017-04-03T19:33:25.345200: step 4778, loss 0.838178, acc 0.703125\n",
      "2017-04-03T19:33:25.546361: step 4779, loss 0.877724, acc 0.703125\n",
      "2017-04-03T19:33:25.733945: step 4780, loss 1.02819, acc 0.703125\n",
      "2017-04-03T19:33:25.934502: step 4781, loss 0.795891, acc 0.765625\n",
      "2017-04-03T19:33:26.134230: step 4782, loss 0.97948, acc 0.6875\n",
      "2017-04-03T19:33:26.331238: step 4783, loss 0.997795, acc 0.6875\n",
      "2017-04-03T19:33:26.525075: step 4784, loss 0.995633, acc 0.65625\n",
      "2017-04-03T19:33:26.769706: step 4785, loss 0.965567, acc 0.65625\n",
      "2017-04-03T19:33:26.966349: step 4786, loss 0.90095, acc 0.671875\n",
      "2017-04-03T19:33:27.168160: step 4787, loss 0.774729, acc 0.734375\n",
      "2017-04-03T19:33:27.364272: step 4788, loss 0.871951, acc 0.71875\n",
      "2017-04-03T19:33:27.565042: step 4789, loss 0.908495, acc 0.703125\n",
      "2017-04-03T19:33:27.760364: step 4790, loss 1.00438, acc 0.703125\n",
      "2017-04-03T19:33:27.959623: step 4791, loss 0.870874, acc 0.734375\n",
      "2017-04-03T19:33:28.150048: step 4792, loss 0.754069, acc 0.765625\n",
      "2017-04-03T19:33:28.347837: step 4793, loss 0.751101, acc 0.765625\n",
      "2017-04-03T19:33:28.546464: step 4794, loss 0.862357, acc 0.671875\n",
      "2017-04-03T19:33:28.751978: step 4795, loss 0.705631, acc 0.8125\n",
      "2017-04-03T19:33:28.947485: step 4796, loss 0.969132, acc 0.625\n",
      "2017-04-03T19:33:29.190724: step 4797, loss 0.895491, acc 0.734375\n",
      "2017-04-03T19:33:29.385459: step 4798, loss 0.957412, acc 0.71875\n",
      "2017-04-03T19:33:29.587290: step 4799, loss 0.84601, acc 0.71875\n",
      "2017-04-03T19:33:29.782593: step 4800, loss 0.966019, acc 0.6875\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:33:31.717695: step 4800, loss 2.20323, acc 0.3315\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-4800\n",
      "\n",
      "2017-04-03T19:33:32.044389: step 4801, loss 0.864824, acc 0.75\n",
      "2017-04-03T19:33:32.245937: step 4802, loss 0.738685, acc 0.671875\n",
      "2017-04-03T19:33:32.446736: step 4803, loss 1.02045, acc 0.671875\n",
      "2017-04-03T19:33:32.648248: step 4804, loss 0.956467, acc 0.703125\n",
      "2017-04-03T19:33:32.850191: step 4805, loss 0.855913, acc 0.703125\n",
      "2017-04-03T19:33:33.048658: step 4806, loss 1.03343, acc 0.65625\n",
      "2017-04-03T19:33:33.252684: step 4807, loss 0.93553, acc 0.65625\n",
      "2017-04-03T19:33:33.458068: step 4808, loss 1.13612, acc 0.59375\n",
      "2017-04-03T19:33:33.701295: step 4809, loss 0.962698, acc 0.703125\n",
      "2017-04-03T19:33:33.903650: step 4810, loss 0.993127, acc 0.625\n",
      "2017-04-03T19:33:34.106160: step 4811, loss 0.824333, acc 0.65625\n",
      "2017-04-03T19:33:34.359136: step 4812, loss 0.795045, acc 0.6875\n",
      "2017-04-03T19:33:34.565126: step 4813, loss 0.931818, acc 0.703125\n",
      "2017-04-03T19:33:34.765777: step 4814, loss 0.965255, acc 0.65625\n",
      "2017-04-03T19:33:34.967573: step 4815, loss 1.03542, acc 0.65625\n",
      "2017-04-03T19:33:35.171612: step 4816, loss 0.865266, acc 0.6875\n",
      "2017-04-03T19:33:35.380069: step 4817, loss 1.01209, acc 0.671875\n",
      "2017-04-03T19:33:35.620229: step 4818, loss 0.922469, acc 0.703125\n",
      "2017-04-03T19:33:35.822031: step 4819, loss 0.890295, acc 0.6875\n",
      "2017-04-03T19:33:36.061721: step 4820, loss 1.04903, acc 0.671875\n",
      "2017-04-03T19:33:36.261023: step 4821, loss 0.791016, acc 0.765625\n",
      "2017-04-03T19:33:36.465718: step 4822, loss 0.937561, acc 0.609375\n",
      "2017-04-03T19:33:36.662856: step 4823, loss 1.14924, acc 0.625\n",
      "2017-04-03T19:33:36.863449: step 4824, loss 0.814065, acc 0.71875\n",
      "2017-04-03T19:33:37.062978: step 4825, loss 0.811629, acc 0.75\n",
      "2017-04-03T19:33:37.306139: step 4826, loss 0.765146, acc 0.75\n",
      "2017-04-03T19:33:37.504294: step 4827, loss 0.996673, acc 0.671875\n",
      "2017-04-03T19:33:37.698386: step 4828, loss 0.922731, acc 0.65625\n",
      "2017-04-03T19:33:37.896937: step 4829, loss 0.657129, acc 0.78125\n",
      "2017-04-03T19:33:38.136574: step 4830, loss 0.934858, acc 0.65625\n",
      "2017-04-03T19:33:38.330549: step 4831, loss 0.901816, acc 0.671875\n",
      "2017-04-03T19:33:38.530483: step 4832, loss 0.823345, acc 0.8125\n",
      "2017-04-03T19:33:38.726931: step 4833, loss 0.973832, acc 0.6875\n",
      "2017-04-03T19:33:38.930628: step 4834, loss 0.719308, acc 0.75\n",
      "2017-04-03T19:33:39.123931: step 4835, loss 0.968175, acc 0.6875\n",
      "2017-04-03T19:33:39.322716: step 4836, loss 1.0082, acc 0.640625\n",
      "2017-04-03T19:33:39.515489: step 4837, loss 0.789504, acc 0.734375\n",
      "2017-04-03T19:33:39.720080: step 4838, loss 0.745898, acc 0.765625\n",
      "2017-04-03T19:33:39.914293: step 4839, loss 1.00418, acc 0.640625\n",
      "2017-04-03T19:33:40.115104: step 4840, loss 0.744277, acc 0.734375\n",
      "2017-04-03T19:33:40.309720: step 4841, loss 0.839647, acc 0.75\n",
      "2017-04-03T19:33:40.514492: step 4842, loss 1.12262, acc 0.625\n",
      "2017-04-03T19:33:40.709760: step 4843, loss 0.753296, acc 0.75\n",
      "2017-04-03T19:33:40.911319: step 4844, loss 1.09929, acc 0.640625\n",
      "2017-04-03T19:33:41.103817: step 4845, loss 0.941306, acc 0.6875\n",
      "2017-04-03T19:33:41.302215: step 4846, loss 0.940664, acc 0.734375\n",
      "2017-04-03T19:33:41.500428: step 4847, loss 0.952115, acc 0.59375\n",
      "2017-04-03T19:33:41.699772: step 4848, loss 0.775488, acc 0.765625\n",
      "2017-04-03T19:33:41.895848: step 4849, loss 0.813317, acc 0.734375\n",
      "2017-04-03T19:33:42.141052: step 4850, loss 1.05771, acc 0.640625\n",
      "2017-04-03T19:33:42.342977: step 4851, loss 0.730351, acc 0.796875\n",
      "2017-04-03T19:33:42.544002: step 4852, loss 0.774727, acc 0.765625\n",
      "2017-04-03T19:33:42.749808: step 4853, loss 0.813728, acc 0.796875\n",
      "2017-04-03T19:33:43.004553: step 4854, loss 0.860959, acc 0.71875\n",
      "2017-04-03T19:33:43.209014: step 4855, loss 0.910649, acc 0.6875\n",
      "2017-04-03T19:33:43.411049: step 4856, loss 0.923785, acc 0.71875\n",
      "2017-04-03T19:33:43.617003: step 4857, loss 0.797618, acc 0.6875\n",
      "2017-04-03T19:33:43.818883: step 4858, loss 0.846091, acc 0.703125\n",
      "2017-04-03T19:33:44.026688: step 4859, loss 0.957038, acc 0.671875\n",
      "2017-04-03T19:33:44.242210: step 4860, loss 0.741479, acc 0.75\n",
      "2017-04-03T19:33:44.464490: step 4861, loss 1.00526, acc 0.6875\n",
      "2017-04-03T19:33:44.681422: step 4862, loss 1.04796, acc 0.609375\n",
      "2017-04-03T19:33:44.880384: step 4863, loss 1.06745, acc 0.6875\n",
      "2017-04-03T19:33:45.084187: step 4864, loss 0.887115, acc 0.703125\n",
      "2017-04-03T19:33:45.280479: step 4865, loss 0.915403, acc 0.6875\n",
      "2017-04-03T19:33:45.482117: step 4866, loss 0.824887, acc 0.6875\n",
      "2017-04-03T19:33:45.680872: step 4867, loss 0.786299, acc 0.75\n",
      "2017-04-03T19:33:45.925967: step 4868, loss 1.03424, acc 0.671875\n",
      "2017-04-03T19:33:46.121730: step 4869, loss 0.897847, acc 0.703125\n",
      "2017-04-03T19:33:46.323032: step 4870, loss 0.778954, acc 0.75\n",
      "2017-04-03T19:33:46.515232: step 4871, loss 0.777983, acc 0.75\n",
      "2017-04-03T19:33:46.715859: step 4872, loss 0.780662, acc 0.765625\n",
      "2017-04-03T19:33:46.915108: step 4873, loss 0.799811, acc 0.78125\n",
      "2017-04-03T19:33:47.119780: step 4874, loss 0.85975, acc 0.6875\n",
      "2017-04-03T19:33:47.312683: step 4875, loss 0.937555, acc 0.640625\n",
      "2017-04-03T19:33:47.509124: step 4876, loss 0.898647, acc 0.703125\n",
      "2017-04-03T19:33:47.707655: step 4877, loss 0.709936, acc 0.71875\n",
      "2017-04-03T19:33:47.909887: step 4878, loss 1.18763, acc 0.5625\n",
      "2017-04-03T19:33:48.103362: step 4879, loss 0.857826, acc 0.671875\n",
      "2017-04-03T19:33:48.305123: step 4880, loss 0.976952, acc 0.65625\n",
      "2017-04-03T19:33:48.500062: step 4881, loss 1.16038, acc 0.578125\n",
      "2017-04-03T19:33:48.700348: step 4882, loss 0.85284, acc 0.75\n",
      "2017-04-03T19:33:48.898550: step 4883, loss 1.23291, acc 0.5625\n",
      "2017-04-03T19:33:49.104289: step 4884, loss 0.882763, acc 0.703125\n",
      "2017-04-03T19:33:49.301881: step 4885, loss 1.03828, acc 0.75\n",
      "2017-04-03T19:33:49.502793: step 4886, loss 0.741311, acc 0.734375\n",
      "2017-04-03T19:33:49.697371: step 4887, loss 0.914451, acc 0.6875\n",
      "2017-04-03T19:33:49.898564: step 4888, loss 1.01791, acc 0.640625\n",
      "2017-04-03T19:33:50.095810: step 4889, loss 0.842356, acc 0.703125\n",
      "2017-04-03T19:33:50.295199: step 4890, loss 1.04441, acc 0.578125\n",
      "2017-04-03T19:33:50.494775: step 4891, loss 0.813313, acc 0.71875\n",
      "2017-04-03T19:33:50.696226: step 4892, loss 0.896108, acc 0.625\n",
      "2017-04-03T19:33:50.894666: step 4893, loss 0.732842, acc 0.75\n",
      "2017-04-03T19:33:51.099480: step 4894, loss 0.875164, acc 0.734375\n",
      "2017-04-03T19:33:51.297606: step 4895, loss 0.879337, acc 0.71875\n",
      "2017-04-03T19:33:51.537291: step 4896, loss 1.06528, acc 0.625\n",
      "2017-04-03T19:33:51.737780: step 4897, loss 0.888805, acc 0.75\n",
      "2017-04-03T19:33:51.940886: step 4898, loss 0.918802, acc 0.65625\n",
      "2017-04-03T19:33:52.132806: step 4899, loss 0.944396, acc 0.625\n",
      "2017-04-03T19:33:52.332545: step 4900, loss 0.752196, acc 0.78125\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:33:54.280259: step 4900, loss 2.22967, acc 0.32775\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-4900\n",
      "\n",
      "2017-04-03T19:33:54.617849: step 4901, loss 1.10562, acc 0.640625\n",
      "2017-04-03T19:33:54.819630: step 4902, loss 0.956362, acc 0.703125\n",
      "2017-04-03T19:33:55.016784: step 4903, loss 0.853824, acc 0.640625\n",
      "2017-04-03T19:33:55.262805: step 4904, loss 0.98772, acc 0.671875\n",
      "2017-04-03T19:33:55.463748: step 4905, loss 1.0487, acc 0.65625\n",
      "2017-04-03T19:33:55.667666: step 4906, loss 0.783247, acc 0.78125\n",
      "2017-04-03T19:33:55.867412: step 4907, loss 0.974849, acc 0.6875\n",
      "2017-04-03T19:33:56.110909: step 4908, loss 1.03715, acc 0.59375\n",
      "2017-04-03T19:33:56.321583: step 4909, loss 0.89969, acc 0.65625\n",
      "2017-04-03T19:33:56.535411: step 4910, loss 0.999636, acc 0.625\n",
      "2017-04-03T19:33:56.737856: step 4911, loss 1.11712, acc 0.5625\n",
      "2017-04-03T19:33:56.939622: step 4912, loss 0.778382, acc 0.8125\n",
      "2017-04-03T19:33:57.143708: step 4913, loss 1.22764, acc 0.53125\n",
      "2017-04-03T19:33:57.343482: step 4914, loss 0.897081, acc 0.75\n",
      "2017-04-03T19:33:57.593247: step 4915, loss 0.928065, acc 0.71875\n",
      "2017-04-03T19:33:57.795913: step 4916, loss 0.814092, acc 0.703125\n",
      "2017-04-03T19:33:58.000356: step 4917, loss 0.797671, acc 0.71875\n",
      "2017-04-03T19:33:58.199310: step 4918, loss 0.847463, acc 0.734375\n",
      "2017-04-03T19:33:58.399695: step 4919, loss 0.92196, acc 0.734375\n",
      "2017-04-03T19:33:58.602397: step 4920, loss 0.846382, acc 0.640625\n",
      "2017-04-03T19:33:58.805273: step 4921, loss 1.13487, acc 0.609375\n",
      "2017-04-03T19:33:59.007067: step 4922, loss 0.943407, acc 0.671875\n",
      "2017-04-03T19:33:59.215164: step 4923, loss 1.10375, acc 0.625\n",
      "2017-04-03T19:33:59.430132: step 4924, loss 0.883024, acc 0.59375\n",
      "2017-04-03T19:33:59.635716: step 4925, loss 0.682858, acc 0.828125\n",
      "2017-04-03T19:33:59.836912: step 4926, loss 0.822049, acc 0.765625\n",
      "2017-04-03T19:34:00.037419: step 4927, loss 1.05693, acc 0.625\n",
      "2017-04-03T19:34:00.243809: step 4928, loss 1.02166, acc 0.640625\n",
      "2017-04-03T19:34:00.444971: step 4929, loss 1.11549, acc 0.578125\n",
      "2017-04-03T19:34:00.646181: step 4930, loss 0.961851, acc 0.671875\n",
      "2017-04-03T19:34:00.850843: step 4931, loss 1.04203, acc 0.625\n",
      "2017-04-03T19:34:01.055949: step 4932, loss 0.739079, acc 0.75\n",
      "2017-04-03T19:34:01.263370: step 4933, loss 0.994286, acc 0.625\n",
      "2017-04-03T19:34:01.469271: step 4934, loss 0.945365, acc 0.640625\n",
      "2017-04-03T19:34:01.668661: step 4935, loss 0.849229, acc 0.671875\n",
      "2017-04-03T19:34:01.873917: step 4936, loss 0.828594, acc 0.703125\n",
      "2017-04-03T19:34:02.076461: step 4937, loss 0.685046, acc 0.796875\n",
      "2017-04-03T19:34:02.289115: step 4938, loss 1.06464, acc 0.625\n",
      "2017-04-03T19:34:02.500429: step 4939, loss 0.839523, acc 0.703125\n",
      "2017-04-03T19:34:02.704438: step 4940, loss 1.01268, acc 0.6875\n",
      "2017-04-03T19:34:02.906409: step 4941, loss 1.04189, acc 0.609375\n",
      "2017-04-03T19:34:03.110343: step 4942, loss 1.00828, acc 0.640625\n",
      "2017-04-03T19:34:03.311530: step 4943, loss 0.888573, acc 0.671875\n",
      "2017-04-03T19:34:03.512364: step 4944, loss 0.608864, acc 0.78125\n",
      "2017-04-03T19:34:03.712960: step 4945, loss 0.664996, acc 0.75\n",
      "2017-04-03T19:34:03.916641: step 4946, loss 0.730771, acc 0.78125\n",
      "2017-04-03T19:34:04.117753: step 4947, loss 0.921024, acc 0.703125\n",
      "2017-04-03T19:34:04.321823: step 4948, loss 1.43122, acc 0.53125\n",
      "2017-04-03T19:34:04.532986: step 4949, loss 0.845928, acc 0.671875\n",
      "2017-04-03T19:34:04.751822: step 4950, loss 0.651146, acc 0.734375\n",
      "2017-04-03T19:34:04.962453: step 4951, loss 0.953273, acc 0.671875\n",
      "2017-04-03T19:34:05.166958: step 4952, loss 0.934833, acc 0.6875\n",
      "2017-04-03T19:34:05.369417: step 4953, loss 1.02241, acc 0.609375\n",
      "2017-04-03T19:34:05.575926: step 4954, loss 0.823364, acc 0.734375\n",
      "2017-04-03T19:34:05.778620: step 4955, loss 1.15787, acc 0.640625\n",
      "2017-04-03T19:34:05.987754: step 4956, loss 1.041, acc 0.640625\n",
      "2017-04-03T19:34:06.189710: step 4957, loss 0.689013, acc 0.796875\n",
      "2017-04-03T19:34:06.441022: step 4958, loss 0.934609, acc 0.734375\n",
      "2017-04-03T19:34:06.642846: step 4959, loss 0.830802, acc 0.703125\n",
      "2017-04-03T19:34:06.846678: step 4960, loss 0.921208, acc 0.671875\n",
      "2017-04-03T19:34:07.047547: step 4961, loss 0.77291, acc 0.6875\n",
      "2017-04-03T19:34:07.248926: step 4962, loss 0.902586, acc 0.6875\n",
      "2017-04-03T19:34:07.452731: step 4963, loss 1.01633, acc 0.78125\n",
      "2017-04-03T19:34:07.655411: step 4964, loss 0.881188, acc 0.671875\n",
      "2017-04-03T19:34:07.854009: step 4965, loss 0.586116, acc 0.84375\n",
      "2017-04-03T19:34:08.060883: step 4966, loss 0.990429, acc 0.5625\n",
      "2017-04-03T19:34:08.260322: step 4967, loss 0.731284, acc 0.75\n",
      "2017-04-03T19:34:08.464966: step 4968, loss 1.01374, acc 0.609375\n",
      "2017-04-03T19:34:08.666804: step 4969, loss 1.08941, acc 0.578125\n",
      "2017-04-03T19:34:08.867825: step 4970, loss 1.10957, acc 0.609375\n",
      "2017-04-03T19:34:09.111712: step 4971, loss 0.900373, acc 0.671875\n",
      "2017-04-03T19:34:09.312810: step 4972, loss 0.826363, acc 0.671875\n",
      "2017-04-03T19:34:09.516670: step 4973, loss 0.801452, acc 0.71875\n",
      "2017-04-03T19:34:09.723227: step 4974, loss 0.956954, acc 0.734375\n",
      "2017-04-03T19:34:09.967511: step 4975, loss 1.08336, acc 0.625\n",
      "2017-04-03T19:34:10.175741: step 4976, loss 0.745975, acc 0.734375\n",
      "2017-04-03T19:34:10.417129: step 4977, loss 1.24236, acc 0.5625\n",
      "2017-04-03T19:34:10.620546: step 4978, loss 1.18177, acc 0.609375\n",
      "2017-04-03T19:34:10.836126: step 4979, loss 1.05864, acc 0.59375\n",
      "2017-04-03T19:34:11.042836: step 4980, loss 0.873594, acc 0.671875\n",
      "2017-04-03T19:34:11.246425: step 4981, loss 1.08188, acc 0.609375\n",
      "2017-04-03T19:34:11.489849: step 4982, loss 1.22341, acc 0.5625\n",
      "2017-04-03T19:34:11.692215: step 4983, loss 1.26713, acc 0.59375\n",
      "2017-04-03T19:34:11.944312: step 4984, loss 1.07345, acc 0.609375\n",
      "2017-04-03T19:34:12.149594: step 4985, loss 0.835407, acc 0.734375\n",
      "2017-04-03T19:34:12.351728: step 4986, loss 1.02315, acc 0.65625\n",
      "2017-04-03T19:34:12.598629: step 4987, loss 0.927081, acc 0.6875\n",
      "2017-04-03T19:34:12.808615: step 4988, loss 0.868907, acc 0.6875\n",
      "2017-04-03T19:34:13.015636: step 4989, loss 1.20853, acc 0.640625\n",
      "2017-04-03T19:34:13.266031: step 4990, loss 0.849322, acc 0.71875\n",
      "2017-04-03T19:34:13.471096: step 4991, loss 0.988054, acc 0.71875\n",
      "2017-04-03T19:34:13.673260: step 4992, loss 1.21038, acc 0.578125\n",
      "2017-04-03T19:34:13.874950: step 4993, loss 0.940263, acc 0.671875\n",
      "2017-04-03T19:34:14.083763: step 4994, loss 0.739835, acc 0.828125\n",
      "2017-04-03T19:34:14.283808: step 4995, loss 0.922964, acc 0.671875\n",
      "2017-04-03T19:34:14.486104: step 4996, loss 0.890131, acc 0.625\n",
      "2017-04-03T19:34:14.688602: step 4997, loss 1.06689, acc 0.625\n",
      "2017-04-03T19:34:14.893880: step 4998, loss 1.1571, acc 0.625\n",
      "2017-04-03T19:34:15.098764: step 4999, loss 0.873992, acc 0.65625\n",
      "2017-04-03T19:34:15.303412: step 5000, loss 0.82483, acc 0.703125\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:34:17.313470: step 5000, loss 2.25404, acc 0.32825\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-5000\n",
      "\n",
      "2017-04-03T19:34:17.653797: step 5001, loss 0.90207, acc 0.703125\n",
      "2017-04-03T19:34:17.860336: step 5002, loss 1.07606, acc 0.578125\n",
      "2017-04-03T19:34:18.059134: step 5003, loss 1.04023, acc 0.59375\n",
      "2017-04-03T19:34:18.264423: step 5004, loss 0.763359, acc 0.75\n",
      "2017-04-03T19:34:18.461999: step 5005, loss 0.974393, acc 0.6875\n",
      "2017-04-03T19:34:18.665430: step 5006, loss 0.794995, acc 0.75\n",
      "2017-04-03T19:34:18.867436: step 5007, loss 0.910118, acc 0.671875\n",
      "2017-04-03T19:34:19.075212: step 5008, loss 1.02381, acc 0.671875\n",
      "2017-04-03T19:34:19.276860: step 5009, loss 0.99729, acc 0.703125\n",
      "2017-04-03T19:34:19.483730: step 5010, loss 0.993014, acc 0.703125\n",
      "2017-04-03T19:34:19.683250: step 5011, loss 0.867649, acc 0.625\n",
      "2017-04-03T19:34:19.881609: step 5012, loss 1.03535, acc 0.609375\n",
      "2017-04-03T19:34:20.091446: step 5013, loss 1.07947, acc 0.671875\n",
      "2017-04-03T19:34:20.293376: step 5014, loss 0.855539, acc 0.65625\n",
      "2017-04-03T19:34:20.493588: step 5015, loss 0.941857, acc 0.65625\n",
      "2017-04-03T19:34:20.698014: step 5016, loss 0.911479, acc 0.6875\n",
      "2017-04-03T19:34:20.903186: step 5017, loss 0.892545, acc 0.671875\n",
      "2017-04-03T19:34:21.105371: step 5018, loss 0.861338, acc 0.6875\n",
      "2017-04-03T19:34:21.307987: step 5019, loss 0.823527, acc 0.6875\n",
      "2017-04-03T19:34:21.511328: step 5020, loss 1.04945, acc 0.5625\n",
      "2017-04-03T19:34:21.715483: step 5021, loss 0.668581, acc 0.75\n",
      "2017-04-03T19:34:21.955276: step 5022, loss 0.986304, acc 0.671875\n",
      "2017-04-03T19:34:22.163052: step 5023, loss 1.14216, acc 0.578125\n",
      "2017-04-03T19:34:22.367151: step 5024, loss 0.889708, acc 0.6875\n",
      "2017-04-03T19:34:22.574053: step 5025, loss 1.22724, acc 0.609375\n",
      "2017-04-03T19:34:22.777639: step 5026, loss 0.935112, acc 0.6875\n",
      "2017-04-03T19:34:22.983423: step 5027, loss 0.968642, acc 0.65625\n",
      "2017-04-03T19:34:23.229012: step 5028, loss 0.938922, acc 0.640625\n",
      "2017-04-03T19:34:23.440727: step 5029, loss 0.817743, acc 0.71875\n",
      "2017-04-03T19:34:23.699267: step 5030, loss 0.951798, acc 0.703125\n",
      "2017-04-03T19:34:23.907116: step 5031, loss 0.837427, acc 0.734375\n",
      "2017-04-03T19:34:24.109246: step 5032, loss 1.05473, acc 0.640625\n",
      "2017-04-03T19:34:24.313515: step 5033, loss 0.995819, acc 0.671875\n",
      "2017-04-03T19:34:24.558075: step 5034, loss 0.788396, acc 0.71875\n",
      "2017-04-03T19:34:24.767994: step 5035, loss 0.787311, acc 0.734375\n",
      "2017-04-03T19:34:24.973536: step 5036, loss 0.989775, acc 0.625\n",
      "2017-04-03T19:34:25.174214: step 5037, loss 0.741978, acc 0.765625\n",
      "2017-04-03T19:34:25.377507: step 5038, loss 0.943258, acc 0.609375\n",
      "2017-04-03T19:34:25.604573: step 5039, loss 0.973522, acc 0.671875\n",
      "2017-04-03T19:34:25.809644: step 5040, loss 0.98619, acc 0.609375\n",
      "2017-04-03T19:34:26.019185: step 5041, loss 0.956197, acc 0.6875\n",
      "2017-04-03T19:34:26.234808: step 5042, loss 1.01281, acc 0.640625\n",
      "2017-04-03T19:34:26.451918: step 5043, loss 0.677931, acc 0.8125\n",
      "2017-04-03T19:34:26.660288: step 5044, loss 0.910993, acc 0.703125\n",
      "2017-04-03T19:34:26.907608: step 5045, loss 0.788485, acc 0.734375\n",
      "2017-04-03T19:34:27.113068: step 5046, loss 1.07291, acc 0.640625\n",
      "2017-04-03T19:34:27.354367: step 5047, loss 0.927856, acc 0.703125\n",
      "2017-04-03T19:34:27.598419: step 5048, loss 0.939623, acc 0.703125\n",
      "2017-04-03T19:34:27.800780: step 5049, loss 1.05917, acc 0.59375\n",
      "2017-04-03T19:34:28.000205: step 5050, loss 0.929782, acc 0.6875\n",
      "2017-04-03T19:34:28.202478: step 5051, loss 0.908775, acc 0.65625\n",
      "2017-04-03T19:34:28.403860: step 5052, loss 0.979644, acc 0.703125\n",
      "2017-04-03T19:34:28.609565: step 5053, loss 0.917979, acc 0.703125\n",
      "2017-04-03T19:34:28.816651: step 5054, loss 0.854228, acc 0.671875\n",
      "2017-04-03T19:34:29.023034: step 5055, loss 0.921921, acc 0.6875\n",
      "2017-04-03T19:34:29.226330: step 5056, loss 0.849266, acc 0.6875\n",
      "2017-04-03T19:34:29.427567: step 5057, loss 1.21902, acc 0.59375\n",
      "2017-04-03T19:34:29.631794: step 5058, loss 0.962245, acc 0.640625\n",
      "2017-04-03T19:34:29.835139: step 5059, loss 1.01462, acc 0.640625\n",
      "2017-04-03T19:34:30.041162: step 5060, loss 0.997514, acc 0.609375\n",
      "2017-04-03T19:34:30.248910: step 5061, loss 1.04865, acc 0.59375\n",
      "2017-04-03T19:34:30.452350: step 5062, loss 1.0779, acc 0.59375\n",
      "2017-04-03T19:34:30.660200: step 5063, loss 0.831419, acc 0.734375\n",
      "2017-04-03T19:34:30.878662: step 5064, loss 0.81413, acc 0.6875\n",
      "2017-04-03T19:34:31.097487: step 5065, loss 1.10911, acc 0.5625\n",
      "2017-04-03T19:34:31.299735: step 5066, loss 0.956893, acc 0.640625\n",
      "2017-04-03T19:34:31.449308: step 5067, loss 1.07584, acc 0.65625\n",
      "2017-04-03T19:34:31.657945: step 5068, loss 0.809302, acc 0.671875\n",
      "2017-04-03T19:34:31.865330: step 5069, loss 0.538371, acc 0.875\n",
      "2017-04-03T19:34:32.071421: step 5070, loss 0.715806, acc 0.71875\n",
      "2017-04-03T19:34:32.271571: step 5071, loss 0.896261, acc 0.671875\n",
      "2017-04-03T19:34:32.514013: step 5072, loss 0.805859, acc 0.734375\n",
      "2017-04-03T19:34:32.753388: step 5073, loss 0.728438, acc 0.703125\n",
      "2017-04-03T19:34:32.966215: step 5074, loss 0.628143, acc 0.78125\n",
      "2017-04-03T19:34:33.170273: step 5075, loss 0.589638, acc 0.8125\n",
      "2017-04-03T19:34:33.375242: step 5076, loss 0.823445, acc 0.765625\n",
      "2017-04-03T19:34:33.578885: step 5077, loss 0.686428, acc 0.796875\n",
      "2017-04-03T19:34:33.787173: step 5078, loss 0.834426, acc 0.8125\n",
      "2017-04-03T19:34:34.035159: step 5079, loss 0.659229, acc 0.84375\n",
      "2017-04-03T19:34:34.244084: step 5080, loss 0.823336, acc 0.71875\n",
      "2017-04-03T19:34:34.446173: step 5081, loss 0.637797, acc 0.765625\n",
      "2017-04-03T19:34:34.643249: step 5082, loss 0.685211, acc 0.8125\n",
      "2017-04-03T19:34:34.845885: step 5083, loss 0.721935, acc 0.75\n",
      "2017-04-03T19:34:35.047640: step 5084, loss 0.686497, acc 0.78125\n",
      "2017-04-03T19:34:35.249876: step 5085, loss 0.735903, acc 0.765625\n",
      "2017-04-03T19:34:35.489243: step 5086, loss 0.793174, acc 0.734375\n",
      "2017-04-03T19:34:35.692400: step 5087, loss 0.589746, acc 0.8125\n",
      "2017-04-03T19:34:35.902643: step 5088, loss 0.651283, acc 0.8125\n",
      "2017-04-03T19:34:36.109940: step 5089, loss 0.689054, acc 0.796875\n",
      "2017-04-03T19:34:36.315361: step 5090, loss 0.70555, acc 0.828125\n",
      "2017-04-03T19:34:36.519149: step 5091, loss 0.866422, acc 0.75\n",
      "2017-04-03T19:34:36.721747: step 5092, loss 0.606403, acc 0.828125\n",
      "2017-04-03T19:34:36.929059: step 5093, loss 0.530963, acc 0.796875\n",
      "2017-04-03T19:34:37.130041: step 5094, loss 0.763626, acc 0.734375\n",
      "2017-04-03T19:34:37.381882: step 5095, loss 0.826084, acc 0.6875\n",
      "2017-04-03T19:34:37.591543: step 5096, loss 0.499766, acc 0.859375\n",
      "2017-04-03T19:34:37.794706: step 5097, loss 0.606495, acc 0.78125\n",
      "2017-04-03T19:34:37.996454: step 5098, loss 0.760679, acc 0.71875\n",
      "2017-04-03T19:34:38.205509: step 5099, loss 0.735091, acc 0.71875\n",
      "2017-04-03T19:34:38.453673: step 5100, loss 0.505296, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:34:40.472231: step 5100, loss 2.2842, acc 0.3265\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-5100\n",
      "\n",
      "2017-04-03T19:34:40.801036: step 5101, loss 0.746246, acc 0.75\n",
      "2017-04-03T19:34:41.016606: step 5102, loss 0.801114, acc 0.734375\n",
      "2017-04-03T19:34:41.221603: step 5103, loss 0.779218, acc 0.78125\n",
      "2017-04-03T19:34:41.427973: step 5104, loss 0.691892, acc 0.78125\n",
      "2017-04-03T19:34:41.636693: step 5105, loss 0.769428, acc 0.75\n",
      "2017-04-03T19:34:41.843959: step 5106, loss 0.625613, acc 0.765625\n",
      "2017-04-03T19:34:42.050453: step 5107, loss 0.855995, acc 0.734375\n",
      "2017-04-03T19:34:42.257717: step 5108, loss 0.744845, acc 0.75\n",
      "2017-04-03T19:34:42.460795: step 5109, loss 0.812652, acc 0.765625\n",
      "2017-04-03T19:34:42.666858: step 5110, loss 0.680287, acc 0.8125\n",
      "2017-04-03T19:34:42.913840: step 5111, loss 0.887434, acc 0.6875\n",
      "2017-04-03T19:34:43.121751: step 5112, loss 0.890886, acc 0.734375\n",
      "2017-04-03T19:34:43.329999: step 5113, loss 0.614799, acc 0.828125\n",
      "2017-04-03T19:34:43.535229: step 5114, loss 0.776158, acc 0.75\n",
      "2017-04-03T19:34:43.738431: step 5115, loss 0.550427, acc 0.859375\n",
      "2017-04-03T19:34:43.940704: step 5116, loss 0.836518, acc 0.75\n",
      "2017-04-03T19:34:44.165719: step 5117, loss 0.613625, acc 0.78125\n",
      "2017-04-03T19:34:44.383156: step 5118, loss 0.797545, acc 0.765625\n",
      "2017-04-03T19:34:44.594775: step 5119, loss 0.902444, acc 0.625\n",
      "2017-04-03T19:34:44.845314: step 5120, loss 0.683972, acc 0.796875\n",
      "2017-04-03T19:34:45.047663: step 5121, loss 0.829571, acc 0.671875\n",
      "2017-04-03T19:34:45.250496: step 5122, loss 0.595704, acc 0.828125\n",
      "2017-04-03T19:34:45.452540: step 5123, loss 0.726919, acc 0.734375\n",
      "2017-04-03T19:34:45.653908: step 5124, loss 0.702193, acc 0.796875\n",
      "2017-04-03T19:34:45.854600: step 5125, loss 0.748885, acc 0.765625\n",
      "2017-04-03T19:34:46.058401: step 5126, loss 0.754634, acc 0.75\n",
      "2017-04-03T19:34:46.304552: step 5127, loss 0.606543, acc 0.828125\n",
      "2017-04-03T19:34:46.558023: step 5128, loss 0.765169, acc 0.78125\n",
      "2017-04-03T19:34:46.768718: step 5129, loss 0.692813, acc 0.765625\n",
      "2017-04-03T19:34:46.968261: step 5130, loss 0.663867, acc 0.859375\n",
      "2017-04-03T19:34:47.171626: step 5131, loss 0.589915, acc 0.828125\n",
      "2017-04-03T19:34:47.376810: step 5132, loss 0.688831, acc 0.765625\n",
      "2017-04-03T19:34:47.626231: step 5133, loss 0.775562, acc 0.75\n",
      "2017-04-03T19:34:47.870985: step 5134, loss 0.680425, acc 0.765625\n",
      "2017-04-03T19:34:48.079906: step 5135, loss 0.792139, acc 0.75\n",
      "2017-04-03T19:34:48.291090: step 5136, loss 0.541669, acc 0.90625\n",
      "2017-04-03T19:34:48.542709: step 5137, loss 0.775116, acc 0.6875\n",
      "2017-04-03T19:34:48.744719: step 5138, loss 0.643292, acc 0.796875\n",
      "2017-04-03T19:34:48.946347: step 5139, loss 0.810301, acc 0.703125\n",
      "2017-04-03T19:34:49.151112: step 5140, loss 0.637901, acc 0.78125\n",
      "2017-04-03T19:34:49.357109: step 5141, loss 0.542644, acc 0.875\n",
      "2017-04-03T19:34:49.562240: step 5142, loss 0.575918, acc 0.828125\n",
      "2017-04-03T19:34:49.813581: step 5143, loss 0.67841, acc 0.765625\n",
      "2017-04-03T19:34:50.022173: step 5144, loss 0.798899, acc 0.65625\n",
      "2017-04-03T19:34:50.223893: step 5145, loss 0.577507, acc 0.796875\n",
      "2017-04-03T19:34:50.434964: step 5146, loss 0.569754, acc 0.78125\n",
      "2017-04-03T19:34:50.642462: step 5147, loss 0.806913, acc 0.765625\n",
      "2017-04-03T19:34:50.842604: step 5148, loss 0.71948, acc 0.828125\n",
      "2017-04-03T19:34:51.095236: step 5149, loss 0.984876, acc 0.65625\n",
      "2017-04-03T19:34:51.296262: step 5150, loss 0.660699, acc 0.75\n",
      "2017-04-03T19:34:51.542508: step 5151, loss 0.783663, acc 0.71875\n",
      "2017-04-03T19:34:51.745730: step 5152, loss 0.642513, acc 0.796875\n",
      "2017-04-03T19:34:51.945719: step 5153, loss 0.669666, acc 0.765625\n",
      "2017-04-03T19:34:52.196208: step 5154, loss 0.752987, acc 0.765625\n",
      "2017-04-03T19:34:52.398087: step 5155, loss 0.615551, acc 0.78125\n",
      "2017-04-03T19:34:52.604170: step 5156, loss 0.627349, acc 0.78125\n",
      "2017-04-03T19:34:52.805510: step 5157, loss 0.871956, acc 0.703125\n",
      "2017-04-03T19:34:53.004980: step 5158, loss 0.721104, acc 0.765625\n",
      "2017-04-03T19:34:53.204332: step 5159, loss 0.553846, acc 0.875\n",
      "2017-04-03T19:34:53.411038: step 5160, loss 0.86552, acc 0.609375\n",
      "2017-04-03T19:34:53.616703: step 5161, loss 0.713817, acc 0.796875\n",
      "2017-04-03T19:34:53.817732: step 5162, loss 0.557312, acc 0.859375\n",
      "2017-04-03T19:34:54.016904: step 5163, loss 0.516832, acc 0.859375\n",
      "2017-04-03T19:34:54.225691: step 5164, loss 0.714703, acc 0.6875\n",
      "2017-04-03T19:34:54.440348: step 5165, loss 0.560653, acc 0.875\n",
      "2017-04-03T19:34:54.644527: step 5166, loss 0.632228, acc 0.796875\n",
      "2017-04-03T19:34:54.850928: step 5167, loss 0.675589, acc 0.8125\n",
      "2017-04-03T19:34:55.053818: step 5168, loss 0.596065, acc 0.828125\n",
      "2017-04-03T19:34:55.258174: step 5169, loss 0.834927, acc 0.75\n",
      "2017-04-03T19:34:55.460641: step 5170, loss 0.552009, acc 0.84375\n",
      "2017-04-03T19:34:55.710354: step 5171, loss 0.826573, acc 0.765625\n",
      "2017-04-03T19:34:55.913168: step 5172, loss 1.00076, acc 0.625\n",
      "2017-04-03T19:34:56.116437: step 5173, loss 0.62934, acc 0.8125\n",
      "2017-04-03T19:34:56.317771: step 5174, loss 0.65343, acc 0.78125\n",
      "2017-04-03T19:34:56.523690: step 5175, loss 0.678299, acc 0.8125\n",
      "2017-04-03T19:34:56.724095: step 5176, loss 0.501412, acc 0.890625\n",
      "2017-04-03T19:34:56.931801: step 5177, loss 0.685977, acc 0.75\n",
      "2017-04-03T19:34:57.136140: step 5178, loss 0.554194, acc 0.8125\n",
      "2017-04-03T19:34:57.336794: step 5179, loss 0.59059, acc 0.828125\n",
      "2017-04-03T19:34:57.535634: step 5180, loss 0.735128, acc 0.75\n",
      "2017-04-03T19:34:57.785336: step 5181, loss 0.738575, acc 0.71875\n",
      "2017-04-03T19:34:57.985567: step 5182, loss 0.579476, acc 0.859375\n",
      "2017-04-03T19:34:58.188092: step 5183, loss 0.734976, acc 0.75\n",
      "2017-04-03T19:34:58.390680: step 5184, loss 0.707024, acc 0.828125\n",
      "2017-04-03T19:34:58.595838: step 5185, loss 0.746244, acc 0.78125\n",
      "2017-04-03T19:34:58.796620: step 5186, loss 0.864557, acc 0.71875\n",
      "2017-04-03T19:34:58.997952: step 5187, loss 0.766069, acc 0.75\n",
      "2017-04-03T19:34:59.208969: step 5188, loss 0.619374, acc 0.78125\n",
      "2017-04-03T19:34:59.413834: step 5189, loss 0.62052, acc 0.734375\n",
      "2017-04-03T19:34:59.612437: step 5190, loss 0.609331, acc 0.8125\n",
      "2017-04-03T19:34:59.817313: step 5191, loss 0.55741, acc 0.796875\n",
      "2017-04-03T19:35:00.017352: step 5192, loss 0.682888, acc 0.75\n",
      "2017-04-03T19:35:00.219187: step 5193, loss 0.696693, acc 0.734375\n",
      "2017-04-03T19:35:00.423594: step 5194, loss 0.791311, acc 0.734375\n",
      "2017-04-03T19:35:00.629587: step 5195, loss 0.682977, acc 0.703125\n",
      "2017-04-03T19:35:00.833135: step 5196, loss 0.736136, acc 0.75\n",
      "2017-04-03T19:35:01.037102: step 5197, loss 0.656451, acc 0.8125\n",
      "2017-04-03T19:35:01.236438: step 5198, loss 0.577297, acc 0.78125\n",
      "2017-04-03T19:35:01.436024: step 5199, loss 0.703216, acc 0.8125\n",
      "2017-04-03T19:35:01.640448: step 5200, loss 0.82338, acc 0.734375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:35:03.675158: step 5200, loss 2.32982, acc 0.32875\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-5200\n",
      "\n",
      "2017-04-03T19:35:04.055003: step 5201, loss 0.817246, acc 0.765625\n",
      "2017-04-03T19:35:04.251630: step 5202, loss 0.684001, acc 0.734375\n",
      "2017-04-03T19:35:04.450304: step 5203, loss 0.674654, acc 0.765625\n",
      "2017-04-03T19:35:04.651095: step 5204, loss 0.739586, acc 0.78125\n",
      "2017-04-03T19:35:04.858550: step 5205, loss 0.603977, acc 0.8125\n",
      "2017-04-03T19:35:05.062593: step 5206, loss 0.633091, acc 0.84375\n",
      "2017-04-03T19:35:05.265253: step 5207, loss 0.604267, acc 0.828125\n",
      "2017-04-03T19:35:05.472273: step 5208, loss 0.605309, acc 0.8125\n",
      "2017-04-03T19:35:05.670369: step 5209, loss 0.768891, acc 0.75\n",
      "2017-04-03T19:35:05.871582: step 5210, loss 0.784936, acc 0.703125\n",
      "2017-04-03T19:35:06.076819: step 5211, loss 0.781364, acc 0.796875\n",
      "2017-04-03T19:35:06.279468: step 5212, loss 0.683601, acc 0.765625\n",
      "2017-04-03T19:35:06.485801: step 5213, loss 0.838499, acc 0.703125\n",
      "2017-04-03T19:35:06.687650: step 5214, loss 0.673903, acc 0.78125\n",
      "2017-04-03T19:35:06.931789: step 5215, loss 0.899159, acc 0.609375\n",
      "2017-04-03T19:35:07.144159: step 5216, loss 0.741985, acc 0.75\n",
      "2017-04-03T19:35:07.346078: step 5217, loss 0.707654, acc 0.71875\n",
      "2017-04-03T19:35:07.551918: step 5218, loss 0.667275, acc 0.765625\n",
      "2017-04-03T19:35:07.756352: step 5219, loss 0.554143, acc 0.828125\n",
      "2017-04-03T19:35:08.012094: step 5220, loss 0.738474, acc 0.765625\n",
      "2017-04-03T19:35:08.217587: step 5221, loss 0.712939, acc 0.703125\n",
      "2017-04-03T19:35:08.426915: step 5222, loss 0.686904, acc 0.75\n",
      "2017-04-03T19:35:08.639135: step 5223, loss 0.840952, acc 0.671875\n",
      "2017-04-03T19:35:08.842101: step 5224, loss 0.823642, acc 0.6875\n",
      "2017-04-03T19:35:09.043114: step 5225, loss 0.842771, acc 0.734375\n",
      "2017-04-03T19:35:09.249296: step 5226, loss 0.815679, acc 0.75\n",
      "2017-04-03T19:35:09.453153: step 5227, loss 0.655464, acc 0.78125\n",
      "2017-04-03T19:35:09.656592: step 5228, loss 0.553494, acc 0.8125\n",
      "2017-04-03T19:35:09.861770: step 5229, loss 0.63647, acc 0.828125\n",
      "2017-04-03T19:35:10.063627: step 5230, loss 0.586549, acc 0.78125\n",
      "2017-04-03T19:35:10.267282: step 5231, loss 0.556723, acc 0.8125\n",
      "2017-04-03T19:35:10.471854: step 5232, loss 0.699184, acc 0.75\n",
      "2017-04-03T19:35:10.685528: step 5233, loss 0.679841, acc 0.765625\n",
      "2017-04-03T19:35:10.904752: step 5234, loss 0.55873, acc 0.8125\n",
      "2017-04-03T19:35:11.110836: step 5235, loss 0.701038, acc 0.8125\n",
      "2017-04-03T19:35:11.310018: step 5236, loss 0.77673, acc 0.703125\n",
      "2017-04-03T19:35:11.514155: step 5237, loss 0.639071, acc 0.71875\n",
      "2017-04-03T19:35:11.715257: step 5238, loss 0.485037, acc 0.84375\n",
      "2017-04-03T19:35:11.922388: step 5239, loss 0.76874, acc 0.765625\n",
      "2017-04-03T19:35:12.123691: step 5240, loss 0.832272, acc 0.71875\n",
      "2017-04-03T19:35:12.327432: step 5241, loss 0.784737, acc 0.71875\n",
      "2017-04-03T19:35:12.526224: step 5242, loss 0.652129, acc 0.734375\n",
      "2017-04-03T19:35:12.746997: step 5243, loss 0.720782, acc 0.8125\n",
      "2017-04-03T19:35:12.950949: step 5244, loss 0.713095, acc 0.75\n",
      "2017-04-03T19:35:13.156129: step 5245, loss 0.990424, acc 0.640625\n",
      "2017-04-03T19:35:13.356108: step 5246, loss 0.935761, acc 0.640625\n",
      "2017-04-03T19:35:13.563228: step 5247, loss 0.732254, acc 0.75\n",
      "2017-04-03T19:35:13.769953: step 5248, loss 0.630921, acc 0.796875\n",
      "2017-04-03T19:35:13.971225: step 5249, loss 0.696428, acc 0.78125\n",
      "2017-04-03T19:35:14.177018: step 5250, loss 0.665623, acc 0.828125\n",
      "2017-04-03T19:35:14.385120: step 5251, loss 0.853657, acc 0.75\n",
      "2017-04-03T19:35:14.595682: step 5252, loss 0.833187, acc 0.6875\n",
      "2017-04-03T19:35:14.803821: step 5253, loss 0.577247, acc 0.8125\n",
      "2017-04-03T19:35:15.013488: step 5254, loss 0.736484, acc 0.75\n",
      "2017-04-03T19:35:15.217103: step 5255, loss 0.687256, acc 0.75\n",
      "2017-04-03T19:35:15.418310: step 5256, loss 0.580405, acc 0.78125\n",
      "2017-04-03T19:35:15.633473: step 5257, loss 1.01374, acc 0.671875\n",
      "2017-04-03T19:35:15.840025: step 5258, loss 0.805578, acc 0.71875\n",
      "2017-04-03T19:35:16.046958: step 5259, loss 0.692657, acc 0.734375\n",
      "2017-04-03T19:35:16.250972: step 5260, loss 0.530657, acc 0.796875\n",
      "2017-04-03T19:35:16.454173: step 5261, loss 0.804404, acc 0.796875\n",
      "2017-04-03T19:35:16.656567: step 5262, loss 0.633545, acc 0.8125\n",
      "2017-04-03T19:35:16.859052: step 5263, loss 0.870596, acc 0.6875\n",
      "2017-04-03T19:35:17.063986: step 5264, loss 0.63608, acc 0.78125\n",
      "2017-04-03T19:35:17.265893: step 5265, loss 0.748135, acc 0.765625\n",
      "2017-04-03T19:35:17.491416: step 5266, loss 0.831336, acc 0.71875\n",
      "2017-04-03T19:35:17.701255: step 5267, loss 0.737738, acc 0.75\n",
      "2017-04-03T19:35:17.909184: step 5268, loss 0.736421, acc 0.765625\n",
      "2017-04-03T19:35:18.118106: step 5269, loss 0.897503, acc 0.65625\n",
      "2017-04-03T19:35:18.318545: step 5270, loss 0.598933, acc 0.828125\n",
      "2017-04-03T19:35:18.519099: step 5271, loss 0.71568, acc 0.796875\n",
      "2017-04-03T19:35:18.718258: step 5272, loss 1.01379, acc 0.671875\n",
      "2017-04-03T19:35:18.916882: step 5273, loss 0.749588, acc 0.734375\n",
      "2017-04-03T19:35:19.116755: step 5274, loss 0.802212, acc 0.75\n",
      "2017-04-03T19:35:19.317184: step 5275, loss 0.987469, acc 0.65625\n",
      "2017-04-03T19:35:19.522424: step 5276, loss 0.921058, acc 0.6875\n",
      "2017-04-03T19:35:19.723706: step 5277, loss 0.837848, acc 0.734375\n",
      "2017-04-03T19:35:19.926558: step 5278, loss 0.945167, acc 0.625\n",
      "2017-04-03T19:35:20.132864: step 5279, loss 0.816578, acc 0.75\n",
      "2017-04-03T19:35:20.331727: step 5280, loss 0.851886, acc 0.6875\n",
      "2017-04-03T19:35:20.569154: step 5281, loss 0.71589, acc 0.78125\n",
      "2017-04-03T19:35:20.769689: step 5282, loss 0.67343, acc 0.75\n",
      "2017-04-03T19:35:20.971431: step 5283, loss 0.866238, acc 0.765625\n",
      "2017-04-03T19:35:21.171957: step 5284, loss 0.774088, acc 0.703125\n",
      "2017-04-03T19:35:21.373682: step 5285, loss 0.788665, acc 0.703125\n",
      "2017-04-03T19:35:21.576436: step 5286, loss 0.937347, acc 0.671875\n",
      "2017-04-03T19:35:21.778517: step 5287, loss 0.713663, acc 0.734375\n",
      "2017-04-03T19:35:21.979441: step 5288, loss 0.674113, acc 0.78125\n",
      "2017-04-03T19:35:22.180273: step 5289, loss 0.884773, acc 0.703125\n",
      "2017-04-03T19:35:22.380128: step 5290, loss 0.817077, acc 0.703125\n",
      "2017-04-03T19:35:22.582727: step 5291, loss 1.06792, acc 0.546875\n",
      "2017-04-03T19:35:22.787061: step 5292, loss 0.79994, acc 0.71875\n",
      "2017-04-03T19:35:22.989313: step 5293, loss 0.581615, acc 0.859375\n",
      "2017-04-03T19:35:23.187397: step 5294, loss 0.591178, acc 0.8125\n",
      "2017-04-03T19:35:23.393212: step 5295, loss 0.755636, acc 0.734375\n",
      "2017-04-03T19:35:23.597119: step 5296, loss 0.808738, acc 0.71875\n",
      "2017-04-03T19:35:23.798724: step 5297, loss 0.592831, acc 0.828125\n",
      "2017-04-03T19:35:24.000453: step 5298, loss 0.750811, acc 0.75\n",
      "2017-04-03T19:35:24.206784: step 5299, loss 0.724019, acc 0.828125\n",
      "2017-04-03T19:35:24.453928: step 5300, loss 0.73723, acc 0.734375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:35:26.466041: step 5300, loss 2.35237, acc 0.328\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-5300\n",
      "\n",
      "2017-04-03T19:35:26.803065: step 5301, loss 0.482435, acc 0.859375\n",
      "2017-04-03T19:35:27.008255: step 5302, loss 0.746799, acc 0.734375\n",
      "2017-04-03T19:35:27.252849: step 5303, loss 0.835342, acc 0.6875\n",
      "2017-04-03T19:35:27.498513: step 5304, loss 0.836989, acc 0.65625\n",
      "2017-04-03T19:35:27.698921: step 5305, loss 0.858002, acc 0.734375\n",
      "2017-04-03T19:35:27.895727: step 5306, loss 0.803987, acc 0.71875\n",
      "2017-04-03T19:35:28.103320: step 5307, loss 0.889378, acc 0.6875\n",
      "2017-04-03T19:35:28.352032: step 5308, loss 0.839054, acc 0.671875\n",
      "2017-04-03T19:35:28.600262: step 5309, loss 0.804486, acc 0.671875\n",
      "2017-04-03T19:35:28.803524: step 5310, loss 1.00286, acc 0.6875\n",
      "2017-04-03T19:35:29.055985: step 5311, loss 0.795448, acc 0.78125\n",
      "2017-04-03T19:35:29.263021: step 5312, loss 0.78045, acc 0.75\n",
      "2017-04-03T19:35:29.466805: step 5313, loss 0.996978, acc 0.625\n",
      "2017-04-03T19:35:29.670589: step 5314, loss 0.7002, acc 0.765625\n",
      "2017-04-03T19:35:29.885926: step 5315, loss 0.672475, acc 0.8125\n",
      "2017-04-03T19:35:30.083632: step 5316, loss 1.03723, acc 0.703125\n",
      "2017-04-03T19:35:30.288109: step 5317, loss 0.774236, acc 0.75\n",
      "2017-04-03T19:35:30.493531: step 5318, loss 0.78933, acc 0.71875\n",
      "2017-04-03T19:35:30.700333: step 5319, loss 0.783879, acc 0.734375\n",
      "2017-04-03T19:35:30.900581: step 5320, loss 1.14992, acc 0.5625\n",
      "2017-04-03T19:35:31.104343: step 5321, loss 0.902916, acc 0.671875\n",
      "2017-04-03T19:35:31.308842: step 5322, loss 0.681752, acc 0.75\n",
      "2017-04-03T19:35:31.517330: step 5323, loss 0.664921, acc 0.78125\n",
      "2017-04-03T19:35:31.717231: step 5324, loss 0.661508, acc 0.796875\n",
      "2017-04-03T19:35:31.919764: step 5325, loss 0.743206, acc 0.734375\n",
      "2017-04-03T19:35:32.132743: step 5326, loss 0.76099, acc 0.734375\n",
      "2017-04-03T19:35:32.342141: step 5327, loss 0.622644, acc 0.8125\n",
      "2017-04-03T19:35:32.586875: step 5328, loss 0.824854, acc 0.703125\n",
      "2017-04-03T19:35:32.789988: step 5329, loss 0.840328, acc 0.6875\n",
      "2017-04-03T19:35:32.986767: step 5330, loss 0.709375, acc 0.71875\n",
      "2017-04-03T19:35:33.193077: step 5331, loss 0.616575, acc 0.84375\n",
      "2017-04-03T19:35:33.393232: step 5332, loss 0.793568, acc 0.78125\n",
      "2017-04-03T19:35:33.636186: step 5333, loss 0.800639, acc 0.71875\n",
      "2017-04-03T19:35:33.831388: step 5334, loss 0.774546, acc 0.703125\n",
      "2017-04-03T19:35:34.029854: step 5335, loss 0.74379, acc 0.734375\n",
      "2017-04-03T19:35:34.228014: step 5336, loss 0.708313, acc 0.78125\n",
      "2017-04-03T19:35:34.425867: step 5337, loss 0.644039, acc 0.78125\n",
      "2017-04-03T19:35:34.624589: step 5338, loss 0.769572, acc 0.71875\n",
      "2017-04-03T19:35:34.830752: step 5339, loss 0.829456, acc 0.71875\n",
      "2017-04-03T19:35:35.029091: step 5340, loss 0.793419, acc 0.75\n",
      "2017-04-03T19:35:35.228217: step 5341, loss 1.00841, acc 0.65625\n",
      "2017-04-03T19:35:35.428922: step 5342, loss 0.817015, acc 0.71875\n",
      "2017-04-03T19:35:35.633284: step 5343, loss 0.744211, acc 0.71875\n",
      "2017-04-03T19:35:35.833637: step 5344, loss 0.905027, acc 0.6875\n",
      "2017-04-03T19:35:36.034714: step 5345, loss 0.884475, acc 0.734375\n",
      "2017-04-03T19:35:36.231364: step 5346, loss 0.788062, acc 0.734375\n",
      "2017-04-03T19:35:36.432983: step 5347, loss 0.795396, acc 0.65625\n",
      "2017-04-03T19:35:36.632172: step 5348, loss 0.664318, acc 0.75\n",
      "2017-04-03T19:35:37.011107: step 5349, loss 0.675672, acc 0.828125\n",
      "2017-04-03T19:35:37.212808: step 5350, loss 0.545171, acc 0.828125\n",
      "2017-04-03T19:35:37.425667: step 5351, loss 0.641804, acc 0.765625\n",
      "2017-04-03T19:35:37.629475: step 5352, loss 0.843777, acc 0.734375\n",
      "2017-04-03T19:35:37.874663: step 5353, loss 0.901298, acc 0.671875\n",
      "2017-04-03T19:35:38.121263: step 5354, loss 0.709373, acc 0.78125\n",
      "2017-04-03T19:35:38.321625: step 5355, loss 0.588082, acc 0.78125\n",
      "2017-04-03T19:35:38.521686: step 5356, loss 0.878483, acc 0.71875\n",
      "2017-04-03T19:35:38.724476: step 5357, loss 0.757229, acc 0.734375\n",
      "2017-04-03T19:35:38.924830: step 5358, loss 0.656576, acc 0.765625\n",
      "2017-04-03T19:35:39.125939: step 5359, loss 0.74608, acc 0.78125\n",
      "2017-04-03T19:35:39.331222: step 5360, loss 0.621182, acc 0.765625\n",
      "2017-04-03T19:35:39.534171: step 5361, loss 0.704292, acc 0.8125\n",
      "2017-04-03T19:35:39.742589: step 5362, loss 1.04471, acc 0.59375\n",
      "2017-04-03T19:35:39.954167: step 5363, loss 0.817158, acc 0.6875\n",
      "2017-04-03T19:35:40.157260: step 5364, loss 0.917216, acc 0.703125\n",
      "2017-04-03T19:35:40.358683: step 5365, loss 0.760067, acc 0.765625\n",
      "2017-04-03T19:35:40.598477: step 5366, loss 0.807922, acc 0.734375\n",
      "2017-04-03T19:35:40.796877: step 5367, loss 0.644912, acc 0.75\n",
      "2017-04-03T19:35:41.000028: step 5368, loss 0.646963, acc 0.71875\n",
      "2017-04-03T19:35:41.195655: step 5369, loss 0.697396, acc 0.78125\n",
      "2017-04-03T19:35:41.399804: step 5370, loss 0.89789, acc 0.75\n",
      "2017-04-03T19:35:41.602023: step 5371, loss 0.742425, acc 0.71875\n",
      "2017-04-03T19:35:41.804242: step 5372, loss 0.610213, acc 0.765625\n",
      "2017-04-03T19:35:42.008928: step 5373, loss 0.537788, acc 0.765625\n",
      "2017-04-03T19:35:42.213803: step 5374, loss 0.92133, acc 0.625\n",
      "2017-04-03T19:35:42.418814: step 5375, loss 0.924059, acc 0.6875\n",
      "2017-04-03T19:35:42.642092: step 5376, loss 0.829571, acc 0.75\n",
      "2017-04-03T19:35:42.877551: step 5377, loss 0.993779, acc 0.65625\n",
      "2017-04-03T19:35:43.082214: step 5378, loss 0.777546, acc 0.765625\n",
      "2017-04-03T19:35:43.287643: step 5379, loss 0.774446, acc 0.71875\n",
      "2017-04-03T19:35:43.486193: step 5380, loss 0.905083, acc 0.71875\n",
      "2017-04-03T19:35:43.689037: step 5381, loss 0.673705, acc 0.765625\n",
      "2017-04-03T19:35:43.892556: step 5382, loss 0.730253, acc 0.6875\n",
      "2017-04-03T19:35:44.091496: step 5383, loss 0.814105, acc 0.703125\n",
      "2017-04-03T19:35:44.293138: step 5384, loss 0.740933, acc 0.734375\n",
      "2017-04-03T19:35:44.508639: step 5385, loss 0.615271, acc 0.8125\n",
      "2017-04-03T19:35:44.712417: step 5386, loss 0.488609, acc 0.859375\n",
      "2017-04-03T19:35:44.915775: step 5387, loss 0.759871, acc 0.703125\n",
      "2017-04-03T19:35:45.119419: step 5388, loss 0.763692, acc 0.734375\n",
      "2017-04-03T19:35:45.320868: step 5389, loss 0.630048, acc 0.796875\n",
      "2017-04-03T19:35:45.528073: step 5390, loss 0.702034, acc 0.78125\n",
      "2017-04-03T19:35:45.725536: step 5391, loss 0.626728, acc 0.78125\n",
      "2017-04-03T19:35:45.927199: step 5392, loss 0.661321, acc 0.796875\n",
      "2017-04-03T19:35:46.130533: step 5393, loss 0.922442, acc 0.65625\n",
      "2017-04-03T19:35:46.331644: step 5394, loss 0.613026, acc 0.765625\n",
      "2017-04-03T19:35:46.533273: step 5395, loss 0.705159, acc 0.84375\n",
      "2017-04-03T19:35:46.736481: step 5396, loss 0.912067, acc 0.703125\n",
      "2017-04-03T19:35:46.942694: step 5397, loss 0.751439, acc 0.734375\n",
      "2017-04-03T19:35:47.187316: step 5398, loss 0.635345, acc 0.765625\n",
      "2017-04-03T19:35:47.392022: step 5399, loss 0.833295, acc 0.6875\n",
      "2017-04-03T19:35:47.596959: step 5400, loss 0.851386, acc 0.78125\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:35:49.623333: step 5400, loss 2.36835, acc 0.32625\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-5400\n",
      "\n",
      "2017-04-03T19:35:49.957807: step 5401, loss 0.738991, acc 0.75\n",
      "2017-04-03T19:35:50.167246: step 5402, loss 0.857562, acc 0.734375\n",
      "2017-04-03T19:35:50.372042: step 5403, loss 0.659498, acc 0.796875\n",
      "2017-04-03T19:35:50.574450: step 5404, loss 0.879968, acc 0.734375\n",
      "2017-04-03T19:35:50.780457: step 5405, loss 0.832196, acc 0.703125\n",
      "2017-04-03T19:35:51.016560: step 5406, loss 0.725841, acc 0.6875\n",
      "2017-04-03T19:35:51.234721: step 5407, loss 0.976937, acc 0.734375\n",
      "2017-04-03T19:35:51.439727: step 5408, loss 0.606673, acc 0.765625\n",
      "2017-04-03T19:35:51.640414: step 5409, loss 0.685842, acc 0.765625\n",
      "2017-04-03T19:35:51.841582: step 5410, loss 0.565798, acc 0.796875\n",
      "2017-04-03T19:35:52.045168: step 5411, loss 0.718206, acc 0.78125\n",
      "2017-04-03T19:35:52.251474: step 5412, loss 0.844264, acc 0.765625\n",
      "2017-04-03T19:35:52.451778: step 5413, loss 0.828429, acc 0.765625\n",
      "2017-04-03T19:35:52.653391: step 5414, loss 0.916403, acc 0.65625\n",
      "2017-04-03T19:35:52.858589: step 5415, loss 0.8281, acc 0.6875\n",
      "2017-04-03T19:35:53.060344: step 5416, loss 0.91046, acc 0.6875\n",
      "2017-04-03T19:35:53.264814: step 5417, loss 0.586081, acc 0.78125\n",
      "2017-04-03T19:35:53.465086: step 5418, loss 0.571058, acc 0.875\n",
      "2017-04-03T19:35:53.667397: step 5419, loss 0.746852, acc 0.71875\n",
      "2017-04-03T19:35:53.872228: step 5420, loss 0.786574, acc 0.734375\n",
      "2017-04-03T19:35:54.076123: step 5421, loss 0.897906, acc 0.625\n",
      "2017-04-03T19:35:54.275713: step 5422, loss 0.744045, acc 0.734375\n",
      "2017-04-03T19:35:54.480936: step 5423, loss 0.69563, acc 0.734375\n",
      "2017-04-03T19:35:54.685317: step 5424, loss 0.66902, acc 0.765625\n",
      "2017-04-03T19:35:54.898688: step 5425, loss 0.722768, acc 0.703125\n",
      "2017-04-03T19:35:55.095640: step 5426, loss 0.786809, acc 0.734375\n",
      "2017-04-03T19:35:55.295373: step 5427, loss 0.801601, acc 0.734375\n",
      "2017-04-03T19:35:55.501337: step 5428, loss 0.591527, acc 0.828125\n",
      "2017-04-03T19:35:55.706794: step 5429, loss 0.61175, acc 0.78125\n",
      "2017-04-03T19:35:55.911730: step 5430, loss 0.821702, acc 0.8125\n",
      "2017-04-03T19:35:56.114700: step 5431, loss 0.493022, acc 0.890625\n",
      "2017-04-03T19:35:56.318138: step 5432, loss 0.678037, acc 0.8125\n",
      "2017-04-03T19:35:56.522750: step 5433, loss 0.882729, acc 0.71875\n",
      "2017-04-03T19:35:56.721361: step 5434, loss 0.756197, acc 0.703125\n",
      "2017-04-03T19:35:56.930038: step 5435, loss 0.68965, acc 0.78125\n",
      "2017-04-03T19:35:57.129199: step 5436, loss 0.878464, acc 0.75\n",
      "2017-04-03T19:35:57.330246: step 5437, loss 0.797969, acc 0.6875\n",
      "2017-04-03T19:35:57.529283: step 5438, loss 0.719891, acc 0.765625\n",
      "2017-04-03T19:35:57.737948: step 5439, loss 0.845646, acc 0.703125\n",
      "2017-04-03T19:35:57.938160: step 5440, loss 0.837329, acc 0.703125\n",
      "2017-04-03T19:35:58.135969: step 5441, loss 0.959141, acc 0.734375\n",
      "2017-04-03T19:35:58.338930: step 5442, loss 0.852443, acc 0.671875\n",
      "2017-04-03T19:35:58.537548: step 5443, loss 0.583963, acc 0.859375\n",
      "2017-04-03T19:35:58.741207: step 5444, loss 0.613198, acc 0.765625\n",
      "2017-04-03T19:35:58.952528: step 5445, loss 0.874468, acc 0.671875\n",
      "2017-04-03T19:35:59.152983: step 5446, loss 0.836278, acc 0.765625\n",
      "2017-04-03T19:35:59.358468: step 5447, loss 0.738442, acc 0.71875\n",
      "2017-04-03T19:35:59.565701: step 5448, loss 0.756014, acc 0.71875\n",
      "2017-04-03T19:35:59.766165: step 5449, loss 0.636779, acc 0.75\n",
      "2017-04-03T19:35:59.970469: step 5450, loss 0.828418, acc 0.703125\n",
      "2017-04-03T19:36:00.210468: step 5451, loss 0.607685, acc 0.796875\n",
      "2017-04-03T19:36:00.458463: step 5452, loss 0.869132, acc 0.671875\n",
      "2017-04-03T19:36:00.663208: step 5453, loss 0.723601, acc 0.71875\n",
      "2017-04-03T19:36:00.868568: step 5454, loss 0.711162, acc 0.765625\n",
      "2017-04-03T19:36:01.069994: step 5455, loss 0.947181, acc 0.6875\n",
      "2017-04-03T19:36:01.272992: step 5456, loss 0.930834, acc 0.703125\n",
      "2017-04-03T19:36:01.478977: step 5457, loss 0.860689, acc 0.703125\n",
      "2017-04-03T19:36:01.682586: step 5458, loss 0.818591, acc 0.71875\n",
      "2017-04-03T19:36:01.891322: step 5459, loss 0.829393, acc 0.6875\n",
      "2017-04-03T19:36:02.097981: step 5460, loss 0.760458, acc 0.75\n",
      "2017-04-03T19:36:02.310917: step 5461, loss 0.830693, acc 0.71875\n",
      "2017-04-03T19:36:02.513589: step 5462, loss 0.82911, acc 0.71875\n",
      "2017-04-03T19:36:02.710545: step 5463, loss 0.809658, acc 0.6875\n",
      "2017-04-03T19:36:02.957532: step 5464, loss 0.582794, acc 0.765625\n",
      "2017-04-03T19:36:03.199014: step 5465, loss 0.744423, acc 0.8125\n",
      "2017-04-03T19:36:03.398579: step 5466, loss 0.770901, acc 0.65625\n",
      "2017-04-03T19:36:03.642283: step 5467, loss 0.719122, acc 0.703125\n",
      "2017-04-03T19:36:03.847475: step 5468, loss 0.774893, acc 0.6875\n",
      "2017-04-03T19:36:04.052806: step 5469, loss 0.595325, acc 0.8125\n",
      "2017-04-03T19:36:04.262914: step 5470, loss 0.675246, acc 0.828125\n",
      "2017-04-03T19:36:04.506660: step 5471, loss 0.927139, acc 0.703125\n",
      "2017-04-03T19:36:04.708042: step 5472, loss 0.872446, acc 0.65625\n",
      "2017-04-03T19:36:04.912577: step 5473, loss 0.944545, acc 0.671875\n",
      "2017-04-03T19:36:05.122531: step 5474, loss 0.783622, acc 0.703125\n",
      "2017-04-03T19:36:05.325914: step 5475, loss 0.82259, acc 0.671875\n",
      "2017-04-03T19:36:05.533271: step 5476, loss 0.826521, acc 0.6875\n",
      "2017-04-03T19:36:05.736319: step 5477, loss 0.923018, acc 0.609375\n",
      "2017-04-03T19:36:05.935613: step 5478, loss 0.754543, acc 0.796875\n",
      "2017-04-03T19:36:06.137851: step 5479, loss 0.618741, acc 0.78125\n",
      "2017-04-03T19:36:06.343609: step 5480, loss 0.678363, acc 0.796875\n",
      "2017-04-03T19:36:06.547456: step 5481, loss 0.718321, acc 0.734375\n",
      "2017-04-03T19:36:06.753719: step 5482, loss 0.598207, acc 0.796875\n",
      "2017-04-03T19:36:06.959590: step 5483, loss 0.790586, acc 0.75\n",
      "2017-04-03T19:36:07.157606: step 5484, loss 0.806651, acc 0.765625\n",
      "2017-04-03T19:36:07.360967: step 5485, loss 0.640702, acc 0.796875\n",
      "2017-04-03T19:36:07.567546: step 5486, loss 0.979139, acc 0.65625\n",
      "2017-04-03T19:36:07.770262: step 5487, loss 0.839115, acc 0.6875\n",
      "2017-04-03T19:36:07.973119: step 5488, loss 1.08944, acc 0.65625\n",
      "2017-04-03T19:36:08.173091: step 5489, loss 0.711278, acc 0.78125\n",
      "2017-04-03T19:36:08.374626: step 5490, loss 0.733169, acc 0.765625\n",
      "2017-04-03T19:36:08.575615: step 5491, loss 0.852522, acc 0.703125\n",
      "2017-04-03T19:36:08.774645: step 5492, loss 0.764953, acc 0.734375\n",
      "2017-04-03T19:36:08.977287: step 5493, loss 0.576764, acc 0.8125\n",
      "2017-04-03T19:36:09.179081: step 5494, loss 0.775654, acc 0.75\n",
      "2017-04-03T19:36:09.381689: step 5495, loss 0.870194, acc 0.65625\n",
      "2017-04-03T19:36:09.584542: step 5496, loss 0.701414, acc 0.765625\n",
      "2017-04-03T19:36:09.792336: step 5497, loss 0.774962, acc 0.703125\n",
      "2017-04-03T19:36:09.996132: step 5498, loss 0.836841, acc 0.6875\n",
      "2017-04-03T19:36:10.201664: step 5499, loss 0.670318, acc 0.75\n",
      "2017-04-03T19:36:10.405465: step 5500, loss 0.985913, acc 0.65625\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:36:12.432940: step 5500, loss 2.40327, acc 0.33125\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-5500\n",
      "\n",
      "2017-04-03T19:36:12.761323: step 5501, loss 0.782787, acc 0.703125\n",
      "2017-04-03T19:36:12.962532: step 5502, loss 0.616904, acc 0.828125\n",
      "2017-04-03T19:36:13.190450: step 5503, loss 0.817183, acc 0.75\n",
      "2017-04-03T19:36:13.400727: step 5504, loss 0.828313, acc 0.703125\n",
      "2017-04-03T19:36:13.602766: step 5505, loss 1.01749, acc 0.640625\n",
      "2017-04-03T19:36:13.805302: step 5506, loss 0.644404, acc 0.8125\n",
      "2017-04-03T19:36:14.006204: step 5507, loss 0.852256, acc 0.765625\n",
      "2017-04-03T19:36:14.250912: step 5508, loss 0.990322, acc 0.671875\n",
      "2017-04-03T19:36:14.501379: step 5509, loss 0.706246, acc 0.765625\n",
      "2017-04-03T19:36:14.704656: step 5510, loss 0.722794, acc 0.796875\n",
      "2017-04-03T19:36:14.910990: step 5511, loss 0.819866, acc 0.703125\n",
      "2017-04-03T19:36:15.114305: step 5512, loss 0.643227, acc 0.828125\n",
      "2017-04-03T19:36:15.320505: step 5513, loss 0.792768, acc 0.671875\n",
      "2017-04-03T19:36:15.524431: step 5514, loss 0.722248, acc 0.734375\n",
      "2017-04-03T19:36:15.741633: step 5515, loss 0.906808, acc 0.734375\n",
      "2017-04-03T19:36:15.945925: step 5516, loss 0.93856, acc 0.71875\n",
      "2017-04-03T19:36:16.193324: step 5517, loss 0.731693, acc 0.765625\n",
      "2017-04-03T19:36:16.394217: step 5518, loss 0.695054, acc 0.78125\n",
      "2017-04-03T19:36:16.644471: step 5519, loss 0.79216, acc 0.78125\n",
      "2017-04-03T19:36:16.895811: step 5520, loss 0.788095, acc 0.78125\n",
      "2017-04-03T19:36:17.140415: step 5521, loss 0.740434, acc 0.75\n",
      "2017-04-03T19:36:17.349518: step 5522, loss 0.82331, acc 0.6875\n",
      "2017-04-03T19:36:17.553063: step 5523, loss 0.794289, acc 0.671875\n",
      "2017-04-03T19:36:17.754299: step 5524, loss 0.705018, acc 0.75\n",
      "2017-04-03T19:36:17.960992: step 5525, loss 0.509686, acc 0.859375\n",
      "2017-04-03T19:36:18.164492: step 5526, loss 0.746038, acc 0.765625\n",
      "2017-04-03T19:36:18.409860: step 5527, loss 0.679471, acc 0.78125\n",
      "2017-04-03T19:36:18.609514: step 5528, loss 0.864683, acc 0.640625\n",
      "2017-04-03T19:36:18.809905: step 5529, loss 0.650458, acc 0.8125\n",
      "2017-04-03T19:36:19.010977: step 5530, loss 0.92665, acc 0.671875\n",
      "2017-04-03T19:36:19.211998: step 5531, loss 0.728036, acc 0.75\n",
      "2017-04-03T19:36:19.411187: step 5532, loss 0.855644, acc 0.78125\n",
      "2017-04-03T19:36:19.617851: step 5533, loss 0.70753, acc 0.78125\n",
      "2017-04-03T19:36:19.818167: step 5534, loss 0.889193, acc 0.65625\n",
      "2017-04-03T19:36:20.020180: step 5535, loss 0.738412, acc 0.765625\n",
      "2017-04-03T19:36:20.223165: step 5536, loss 0.813592, acc 0.703125\n",
      "2017-04-03T19:36:20.428055: step 5537, loss 0.905023, acc 0.65625\n",
      "2017-04-03T19:36:20.631343: step 5538, loss 0.704807, acc 0.75\n",
      "2017-04-03T19:36:20.831922: step 5539, loss 0.727597, acc 0.734375\n",
      "2017-04-03T19:36:21.075758: step 5540, loss 0.981701, acc 0.671875\n",
      "2017-04-03T19:36:21.282900: step 5541, loss 0.823368, acc 0.65625\n",
      "2017-04-03T19:36:21.488751: step 5542, loss 1.0069, acc 0.640625\n",
      "2017-04-03T19:36:21.691191: step 5543, loss 0.846408, acc 0.703125\n",
      "2017-04-03T19:36:21.897841: step 5544, loss 0.571715, acc 0.828125\n",
      "2017-04-03T19:36:22.102816: step 5545, loss 0.90137, acc 0.703125\n",
      "2017-04-03T19:36:22.303884: step 5546, loss 0.827577, acc 0.6875\n",
      "2017-04-03T19:36:22.509493: step 5547, loss 0.615281, acc 0.796875\n",
      "2017-04-03T19:36:22.715942: step 5548, loss 0.774409, acc 0.734375\n",
      "2017-04-03T19:36:22.920492: step 5549, loss 0.771484, acc 0.6875\n",
      "2017-04-03T19:36:23.123876: step 5550, loss 0.864562, acc 0.703125\n",
      "2017-04-03T19:36:23.326922: step 5551, loss 0.851993, acc 0.75\n",
      "2017-04-03T19:36:23.534373: step 5552, loss 0.740287, acc 0.78125\n",
      "2017-04-03T19:36:23.736653: step 5553, loss 0.864139, acc 0.734375\n",
      "2017-04-03T19:36:23.936181: step 5554, loss 0.73481, acc 0.734375\n",
      "2017-04-03T19:36:24.148108: step 5555, loss 0.818909, acc 0.6875\n",
      "2017-04-03T19:36:24.348952: step 5556, loss 0.8103, acc 0.734375\n",
      "2017-04-03T19:36:24.552377: step 5557, loss 0.791706, acc 0.796875\n",
      "2017-04-03T19:36:24.752802: step 5558, loss 0.593846, acc 0.78125\n",
      "2017-04-03T19:36:24.969730: step 5559, loss 0.733884, acc 0.765625\n",
      "2017-04-03T19:36:25.185675: step 5560, loss 0.81459, acc 0.703125\n",
      "2017-04-03T19:36:25.386083: step 5561, loss 0.79513, acc 0.71875\n",
      "2017-04-03T19:36:25.584944: step 5562, loss 0.775967, acc 0.75\n",
      "2017-04-03T19:36:25.785772: step 5563, loss 0.799518, acc 0.703125\n",
      "2017-04-03T19:36:26.031098: step 5564, loss 0.789907, acc 0.734375\n",
      "2017-04-03T19:36:26.229814: step 5565, loss 0.750812, acc 0.71875\n",
      "2017-04-03T19:36:26.429110: step 5566, loss 0.659962, acc 0.8125\n",
      "2017-04-03T19:36:26.628655: step 5567, loss 0.966109, acc 0.6875\n",
      "2017-04-03T19:36:26.829751: step 5568, loss 0.692613, acc 0.828125\n",
      "2017-04-03T19:36:27.029785: step 5569, loss 0.732944, acc 0.796875\n",
      "2017-04-03T19:36:27.231668: step 5570, loss 0.721711, acc 0.78125\n",
      "2017-04-03T19:36:27.432707: step 5571, loss 0.917365, acc 0.6875\n",
      "2017-04-03T19:36:27.685520: step 5572, loss 0.751366, acc 0.734375\n",
      "2017-04-03T19:36:27.893674: step 5573, loss 0.785971, acc 0.75\n",
      "2017-04-03T19:36:28.098834: step 5574, loss 0.748934, acc 0.75\n",
      "2017-04-03T19:36:28.300146: step 5575, loss 0.673318, acc 0.796875\n",
      "2017-04-03T19:36:28.502048: step 5576, loss 0.588409, acc 0.8125\n",
      "2017-04-03T19:36:28.705449: step 5577, loss 0.950967, acc 0.59375\n",
      "2017-04-03T19:36:28.910629: step 5578, loss 0.885449, acc 0.671875\n",
      "2017-04-03T19:36:29.115522: step 5579, loss 1.0085, acc 0.640625\n",
      "2017-04-03T19:36:29.365280: step 5580, loss 0.842355, acc 0.734375\n",
      "2017-04-03T19:36:29.568588: step 5581, loss 0.853092, acc 0.703125\n",
      "2017-04-03T19:36:29.775738: step 5582, loss 0.907524, acc 0.671875\n",
      "2017-04-03T19:36:29.978997: step 5583, loss 1.01496, acc 0.6875\n",
      "2017-04-03T19:36:30.182190: step 5584, loss 0.506802, acc 0.78125\n",
      "2017-04-03T19:36:30.396300: step 5585, loss 0.937583, acc 0.625\n",
      "2017-04-03T19:36:30.602489: step 5586, loss 0.669742, acc 0.71875\n",
      "2017-04-03T19:36:30.799198: step 5587, loss 0.679836, acc 0.765625\n",
      "2017-04-03T19:36:31.048688: step 5588, loss 0.556759, acc 0.859375\n",
      "2017-04-03T19:36:31.258918: step 5589, loss 0.967673, acc 0.6875\n",
      "2017-04-03T19:36:31.466148: step 5590, loss 0.915676, acc 0.625\n",
      "2017-04-03T19:36:31.670663: step 5591, loss 0.794437, acc 0.703125\n",
      "2017-04-03T19:36:31.879077: step 5592, loss 0.798542, acc 0.71875\n",
      "2017-04-03T19:36:32.078609: step 5593, loss 0.95812, acc 0.671875\n",
      "2017-04-03T19:36:32.282285: step 5594, loss 0.93648, acc 0.625\n",
      "2017-04-03T19:36:32.485811: step 5595, loss 0.824587, acc 0.6875\n",
      "2017-04-03T19:36:32.690612: step 5596, loss 0.78809, acc 0.703125\n",
      "2017-04-03T19:36:32.891695: step 5597, loss 0.777251, acc 0.734375\n",
      "2017-04-03T19:36:33.135675: step 5598, loss 0.842544, acc 0.71875\n",
      "2017-04-03T19:36:33.351140: step 5599, loss 1.05848, acc 0.625\n",
      "2017-04-03T19:36:33.554063: step 5600, loss 0.651085, acc 0.796875\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:36:35.527988: step 5600, loss 2.43564, acc 0.33075\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-5600\n",
      "\n",
      "2017-04-03T19:36:35.860722: step 5601, loss 0.673596, acc 0.765625\n",
      "2017-04-03T19:36:36.080034: step 5602, loss 0.581834, acc 0.78125\n",
      "2017-04-03T19:36:36.295182: step 5603, loss 0.611767, acc 0.75\n",
      "2017-04-03T19:36:36.501292: step 5604, loss 0.661348, acc 0.75\n",
      "2017-04-03T19:36:36.704124: step 5605, loss 1.0677, acc 0.671875\n",
      "2017-04-03T19:36:36.953604: step 5606, loss 0.751628, acc 0.71875\n",
      "2017-04-03T19:36:37.156196: step 5607, loss 0.82495, acc 0.765625\n",
      "2017-04-03T19:36:37.362604: step 5608, loss 0.585477, acc 0.828125\n",
      "2017-04-03T19:36:37.566011: step 5609, loss 0.752397, acc 0.78125\n",
      "2017-04-03T19:36:37.767182: step 5610, loss 0.56204, acc 0.78125\n",
      "2017-04-03T19:36:37.969087: step 5611, loss 0.944029, acc 0.65625\n",
      "2017-04-03T19:36:38.168495: step 5612, loss 0.777995, acc 0.703125\n",
      "2017-04-03T19:36:38.370377: step 5613, loss 0.640551, acc 0.796875\n",
      "2017-04-03T19:36:38.574201: step 5614, loss 0.777918, acc 0.703125\n",
      "2017-04-03T19:36:38.776465: step 5615, loss 0.973663, acc 0.59375\n",
      "2017-04-03T19:36:38.981787: step 5616, loss 0.775277, acc 0.71875\n",
      "2017-04-03T19:36:39.192181: step 5617, loss 0.785628, acc 0.6875\n",
      "2017-04-03T19:36:39.411308: step 5618, loss 0.819121, acc 0.65625\n",
      "2017-04-03T19:36:39.615086: step 5619, loss 0.833556, acc 0.78125\n",
      "2017-04-03T19:36:39.830013: step 5620, loss 0.798476, acc 0.75\n",
      "2017-04-03T19:36:40.037422: step 5621, loss 0.900761, acc 0.734375\n",
      "2017-04-03T19:36:40.237299: step 5622, loss 0.904763, acc 0.71875\n",
      "2017-04-03T19:36:40.441941: step 5623, loss 0.846692, acc 0.65625\n",
      "2017-04-03T19:36:40.647957: step 5624, loss 0.789281, acc 0.6875\n",
      "2017-04-03T19:36:40.847907: step 5625, loss 0.791078, acc 0.734375\n",
      "2017-04-03T19:36:41.052056: step 5626, loss 0.740151, acc 0.8125\n",
      "2017-04-03T19:36:41.261721: step 5627, loss 0.68545, acc 0.765625\n",
      "2017-04-03T19:36:41.508407: step 5628, loss 0.883752, acc 0.71875\n",
      "2017-04-03T19:36:41.711629: step 5629, loss 0.925034, acc 0.703125\n",
      "2017-04-03T19:36:41.857107: step 5630, loss 0.851363, acc 0.6875\n",
      "2017-04-03T19:36:42.102827: step 5631, loss 0.494914, acc 0.84375\n",
      "2017-04-03T19:36:42.305348: step 5632, loss 0.478259, acc 0.84375\n",
      "2017-04-03T19:36:42.510670: step 5633, loss 0.622782, acc 0.75\n",
      "2017-04-03T19:36:42.759708: step 5634, loss 0.666759, acc 0.703125\n",
      "2017-04-03T19:36:42.979609: step 5635, loss 0.563048, acc 0.828125\n",
      "2017-04-03T19:36:43.181697: step 5636, loss 0.630223, acc 0.8125\n",
      "2017-04-03T19:36:43.429522: step 5637, loss 0.37445, acc 0.9375\n",
      "2017-04-03T19:36:43.634484: step 5638, loss 0.631304, acc 0.75\n",
      "2017-04-03T19:36:43.841467: step 5639, loss 0.418388, acc 0.84375\n",
      "2017-04-03T19:36:44.046740: step 5640, loss 0.620702, acc 0.78125\n",
      "2017-04-03T19:36:44.252836: step 5641, loss 0.521319, acc 0.875\n",
      "2017-04-03T19:36:44.458682: step 5642, loss 0.674481, acc 0.78125\n",
      "2017-04-03T19:36:44.663131: step 5643, loss 0.600624, acc 0.828125\n",
      "2017-04-03T19:36:44.866874: step 5644, loss 0.455348, acc 0.875\n",
      "2017-04-03T19:36:45.068250: step 5645, loss 0.604601, acc 0.78125\n",
      "2017-04-03T19:36:45.282974: step 5646, loss 0.56537, acc 0.8125\n",
      "2017-04-03T19:36:45.487627: step 5647, loss 0.467846, acc 0.84375\n",
      "2017-04-03T19:36:45.741452: step 5648, loss 0.510178, acc 0.828125\n",
      "2017-04-03T19:36:45.953413: step 5649, loss 0.46036, acc 0.8125\n",
      "2017-04-03T19:36:46.158052: step 5650, loss 0.640739, acc 0.75\n",
      "2017-04-03T19:36:46.361155: step 5651, loss 0.571316, acc 0.8125\n",
      "2017-04-03T19:36:46.565527: step 5652, loss 0.512487, acc 0.78125\n",
      "2017-04-03T19:36:46.810816: step 5653, loss 0.542391, acc 0.84375\n",
      "2017-04-03T19:36:47.022900: step 5654, loss 0.560451, acc 0.84375\n",
      "2017-04-03T19:36:47.222347: step 5655, loss 0.553314, acc 0.8125\n",
      "2017-04-03T19:36:47.423184: step 5656, loss 0.487782, acc 0.859375\n",
      "2017-04-03T19:36:47.626722: step 5657, loss 0.636232, acc 0.828125\n",
      "2017-04-03T19:36:47.835508: step 5658, loss 0.504321, acc 0.859375\n",
      "2017-04-03T19:36:48.077265: step 5659, loss 0.745581, acc 0.75\n",
      "2017-04-03T19:36:48.291181: step 5660, loss 0.676299, acc 0.796875\n",
      "2017-04-03T19:36:48.511937: step 5661, loss 0.552314, acc 0.84375\n",
      "2017-04-03T19:36:48.732922: step 5662, loss 0.56012, acc 0.828125\n",
      "2017-04-03T19:36:48.934553: step 5663, loss 0.466533, acc 0.828125\n",
      "2017-04-03T19:36:49.142917: step 5664, loss 0.525205, acc 0.796875\n",
      "2017-04-03T19:36:49.350326: step 5665, loss 0.742512, acc 0.703125\n",
      "2017-04-03T19:36:49.548857: step 5666, loss 0.605119, acc 0.75\n",
      "2017-04-03T19:36:49.749627: step 5667, loss 0.455741, acc 0.890625\n",
      "2017-04-03T19:36:49.952860: step 5668, loss 0.681266, acc 0.75\n",
      "2017-04-03T19:36:50.164766: step 5669, loss 0.712096, acc 0.703125\n",
      "2017-04-03T19:36:50.371361: step 5670, loss 0.44515, acc 0.859375\n",
      "2017-04-03T19:36:50.572927: step 5671, loss 0.700217, acc 0.765625\n",
      "2017-04-03T19:36:50.774801: step 5672, loss 0.533225, acc 0.796875\n",
      "2017-04-03T19:36:50.982848: step 5673, loss 0.643328, acc 0.828125\n",
      "2017-04-03T19:36:51.187269: step 5674, loss 0.7211, acc 0.6875\n",
      "2017-04-03T19:36:51.392615: step 5675, loss 0.675956, acc 0.75\n",
      "2017-04-03T19:36:51.594349: step 5676, loss 0.535145, acc 0.78125\n",
      "2017-04-03T19:36:51.802018: step 5677, loss 0.444828, acc 0.875\n",
      "2017-04-03T19:36:52.000782: step 5678, loss 0.432957, acc 0.9375\n",
      "2017-04-03T19:36:52.250583: step 5679, loss 0.595013, acc 0.75\n",
      "2017-04-03T19:36:52.455155: step 5680, loss 0.518123, acc 0.875\n",
      "2017-04-03T19:36:52.657072: step 5681, loss 0.508621, acc 0.8125\n",
      "2017-04-03T19:36:52.860069: step 5682, loss 0.68221, acc 0.78125\n",
      "2017-04-03T19:36:53.065205: step 5683, loss 0.881162, acc 0.65625\n",
      "2017-04-03T19:36:53.311766: step 5684, loss 0.527299, acc 0.8125\n",
      "2017-04-03T19:36:53.519780: step 5685, loss 0.580032, acc 0.828125\n",
      "2017-04-03T19:36:53.728034: step 5686, loss 0.645587, acc 0.75\n",
      "2017-04-03T19:36:53.932219: step 5687, loss 0.540085, acc 0.859375\n",
      "2017-04-03T19:36:54.135082: step 5688, loss 0.587598, acc 0.828125\n",
      "2017-04-03T19:36:54.338516: step 5689, loss 0.377814, acc 0.90625\n",
      "2017-04-03T19:36:54.551624: step 5690, loss 0.602844, acc 0.78125\n",
      "2017-04-03T19:36:54.753894: step 5691, loss 0.514072, acc 0.84375\n",
      "2017-04-03T19:36:54.957320: step 5692, loss 0.639591, acc 0.8125\n",
      "2017-04-03T19:36:55.160132: step 5693, loss 0.46546, acc 0.828125\n",
      "2017-04-03T19:36:55.363223: step 5694, loss 0.529115, acc 0.828125\n",
      "2017-04-03T19:36:55.573896: step 5695, loss 0.640522, acc 0.796875\n",
      "2017-04-03T19:36:55.825022: step 5696, loss 0.496309, acc 0.828125\n",
      "2017-04-03T19:36:56.028558: step 5697, loss 0.640968, acc 0.796875\n",
      "2017-04-03T19:36:56.232794: step 5698, loss 0.594207, acc 0.796875\n",
      "2017-04-03T19:36:56.434686: step 5699, loss 0.445276, acc 0.890625\n",
      "2017-04-03T19:36:56.636344: step 5700, loss 0.474765, acc 0.828125\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:36:58.655893: step 5700, loss 2.4844, acc 0.3275\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-5700\n",
      "\n",
      "2017-04-03T19:36:58.994605: step 5701, loss 0.481329, acc 0.859375\n",
      "2017-04-03T19:36:59.209877: step 5702, loss 0.505618, acc 0.84375\n",
      "2017-04-03T19:36:59.418928: step 5703, loss 0.604337, acc 0.703125\n",
      "2017-04-03T19:36:59.625221: step 5704, loss 0.667187, acc 0.75\n",
      "2017-04-03T19:36:59.834352: step 5705, loss 0.670698, acc 0.734375\n",
      "2017-04-03T19:37:00.040793: step 5706, loss 0.493521, acc 0.8125\n",
      "2017-04-03T19:37:00.247594: step 5707, loss 0.508145, acc 0.828125\n",
      "2017-04-03T19:37:00.444587: step 5708, loss 0.477095, acc 0.84375\n",
      "2017-04-03T19:37:00.652959: step 5709, loss 0.617894, acc 0.765625\n",
      "2017-04-03T19:37:00.897240: step 5710, loss 0.620687, acc 0.8125\n",
      "2017-04-03T19:37:01.106082: step 5711, loss 0.56221, acc 0.84375\n",
      "2017-04-03T19:37:01.313768: step 5712, loss 0.539558, acc 0.828125\n",
      "2017-04-03T19:37:01.524188: step 5713, loss 0.525571, acc 0.84375\n",
      "2017-04-03T19:37:01.727925: step 5714, loss 0.447953, acc 0.859375\n",
      "2017-04-03T19:37:01.947451: step 5715, loss 0.579289, acc 0.84375\n",
      "2017-04-03T19:37:02.153245: step 5716, loss 0.548522, acc 0.796875\n",
      "2017-04-03T19:37:02.398336: step 5717, loss 0.699258, acc 0.765625\n",
      "2017-04-03T19:37:02.603898: step 5718, loss 0.576777, acc 0.8125\n",
      "2017-04-03T19:37:02.809015: step 5719, loss 0.514972, acc 0.828125\n",
      "2017-04-03T19:37:03.013243: step 5720, loss 0.661485, acc 0.75\n",
      "2017-04-03T19:37:03.220976: step 5721, loss 0.713612, acc 0.703125\n",
      "2017-04-03T19:37:03.423070: step 5722, loss 0.690584, acc 0.765625\n",
      "2017-04-03T19:37:03.625367: step 5723, loss 0.63715, acc 0.84375\n",
      "2017-04-03T19:37:03.827165: step 5724, loss 0.432267, acc 0.890625\n",
      "2017-04-03T19:37:04.030879: step 5725, loss 0.544129, acc 0.796875\n",
      "2017-04-03T19:37:04.231719: step 5726, loss 0.768525, acc 0.734375\n",
      "2017-04-03T19:37:04.438716: step 5727, loss 0.595905, acc 0.859375\n",
      "2017-04-03T19:37:04.639849: step 5728, loss 0.813232, acc 0.703125\n",
      "2017-04-03T19:37:04.844969: step 5729, loss 0.567478, acc 0.796875\n",
      "2017-04-03T19:37:05.049675: step 5730, loss 0.521062, acc 0.8125\n",
      "2017-04-03T19:37:05.251410: step 5731, loss 0.556957, acc 0.828125\n",
      "2017-04-03T19:37:05.454169: step 5732, loss 0.479528, acc 0.859375\n",
      "2017-04-03T19:37:05.661737: step 5733, loss 0.554787, acc 0.828125\n",
      "2017-04-03T19:37:05.862581: step 5734, loss 0.580035, acc 0.765625\n",
      "2017-04-03T19:37:06.066717: step 5735, loss 0.502977, acc 0.84375\n",
      "2017-04-03T19:37:06.271778: step 5736, loss 0.651225, acc 0.765625\n",
      "2017-04-03T19:37:06.483730: step 5737, loss 0.782025, acc 0.71875\n",
      "2017-04-03T19:37:06.694205: step 5738, loss 0.805529, acc 0.78125\n",
      "2017-04-03T19:37:06.898951: step 5739, loss 0.495011, acc 0.875\n",
      "2017-04-03T19:37:07.098423: step 5740, loss 0.820707, acc 0.703125\n",
      "2017-04-03T19:37:07.307096: step 5741, loss 0.52186, acc 0.859375\n",
      "2017-04-03T19:37:07.551269: step 5742, loss 0.475808, acc 0.84375\n",
      "2017-04-03T19:37:07.754929: step 5743, loss 0.554708, acc 0.859375\n",
      "2017-04-03T19:37:07.959437: step 5744, loss 0.517061, acc 0.875\n",
      "2017-04-03T19:37:08.176790: step 5745, loss 0.712441, acc 0.734375\n",
      "2017-04-03T19:37:08.381491: step 5746, loss 0.642857, acc 0.8125\n",
      "2017-04-03T19:37:08.582231: step 5747, loss 0.509152, acc 0.84375\n",
      "2017-04-03T19:37:08.788332: step 5748, loss 0.662923, acc 0.75\n",
      "2017-04-03T19:37:08.989202: step 5749, loss 0.65732, acc 0.78125\n",
      "2017-04-03T19:37:09.190471: step 5750, loss 0.625831, acc 0.765625\n",
      "2017-04-03T19:37:09.391465: step 5751, loss 0.683063, acc 0.796875\n",
      "2017-04-03T19:37:09.597641: step 5752, loss 0.695931, acc 0.75\n",
      "2017-04-03T19:37:09.805118: step 5753, loss 0.401124, acc 0.84375\n",
      "2017-04-03T19:37:10.015078: step 5754, loss 0.650904, acc 0.796875\n",
      "2017-04-03T19:37:10.218064: step 5755, loss 0.609924, acc 0.84375\n",
      "2017-04-03T19:37:10.419215: step 5756, loss 0.663036, acc 0.8125\n",
      "2017-04-03T19:37:10.621380: step 5757, loss 0.620515, acc 0.78125\n",
      "2017-04-03T19:37:10.834509: step 5758, loss 0.622454, acc 0.828125\n",
      "2017-04-03T19:37:11.036651: step 5759, loss 0.479198, acc 0.859375\n",
      "2017-04-03T19:37:11.259965: step 5760, loss 0.666516, acc 0.75\n",
      "2017-04-03T19:37:11.513907: step 5761, loss 0.585086, acc 0.84375\n",
      "2017-04-03T19:37:11.723467: step 5762, loss 0.633176, acc 0.734375\n",
      "2017-04-03T19:37:11.932014: step 5763, loss 0.48248, acc 0.828125\n",
      "2017-04-03T19:37:12.131011: step 5764, loss 0.439204, acc 0.890625\n",
      "2017-04-03T19:37:12.339105: step 5765, loss 0.521367, acc 0.84375\n",
      "2017-04-03T19:37:12.543569: step 5766, loss 0.483517, acc 0.859375\n",
      "2017-04-03T19:37:12.749139: step 5767, loss 0.700965, acc 0.765625\n",
      "2017-04-03T19:37:12.954447: step 5768, loss 0.651117, acc 0.78125\n",
      "2017-04-03T19:37:13.154324: step 5769, loss 0.789561, acc 0.75\n",
      "2017-04-03T19:37:13.409957: step 5770, loss 0.734155, acc 0.765625\n",
      "2017-04-03T19:37:13.620877: step 5771, loss 0.667, acc 0.8125\n",
      "2017-04-03T19:37:13.823265: step 5772, loss 0.645427, acc 0.828125\n",
      "2017-04-03T19:37:14.025869: step 5773, loss 0.68285, acc 0.78125\n",
      "2017-04-03T19:37:14.226852: step 5774, loss 0.409031, acc 0.875\n",
      "2017-04-03T19:37:14.429239: step 5775, loss 0.605604, acc 0.765625\n",
      "2017-04-03T19:37:14.630858: step 5776, loss 0.657745, acc 0.75\n",
      "2017-04-03T19:37:14.858917: step 5777, loss 0.524627, acc 0.84375\n",
      "2017-04-03T19:37:15.109605: step 5778, loss 0.50793, acc 0.859375\n",
      "2017-04-03T19:37:15.310761: step 5779, loss 0.57222, acc 0.8125\n",
      "2017-04-03T19:37:15.556909: step 5780, loss 0.418664, acc 0.859375\n",
      "2017-04-03T19:37:15.758247: step 5781, loss 0.369704, acc 0.859375\n",
      "2017-04-03T19:37:15.960400: step 5782, loss 0.528754, acc 0.8125\n",
      "2017-04-03T19:37:16.217616: step 5783, loss 0.740993, acc 0.6875\n",
      "2017-04-03T19:37:16.420247: step 5784, loss 0.409886, acc 0.859375\n",
      "2017-04-03T19:37:16.619967: step 5785, loss 0.888768, acc 0.6875\n",
      "2017-04-03T19:37:16.828233: step 5786, loss 0.764746, acc 0.78125\n",
      "2017-04-03T19:37:17.030605: step 5787, loss 0.490957, acc 0.78125\n",
      "2017-04-03T19:37:17.234541: step 5788, loss 0.65679, acc 0.765625\n",
      "2017-04-03T19:37:17.447371: step 5789, loss 0.511832, acc 0.890625\n",
      "2017-04-03T19:37:17.648656: step 5790, loss 0.549942, acc 0.78125\n",
      "2017-04-03T19:37:17.852364: step 5791, loss 0.448957, acc 0.828125\n",
      "2017-04-03T19:37:18.056962: step 5792, loss 0.678904, acc 0.734375\n",
      "2017-04-03T19:37:18.257040: step 5793, loss 0.838511, acc 0.6875\n",
      "2017-04-03T19:37:18.463624: step 5794, loss 0.79959, acc 0.734375\n",
      "2017-04-03T19:37:18.663836: step 5795, loss 0.587975, acc 0.828125\n",
      "2017-04-03T19:37:18.909427: step 5796, loss 0.459153, acc 0.859375\n",
      "2017-04-03T19:37:19.108758: step 5797, loss 0.769281, acc 0.78125\n",
      "2017-04-03T19:37:19.308858: step 5798, loss 0.474125, acc 0.890625\n",
      "2017-04-03T19:37:19.508263: step 5799, loss 0.849468, acc 0.71875\n",
      "2017-04-03T19:37:19.712076: step 5800, loss 0.566309, acc 0.8125\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:37:21.715724: step 5800, loss 2.53757, acc 0.3275\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-5800\n",
      "\n",
      "2017-04-03T19:37:22.044864: step 5801, loss 0.60352, acc 0.8125\n",
      "2017-04-03T19:37:22.248399: step 5802, loss 0.574281, acc 0.828125\n",
      "2017-04-03T19:37:22.451989: step 5803, loss 0.637039, acc 0.796875\n",
      "2017-04-03T19:37:22.654866: step 5804, loss 0.954797, acc 0.625\n",
      "2017-04-03T19:37:22.855223: step 5805, loss 0.432203, acc 0.859375\n",
      "2017-04-03T19:37:23.098182: step 5806, loss 0.582481, acc 0.765625\n",
      "2017-04-03T19:37:23.348752: step 5807, loss 0.543487, acc 0.8125\n",
      "2017-04-03T19:37:23.590197: step 5808, loss 0.891535, acc 0.734375\n",
      "2017-04-03T19:37:23.797625: step 5809, loss 0.781371, acc 0.734375\n",
      "2017-04-03T19:37:24.004687: step 5810, loss 0.774679, acc 0.71875\n",
      "2017-04-03T19:37:24.206431: step 5811, loss 0.58322, acc 0.8125\n",
      "2017-04-03T19:37:24.412995: step 5812, loss 0.73455, acc 0.8125\n",
      "2017-04-03T19:37:24.623169: step 5813, loss 0.533202, acc 0.796875\n",
      "2017-04-03T19:37:24.835183: step 5814, loss 0.484236, acc 0.890625\n",
      "2017-04-03T19:37:25.038231: step 5815, loss 0.545672, acc 0.828125\n",
      "2017-04-03T19:37:25.241298: step 5816, loss 0.596036, acc 0.796875\n",
      "2017-04-03T19:37:25.442151: step 5817, loss 0.541453, acc 0.78125\n",
      "2017-04-03T19:37:25.695658: step 5818, loss 0.533391, acc 0.84375\n",
      "2017-04-03T19:37:25.899857: step 5819, loss 0.616973, acc 0.765625\n",
      "2017-04-03T19:37:26.103382: step 5820, loss 0.668567, acc 0.78125\n",
      "2017-04-03T19:37:26.301965: step 5821, loss 0.579861, acc 0.78125\n",
      "2017-04-03T19:37:26.516078: step 5822, loss 0.794353, acc 0.703125\n",
      "2017-04-03T19:37:26.711423: step 5823, loss 0.686016, acc 0.71875\n",
      "2017-04-03T19:37:26.909306: step 5824, loss 0.713539, acc 0.78125\n",
      "2017-04-03T19:37:27.114401: step 5825, loss 0.751562, acc 0.75\n",
      "2017-04-03T19:37:27.324599: step 5826, loss 0.456475, acc 0.859375\n",
      "2017-04-03T19:37:27.525025: step 5827, loss 0.587554, acc 0.875\n",
      "2017-04-03T19:37:27.727260: step 5828, loss 0.43745, acc 0.84375\n",
      "2017-04-03T19:37:27.930324: step 5829, loss 0.719107, acc 0.78125\n",
      "2017-04-03T19:37:28.131304: step 5830, loss 0.684029, acc 0.78125\n",
      "2017-04-03T19:37:28.332886: step 5831, loss 0.481746, acc 0.828125\n",
      "2017-04-03T19:37:28.533826: step 5832, loss 0.707885, acc 0.71875\n",
      "2017-04-03T19:37:28.732099: step 5833, loss 0.60338, acc 0.796875\n",
      "2017-04-03T19:37:28.932029: step 5834, loss 0.742249, acc 0.734375\n",
      "2017-04-03T19:37:29.133506: step 5835, loss 0.437184, acc 0.859375\n",
      "2017-04-03T19:37:29.329998: step 5836, loss 0.629211, acc 0.84375\n",
      "2017-04-03T19:37:29.530439: step 5837, loss 0.557288, acc 0.890625\n",
      "2017-04-03T19:37:29.730058: step 5838, loss 0.574698, acc 0.859375\n",
      "2017-04-03T19:37:29.933088: step 5839, loss 0.541359, acc 0.796875\n",
      "2017-04-03T19:37:30.133137: step 5840, loss 0.784809, acc 0.75\n",
      "2017-04-03T19:37:30.342795: step 5841, loss 0.700699, acc 0.75\n",
      "2017-04-03T19:37:30.535408: step 5842, loss 0.409324, acc 0.828125\n",
      "2017-04-03T19:37:30.742238: step 5843, loss 0.759639, acc 0.765625\n",
      "2017-04-03T19:37:30.942068: step 5844, loss 0.493065, acc 0.828125\n",
      "2017-04-03T19:37:31.138854: step 5845, loss 0.753094, acc 0.78125\n",
      "2017-04-03T19:37:31.339459: step 5846, loss 0.524228, acc 0.875\n",
      "2017-04-03T19:37:31.587348: step 5847, loss 0.651254, acc 0.78125\n",
      "2017-04-03T19:37:31.789262: step 5848, loss 0.59427, acc 0.84375\n",
      "2017-04-03T19:37:31.995818: step 5849, loss 0.472173, acc 0.828125\n",
      "2017-04-03T19:37:32.196076: step 5850, loss 0.396632, acc 0.875\n",
      "2017-04-03T19:37:32.399287: step 5851, loss 0.843265, acc 0.75\n",
      "2017-04-03T19:37:32.641001: step 5852, loss 0.611493, acc 0.734375\n",
      "2017-04-03T19:37:32.841985: step 5853, loss 0.67786, acc 0.796875\n",
      "2017-04-03T19:37:33.045026: step 5854, loss 0.646139, acc 0.78125\n",
      "2017-04-03T19:37:33.243533: step 5855, loss 0.641537, acc 0.8125\n",
      "2017-04-03T19:37:33.446097: step 5856, loss 0.541016, acc 0.8125\n",
      "2017-04-03T19:37:33.646502: step 5857, loss 0.5402, acc 0.8125\n",
      "2017-04-03T19:37:33.894410: step 5858, loss 0.566877, acc 0.78125\n",
      "2017-04-03T19:37:34.101039: step 5859, loss 0.669944, acc 0.796875\n",
      "2017-04-03T19:37:34.303364: step 5860, loss 0.668045, acc 0.765625\n",
      "2017-04-03T19:37:34.508029: step 5861, loss 0.69262, acc 0.765625\n",
      "2017-04-03T19:37:34.708635: step 5862, loss 0.739227, acc 0.703125\n",
      "2017-04-03T19:37:34.958863: step 5863, loss 0.657266, acc 0.8125\n",
      "2017-04-03T19:37:35.168142: step 5864, loss 0.519019, acc 0.84375\n",
      "2017-04-03T19:37:35.374096: step 5865, loss 0.799108, acc 0.75\n",
      "2017-04-03T19:37:35.576237: step 5866, loss 0.640927, acc 0.78125\n",
      "2017-04-03T19:37:35.817916: step 5867, loss 0.560346, acc 0.796875\n",
      "2017-04-03T19:37:36.015853: step 5868, loss 0.799011, acc 0.6875\n",
      "2017-04-03T19:37:36.217340: step 5869, loss 0.513254, acc 0.859375\n",
      "2017-04-03T19:37:36.419127: step 5870, loss 0.597038, acc 0.796875\n",
      "2017-04-03T19:37:36.615007: step 5871, loss 0.792031, acc 0.6875\n",
      "2017-04-03T19:37:36.858489: step 5872, loss 0.538593, acc 0.84375\n",
      "2017-04-03T19:37:37.082302: step 5873, loss 0.753654, acc 0.78125\n",
      "2017-04-03T19:37:37.283825: step 5874, loss 0.744071, acc 0.75\n",
      "2017-04-03T19:37:37.485079: step 5875, loss 0.502148, acc 0.875\n",
      "2017-04-03T19:37:37.687051: step 5876, loss 0.603164, acc 0.796875\n",
      "2017-04-03T19:37:37.888905: step 5877, loss 0.626502, acc 0.828125\n",
      "2017-04-03T19:37:38.091436: step 5878, loss 0.695134, acc 0.765625\n",
      "2017-04-03T19:37:38.294703: step 5879, loss 0.582497, acc 0.78125\n",
      "2017-04-03T19:37:38.491040: step 5880, loss 0.749199, acc 0.765625\n",
      "2017-04-03T19:37:38.689982: step 5881, loss 0.543271, acc 0.796875\n",
      "2017-04-03T19:37:38.890490: step 5882, loss 0.809209, acc 0.765625\n",
      "2017-04-03T19:37:39.091773: step 5883, loss 0.595777, acc 0.78125\n",
      "2017-04-03T19:37:39.293687: step 5884, loss 0.696093, acc 0.734375\n",
      "2017-04-03T19:37:39.539550: step 5885, loss 0.689282, acc 0.75\n",
      "2017-04-03T19:37:39.739059: step 5886, loss 0.553076, acc 0.8125\n",
      "2017-04-03T19:37:39.983493: step 5887, loss 0.631011, acc 0.78125\n",
      "2017-04-03T19:37:40.225231: step 5888, loss 0.612024, acc 0.796875\n",
      "2017-04-03T19:37:40.474195: step 5889, loss 0.560727, acc 0.8125\n",
      "2017-04-03T19:37:40.676208: step 5890, loss 0.448332, acc 0.890625\n",
      "2017-04-03T19:37:40.876927: step 5891, loss 0.547101, acc 0.84375\n",
      "2017-04-03T19:37:41.081651: step 5892, loss 0.765384, acc 0.765625\n",
      "2017-04-03T19:37:41.326166: step 5893, loss 0.751855, acc 0.78125\n",
      "2017-04-03T19:37:41.569370: step 5894, loss 0.81159, acc 0.71875\n",
      "2017-04-03T19:37:41.780676: step 5895, loss 0.66532, acc 0.75\n",
      "2017-04-03T19:37:42.023428: step 5896, loss 0.624197, acc 0.84375\n",
      "2017-04-03T19:37:42.224245: step 5897, loss 0.636522, acc 0.75\n",
      "2017-04-03T19:37:42.467572: step 5898, loss 0.668312, acc 0.765625\n",
      "2017-04-03T19:37:42.721404: step 5899, loss 0.749261, acc 0.8125\n",
      "2017-04-03T19:37:42.956852: step 5900, loss 0.694183, acc 0.75\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:37:44.986569: step 5900, loss 2.57145, acc 0.33275\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-5900\n",
      "\n",
      "2017-04-03T19:37:45.324863: step 5901, loss 0.5321, acc 0.84375\n",
      "2017-04-03T19:37:45.544762: step 5902, loss 0.873228, acc 0.6875\n",
      "2017-04-03T19:37:45.744964: step 5903, loss 0.644422, acc 0.796875\n",
      "2017-04-03T19:37:45.948392: step 5904, loss 0.628858, acc 0.84375\n",
      "2017-04-03T19:37:46.153320: step 5905, loss 0.521198, acc 0.8125\n",
      "2017-04-03T19:37:46.351872: step 5906, loss 0.41159, acc 0.890625\n",
      "2017-04-03T19:37:46.595200: step 5907, loss 0.642046, acc 0.796875\n",
      "2017-04-03T19:37:46.793297: step 5908, loss 0.598557, acc 0.796875\n",
      "2017-04-03T19:37:46.995253: step 5909, loss 0.613409, acc 0.796875\n",
      "2017-04-03T19:37:47.195487: step 5910, loss 0.666754, acc 0.8125\n",
      "2017-04-03T19:37:47.395718: step 5911, loss 0.534355, acc 0.8125\n",
      "2017-04-03T19:37:47.596928: step 5912, loss 0.539768, acc 0.828125\n",
      "2017-04-03T19:37:47.796398: step 5913, loss 0.585656, acc 0.8125\n",
      "2017-04-03T19:37:47.997710: step 5914, loss 0.7243, acc 0.734375\n",
      "2017-04-03T19:37:48.200881: step 5915, loss 0.659775, acc 0.828125\n",
      "2017-04-03T19:37:48.398987: step 5916, loss 0.712403, acc 0.78125\n",
      "2017-04-03T19:37:48.642760: step 5917, loss 0.625622, acc 0.796875\n",
      "2017-04-03T19:37:48.845585: step 5918, loss 0.611418, acc 0.78125\n",
      "2017-04-03T19:37:49.044440: step 5919, loss 0.601677, acc 0.796875\n",
      "2017-04-03T19:37:49.246944: step 5920, loss 0.734844, acc 0.734375\n",
      "2017-04-03T19:37:49.448105: step 5921, loss 0.566366, acc 0.8125\n",
      "2017-04-03T19:37:49.649252: step 5922, loss 0.500871, acc 0.859375\n",
      "2017-04-03T19:37:49.858272: step 5923, loss 0.770517, acc 0.703125\n",
      "2017-04-03T19:37:50.066018: step 5924, loss 0.708012, acc 0.828125\n",
      "2017-04-03T19:37:50.268033: step 5925, loss 0.732017, acc 0.734375\n",
      "2017-04-03T19:37:50.468022: step 5926, loss 0.759366, acc 0.796875\n",
      "2017-04-03T19:37:50.666141: step 5927, loss 0.765641, acc 0.8125\n",
      "2017-04-03T19:37:50.867378: step 5928, loss 0.508844, acc 0.796875\n",
      "2017-04-03T19:37:51.065949: step 5929, loss 0.689942, acc 0.796875\n",
      "2017-04-03T19:37:51.265593: step 5930, loss 0.570411, acc 0.828125\n",
      "2017-04-03T19:37:51.469175: step 5931, loss 0.570285, acc 0.796875\n",
      "2017-04-03T19:37:51.669348: step 5932, loss 0.667308, acc 0.75\n",
      "2017-04-03T19:37:51.869081: step 5933, loss 0.636379, acc 0.796875\n",
      "2017-04-03T19:37:52.070693: step 5934, loss 0.552228, acc 0.78125\n",
      "2017-04-03T19:37:52.274238: step 5935, loss 0.569875, acc 0.765625\n",
      "2017-04-03T19:37:52.470538: step 5936, loss 0.62151, acc 0.796875\n",
      "2017-04-03T19:37:52.675146: step 5937, loss 0.759236, acc 0.796875\n",
      "2017-04-03T19:37:52.879343: step 5938, loss 0.516064, acc 0.828125\n",
      "2017-04-03T19:37:53.082702: step 5939, loss 0.616039, acc 0.75\n",
      "2017-04-03T19:37:53.283967: step 5940, loss 0.634025, acc 0.75\n",
      "2017-04-03T19:37:53.486637: step 5941, loss 0.785038, acc 0.765625\n",
      "2017-04-03T19:37:53.688139: step 5942, loss 0.513527, acc 0.84375\n",
      "2017-04-03T19:37:53.931349: step 5943, loss 0.650031, acc 0.78125\n",
      "2017-04-03T19:37:54.179102: step 5944, loss 0.506241, acc 0.859375\n",
      "2017-04-03T19:37:54.388717: step 5945, loss 0.548282, acc 0.859375\n",
      "2017-04-03T19:37:54.588792: step 5946, loss 0.739818, acc 0.78125\n",
      "2017-04-03T19:37:54.806843: step 5947, loss 0.588101, acc 0.796875\n",
      "2017-04-03T19:37:55.008660: step 5948, loss 0.535688, acc 0.84375\n",
      "2017-04-03T19:37:55.221238: step 5949, loss 0.504623, acc 0.828125\n",
      "2017-04-03T19:37:55.425404: step 5950, loss 0.620373, acc 0.78125\n",
      "2017-04-03T19:37:55.627413: step 5951, loss 0.681719, acc 0.765625\n",
      "2017-04-03T19:37:55.832994: step 5952, loss 0.456374, acc 0.875\n",
      "2017-04-03T19:37:56.035518: step 5953, loss 0.652777, acc 0.796875\n",
      "2017-04-03T19:37:56.235815: step 5954, loss 0.827981, acc 0.65625\n",
      "2017-04-03T19:37:56.440230: step 5955, loss 0.824973, acc 0.6875\n",
      "2017-04-03T19:37:56.644215: step 5956, loss 0.40863, acc 0.890625\n",
      "2017-04-03T19:37:56.848873: step 5957, loss 0.42404, acc 0.90625\n",
      "2017-04-03T19:37:57.051918: step 5958, loss 0.509541, acc 0.8125\n",
      "2017-04-03T19:37:57.254335: step 5959, loss 0.640902, acc 0.84375\n",
      "2017-04-03T19:37:57.455880: step 5960, loss 0.815307, acc 0.765625\n",
      "2017-04-03T19:37:57.653082: step 5961, loss 0.543271, acc 0.859375\n",
      "2017-04-03T19:37:57.863482: step 5962, loss 0.653841, acc 0.8125\n",
      "2017-04-03T19:37:58.065381: step 5963, loss 0.498516, acc 0.828125\n",
      "2017-04-03T19:37:58.305963: step 5964, loss 0.810678, acc 0.671875\n",
      "2017-04-03T19:37:58.514937: step 5965, loss 0.644467, acc 0.8125\n",
      "2017-04-03T19:37:58.713407: step 5966, loss 0.591247, acc 0.8125\n",
      "2017-04-03T19:37:58.916500: step 5967, loss 0.815957, acc 0.75\n",
      "2017-04-03T19:37:59.121938: step 5968, loss 0.876869, acc 0.734375\n",
      "2017-04-03T19:37:59.324022: step 5969, loss 0.559868, acc 0.828125\n",
      "2017-04-03T19:37:59.527172: step 5970, loss 0.687809, acc 0.796875\n",
      "2017-04-03T19:37:59.728418: step 5971, loss 0.458065, acc 0.828125\n",
      "2017-04-03T19:37:59.971879: step 5972, loss 0.648379, acc 0.8125\n",
      "2017-04-03T19:38:00.217581: step 5973, loss 0.632237, acc 0.8125\n",
      "2017-04-03T19:38:00.421268: step 5974, loss 0.725744, acc 0.734375\n",
      "2017-04-03T19:38:00.625902: step 5975, loss 0.696699, acc 0.75\n",
      "2017-04-03T19:38:00.836239: step 5976, loss 0.702025, acc 0.78125\n",
      "2017-04-03T19:38:01.039702: step 5977, loss 0.39371, acc 0.90625\n",
      "2017-04-03T19:38:01.239190: step 5978, loss 0.714935, acc 0.734375\n",
      "2017-04-03T19:38:01.446811: step 5979, loss 0.637758, acc 0.8125\n",
      "2017-04-03T19:38:01.653592: step 5980, loss 0.631635, acc 0.8125\n",
      "2017-04-03T19:38:01.854463: step 5981, loss 0.543514, acc 0.8125\n",
      "2017-04-03T19:38:02.053674: step 5982, loss 0.677709, acc 0.734375\n",
      "2017-04-03T19:38:02.258341: step 5983, loss 0.862462, acc 0.796875\n",
      "2017-04-03T19:38:02.458702: step 5984, loss 0.666319, acc 0.84375\n",
      "2017-04-03T19:38:02.690542: step 5985, loss 0.460998, acc 0.875\n",
      "2017-04-03T19:38:02.890990: step 5986, loss 0.75669, acc 0.703125\n",
      "2017-04-03T19:38:03.134052: step 5987, loss 0.280663, acc 0.953125\n",
      "2017-04-03T19:38:03.333555: step 5988, loss 0.65543, acc 0.8125\n",
      "2017-04-03T19:38:03.540711: step 5989, loss 0.534627, acc 0.875\n",
      "2017-04-03T19:38:03.747593: step 5990, loss 0.611326, acc 0.796875\n",
      "2017-04-03T19:38:03.947743: step 5991, loss 0.723065, acc 0.71875\n",
      "2017-04-03T19:38:04.147061: step 5992, loss 0.569161, acc 0.78125\n",
      "2017-04-03T19:38:04.348122: step 5993, loss 0.766405, acc 0.734375\n",
      "2017-04-03T19:38:04.547501: step 5994, loss 0.707565, acc 0.796875\n",
      "2017-04-03T19:38:04.761245: step 5995, loss 0.4951, acc 0.8125\n",
      "2017-04-03T19:38:04.959658: step 5996, loss 0.659477, acc 0.78125\n",
      "2017-04-03T19:38:05.164982: step 5997, loss 0.620016, acc 0.78125\n",
      "2017-04-03T19:38:05.367870: step 5998, loss 0.950089, acc 0.6875\n",
      "2017-04-03T19:38:05.571320: step 5999, loss 0.378241, acc 0.921875\n",
      "2017-04-03T19:38:05.770506: step 6000, loss 0.689765, acc 0.75\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:38:07.766935: step 6000, loss 2.59198, acc 0.32975\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-6000\n",
      "\n",
      "2017-04-03T19:38:08.101079: step 6001, loss 0.604306, acc 0.8125\n",
      "2017-04-03T19:38:08.309261: step 6002, loss 0.642839, acc 0.78125\n",
      "2017-04-03T19:38:08.511937: step 6003, loss 0.660611, acc 0.765625\n",
      "2017-04-03T19:38:08.719837: step 6004, loss 0.512992, acc 0.796875\n",
      "2017-04-03T19:38:08.922582: step 6005, loss 0.708704, acc 0.78125\n",
      "2017-04-03T19:38:09.124149: step 6006, loss 0.647248, acc 0.765625\n",
      "2017-04-03T19:38:09.366997: step 6007, loss 0.582989, acc 0.828125\n",
      "2017-04-03T19:38:09.571217: step 6008, loss 0.872398, acc 0.765625\n",
      "2017-04-03T19:38:09.781509: step 6009, loss 0.774039, acc 0.734375\n",
      "2017-04-03T19:38:09.979882: step 6010, loss 0.839821, acc 0.671875\n",
      "2017-04-03T19:38:10.185687: step 6011, loss 0.807218, acc 0.734375\n",
      "2017-04-03T19:38:10.387054: step 6012, loss 0.588463, acc 0.796875\n",
      "2017-04-03T19:38:10.590253: step 6013, loss 0.596177, acc 0.84375\n",
      "2017-04-03T19:38:10.796712: step 6014, loss 0.738025, acc 0.703125\n",
      "2017-04-03T19:38:10.999842: step 6015, loss 0.600911, acc 0.78125\n",
      "2017-04-03T19:38:11.201787: step 6016, loss 0.612079, acc 0.796875\n",
      "2017-04-03T19:38:11.409823: step 6017, loss 0.594279, acc 0.8125\n",
      "2017-04-03T19:38:11.610183: step 6018, loss 0.697558, acc 0.71875\n",
      "2017-04-03T19:38:11.814266: step 6019, loss 0.712174, acc 0.8125\n",
      "2017-04-03T19:38:12.061279: step 6020, loss 0.699841, acc 0.734375\n",
      "2017-04-03T19:38:12.263120: step 6021, loss 0.660887, acc 0.828125\n",
      "2017-04-03T19:38:12.469228: step 6022, loss 0.748226, acc 0.75\n",
      "2017-04-03T19:38:12.687558: step 6023, loss 0.641657, acc 0.75\n",
      "2017-04-03T19:38:12.903442: step 6024, loss 0.492109, acc 0.84375\n",
      "2017-04-03T19:38:13.121545: step 6025, loss 0.734016, acc 0.78125\n",
      "2017-04-03T19:38:13.323065: step 6026, loss 0.525863, acc 0.828125\n",
      "2017-04-03T19:38:13.527083: step 6027, loss 0.603992, acc 0.796875\n",
      "2017-04-03T19:38:13.770498: step 6028, loss 0.774527, acc 0.6875\n",
      "2017-04-03T19:38:13.974359: step 6029, loss 0.760918, acc 0.78125\n",
      "2017-04-03T19:38:14.172941: step 6030, loss 0.694432, acc 0.78125\n",
      "2017-04-03T19:38:14.374468: step 6031, loss 0.590426, acc 0.828125\n",
      "2017-04-03T19:38:14.587963: step 6032, loss 0.666641, acc 0.78125\n",
      "2017-04-03T19:38:14.796975: step 6033, loss 0.44417, acc 0.84375\n",
      "2017-04-03T19:38:15.000361: step 6034, loss 0.725624, acc 0.78125\n",
      "2017-04-03T19:38:15.202638: step 6035, loss 0.754127, acc 0.78125\n",
      "2017-04-03T19:38:15.420165: step 6036, loss 0.728854, acc 0.71875\n",
      "2017-04-03T19:38:15.632082: step 6037, loss 0.617813, acc 0.796875\n",
      "2017-04-03T19:38:15.838661: step 6038, loss 0.725148, acc 0.703125\n",
      "2017-04-03T19:38:16.079616: step 6039, loss 0.587017, acc 0.796875\n",
      "2017-04-03T19:38:16.294138: step 6040, loss 0.608657, acc 0.78125\n",
      "2017-04-03T19:38:16.497267: step 6041, loss 0.560144, acc 0.78125\n",
      "2017-04-03T19:38:16.696209: step 6042, loss 0.633177, acc 0.78125\n",
      "2017-04-03T19:38:16.946991: step 6043, loss 0.661247, acc 0.765625\n",
      "2017-04-03T19:38:17.152254: step 6044, loss 0.651657, acc 0.75\n",
      "2017-04-03T19:38:17.360668: step 6045, loss 0.411108, acc 0.859375\n",
      "2017-04-03T19:38:17.569719: step 6046, loss 0.55161, acc 0.84375\n",
      "2017-04-03T19:38:17.774692: step 6047, loss 0.638426, acc 0.734375\n",
      "2017-04-03T19:38:17.988220: step 6048, loss 0.864352, acc 0.765625\n",
      "2017-04-03T19:38:18.191840: step 6049, loss 0.687168, acc 0.796875\n",
      "2017-04-03T19:38:18.397097: step 6050, loss 0.505956, acc 0.859375\n",
      "2017-04-03T19:38:18.598238: step 6051, loss 0.654701, acc 0.78125\n",
      "2017-04-03T19:38:18.804397: step 6052, loss 0.886088, acc 0.65625\n",
      "2017-04-03T19:38:19.009451: step 6053, loss 0.504018, acc 0.8125\n",
      "2017-04-03T19:38:19.219561: step 6054, loss 0.799878, acc 0.734375\n",
      "2017-04-03T19:38:19.465015: step 6055, loss 0.629421, acc 0.78125\n",
      "2017-04-03T19:38:19.662423: step 6056, loss 0.516966, acc 0.875\n",
      "2017-04-03T19:38:19.867144: step 6057, loss 0.48315, acc 0.8125\n",
      "2017-04-03T19:38:20.080361: step 6058, loss 0.722644, acc 0.765625\n",
      "2017-04-03T19:38:20.287067: step 6059, loss 0.633391, acc 0.734375\n",
      "2017-04-03T19:38:20.527379: step 6060, loss 0.765991, acc 0.75\n",
      "2017-04-03T19:38:20.731345: step 6061, loss 0.595954, acc 0.828125\n",
      "2017-04-03T19:38:20.937444: step 6062, loss 0.561826, acc 0.84375\n",
      "2017-04-03T19:38:21.144206: step 6063, loss 0.64148, acc 0.75\n",
      "2017-04-03T19:38:21.349375: step 6064, loss 0.823449, acc 0.6875\n",
      "2017-04-03T19:38:21.549718: step 6065, loss 0.658228, acc 0.796875\n",
      "2017-04-03T19:38:21.796327: step 6066, loss 0.595095, acc 0.796875\n",
      "2017-04-03T19:38:22.003097: step 6067, loss 0.699736, acc 0.734375\n",
      "2017-04-03T19:38:22.209277: step 6068, loss 0.881852, acc 0.734375\n",
      "2017-04-03T19:38:22.411705: step 6069, loss 0.794961, acc 0.71875\n",
      "2017-04-03T19:38:22.610018: step 6070, loss 0.807704, acc 0.765625\n",
      "2017-04-03T19:38:22.811390: step 6071, loss 0.637817, acc 0.796875\n",
      "2017-04-03T19:38:23.011295: step 6072, loss 0.626259, acc 0.734375\n",
      "2017-04-03T19:38:23.217814: step 6073, loss 0.51394, acc 0.84375\n",
      "2017-04-03T19:38:23.419471: step 6074, loss 0.683463, acc 0.765625\n",
      "2017-04-03T19:38:23.620014: step 6075, loss 0.634828, acc 0.78125\n",
      "2017-04-03T19:38:23.824111: step 6076, loss 0.796554, acc 0.671875\n",
      "2017-04-03T19:38:24.057192: step 6077, loss 0.712096, acc 0.71875\n",
      "2017-04-03T19:38:24.257053: step 6078, loss 0.745631, acc 0.71875\n",
      "2017-04-03T19:38:24.462869: step 6079, loss 0.805033, acc 0.71875\n",
      "2017-04-03T19:38:24.665346: step 6080, loss 0.563816, acc 0.8125\n",
      "2017-04-03T19:38:24.867212: step 6081, loss 0.659104, acc 0.8125\n",
      "2017-04-03T19:38:25.113702: step 6082, loss 0.574857, acc 0.84375\n",
      "2017-04-03T19:38:25.319146: step 6083, loss 0.674996, acc 0.71875\n",
      "2017-04-03T19:38:25.521220: step 6084, loss 0.459422, acc 0.84375\n",
      "2017-04-03T19:38:25.763556: step 6085, loss 0.617604, acc 0.75\n",
      "2017-04-03T19:38:25.974807: step 6086, loss 0.618487, acc 0.859375\n",
      "2017-04-03T19:38:26.176025: step 6087, loss 0.615312, acc 0.8125\n",
      "2017-04-03T19:38:26.378047: step 6088, loss 0.556567, acc 0.859375\n",
      "2017-04-03T19:38:26.580149: step 6089, loss 0.652065, acc 0.765625\n",
      "2017-04-03T19:38:26.823228: step 6090, loss 0.597907, acc 0.84375\n",
      "2017-04-03T19:38:27.023982: step 6091, loss 0.612022, acc 0.765625\n",
      "2017-04-03T19:38:27.231527: step 6092, loss 0.558894, acc 0.8125\n",
      "2017-04-03T19:38:27.437779: step 6093, loss 0.585648, acc 0.84375\n",
      "2017-04-03T19:38:27.640110: step 6094, loss 0.640948, acc 0.71875\n",
      "2017-04-03T19:38:27.848767: step 6095, loss 0.399562, acc 0.890625\n",
      "2017-04-03T19:38:28.067711: step 6096, loss 0.860373, acc 0.71875\n",
      "2017-04-03T19:38:28.311566: step 6097, loss 0.712817, acc 0.734375\n",
      "2017-04-03T19:38:28.521308: step 6098, loss 0.555908, acc 0.796875\n",
      "2017-04-03T19:38:28.763244: step 6099, loss 0.447004, acc 0.875\n",
      "2017-04-03T19:38:28.968332: step 6100, loss 0.775557, acc 0.75\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:38:30.982921: step 6100, loss 2.63649, acc 0.3315\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-6100\n",
      "\n",
      "2017-04-03T19:38:31.352340: step 6101, loss 0.610165, acc 0.8125\n",
      "2017-04-03T19:38:31.570808: step 6102, loss 0.67285, acc 0.71875\n",
      "2017-04-03T19:38:31.772486: step 6103, loss 0.592188, acc 0.796875\n",
      "2017-04-03T19:38:32.022132: step 6104, loss 0.66893, acc 0.78125\n",
      "2017-04-03T19:38:32.278492: step 6105, loss 0.724435, acc 0.75\n",
      "2017-04-03T19:38:32.480630: step 6106, loss 0.74465, acc 0.703125\n",
      "2017-04-03T19:38:32.689782: step 6107, loss 0.701231, acc 0.796875\n",
      "2017-04-03T19:38:32.893961: step 6108, loss 0.563462, acc 0.796875\n",
      "2017-04-03T19:38:33.115307: step 6109, loss 0.870184, acc 0.703125\n",
      "2017-04-03T19:38:33.331869: step 6110, loss 0.660011, acc 0.796875\n",
      "2017-04-03T19:38:33.551407: step 6111, loss 0.538895, acc 0.8125\n",
      "2017-04-03T19:38:33.751827: step 6112, loss 0.720291, acc 0.734375\n",
      "2017-04-03T19:38:33.955163: step 6113, loss 0.676381, acc 0.796875\n",
      "2017-04-03T19:38:34.159166: step 6114, loss 0.676826, acc 0.75\n",
      "2017-04-03T19:38:34.358726: step 6115, loss 0.60221, acc 0.78125\n",
      "2017-04-03T19:38:34.566392: step 6116, loss 0.498729, acc 0.84375\n",
      "2017-04-03T19:38:34.772449: step 6117, loss 0.691448, acc 0.765625\n",
      "2017-04-03T19:38:34.974533: step 6118, loss 0.653915, acc 0.71875\n",
      "2017-04-03T19:38:35.176725: step 6119, loss 0.567053, acc 0.84375\n",
      "2017-04-03T19:38:35.422635: step 6120, loss 0.636802, acc 0.71875\n",
      "2017-04-03T19:38:35.628637: step 6121, loss 0.573023, acc 0.828125\n",
      "2017-04-03T19:38:35.831012: step 6122, loss 0.563132, acc 0.828125\n",
      "2017-04-03T19:38:36.074674: step 6123, loss 0.815354, acc 0.734375\n",
      "2017-04-03T19:38:36.277928: step 6124, loss 0.905923, acc 0.640625\n",
      "2017-04-03T19:38:36.480056: step 6125, loss 0.636035, acc 0.78125\n",
      "2017-04-03T19:38:36.726630: step 6126, loss 0.687532, acc 0.734375\n",
      "2017-04-03T19:38:36.940258: step 6127, loss 0.803608, acc 0.75\n",
      "2017-04-03T19:38:37.156514: step 6128, loss 0.639681, acc 0.796875\n",
      "2017-04-03T19:38:37.370529: step 6129, loss 0.689017, acc 0.78125\n",
      "2017-04-03T19:38:37.573119: step 6130, loss 0.776336, acc 0.75\n",
      "2017-04-03T19:38:37.777520: step 6131, loss 0.789191, acc 0.6875\n",
      "2017-04-03T19:38:37.978968: step 6132, loss 0.586288, acc 0.765625\n",
      "2017-04-03T19:38:38.180736: step 6133, loss 0.730969, acc 0.78125\n",
      "2017-04-03T19:38:38.381037: step 6134, loss 0.648953, acc 0.734375\n",
      "2017-04-03T19:38:38.593494: step 6135, loss 0.74647, acc 0.640625\n",
      "2017-04-03T19:38:38.801767: step 6136, loss 0.620507, acc 0.75\n",
      "2017-04-03T19:38:39.014720: step 6137, loss 0.550517, acc 0.765625\n",
      "2017-04-03T19:38:39.217530: step 6138, loss 0.616374, acc 0.78125\n",
      "2017-04-03T19:38:39.461168: step 6139, loss 0.562875, acc 0.78125\n",
      "2017-04-03T19:38:39.661519: step 6140, loss 0.658873, acc 0.8125\n",
      "2017-04-03T19:38:39.869625: step 6141, loss 0.563835, acc 0.8125\n",
      "2017-04-03T19:38:40.082993: step 6142, loss 0.797683, acc 0.71875\n",
      "2017-04-03T19:38:40.286863: step 6143, loss 0.600099, acc 0.8125\n",
      "2017-04-03T19:38:40.490939: step 6144, loss 0.49132, acc 0.875\n",
      "2017-04-03T19:38:40.697270: step 6145, loss 0.652763, acc 0.796875\n",
      "2017-04-03T19:38:40.902906: step 6146, loss 0.599424, acc 0.78125\n",
      "2017-04-03T19:38:41.125493: step 6147, loss 0.501301, acc 0.84375\n",
      "2017-04-03T19:38:41.325783: step 6148, loss 0.649002, acc 0.78125\n",
      "2017-04-03T19:38:41.575393: step 6149, loss 0.688854, acc 0.78125\n",
      "2017-04-03T19:38:41.790591: step 6150, loss 0.890539, acc 0.75\n",
      "2017-04-03T19:38:42.035331: step 6151, loss 1.0239, acc 0.671875\n",
      "2017-04-03T19:38:42.280146: step 6152, loss 0.433069, acc 0.875\n",
      "2017-04-03T19:38:42.491872: step 6153, loss 0.540494, acc 0.796875\n",
      "2017-04-03T19:38:42.695866: step 6154, loss 0.573555, acc 0.828125\n",
      "2017-04-03T19:38:42.897242: step 6155, loss 0.684317, acc 0.796875\n",
      "2017-04-03T19:38:43.099437: step 6156, loss 0.677647, acc 0.75\n",
      "2017-04-03T19:38:43.304840: step 6157, loss 0.863038, acc 0.6875\n",
      "2017-04-03T19:38:43.510061: step 6158, loss 0.624054, acc 0.78125\n",
      "2017-04-03T19:38:43.713666: step 6159, loss 0.68246, acc 0.765625\n",
      "2017-04-03T19:38:43.914741: step 6160, loss 0.777164, acc 0.75\n",
      "2017-04-03T19:38:44.118676: step 6161, loss 0.791379, acc 0.765625\n",
      "2017-04-03T19:38:44.324065: step 6162, loss 0.862175, acc 0.6875\n",
      "2017-04-03T19:38:44.530730: step 6163, loss 0.658076, acc 0.765625\n",
      "2017-04-03T19:38:44.742893: step 6164, loss 0.678544, acc 0.765625\n",
      "2017-04-03T19:38:44.943897: step 6165, loss 0.630917, acc 0.78125\n",
      "2017-04-03T19:38:45.155459: step 6166, loss 0.530384, acc 0.84375\n",
      "2017-04-03T19:38:45.383398: step 6167, loss 0.685885, acc 0.765625\n",
      "2017-04-03T19:38:45.588243: step 6168, loss 0.868545, acc 0.71875\n",
      "2017-04-03T19:38:45.791365: step 6169, loss 0.626917, acc 0.78125\n",
      "2017-04-03T19:38:46.031207: step 6170, loss 0.540408, acc 0.828125\n",
      "2017-04-03T19:38:46.233255: step 6171, loss 0.843387, acc 0.703125\n",
      "2017-04-03T19:38:46.439225: step 6172, loss 0.524, acc 0.859375\n",
      "2017-04-03T19:38:46.640856: step 6173, loss 0.751594, acc 0.734375\n",
      "2017-04-03T19:38:46.846900: step 6174, loss 0.55628, acc 0.8125\n",
      "2017-04-03T19:38:47.057096: step 6175, loss 0.552021, acc 0.84375\n",
      "2017-04-03T19:38:47.258270: step 6176, loss 0.761047, acc 0.765625\n",
      "2017-04-03T19:38:47.461721: step 6177, loss 0.634002, acc 0.765625\n",
      "2017-04-03T19:38:47.670328: step 6178, loss 0.56187, acc 0.8125\n",
      "2017-04-03T19:38:47.874024: step 6179, loss 0.625209, acc 0.765625\n",
      "2017-04-03T19:38:48.116464: step 6180, loss 0.433426, acc 0.8125\n",
      "2017-04-03T19:38:48.318485: step 6181, loss 0.769464, acc 0.734375\n",
      "2017-04-03T19:38:48.522739: step 6182, loss 0.739875, acc 0.78125\n",
      "2017-04-03T19:38:48.725936: step 6183, loss 0.65947, acc 0.796875\n",
      "2017-04-03T19:38:48.931089: step 6184, loss 0.652696, acc 0.78125\n",
      "2017-04-03T19:38:49.132985: step 6185, loss 0.584205, acc 0.765625\n",
      "2017-04-03T19:38:49.381813: step 6186, loss 0.485461, acc 0.8125\n",
      "2017-04-03T19:38:49.644686: step 6187, loss 0.651297, acc 0.8125\n",
      "2017-04-03T19:38:49.849799: step 6188, loss 0.527507, acc 0.78125\n",
      "2017-04-03T19:38:50.101300: step 6189, loss 0.6296, acc 0.796875\n",
      "2017-04-03T19:38:50.304105: step 6190, loss 0.873156, acc 0.703125\n",
      "2017-04-03T19:38:50.511955: step 6191, loss 0.815276, acc 0.75\n",
      "2017-04-03T19:38:50.717285: step 6192, loss 0.712907, acc 0.703125\n",
      "2017-04-03T19:38:50.876406: step 6193, loss 0.952421, acc 0.71875\n",
      "2017-04-03T19:38:51.087692: step 6194, loss 0.507092, acc 0.828125\n",
      "2017-04-03T19:38:51.293361: step 6195, loss 0.451207, acc 0.890625\n",
      "2017-04-03T19:38:51.501877: step 6196, loss 0.332469, acc 0.859375\n",
      "2017-04-03T19:38:51.746874: step 6197, loss 0.399391, acc 0.875\n",
      "2017-04-03T19:38:51.952060: step 6198, loss 0.493873, acc 0.859375\n",
      "2017-04-03T19:38:52.160106: step 6199, loss 0.585295, acc 0.796875\n",
      "2017-04-03T19:38:52.366019: step 6200, loss 0.522536, acc 0.859375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:38:54.398907: step 6200, loss 2.66276, acc 0.326\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-6200\n",
      "\n",
      "2017-04-03T19:38:54.735083: step 6201, loss 0.487942, acc 0.828125\n",
      "2017-04-03T19:38:54.953544: step 6202, loss 0.520255, acc 0.875\n",
      "2017-04-03T19:38:55.156287: step 6203, loss 0.387292, acc 0.875\n",
      "2017-04-03T19:38:55.359549: step 6204, loss 0.498703, acc 0.84375\n",
      "2017-04-03T19:38:55.561531: step 6205, loss 0.842189, acc 0.71875\n",
      "2017-04-03T19:38:55.769717: step 6206, loss 0.428338, acc 0.859375\n",
      "2017-04-03T19:38:56.015651: step 6207, loss 0.570339, acc 0.796875\n",
      "2017-04-03T19:38:56.234623: step 6208, loss 0.612889, acc 0.765625\n",
      "2017-04-03T19:38:56.454907: step 6209, loss 0.474112, acc 0.84375\n",
      "2017-04-03T19:38:56.648416: step 6210, loss 0.638876, acc 0.765625\n",
      "2017-04-03T19:38:56.853443: step 6211, loss 0.36485, acc 0.890625\n",
      "2017-04-03T19:38:57.057365: step 6212, loss 0.719282, acc 0.734375\n",
      "2017-04-03T19:38:57.261905: step 6213, loss 0.455814, acc 0.8125\n",
      "2017-04-03T19:38:57.465377: step 6214, loss 0.427431, acc 0.859375\n",
      "2017-04-03T19:38:57.668903: step 6215, loss 0.508276, acc 0.828125\n",
      "2017-04-03T19:38:57.874884: step 6216, loss 0.474842, acc 0.8125\n",
      "2017-04-03T19:38:58.080600: step 6217, loss 0.531281, acc 0.84375\n",
      "2017-04-03T19:38:58.279965: step 6218, loss 0.559558, acc 0.796875\n",
      "2017-04-03T19:38:58.493055: step 6219, loss 0.517063, acc 0.828125\n",
      "2017-04-03T19:38:58.739888: step 6220, loss 0.545597, acc 0.78125\n",
      "2017-04-03T19:38:58.949086: step 6221, loss 0.359072, acc 0.921875\n",
      "2017-04-03T19:38:59.152667: step 6222, loss 0.438653, acc 0.875\n",
      "2017-04-03T19:38:59.359594: step 6223, loss 0.629076, acc 0.84375\n",
      "2017-04-03T19:38:59.565632: step 6224, loss 0.678792, acc 0.8125\n",
      "2017-04-03T19:38:59.771899: step 6225, loss 0.43292, acc 0.859375\n",
      "2017-04-03T19:38:59.977045: step 6226, loss 0.404542, acc 0.875\n",
      "2017-04-03T19:39:00.184949: step 6227, loss 0.409395, acc 0.828125\n",
      "2017-04-03T19:39:00.403856: step 6228, loss 0.45422, acc 0.859375\n",
      "2017-04-03T19:39:00.615575: step 6229, loss 0.442184, acc 0.875\n",
      "2017-04-03T19:39:00.864359: step 6230, loss 0.433171, acc 0.875\n",
      "2017-04-03T19:39:01.067507: step 6231, loss 0.594844, acc 0.78125\n",
      "2017-04-03T19:39:01.274848: step 6232, loss 0.359789, acc 0.84375\n",
      "2017-04-03T19:39:01.481043: step 6233, loss 0.397389, acc 0.84375\n",
      "2017-04-03T19:39:01.703456: step 6234, loss 0.371331, acc 0.921875\n",
      "2017-04-03T19:39:01.920830: step 6235, loss 0.552293, acc 0.84375\n",
      "2017-04-03T19:39:02.128236: step 6236, loss 0.503966, acc 0.890625\n",
      "2017-04-03T19:39:02.378038: step 6237, loss 0.635942, acc 0.796875\n",
      "2017-04-03T19:39:02.583519: step 6238, loss 0.444408, acc 0.859375\n",
      "2017-04-03T19:39:02.792203: step 6239, loss 0.563237, acc 0.8125\n",
      "2017-04-03T19:39:02.996899: step 6240, loss 0.638076, acc 0.78125\n",
      "2017-04-03T19:39:03.199606: step 6241, loss 0.550964, acc 0.84375\n",
      "2017-04-03T19:39:03.403900: step 6242, loss 0.477154, acc 0.78125\n",
      "2017-04-03T19:39:03.605590: step 6243, loss 0.391804, acc 0.890625\n",
      "2017-04-03T19:39:03.799522: step 6244, loss 0.485821, acc 0.84375\n",
      "2017-04-03T19:39:04.048739: step 6245, loss 0.411604, acc 0.90625\n",
      "2017-04-03T19:39:04.276844: step 6246, loss 0.527939, acc 0.828125\n",
      "2017-04-03T19:39:04.525699: step 6247, loss 0.538086, acc 0.84375\n",
      "2017-04-03T19:39:04.745883: step 6248, loss 0.771417, acc 0.828125\n",
      "2017-04-03T19:39:04.948937: step 6249, loss 0.412003, acc 0.890625\n",
      "2017-04-03T19:39:05.151773: step 6250, loss 0.506827, acc 0.796875\n",
      "2017-04-03T19:39:05.360873: step 6251, loss 0.485795, acc 0.828125\n",
      "2017-04-03T19:39:05.559985: step 6252, loss 0.464933, acc 0.859375\n",
      "2017-04-03T19:39:05.769881: step 6253, loss 0.442688, acc 0.859375\n",
      "2017-04-03T19:39:05.974862: step 6254, loss 0.573053, acc 0.828125\n",
      "2017-04-03T19:39:06.183371: step 6255, loss 0.517031, acc 0.875\n",
      "2017-04-03T19:39:06.391172: step 6256, loss 0.471958, acc 0.84375\n",
      "2017-04-03T19:39:06.645909: step 6257, loss 0.464468, acc 0.828125\n",
      "2017-04-03T19:39:06.851509: step 6258, loss 0.448684, acc 0.90625\n",
      "2017-04-03T19:39:07.057145: step 6259, loss 0.420549, acc 0.859375\n",
      "2017-04-03T19:39:07.263005: step 6260, loss 0.48294, acc 0.84375\n",
      "2017-04-03T19:39:07.463615: step 6261, loss 0.378547, acc 0.875\n",
      "2017-04-03T19:39:07.669372: step 6262, loss 0.572528, acc 0.828125\n",
      "2017-04-03T19:39:07.874864: step 6263, loss 0.48571, acc 0.875\n",
      "2017-04-03T19:39:08.121050: step 6264, loss 0.575112, acc 0.8125\n",
      "2017-04-03T19:39:08.330839: step 6265, loss 0.486369, acc 0.828125\n",
      "2017-04-03T19:39:08.535405: step 6266, loss 0.52275, acc 0.859375\n",
      "2017-04-03T19:39:08.743955: step 6267, loss 0.501961, acc 0.84375\n",
      "2017-04-03T19:39:08.999732: step 6268, loss 0.440885, acc 0.8125\n",
      "2017-04-03T19:39:09.206212: step 6269, loss 0.53354, acc 0.78125\n",
      "2017-04-03T19:39:09.436540: step 6270, loss 0.426673, acc 0.859375\n",
      "2017-04-03T19:39:09.644835: step 6271, loss 0.589478, acc 0.8125\n",
      "2017-04-03T19:39:09.847924: step 6272, loss 0.378851, acc 0.875\n",
      "2017-04-03T19:39:10.052827: step 6273, loss 0.417232, acc 0.859375\n",
      "2017-04-03T19:39:10.261128: step 6274, loss 0.493045, acc 0.8125\n",
      "2017-04-03T19:39:10.497518: step 6275, loss 0.583035, acc 0.78125\n",
      "2017-04-03T19:39:10.717203: step 6276, loss 0.513204, acc 0.765625\n",
      "2017-04-03T19:39:10.935090: step 6277, loss 0.60883, acc 0.828125\n",
      "2017-04-03T19:39:11.144071: step 6278, loss 0.594402, acc 0.796875\n",
      "2017-04-03T19:39:11.347151: step 6279, loss 0.448672, acc 0.84375\n",
      "2017-04-03T19:39:11.593417: step 6280, loss 0.516871, acc 0.84375\n",
      "2017-04-03T19:39:11.796596: step 6281, loss 0.388324, acc 0.828125\n",
      "2017-04-03T19:39:12.017613: step 6282, loss 0.636438, acc 0.796875\n",
      "2017-04-03T19:39:12.214092: step 6283, loss 0.481986, acc 0.859375\n",
      "2017-04-03T19:39:12.416911: step 6284, loss 0.518093, acc 0.765625\n",
      "2017-04-03T19:39:12.622023: step 6285, loss 0.567367, acc 0.796875\n",
      "2017-04-03T19:39:12.832794: step 6286, loss 0.42003, acc 0.84375\n",
      "2017-04-03T19:39:13.037515: step 6287, loss 0.463311, acc 0.859375\n",
      "2017-04-03T19:39:13.235248: step 6288, loss 0.422577, acc 0.875\n",
      "2017-04-03T19:39:13.445227: step 6289, loss 0.342061, acc 0.890625\n",
      "2017-04-03T19:39:13.686645: step 6290, loss 0.35426, acc 0.890625\n",
      "2017-04-03T19:39:13.907290: step 6291, loss 0.526682, acc 0.8125\n",
      "2017-04-03T19:39:14.106706: step 6292, loss 0.621823, acc 0.84375\n",
      "2017-04-03T19:39:14.353774: step 6293, loss 0.301206, acc 0.921875\n",
      "2017-04-03T19:39:14.561968: step 6294, loss 0.638659, acc 0.78125\n",
      "2017-04-03T19:39:14.779935: step 6295, loss 0.362582, acc 0.890625\n",
      "2017-04-03T19:39:14.982108: step 6296, loss 0.65437, acc 0.765625\n",
      "2017-04-03T19:39:15.223021: step 6297, loss 0.419728, acc 0.90625\n",
      "2017-04-03T19:39:15.430782: step 6298, loss 0.297179, acc 0.90625\n",
      "2017-04-03T19:39:15.641910: step 6299, loss 0.548677, acc 0.796875\n",
      "2017-04-03T19:39:15.840776: step 6300, loss 0.322756, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:39:17.864263: step 6300, loss 2.70995, acc 0.32\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-6300\n",
      "\n",
      "2017-04-03T19:39:18.197907: step 6301, loss 0.623286, acc 0.8125\n",
      "2017-04-03T19:39:18.417571: step 6302, loss 0.348624, acc 0.890625\n",
      "2017-04-03T19:39:18.620709: step 6303, loss 0.459096, acc 0.875\n",
      "2017-04-03T19:39:18.823747: step 6304, loss 0.269161, acc 0.953125\n",
      "2017-04-03T19:39:19.032197: step 6305, loss 0.483257, acc 0.8125\n",
      "2017-04-03T19:39:19.230606: step 6306, loss 0.65068, acc 0.796875\n",
      "2017-04-03T19:39:19.433873: step 6307, loss 0.470296, acc 0.8125\n",
      "2017-04-03T19:39:19.634011: step 6308, loss 0.534503, acc 0.859375\n",
      "2017-04-03T19:39:19.835784: step 6309, loss 0.491887, acc 0.84375\n",
      "2017-04-03T19:39:20.086772: step 6310, loss 0.470827, acc 0.84375\n",
      "2017-04-03T19:39:20.286805: step 6311, loss 0.434042, acc 0.921875\n",
      "2017-04-03T19:39:20.484800: step 6312, loss 0.619994, acc 0.828125\n",
      "2017-04-03T19:39:20.692879: step 6313, loss 0.406667, acc 0.9375\n",
      "2017-04-03T19:39:20.901334: step 6314, loss 0.436708, acc 0.84375\n",
      "2017-04-03T19:39:21.100295: step 6315, loss 0.499062, acc 0.828125\n",
      "2017-04-03T19:39:21.301146: step 6316, loss 0.479125, acc 0.859375\n",
      "2017-04-03T19:39:21.498782: step 6317, loss 0.33576, acc 0.875\n",
      "2017-04-03T19:39:21.709481: step 6318, loss 0.512482, acc 0.890625\n",
      "2017-04-03T19:39:21.915181: step 6319, loss 0.5606, acc 0.828125\n",
      "2017-04-03T19:39:22.116427: step 6320, loss 0.358629, acc 0.875\n",
      "2017-04-03T19:39:22.328118: step 6321, loss 0.779869, acc 0.71875\n",
      "2017-04-03T19:39:22.528591: step 6322, loss 0.483485, acc 0.84375\n",
      "2017-04-03T19:39:22.735125: step 6323, loss 0.51339, acc 0.828125\n",
      "2017-04-03T19:39:22.936849: step 6324, loss 0.467653, acc 0.84375\n",
      "2017-04-03T19:39:23.137322: step 6325, loss 0.718637, acc 0.75\n",
      "2017-04-03T19:39:23.339328: step 6326, loss 0.630239, acc 0.796875\n",
      "2017-04-03T19:39:23.539784: step 6327, loss 0.386063, acc 0.875\n",
      "2017-04-03T19:39:23.779584: step 6328, loss 0.573041, acc 0.828125\n",
      "2017-04-03T19:39:23.995509: step 6329, loss 0.409076, acc 0.9375\n",
      "2017-04-03T19:39:24.202444: step 6330, loss 0.481092, acc 0.828125\n",
      "2017-04-03T19:39:24.410619: step 6331, loss 0.547806, acc 0.796875\n",
      "2017-04-03T19:39:24.612920: step 6332, loss 0.589924, acc 0.75\n",
      "2017-04-03T19:39:24.816223: step 6333, loss 0.488923, acc 0.84375\n",
      "2017-04-03T19:39:25.017423: step 6334, loss 0.494699, acc 0.875\n",
      "2017-04-03T19:39:25.221862: step 6335, loss 0.506588, acc 0.78125\n",
      "2017-04-03T19:39:25.424293: step 6336, loss 0.563805, acc 0.8125\n",
      "2017-04-03T19:39:25.622481: step 6337, loss 0.446705, acc 0.859375\n",
      "2017-04-03T19:39:25.836687: step 6338, loss 0.315338, acc 0.921875\n",
      "2017-04-03T19:39:26.036036: step 6339, loss 0.668889, acc 0.75\n",
      "2017-04-03T19:39:26.238972: step 6340, loss 0.363244, acc 0.859375\n",
      "2017-04-03T19:39:26.441648: step 6341, loss 0.576054, acc 0.78125\n",
      "2017-04-03T19:39:26.644675: step 6342, loss 0.684391, acc 0.796875\n",
      "2017-04-03T19:39:26.853222: step 6343, loss 0.550098, acc 0.8125\n",
      "2017-04-03T19:39:27.064571: step 6344, loss 0.467124, acc 0.875\n",
      "2017-04-03T19:39:27.272986: step 6345, loss 0.444218, acc 0.859375\n",
      "2017-04-03T19:39:27.490558: step 6346, loss 0.413602, acc 0.890625\n",
      "2017-04-03T19:39:27.695457: step 6347, loss 0.630706, acc 0.8125\n",
      "2017-04-03T19:39:27.900223: step 6348, loss 0.439322, acc 0.84375\n",
      "2017-04-03T19:39:28.142640: step 6349, loss 0.456105, acc 0.859375\n",
      "2017-04-03T19:39:28.342552: step 6350, loss 0.700316, acc 0.71875\n",
      "2017-04-03T19:39:28.538094: step 6351, loss 0.462409, acc 0.875\n",
      "2017-04-03T19:39:28.779515: step 6352, loss 0.495206, acc 0.828125\n",
      "2017-04-03T19:39:28.990644: step 6353, loss 0.796535, acc 0.796875\n",
      "2017-04-03T19:39:29.194950: step 6354, loss 0.533555, acc 0.8125\n",
      "2017-04-03T19:39:29.403820: step 6355, loss 0.661524, acc 0.78125\n",
      "2017-04-03T19:39:29.610041: step 6356, loss 0.579149, acc 0.796875\n",
      "2017-04-03T19:39:29.813635: step 6357, loss 0.630168, acc 0.78125\n",
      "2017-04-03T19:39:30.017794: step 6358, loss 0.616087, acc 0.78125\n",
      "2017-04-03T19:39:30.263927: step 6359, loss 0.594163, acc 0.8125\n",
      "2017-04-03T19:39:30.472730: step 6360, loss 0.852548, acc 0.8125\n",
      "2017-04-03T19:39:30.676248: step 6361, loss 0.370848, acc 0.890625\n",
      "2017-04-03T19:39:30.885388: step 6362, loss 0.674777, acc 0.78125\n",
      "2017-04-03T19:39:31.093779: step 6363, loss 0.429258, acc 0.890625\n",
      "2017-04-03T19:39:31.300505: step 6364, loss 0.416349, acc 0.859375\n",
      "2017-04-03T19:39:31.512997: step 6365, loss 0.805901, acc 0.734375\n",
      "2017-04-03T19:39:31.711977: step 6366, loss 0.639564, acc 0.78125\n",
      "2017-04-03T19:39:31.918100: step 6367, loss 0.473483, acc 0.796875\n",
      "2017-04-03T19:39:32.119752: step 6368, loss 0.414511, acc 0.875\n",
      "2017-04-03T19:39:32.320714: step 6369, loss 0.333202, acc 0.875\n",
      "2017-04-03T19:39:32.525824: step 6370, loss 0.438605, acc 0.859375\n",
      "2017-04-03T19:39:32.729662: step 6371, loss 0.492242, acc 0.84375\n",
      "2017-04-03T19:39:32.932170: step 6372, loss 0.551886, acc 0.828125\n",
      "2017-04-03T19:39:33.137056: step 6373, loss 0.553293, acc 0.84375\n",
      "2017-04-03T19:39:33.340395: step 6374, loss 0.645601, acc 0.78125\n",
      "2017-04-03T19:39:33.539443: step 6375, loss 0.581855, acc 0.78125\n",
      "2017-04-03T19:39:33.743096: step 6376, loss 0.517192, acc 0.84375\n",
      "2017-04-03T19:39:33.946776: step 6377, loss 0.615742, acc 0.765625\n",
      "2017-04-03T19:39:34.187350: step 6378, loss 0.499465, acc 0.84375\n",
      "2017-04-03T19:39:34.386091: step 6379, loss 0.494827, acc 0.84375\n",
      "2017-04-03T19:39:34.591987: step 6380, loss 0.512095, acc 0.859375\n",
      "2017-04-03T19:39:34.794315: step 6381, loss 0.581264, acc 0.859375\n",
      "2017-04-03T19:39:34.995639: step 6382, loss 0.433908, acc 0.875\n",
      "2017-04-03T19:39:35.197541: step 6383, loss 0.431044, acc 0.859375\n",
      "2017-04-03T19:39:35.411182: step 6384, loss 0.678159, acc 0.78125\n",
      "2017-04-03T19:39:35.639494: step 6385, loss 0.542652, acc 0.765625\n",
      "2017-04-03T19:39:35.842090: step 6386, loss 0.462529, acc 0.84375\n",
      "2017-04-03T19:39:36.051637: step 6387, loss 0.463466, acc 0.84375\n",
      "2017-04-03T19:39:36.260575: step 6388, loss 0.682102, acc 0.734375\n",
      "2017-04-03T19:39:36.509933: step 6389, loss 0.552898, acc 0.828125\n",
      "2017-04-03T19:39:36.714242: step 6390, loss 0.666871, acc 0.796875\n",
      "2017-04-03T19:39:36.913562: step 6391, loss 0.661924, acc 0.8125\n",
      "2017-04-03T19:39:37.160052: step 6392, loss 0.388953, acc 0.890625\n",
      "2017-04-03T19:39:37.365723: step 6393, loss 0.831721, acc 0.75\n",
      "2017-04-03T19:39:37.565768: step 6394, loss 0.287148, acc 0.921875\n",
      "2017-04-03T19:39:37.810911: step 6395, loss 0.493341, acc 0.8125\n",
      "2017-04-03T19:39:38.016794: step 6396, loss 0.507254, acc 0.796875\n",
      "2017-04-03T19:39:38.217774: step 6397, loss 0.453457, acc 0.84375\n",
      "2017-04-03T19:39:38.424107: step 6398, loss 0.494104, acc 0.828125\n",
      "2017-04-03T19:39:38.625575: step 6399, loss 0.520913, acc 0.828125\n",
      "2017-04-03T19:39:38.831220: step 6400, loss 0.679413, acc 0.734375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:39:40.803899: step 6400, loss 2.77465, acc 0.3195\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-6400\n",
      "\n",
      "2017-04-03T19:39:41.135959: step 6401, loss 0.511273, acc 0.8125\n",
      "2017-04-03T19:39:41.338538: step 6402, loss 0.86289, acc 0.703125\n",
      "2017-04-03T19:39:41.578907: step 6403, loss 0.493244, acc 0.84375\n",
      "2017-04-03T19:39:41.785366: step 6404, loss 0.450248, acc 0.859375\n",
      "2017-04-03T19:39:41.986861: step 6405, loss 0.638546, acc 0.796875\n",
      "2017-04-03T19:39:42.185642: step 6406, loss 0.760124, acc 0.703125\n",
      "2017-04-03T19:39:42.388761: step 6407, loss 0.644557, acc 0.75\n",
      "2017-04-03T19:39:42.595662: step 6408, loss 0.571723, acc 0.8125\n",
      "2017-04-03T19:39:42.844876: step 6409, loss 0.389699, acc 0.859375\n",
      "2017-04-03T19:39:43.053066: step 6410, loss 0.585559, acc 0.8125\n",
      "2017-04-03T19:39:43.253497: step 6411, loss 0.483206, acc 0.875\n",
      "2017-04-03T19:39:43.455086: step 6412, loss 0.443703, acc 0.875\n",
      "2017-04-03T19:39:43.700738: step 6413, loss 0.506346, acc 0.828125\n",
      "2017-04-03T19:39:43.901847: step 6414, loss 0.574193, acc 0.765625\n",
      "2017-04-03T19:39:44.152889: step 6415, loss 0.504315, acc 0.8125\n",
      "2017-04-03T19:39:44.351379: step 6416, loss 0.63221, acc 0.75\n",
      "2017-04-03T19:39:44.552167: step 6417, loss 0.450935, acc 0.828125\n",
      "2017-04-03T19:39:44.756452: step 6418, loss 0.425856, acc 0.875\n",
      "2017-04-03T19:39:44.954810: step 6419, loss 0.561704, acc 0.8125\n",
      "2017-04-03T19:39:45.162494: step 6420, loss 0.568265, acc 0.8125\n",
      "2017-04-03T19:39:45.362300: step 6421, loss 0.42072, acc 0.90625\n",
      "2017-04-03T19:39:45.563415: step 6422, loss 0.484039, acc 0.828125\n",
      "2017-04-03T19:39:45.761758: step 6423, loss 0.445978, acc 0.859375\n",
      "2017-04-03T19:39:45.962730: step 6424, loss 0.56119, acc 0.828125\n",
      "2017-04-03T19:39:46.169264: step 6425, loss 0.591203, acc 0.796875\n",
      "2017-04-03T19:39:46.375089: step 6426, loss 0.331634, acc 0.90625\n",
      "2017-04-03T19:39:46.578974: step 6427, loss 0.39623, acc 0.828125\n",
      "2017-04-03T19:39:46.824358: step 6428, loss 0.522909, acc 0.8125\n",
      "2017-04-03T19:39:47.041832: step 6429, loss 0.378324, acc 0.828125\n",
      "2017-04-03T19:39:47.242557: step 6430, loss 0.572709, acc 0.859375\n",
      "2017-04-03T19:39:47.441519: step 6431, loss 0.861511, acc 0.75\n",
      "2017-04-03T19:39:47.644722: step 6432, loss 0.492787, acc 0.875\n",
      "2017-04-03T19:39:47.857736: step 6433, loss 0.581857, acc 0.859375\n",
      "2017-04-03T19:39:48.059553: step 6434, loss 0.332495, acc 0.921875\n",
      "2017-04-03T19:39:48.260484: step 6435, loss 0.520098, acc 0.875\n",
      "2017-04-03T19:39:48.473294: step 6436, loss 0.381499, acc 0.875\n",
      "2017-04-03T19:39:48.688773: step 6437, loss 0.278234, acc 0.890625\n",
      "2017-04-03T19:39:48.888352: step 6438, loss 0.53301, acc 0.890625\n",
      "2017-04-03T19:39:49.093956: step 6439, loss 0.476031, acc 0.84375\n",
      "2017-04-03T19:39:49.294038: step 6440, loss 0.740968, acc 0.765625\n",
      "2017-04-03T19:39:49.494669: step 6441, loss 0.686021, acc 0.765625\n",
      "2017-04-03T19:39:49.695590: step 6442, loss 0.505202, acc 0.796875\n",
      "2017-04-03T19:39:49.906321: step 6443, loss 0.616364, acc 0.78125\n",
      "2017-04-03T19:39:50.107939: step 6444, loss 0.547516, acc 0.8125\n",
      "2017-04-03T19:39:50.307519: step 6445, loss 0.583164, acc 0.890625\n",
      "2017-04-03T19:39:50.511285: step 6446, loss 0.617985, acc 0.8125\n",
      "2017-04-03T19:39:50.715538: step 6447, loss 0.45799, acc 0.859375\n",
      "2017-04-03T19:39:50.931280: step 6448, loss 0.586186, acc 0.796875\n",
      "2017-04-03T19:39:51.180544: step 6449, loss 0.650448, acc 0.828125\n",
      "2017-04-03T19:39:51.379947: step 6450, loss 0.400191, acc 0.875\n",
      "2017-04-03T19:39:51.579439: step 6451, loss 0.674716, acc 0.71875\n",
      "2017-04-03T19:39:51.778579: step 6452, loss 0.481738, acc 0.84375\n",
      "2017-04-03T19:39:51.984559: step 6453, loss 0.398581, acc 0.84375\n",
      "2017-04-03T19:39:52.196069: step 6454, loss 0.531805, acc 0.84375\n",
      "2017-04-03T19:39:52.397307: step 6455, loss 0.41733, acc 0.921875\n",
      "2017-04-03T19:39:52.640478: step 6456, loss 0.665957, acc 0.765625\n",
      "2017-04-03T19:39:52.850594: step 6457, loss 0.36496, acc 0.890625\n",
      "2017-04-03T19:39:53.089889: step 6458, loss 0.43461, acc 0.890625\n",
      "2017-04-03T19:39:53.297278: step 6459, loss 0.733503, acc 0.78125\n",
      "2017-04-03T19:39:53.510696: step 6460, loss 0.535692, acc 0.765625\n",
      "2017-04-03T19:39:53.715052: step 6461, loss 0.494118, acc 0.859375\n",
      "2017-04-03T19:39:53.973605: step 6462, loss 0.504801, acc 0.828125\n",
      "2017-04-03T19:39:54.219152: step 6463, loss 0.354903, acc 0.90625\n",
      "2017-04-03T19:39:54.438096: step 6464, loss 0.46941, acc 0.84375\n",
      "2017-04-03T19:39:54.639776: step 6465, loss 0.68887, acc 0.765625\n",
      "2017-04-03T19:39:54.884935: step 6466, loss 0.691656, acc 0.78125\n",
      "2017-04-03T19:39:55.084158: step 6467, loss 0.482022, acc 0.859375\n",
      "2017-04-03T19:39:55.289173: step 6468, loss 0.521405, acc 0.8125\n",
      "2017-04-03T19:39:55.496422: step 6469, loss 0.45018, acc 0.859375\n",
      "2017-04-03T19:39:55.696326: step 6470, loss 0.564787, acc 0.84375\n",
      "2017-04-03T19:39:55.887580: step 6471, loss 0.416342, acc 0.890625\n",
      "2017-04-03T19:39:56.099668: step 6472, loss 0.493209, acc 0.828125\n",
      "2017-04-03T19:39:56.302209: step 6473, loss 0.575939, acc 0.8125\n",
      "2017-04-03T19:39:56.504717: step 6474, loss 0.473713, acc 0.90625\n",
      "2017-04-03T19:39:56.707365: step 6475, loss 0.406929, acc 0.859375\n",
      "2017-04-03T19:39:56.919922: step 6476, loss 0.588311, acc 0.78125\n",
      "2017-04-03T19:39:57.166500: step 6477, loss 0.618299, acc 0.796875\n",
      "2017-04-03T19:39:57.370757: step 6478, loss 0.553141, acc 0.796875\n",
      "2017-04-03T19:39:57.611168: step 6479, loss 0.525288, acc 0.8125\n",
      "2017-04-03T19:39:57.815039: step 6480, loss 0.419862, acc 0.90625\n",
      "2017-04-03T19:39:58.020210: step 6481, loss 0.619467, acc 0.84375\n",
      "2017-04-03T19:39:58.221064: step 6482, loss 0.53235, acc 0.796875\n",
      "2017-04-03T19:39:58.427371: step 6483, loss 0.656166, acc 0.796875\n",
      "2017-04-03T19:39:58.641570: step 6484, loss 0.565806, acc 0.796875\n",
      "2017-04-03T19:39:58.837159: step 6485, loss 0.510625, acc 0.84375\n",
      "2017-04-03T19:39:59.039530: step 6486, loss 0.388449, acc 0.890625\n",
      "2017-04-03T19:39:59.239470: step 6487, loss 0.460654, acc 0.84375\n",
      "2017-04-03T19:39:59.443604: step 6488, loss 0.376927, acc 0.84375\n",
      "2017-04-03T19:39:59.647394: step 6489, loss 0.590426, acc 0.796875\n",
      "2017-04-03T19:39:59.853214: step 6490, loss 0.738122, acc 0.75\n",
      "2017-04-03T19:40:00.095909: step 6491, loss 0.481222, acc 0.84375\n",
      "2017-04-03T19:40:00.303577: step 6492, loss 0.603559, acc 0.796875\n",
      "2017-04-03T19:40:00.504653: step 6493, loss 0.493154, acc 0.828125\n",
      "2017-04-03T19:40:00.705959: step 6494, loss 0.622169, acc 0.71875\n",
      "2017-04-03T19:40:00.908470: step 6495, loss 0.545222, acc 0.828125\n",
      "2017-04-03T19:40:01.108469: step 6496, loss 0.626671, acc 0.78125\n",
      "2017-04-03T19:40:01.308190: step 6497, loss 0.494042, acc 0.859375\n",
      "2017-04-03T19:40:01.549967: step 6498, loss 0.598862, acc 0.734375\n",
      "2017-04-03T19:40:01.760016: step 6499, loss 0.412411, acc 0.859375\n",
      "2017-04-03T19:40:01.966366: step 6500, loss 0.673847, acc 0.796875\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:40:04.003445: step 6500, loss 2.81346, acc 0.32625\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-6500\n",
      "\n",
      "2017-04-03T19:40:04.336022: step 6501, loss 0.389897, acc 0.890625\n",
      "2017-04-03T19:40:04.569553: step 6502, loss 0.57184, acc 0.78125\n",
      "2017-04-03T19:40:04.775703: step 6503, loss 0.595482, acc 0.71875\n",
      "2017-04-03T19:40:05.021908: step 6504, loss 0.373843, acc 0.9375\n",
      "2017-04-03T19:40:05.225765: step 6505, loss 0.336742, acc 0.875\n",
      "2017-04-03T19:40:05.429384: step 6506, loss 0.641312, acc 0.75\n",
      "2017-04-03T19:40:05.631573: step 6507, loss 0.649755, acc 0.78125\n",
      "2017-04-03T19:40:05.833851: step 6508, loss 0.460637, acc 0.8125\n",
      "2017-04-03T19:40:06.039352: step 6509, loss 0.454173, acc 0.84375\n",
      "2017-04-03T19:40:06.238830: step 6510, loss 0.547116, acc 0.875\n",
      "2017-04-03T19:40:06.440605: step 6511, loss 0.675481, acc 0.765625\n",
      "2017-04-03T19:40:06.640346: step 6512, loss 0.462724, acc 0.859375\n",
      "2017-04-03T19:40:06.894519: step 6513, loss 0.688345, acc 0.75\n",
      "2017-04-03T19:40:07.101800: step 6514, loss 0.624236, acc 0.796875\n",
      "2017-04-03T19:40:07.303429: step 6515, loss 0.512114, acc 0.859375\n",
      "2017-04-03T19:40:07.508920: step 6516, loss 0.552642, acc 0.796875\n",
      "2017-04-03T19:40:07.710983: step 6517, loss 0.681129, acc 0.71875\n",
      "2017-04-03T19:40:07.911493: step 6518, loss 0.44208, acc 0.84375\n",
      "2017-04-03T19:40:08.112886: step 6519, loss 0.588939, acc 0.8125\n",
      "2017-04-03T19:40:08.314917: step 6520, loss 0.46129, acc 0.890625\n",
      "2017-04-03T19:40:08.516336: step 6521, loss 0.515827, acc 0.78125\n",
      "2017-04-03T19:40:08.765396: step 6522, loss 0.547304, acc 0.8125\n",
      "2017-04-03T19:40:08.983761: step 6523, loss 0.620907, acc 0.78125\n",
      "2017-04-03T19:40:09.189011: step 6524, loss 0.423817, acc 0.84375\n",
      "2017-04-03T19:40:09.390356: step 6525, loss 0.427973, acc 0.859375\n",
      "2017-04-03T19:40:09.597773: step 6526, loss 0.669712, acc 0.765625\n",
      "2017-04-03T19:40:09.797701: step 6527, loss 0.58714, acc 0.765625\n",
      "2017-04-03T19:40:09.999326: step 6528, loss 0.594908, acc 0.765625\n",
      "2017-04-03T19:40:10.199572: step 6529, loss 0.621615, acc 0.796875\n",
      "2017-04-03T19:40:10.398519: step 6530, loss 0.535689, acc 0.828125\n",
      "2017-04-03T19:40:10.602666: step 6531, loss 0.434908, acc 0.84375\n",
      "2017-04-03T19:40:10.801310: step 6532, loss 0.540718, acc 0.875\n",
      "2017-04-03T19:40:11.044232: step 6533, loss 0.562851, acc 0.8125\n",
      "2017-04-03T19:40:11.245277: step 6534, loss 0.521434, acc 0.828125\n",
      "2017-04-03T19:40:11.447364: step 6535, loss 0.386259, acc 0.875\n",
      "2017-04-03T19:40:11.650284: step 6536, loss 0.440722, acc 0.828125\n",
      "2017-04-03T19:40:11.851165: step 6537, loss 0.61811, acc 0.8125\n",
      "2017-04-03T19:40:12.061551: step 6538, loss 0.742071, acc 0.765625\n",
      "2017-04-03T19:40:12.267332: step 6539, loss 0.578935, acc 0.78125\n",
      "2017-04-03T19:40:12.473841: step 6540, loss 0.601596, acc 0.796875\n",
      "2017-04-03T19:40:12.675171: step 6541, loss 0.478208, acc 0.84375\n",
      "2017-04-03T19:40:12.880329: step 6542, loss 0.56374, acc 0.78125\n",
      "2017-04-03T19:40:13.118755: step 6543, loss 0.546709, acc 0.84375\n",
      "2017-04-03T19:40:13.324215: step 6544, loss 0.6236, acc 0.734375\n",
      "2017-04-03T19:40:13.529010: step 6545, loss 0.504648, acc 0.875\n",
      "2017-04-03T19:40:13.733666: step 6546, loss 0.444931, acc 0.84375\n",
      "2017-04-03T19:40:13.934738: step 6547, loss 0.445806, acc 0.890625\n",
      "2017-04-03T19:40:14.138633: step 6548, loss 0.627798, acc 0.703125\n",
      "2017-04-03T19:40:14.341048: step 6549, loss 0.547745, acc 0.8125\n",
      "2017-04-03T19:40:14.582895: step 6550, loss 0.395943, acc 0.890625\n",
      "2017-04-03T19:40:14.783912: step 6551, loss 0.495845, acc 0.828125\n",
      "2017-04-03T19:40:14.982561: step 6552, loss 0.543023, acc 0.859375\n",
      "2017-04-03T19:40:15.187965: step 6553, loss 0.466917, acc 0.859375\n",
      "2017-04-03T19:40:15.392409: step 6554, loss 0.684424, acc 0.8125\n",
      "2017-04-03T19:40:15.639009: step 6555, loss 0.591811, acc 0.84375\n",
      "2017-04-03T19:40:15.847353: step 6556, loss 0.518348, acc 0.796875\n",
      "2017-04-03T19:40:16.050552: step 6557, loss 0.458449, acc 0.84375\n",
      "2017-04-03T19:40:16.248257: step 6558, loss 0.698298, acc 0.796875\n",
      "2017-04-03T19:40:16.462858: step 6559, loss 0.598827, acc 0.84375\n",
      "2017-04-03T19:40:16.666106: step 6560, loss 0.635617, acc 0.796875\n",
      "2017-04-03T19:40:16.864571: step 6561, loss 0.557964, acc 0.84375\n",
      "2017-04-03T19:40:17.066593: step 6562, loss 0.474358, acc 0.828125\n",
      "2017-04-03T19:40:17.267242: step 6563, loss 0.560615, acc 0.796875\n",
      "2017-04-03T19:40:17.478456: step 6564, loss 0.507728, acc 0.828125\n",
      "2017-04-03T19:40:17.684645: step 6565, loss 0.393446, acc 0.890625\n",
      "2017-04-03T19:40:17.882980: step 6566, loss 0.56897, acc 0.8125\n",
      "2017-04-03T19:40:18.081688: step 6567, loss 0.654924, acc 0.765625\n",
      "2017-04-03T19:40:18.281995: step 6568, loss 0.533429, acc 0.8125\n",
      "2017-04-03T19:40:18.485037: step 6569, loss 0.595886, acc 0.796875\n",
      "2017-04-03T19:40:18.692228: step 6570, loss 0.691661, acc 0.828125\n",
      "2017-04-03T19:40:18.900565: step 6571, loss 0.485243, acc 0.78125\n",
      "2017-04-03T19:40:19.101346: step 6572, loss 0.479246, acc 0.8125\n",
      "2017-04-03T19:40:19.311443: step 6573, loss 0.71819, acc 0.71875\n",
      "2017-04-03T19:40:19.515740: step 6574, loss 0.571432, acc 0.84375\n",
      "2017-04-03T19:40:19.719495: step 6575, loss 0.680678, acc 0.765625\n",
      "2017-04-03T19:40:19.924803: step 6576, loss 0.537922, acc 0.8125\n",
      "2017-04-03T19:40:20.127256: step 6577, loss 0.473967, acc 0.84375\n",
      "2017-04-03T19:40:20.328976: step 6578, loss 0.579612, acc 0.78125\n",
      "2017-04-03T19:40:20.524650: step 6579, loss 0.608767, acc 0.78125\n",
      "2017-04-03T19:40:20.724482: step 6580, loss 0.724028, acc 0.734375\n",
      "2017-04-03T19:40:20.928235: step 6581, loss 0.661047, acc 0.796875\n",
      "2017-04-03T19:40:21.134022: step 6582, loss 0.690614, acc 0.78125\n",
      "2017-04-03T19:40:21.387422: step 6583, loss 0.688469, acc 0.765625\n",
      "2017-04-03T19:40:21.593121: step 6584, loss 0.411278, acc 0.875\n",
      "2017-04-03T19:40:21.796499: step 6585, loss 0.424169, acc 0.84375\n",
      "2017-04-03T19:40:22.009492: step 6586, loss 0.649515, acc 0.796875\n",
      "2017-04-03T19:40:22.216430: step 6587, loss 0.627454, acc 0.8125\n",
      "2017-04-03T19:40:22.456180: step 6588, loss 0.600824, acc 0.796875\n",
      "2017-04-03T19:40:22.656737: step 6589, loss 0.428115, acc 0.828125\n",
      "2017-04-03T19:40:22.857281: step 6590, loss 0.67095, acc 0.765625\n",
      "2017-04-03T19:40:23.061116: step 6591, loss 0.36558, acc 0.90625\n",
      "2017-04-03T19:40:23.265226: step 6592, loss 0.596529, acc 0.765625\n",
      "2017-04-03T19:40:23.510955: step 6593, loss 0.562305, acc 0.78125\n",
      "2017-04-03T19:40:23.715813: step 6594, loss 0.496437, acc 0.859375\n",
      "2017-04-03T19:40:23.917320: step 6595, loss 0.548408, acc 0.84375\n",
      "2017-04-03T19:40:24.125090: step 6596, loss 0.686849, acc 0.765625\n",
      "2017-04-03T19:40:24.338256: step 6597, loss 0.726747, acc 0.734375\n",
      "2017-04-03T19:40:24.541124: step 6598, loss 0.646078, acc 0.78125\n",
      "2017-04-03T19:40:24.746205: step 6599, loss 0.491006, acc 0.84375\n",
      "2017-04-03T19:40:24.941307: step 6600, loss 0.465343, acc 0.796875\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:40:26.959067: step 6600, loss 2.81144, acc 0.323\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-6600\n",
      "\n",
      "2017-04-03T19:40:27.282647: step 6601, loss 0.482066, acc 0.84375\n",
      "2017-04-03T19:40:27.503549: step 6602, loss 0.634244, acc 0.796875\n",
      "2017-04-03T19:40:27.745528: step 6603, loss 0.646021, acc 0.75\n",
      "2017-04-03T19:40:27.953068: step 6604, loss 0.54946, acc 0.828125\n",
      "2017-04-03T19:40:28.159488: step 6605, loss 0.579037, acc 0.796875\n",
      "2017-04-03T19:40:28.360460: step 6606, loss 0.516961, acc 0.8125\n",
      "2017-04-03T19:40:28.563806: step 6607, loss 0.397048, acc 0.875\n",
      "2017-04-03T19:40:28.792963: step 6608, loss 0.487562, acc 0.8125\n",
      "2017-04-03T19:40:29.000595: step 6609, loss 0.496332, acc 0.875\n",
      "2017-04-03T19:40:29.247001: step 6610, loss 0.591956, acc 0.765625\n",
      "2017-04-03T19:40:29.449471: step 6611, loss 0.57117, acc 0.796875\n",
      "2017-04-03T19:40:29.654129: step 6612, loss 0.541905, acc 0.734375\n",
      "2017-04-03T19:40:29.862377: step 6613, loss 0.536083, acc 0.84375\n",
      "2017-04-03T19:40:30.073170: step 6614, loss 0.489795, acc 0.859375\n",
      "2017-04-03T19:40:30.275926: step 6615, loss 0.382286, acc 0.90625\n",
      "2017-04-03T19:40:30.476074: step 6616, loss 0.741561, acc 0.828125\n",
      "2017-04-03T19:40:30.680939: step 6617, loss 0.453973, acc 0.90625\n",
      "2017-04-03T19:40:30.892156: step 6618, loss 0.616721, acc 0.8125\n",
      "2017-04-03T19:40:31.092244: step 6619, loss 0.456727, acc 0.84375\n",
      "2017-04-03T19:40:31.301287: step 6620, loss 0.490504, acc 0.8125\n",
      "2017-04-03T19:40:31.505286: step 6621, loss 0.522339, acc 0.796875\n",
      "2017-04-03T19:40:31.705725: step 6622, loss 0.493807, acc 0.796875\n",
      "2017-04-03T19:40:31.910637: step 6623, loss 0.620402, acc 0.78125\n",
      "2017-04-03T19:40:32.120077: step 6624, loss 0.611936, acc 0.8125\n",
      "2017-04-03T19:40:32.322495: step 6625, loss 0.760138, acc 0.78125\n",
      "2017-04-03T19:40:32.523689: step 6626, loss 0.47383, acc 0.84375\n",
      "2017-04-03T19:40:32.727918: step 6627, loss 0.615379, acc 0.796875\n",
      "2017-04-03T19:40:32.935978: step 6628, loss 0.439729, acc 0.84375\n",
      "2017-04-03T19:40:33.153786: step 6629, loss 0.385346, acc 0.890625\n",
      "2017-04-03T19:40:33.360002: step 6630, loss 0.408686, acc 0.84375\n",
      "2017-04-03T19:40:33.561963: step 6631, loss 0.694362, acc 0.765625\n",
      "2017-04-03T19:40:33.762936: step 6632, loss 0.519284, acc 0.8125\n",
      "2017-04-03T19:40:33.965241: step 6633, loss 0.558353, acc 0.78125\n",
      "2017-04-03T19:40:34.168869: step 6634, loss 0.465731, acc 0.828125\n",
      "2017-04-03T19:40:34.371220: step 6635, loss 0.406199, acc 0.875\n",
      "2017-04-03T19:40:34.617129: step 6636, loss 0.516553, acc 0.84375\n",
      "2017-04-03T19:40:34.821635: step 6637, loss 0.381777, acc 0.875\n",
      "2017-04-03T19:40:35.024354: step 6638, loss 0.479732, acc 0.84375\n",
      "2017-04-03T19:40:35.227653: step 6639, loss 0.605356, acc 0.796875\n",
      "2017-04-03T19:40:35.431021: step 6640, loss 0.507392, acc 0.78125\n",
      "2017-04-03T19:40:35.637408: step 6641, loss 0.44461, acc 0.890625\n",
      "2017-04-03T19:40:35.838391: step 6642, loss 0.532441, acc 0.8125\n",
      "2017-04-03T19:40:36.053008: step 6643, loss 0.62975, acc 0.796875\n",
      "2017-04-03T19:40:36.261434: step 6644, loss 0.415669, acc 0.875\n",
      "2017-04-03T19:40:36.457099: step 6645, loss 0.658457, acc 0.796875\n",
      "2017-04-03T19:40:36.670027: step 6646, loss 0.581643, acc 0.8125\n",
      "2017-04-03T19:40:36.870410: step 6647, loss 0.495039, acc 0.84375\n",
      "2017-04-03T19:40:37.068417: step 6648, loss 0.41665, acc 0.875\n",
      "2017-04-03T19:40:37.278918: step 6649, loss 0.443603, acc 0.796875\n",
      "2017-04-03T19:40:37.531113: step 6650, loss 0.325858, acc 0.9375\n",
      "2017-04-03T19:40:37.735505: step 6651, loss 0.629783, acc 0.765625\n",
      "2017-04-03T19:40:37.940141: step 6652, loss 0.550406, acc 0.8125\n",
      "2017-04-03T19:40:38.158169: step 6653, loss 0.453564, acc 0.859375\n",
      "2017-04-03T19:40:38.363775: step 6654, loss 0.595037, acc 0.8125\n",
      "2017-04-03T19:40:38.576396: step 6655, loss 0.669801, acc 0.765625\n",
      "2017-04-03T19:40:38.779505: step 6656, loss 0.447621, acc 0.859375\n",
      "2017-04-03T19:40:38.988145: step 6657, loss 0.543317, acc 0.8125\n",
      "2017-04-03T19:40:39.190995: step 6658, loss 0.643187, acc 0.75\n",
      "2017-04-03T19:40:39.393999: step 6659, loss 0.366195, acc 0.921875\n",
      "2017-04-03T19:40:39.593867: step 6660, loss 0.565987, acc 0.765625\n",
      "2017-04-03T19:40:39.804556: step 6661, loss 0.423968, acc 0.875\n",
      "2017-04-03T19:40:40.005047: step 6662, loss 0.625334, acc 0.703125\n",
      "2017-04-03T19:40:40.210816: step 6663, loss 0.455556, acc 0.859375\n",
      "2017-04-03T19:40:40.422811: step 6664, loss 0.482667, acc 0.796875\n",
      "2017-04-03T19:40:40.666444: step 6665, loss 0.504117, acc 0.84375\n",
      "2017-04-03T19:40:40.873151: step 6666, loss 0.632897, acc 0.796875\n",
      "2017-04-03T19:40:41.115153: step 6667, loss 0.503925, acc 0.8125\n",
      "2017-04-03T19:40:41.320882: step 6668, loss 0.730077, acc 0.765625\n",
      "2017-04-03T19:40:41.524213: step 6669, loss 0.530971, acc 0.8125\n",
      "2017-04-03T19:40:41.736924: step 6670, loss 0.443503, acc 0.84375\n",
      "2017-04-03T19:40:41.953920: step 6671, loss 0.579199, acc 0.796875\n",
      "2017-04-03T19:40:42.156119: step 6672, loss 0.36682, acc 0.90625\n",
      "2017-04-03T19:40:42.354607: step 6673, loss 0.523126, acc 0.84375\n",
      "2017-04-03T19:40:42.560578: step 6674, loss 0.441763, acc 0.828125\n",
      "2017-04-03T19:40:42.778542: step 6675, loss 0.599485, acc 0.78125\n",
      "2017-04-03T19:40:42.994962: step 6676, loss 0.626556, acc 0.78125\n",
      "2017-04-03T19:40:43.212646: step 6677, loss 0.618103, acc 0.796875\n",
      "2017-04-03T19:40:43.431499: step 6678, loss 0.786362, acc 0.75\n",
      "2017-04-03T19:40:43.631029: step 6679, loss 0.413022, acc 0.875\n",
      "2017-04-03T19:40:43.832165: step 6680, loss 0.480849, acc 0.859375\n",
      "2017-04-03T19:40:44.035004: step 6681, loss 0.83206, acc 0.78125\n",
      "2017-04-03T19:40:44.235445: step 6682, loss 0.599415, acc 0.8125\n",
      "2017-04-03T19:40:44.446811: step 6683, loss 0.612873, acc 0.8125\n",
      "2017-04-03T19:40:44.650842: step 6684, loss 0.635992, acc 0.8125\n",
      "2017-04-03T19:40:44.853927: step 6685, loss 0.503881, acc 0.84375\n",
      "2017-04-03T19:40:45.055646: step 6686, loss 0.682251, acc 0.796875\n",
      "2017-04-03T19:40:45.257797: step 6687, loss 0.379976, acc 0.890625\n",
      "2017-04-03T19:40:45.459946: step 6688, loss 0.529173, acc 0.828125\n",
      "2017-04-03T19:40:45.702461: step 6689, loss 0.447688, acc 0.859375\n",
      "2017-04-03T19:40:45.908002: step 6690, loss 0.586912, acc 0.796875\n",
      "2017-04-03T19:40:46.113214: step 6691, loss 0.479275, acc 0.8125\n",
      "2017-04-03T19:40:46.316057: step 6692, loss 0.382732, acc 0.90625\n",
      "2017-04-03T19:40:46.516897: step 6693, loss 0.553511, acc 0.84375\n",
      "2017-04-03T19:40:46.718961: step 6694, loss 0.606256, acc 0.796875\n",
      "2017-04-03T19:40:46.919745: step 6695, loss 0.529174, acc 0.78125\n",
      "2017-04-03T19:40:47.123376: step 6696, loss 0.657859, acc 0.78125\n",
      "2017-04-03T19:40:47.327441: step 6697, loss 0.740683, acc 0.8125\n",
      "2017-04-03T19:40:47.578131: step 6698, loss 0.527907, acc 0.828125\n",
      "2017-04-03T19:40:47.819486: step 6699, loss 0.517944, acc 0.84375\n",
      "2017-04-03T19:40:48.033761: step 6700, loss 0.340428, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:40:50.089057: step 6700, loss 2.85947, acc 0.32325\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-6700\n",
      "\n",
      "2017-04-03T19:40:50.462579: step 6701, loss 0.595364, acc 0.765625\n",
      "2017-04-03T19:40:50.673612: step 6702, loss 0.425423, acc 0.90625\n",
      "2017-04-03T19:40:50.871462: step 6703, loss 0.405075, acc 0.875\n",
      "2017-04-03T19:40:51.088420: step 6704, loss 0.502593, acc 0.859375\n",
      "2017-04-03T19:40:51.294175: step 6705, loss 0.609209, acc 0.734375\n",
      "2017-04-03T19:40:51.492971: step 6706, loss 0.528163, acc 0.796875\n",
      "2017-04-03T19:40:51.700923: step 6707, loss 0.771057, acc 0.78125\n",
      "2017-04-03T19:40:51.930726: step 6708, loss 0.439165, acc 0.796875\n",
      "2017-04-03T19:40:52.139313: step 6709, loss 0.608206, acc 0.765625\n",
      "2017-04-03T19:40:52.387554: step 6710, loss 0.675497, acc 0.78125\n",
      "2017-04-03T19:40:52.592537: step 6711, loss 0.555572, acc 0.8125\n",
      "2017-04-03T19:40:52.845500: step 6712, loss 0.592426, acc 0.765625\n",
      "2017-04-03T19:40:53.055466: step 6713, loss 0.683264, acc 0.828125\n",
      "2017-04-03T19:40:53.257521: step 6714, loss 0.604667, acc 0.734375\n",
      "2017-04-03T19:40:53.459487: step 6715, loss 0.508013, acc 0.875\n",
      "2017-04-03T19:40:53.667433: step 6716, loss 0.498106, acc 0.9375\n",
      "2017-04-03T19:40:53.912754: step 6717, loss 0.450481, acc 0.828125\n",
      "2017-04-03T19:40:54.128744: step 6718, loss 0.680118, acc 0.765625\n",
      "2017-04-03T19:40:54.333899: step 6719, loss 0.50256, acc 0.796875\n",
      "2017-04-03T19:40:54.537238: step 6720, loss 0.533041, acc 0.796875\n",
      "2017-04-03T19:40:54.736600: step 6721, loss 0.600173, acc 0.8125\n",
      "2017-04-03T19:40:54.944586: step 6722, loss 0.52135, acc 0.796875\n",
      "2017-04-03T19:40:55.144453: step 6723, loss 0.499746, acc 0.84375\n",
      "2017-04-03T19:40:55.348690: step 6724, loss 0.424089, acc 0.890625\n",
      "2017-04-03T19:40:55.557935: step 6725, loss 0.572525, acc 0.8125\n",
      "2017-04-03T19:40:55.766361: step 6726, loss 0.642899, acc 0.8125\n",
      "2017-04-03T19:40:55.967703: step 6727, loss 0.645913, acc 0.78125\n",
      "2017-04-03T19:40:56.172564: step 6728, loss 0.445122, acc 0.90625\n",
      "2017-04-03T19:40:56.382036: step 6729, loss 0.691582, acc 0.75\n",
      "2017-04-03T19:40:56.591290: step 6730, loss 0.511299, acc 0.828125\n",
      "2017-04-03T19:40:56.792240: step 6731, loss 0.339614, acc 0.828125\n",
      "2017-04-03T19:40:56.994640: step 6732, loss 0.65499, acc 0.765625\n",
      "2017-04-03T19:40:57.200241: step 6733, loss 0.529232, acc 0.796875\n",
      "2017-04-03T19:40:57.407184: step 6734, loss 0.570653, acc 0.8125\n",
      "2017-04-03T19:40:57.647620: step 6735, loss 0.42238, acc 0.90625\n",
      "2017-04-03T19:40:57.859019: step 6736, loss 0.649979, acc 0.78125\n",
      "2017-04-03T19:40:58.065988: step 6737, loss 0.382818, acc 0.875\n",
      "2017-04-03T19:40:58.269107: step 6738, loss 0.607553, acc 0.78125\n",
      "2017-04-03T19:40:58.481858: step 6739, loss 0.510979, acc 0.8125\n",
      "2017-04-03T19:40:58.723340: step 6740, loss 0.435015, acc 0.875\n",
      "2017-04-03T19:40:58.926492: step 6741, loss 0.498902, acc 0.8125\n",
      "2017-04-03T19:40:59.131659: step 6742, loss 0.808983, acc 0.71875\n",
      "2017-04-03T19:40:59.338449: step 6743, loss 0.604467, acc 0.84375\n",
      "2017-04-03T19:40:59.544482: step 6744, loss 0.621937, acc 0.765625\n",
      "2017-04-03T19:40:59.788245: step 6745, loss 0.686586, acc 0.765625\n",
      "2017-04-03T19:40:59.988801: step 6746, loss 0.596412, acc 0.75\n",
      "2017-04-03T19:41:00.193936: step 6747, loss 0.584896, acc 0.828125\n",
      "2017-04-03T19:41:00.400456: step 6748, loss 0.43517, acc 0.84375\n",
      "2017-04-03T19:41:00.643467: step 6749, loss 0.514021, acc 0.828125\n",
      "2017-04-03T19:41:00.854761: step 6750, loss 0.779829, acc 0.734375\n",
      "2017-04-03T19:41:01.056995: step 6751, loss 0.534133, acc 0.796875\n",
      "2017-04-03T19:41:01.259975: step 6752, loss 0.507046, acc 0.796875\n",
      "2017-04-03T19:41:01.466940: step 6753, loss 0.756881, acc 0.75\n",
      "2017-04-03T19:41:01.713527: step 6754, loss 0.376983, acc 0.890625\n",
      "2017-04-03T19:41:01.919020: step 6755, loss 0.543201, acc 0.828125\n",
      "2017-04-03T19:41:02.064412: step 6756, loss 0.562313, acc 0.84375\n",
      "2017-04-03T19:41:02.269017: step 6757, loss 0.400366, acc 0.828125\n",
      "2017-04-03T19:41:02.469620: step 6758, loss 0.436214, acc 0.875\n",
      "2017-04-03T19:41:02.670529: step 6759, loss 0.376924, acc 0.921875\n",
      "2017-04-03T19:41:02.873990: step 6760, loss 0.409118, acc 0.84375\n",
      "2017-04-03T19:41:03.121558: step 6761, loss 0.450797, acc 0.890625\n",
      "2017-04-03T19:41:03.320545: step 6762, loss 0.35666, acc 0.90625\n",
      "2017-04-03T19:41:03.520909: step 6763, loss 0.402554, acc 0.90625\n",
      "2017-04-03T19:41:03.725326: step 6764, loss 0.622909, acc 0.8125\n",
      "2017-04-03T19:41:03.928384: step 6765, loss 0.310024, acc 0.921875\n",
      "2017-04-03T19:41:04.132439: step 6766, loss 0.404637, acc 0.84375\n",
      "2017-04-03T19:41:04.344222: step 6767, loss 0.688073, acc 0.78125\n",
      "2017-04-03T19:41:04.595201: step 6768, loss 0.387509, acc 0.921875\n",
      "2017-04-03T19:41:04.809263: step 6769, loss 0.586131, acc 0.75\n",
      "2017-04-03T19:41:05.058865: step 6770, loss 0.320133, acc 0.953125\n",
      "2017-04-03T19:41:05.275020: step 6771, loss 0.446555, acc 0.828125\n",
      "2017-04-03T19:41:05.527447: step 6772, loss 0.286141, acc 0.890625\n",
      "2017-04-03T19:41:05.795560: step 6773, loss 0.442132, acc 0.890625\n",
      "2017-04-03T19:41:06.008527: step 6774, loss 0.453853, acc 0.84375\n",
      "2017-04-03T19:41:06.217638: step 6775, loss 0.412621, acc 0.890625\n",
      "2017-04-03T19:41:06.419076: step 6776, loss 0.327748, acc 0.921875\n",
      "2017-04-03T19:41:06.624123: step 6777, loss 0.344687, acc 0.921875\n",
      "2017-04-03T19:41:06.830370: step 6778, loss 0.264926, acc 0.890625\n",
      "2017-04-03T19:41:07.032521: step 6779, loss 0.455286, acc 0.84375\n",
      "2017-04-03T19:41:07.225823: step 6780, loss 0.538964, acc 0.78125\n",
      "2017-04-03T19:41:07.436040: step 6781, loss 0.448233, acc 0.875\n",
      "2017-04-03T19:41:07.645047: step 6782, loss 0.379085, acc 0.890625\n",
      "2017-04-03T19:41:07.847888: step 6783, loss 0.389089, acc 0.890625\n",
      "2017-04-03T19:41:08.056035: step 6784, loss 0.475679, acc 0.84375\n",
      "2017-04-03T19:41:08.268309: step 6785, loss 0.553227, acc 0.8125\n",
      "2017-04-03T19:41:08.478456: step 6786, loss 0.371567, acc 0.875\n",
      "2017-04-03T19:41:08.683199: step 6787, loss 0.329151, acc 0.921875\n",
      "2017-04-03T19:41:08.889196: step 6788, loss 0.367383, acc 0.90625\n",
      "2017-04-03T19:41:09.132482: step 6789, loss 0.385887, acc 0.890625\n",
      "2017-04-03T19:41:09.377230: step 6790, loss 0.405969, acc 0.859375\n",
      "2017-04-03T19:41:09.584353: step 6791, loss 0.950946, acc 0.6875\n",
      "2017-04-03T19:41:09.835806: step 6792, loss 0.354, acc 0.90625\n",
      "2017-04-03T19:41:10.037475: step 6793, loss 0.30262, acc 0.921875\n",
      "2017-04-03T19:41:10.240187: step 6794, loss 0.194314, acc 0.96875\n",
      "2017-04-03T19:41:10.452932: step 6795, loss 0.619719, acc 0.765625\n",
      "2017-04-03T19:41:10.665988: step 6796, loss 0.394781, acc 0.859375\n",
      "2017-04-03T19:41:10.869924: step 6797, loss 0.346913, acc 0.921875\n",
      "2017-04-03T19:41:11.086059: step 6798, loss 0.448629, acc 0.890625\n",
      "2017-04-03T19:41:11.288766: step 6799, loss 0.457196, acc 0.828125\n",
      "2017-04-03T19:41:11.498392: step 6800, loss 0.356465, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:41:13.511036: step 6800, loss 2.89153, acc 0.3155\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-6800\n",
      "\n",
      "2017-04-03T19:41:13.886791: step 6801, loss 0.554552, acc 0.828125\n",
      "2017-04-03T19:41:14.118313: step 6802, loss 0.347745, acc 0.875\n",
      "2017-04-03T19:41:14.323323: step 6803, loss 0.513714, acc 0.875\n",
      "2017-04-03T19:41:14.529852: step 6804, loss 0.376288, acc 0.90625\n",
      "2017-04-03T19:41:14.731692: step 6805, loss 0.539004, acc 0.84375\n",
      "2017-04-03T19:41:14.936409: step 6806, loss 0.310128, acc 0.9375\n",
      "2017-04-03T19:41:15.142873: step 6807, loss 0.421452, acc 0.859375\n",
      "2017-04-03T19:41:15.346114: step 6808, loss 0.432769, acc 0.8125\n",
      "2017-04-03T19:41:15.587914: step 6809, loss 0.48044, acc 0.8125\n",
      "2017-04-03T19:41:15.788812: step 6810, loss 0.405806, acc 0.875\n",
      "2017-04-03T19:41:15.993106: step 6811, loss 0.39241, acc 0.875\n",
      "2017-04-03T19:41:16.197476: step 6812, loss 0.402988, acc 0.84375\n",
      "2017-04-03T19:41:16.399360: step 6813, loss 0.5716, acc 0.796875\n",
      "2017-04-03T19:41:16.604250: step 6814, loss 0.546387, acc 0.8125\n",
      "2017-04-03T19:41:16.808184: step 6815, loss 0.501596, acc 0.8125\n",
      "2017-04-03T19:41:17.009435: step 6816, loss 0.303845, acc 0.921875\n",
      "2017-04-03T19:41:17.214306: step 6817, loss 0.440953, acc 0.921875\n",
      "2017-04-03T19:41:17.414606: step 6818, loss 0.413339, acc 0.921875\n",
      "2017-04-03T19:41:17.619290: step 6819, loss 0.368951, acc 0.890625\n",
      "2017-04-03T19:41:17.862721: step 6820, loss 0.407625, acc 0.8125\n",
      "2017-04-03T19:41:18.069658: step 6821, loss 0.252348, acc 0.9375\n",
      "2017-04-03T19:41:18.277520: step 6822, loss 0.731157, acc 0.734375\n",
      "2017-04-03T19:41:18.481368: step 6823, loss 0.326419, acc 0.859375\n",
      "2017-04-03T19:41:18.688680: step 6824, loss 0.404247, acc 0.84375\n",
      "2017-04-03T19:41:18.897792: step 6825, loss 0.426553, acc 0.828125\n",
      "2017-04-03T19:41:19.102375: step 6826, loss 0.418495, acc 0.890625\n",
      "2017-04-03T19:41:19.313542: step 6827, loss 0.472996, acc 0.859375\n",
      "2017-04-03T19:41:19.516599: step 6828, loss 0.425027, acc 0.921875\n",
      "2017-04-03T19:41:19.717627: step 6829, loss 0.447975, acc 0.875\n",
      "2017-04-03T19:41:19.915882: step 6830, loss 0.430505, acc 0.875\n",
      "2017-04-03T19:41:20.121225: step 6831, loss 0.417493, acc 0.859375\n",
      "2017-04-03T19:41:20.328177: step 6832, loss 0.348752, acc 0.9375\n",
      "2017-04-03T19:41:20.537859: step 6833, loss 0.485141, acc 0.828125\n",
      "2017-04-03T19:41:20.742769: step 6834, loss 0.418298, acc 0.890625\n",
      "2017-04-03T19:41:20.943471: step 6835, loss 0.562058, acc 0.859375\n",
      "2017-04-03T19:41:21.148344: step 6836, loss 0.511289, acc 0.828125\n",
      "2017-04-03T19:41:21.348617: step 6837, loss 0.371088, acc 0.875\n",
      "2017-04-03T19:41:21.556217: step 6838, loss 0.479859, acc 0.8125\n",
      "2017-04-03T19:41:21.760455: step 6839, loss 0.244079, acc 0.9375\n",
      "2017-04-03T19:41:21.964486: step 6840, loss 0.58645, acc 0.78125\n",
      "2017-04-03T19:41:22.169887: step 6841, loss 0.446871, acc 0.828125\n",
      "2017-04-03T19:41:22.372357: step 6842, loss 0.434975, acc 0.828125\n",
      "2017-04-03T19:41:22.577808: step 6843, loss 0.39004, acc 0.875\n",
      "2017-04-03T19:41:22.785793: step 6844, loss 0.538088, acc 0.828125\n",
      "2017-04-03T19:41:23.030026: step 6845, loss 0.747247, acc 0.75\n",
      "2017-04-03T19:41:23.232634: step 6846, loss 0.440993, acc 0.859375\n",
      "2017-04-03T19:41:23.431503: step 6847, loss 0.470451, acc 0.84375\n",
      "2017-04-03T19:41:23.630459: step 6848, loss 0.30953, acc 0.890625\n",
      "2017-04-03T19:41:23.831941: step 6849, loss 0.352266, acc 0.875\n",
      "2017-04-03T19:41:24.041681: step 6850, loss 0.392649, acc 0.859375\n",
      "2017-04-03T19:41:24.246068: step 6851, loss 0.53377, acc 0.8125\n",
      "2017-04-03T19:41:24.456565: step 6852, loss 0.484745, acc 0.828125\n",
      "2017-04-03T19:41:24.658928: step 6853, loss 0.459088, acc 0.8125\n",
      "2017-04-03T19:41:24.862677: step 6854, loss 0.334927, acc 0.890625\n",
      "2017-04-03T19:41:25.065780: step 6855, loss 0.470647, acc 0.828125\n",
      "2017-04-03T19:41:25.269701: step 6856, loss 0.42544, acc 0.828125\n",
      "2017-04-03T19:41:25.471460: step 6857, loss 0.449629, acc 0.78125\n",
      "2017-04-03T19:41:25.668645: step 6858, loss 0.52427, acc 0.8125\n",
      "2017-04-03T19:41:25.889280: step 6859, loss 0.467426, acc 0.84375\n",
      "2017-04-03T19:41:26.091119: step 6860, loss 0.430638, acc 0.875\n",
      "2017-04-03T19:41:26.294566: step 6861, loss 0.489803, acc 0.828125\n",
      "2017-04-03T19:41:26.495454: step 6862, loss 0.384271, acc 0.890625\n",
      "2017-04-03T19:41:26.695900: step 6863, loss 0.407566, acc 0.875\n",
      "2017-04-03T19:41:26.896716: step 6864, loss 0.522406, acc 0.796875\n",
      "2017-04-03T19:41:27.143160: step 6865, loss 0.550007, acc 0.8125\n",
      "2017-04-03T19:41:27.348694: step 6866, loss 0.487041, acc 0.8125\n",
      "2017-04-03T19:41:27.541394: step 6867, loss 0.425672, acc 0.84375\n",
      "2017-04-03T19:41:27.761575: step 6868, loss 0.305584, acc 0.890625\n",
      "2017-04-03T19:41:27.966986: step 6869, loss 0.490909, acc 0.890625\n",
      "2017-04-03T19:41:28.168194: step 6870, loss 0.372702, acc 0.890625\n",
      "2017-04-03T19:41:28.369353: step 6871, loss 0.573251, acc 0.8125\n",
      "2017-04-03T19:41:28.579908: step 6872, loss 0.399669, acc 0.8125\n",
      "2017-04-03T19:41:28.784838: step 6873, loss 0.285775, acc 0.90625\n",
      "2017-04-03T19:41:28.992385: step 6874, loss 0.508344, acc 0.84375\n",
      "2017-04-03T19:41:29.195766: step 6875, loss 0.40163, acc 0.859375\n",
      "2017-04-03T19:41:29.402935: step 6876, loss 0.414814, acc 0.828125\n",
      "2017-04-03T19:41:29.603382: step 6877, loss 0.397411, acc 0.8125\n",
      "2017-04-03T19:41:29.805352: step 6878, loss 0.579349, acc 0.8125\n",
      "2017-04-03T19:41:30.004215: step 6879, loss 0.367214, acc 0.84375\n",
      "2017-04-03T19:41:30.208774: step 6880, loss 0.388913, acc 0.859375\n",
      "2017-04-03T19:41:30.412891: step 6881, loss 0.430187, acc 0.859375\n",
      "2017-04-03T19:41:30.615512: step 6882, loss 0.418304, acc 0.875\n",
      "2017-04-03T19:41:30.819159: step 6883, loss 0.432754, acc 0.875\n",
      "2017-04-03T19:41:31.028081: step 6884, loss 0.559673, acc 0.796875\n",
      "2017-04-03T19:41:31.234008: step 6885, loss 0.265755, acc 0.90625\n",
      "2017-04-03T19:41:31.436581: step 6886, loss 0.302124, acc 0.921875\n",
      "2017-04-03T19:41:31.638809: step 6887, loss 0.378713, acc 0.90625\n",
      "2017-04-03T19:41:31.841705: step 6888, loss 0.311116, acc 0.875\n",
      "2017-04-03T19:41:32.045995: step 6889, loss 0.314026, acc 0.921875\n",
      "2017-04-03T19:41:32.251558: step 6890, loss 0.405512, acc 0.875\n",
      "2017-04-03T19:41:32.496418: step 6891, loss 0.448535, acc 0.84375\n",
      "2017-04-03T19:41:32.700817: step 6892, loss 0.450048, acc 0.875\n",
      "2017-04-03T19:41:32.903071: step 6893, loss 0.415072, acc 0.828125\n",
      "2017-04-03T19:41:33.108268: step 6894, loss 0.32904, acc 0.890625\n",
      "2017-04-03T19:41:33.311487: step 6895, loss 0.341769, acc 0.90625\n",
      "2017-04-03T19:41:33.516341: step 6896, loss 0.516522, acc 0.78125\n",
      "2017-04-03T19:41:33.717365: step 6897, loss 0.598271, acc 0.796875\n",
      "2017-04-03T19:41:33.963298: step 6898, loss 0.347683, acc 0.875\n",
      "2017-04-03T19:41:34.171601: step 6899, loss 0.415817, acc 0.890625\n",
      "2017-04-03T19:41:34.375083: step 6900, loss 0.449149, acc 0.84375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:41:36.365644: step 6900, loss 2.93669, acc 0.3145\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-6900\n",
      "\n",
      "2017-04-03T19:41:36.701166: step 6901, loss 0.491684, acc 0.890625\n",
      "2017-04-03T19:41:36.900481: step 6902, loss 0.493256, acc 0.84375\n",
      "2017-04-03T19:41:37.104906: step 6903, loss 0.448621, acc 0.84375\n",
      "2017-04-03T19:41:37.321712: step 6904, loss 0.383002, acc 0.90625\n",
      "2017-04-03T19:41:37.575251: step 6905, loss 0.36484, acc 0.890625\n",
      "2017-04-03T19:41:37.782701: step 6906, loss 0.412204, acc 0.828125\n",
      "2017-04-03T19:41:37.984620: step 6907, loss 0.301199, acc 0.921875\n",
      "2017-04-03T19:41:38.188337: step 6908, loss 0.427531, acc 0.859375\n",
      "2017-04-03T19:41:38.407560: step 6909, loss 0.334551, acc 0.921875\n",
      "2017-04-03T19:41:38.608801: step 6910, loss 0.550088, acc 0.84375\n",
      "2017-04-03T19:41:38.811265: step 6911, loss 0.361024, acc 0.84375\n",
      "2017-04-03T19:41:39.020825: step 6912, loss 0.378621, acc 0.84375\n",
      "2017-04-03T19:41:39.223589: step 6913, loss 0.408893, acc 0.859375\n",
      "2017-04-03T19:41:39.470555: step 6914, loss 0.809788, acc 0.765625\n",
      "2017-04-03T19:41:39.677496: step 6915, loss 0.28458, acc 0.90625\n",
      "2017-04-03T19:41:39.875648: step 6916, loss 0.460801, acc 0.84375\n",
      "2017-04-03T19:41:40.078885: step 6917, loss 0.297308, acc 0.90625\n",
      "2017-04-03T19:41:40.280131: step 6918, loss 0.501553, acc 0.875\n",
      "2017-04-03T19:41:40.530545: step 6919, loss 0.574709, acc 0.765625\n",
      "2017-04-03T19:41:40.735036: step 6920, loss 0.759018, acc 0.78125\n",
      "2017-04-03T19:41:40.940111: step 6921, loss 0.546539, acc 0.84375\n",
      "2017-04-03T19:41:41.138353: step 6922, loss 0.563278, acc 0.765625\n",
      "2017-04-03T19:41:41.340153: step 6923, loss 0.576708, acc 0.78125\n",
      "2017-04-03T19:41:41.542337: step 6924, loss 0.377419, acc 0.859375\n",
      "2017-04-03T19:41:41.751584: step 6925, loss 0.378847, acc 0.875\n",
      "2017-04-03T19:41:41.954307: step 6926, loss 0.577505, acc 0.84375\n",
      "2017-04-03T19:41:42.193357: step 6927, loss 0.469508, acc 0.8125\n",
      "2017-04-03T19:41:42.400115: step 6928, loss 0.472947, acc 0.8125\n",
      "2017-04-03T19:41:42.602854: step 6929, loss 0.426745, acc 0.890625\n",
      "2017-04-03T19:41:42.802860: step 6930, loss 0.460039, acc 0.8125\n",
      "2017-04-03T19:41:43.008052: step 6931, loss 0.447539, acc 0.890625\n",
      "2017-04-03T19:41:43.212938: step 6932, loss 0.510939, acc 0.859375\n",
      "2017-04-03T19:41:43.416864: step 6933, loss 0.413627, acc 0.84375\n",
      "2017-04-03T19:41:43.617015: step 6934, loss 0.418556, acc 0.890625\n",
      "2017-04-03T19:41:43.819443: step 6935, loss 0.766303, acc 0.765625\n",
      "2017-04-03T19:41:44.019967: step 6936, loss 0.32615, acc 0.890625\n",
      "2017-04-03T19:41:44.219845: step 6937, loss 0.335982, acc 0.890625\n",
      "2017-04-03T19:41:44.419056: step 6938, loss 0.465947, acc 0.796875\n",
      "2017-04-03T19:41:44.626362: step 6939, loss 0.538202, acc 0.8125\n",
      "2017-04-03T19:41:44.826987: step 6940, loss 0.339932, acc 0.921875\n",
      "2017-04-03T19:41:45.069223: step 6941, loss 0.529408, acc 0.8125\n",
      "2017-04-03T19:41:45.270194: step 6942, loss 0.303288, acc 0.890625\n",
      "2017-04-03T19:41:45.479002: step 6943, loss 0.34717, acc 0.84375\n",
      "2017-04-03T19:41:45.683140: step 6944, loss 0.298295, acc 0.9375\n",
      "2017-04-03T19:41:45.883664: step 6945, loss 0.540672, acc 0.859375\n",
      "2017-04-03T19:41:46.084256: step 6946, loss 0.343408, acc 0.890625\n",
      "2017-04-03T19:41:46.288590: step 6947, loss 0.442189, acc 0.8125\n",
      "2017-04-03T19:41:46.487299: step 6948, loss 0.319292, acc 0.90625\n",
      "2017-04-03T19:41:46.688811: step 6949, loss 0.53788, acc 0.796875\n",
      "2017-04-03T19:41:46.889755: step 6950, loss 0.351334, acc 0.890625\n",
      "2017-04-03T19:41:47.089440: step 6951, loss 0.540006, acc 0.84375\n",
      "2017-04-03T19:41:47.291144: step 6952, loss 0.47193, acc 0.84375\n",
      "2017-04-03T19:41:47.498497: step 6953, loss 0.462067, acc 0.875\n",
      "2017-04-03T19:41:47.701698: step 6954, loss 0.320127, acc 0.90625\n",
      "2017-04-03T19:41:47.906634: step 6955, loss 0.504814, acc 0.859375\n",
      "2017-04-03T19:41:48.110393: step 6956, loss 0.307821, acc 0.921875\n",
      "2017-04-03T19:41:48.312438: step 6957, loss 0.478118, acc 0.84375\n",
      "2017-04-03T19:41:48.524439: step 6958, loss 0.350586, acc 0.890625\n",
      "2017-04-03T19:41:48.728916: step 6959, loss 0.500869, acc 0.84375\n",
      "2017-04-03T19:41:48.933203: step 6960, loss 0.293588, acc 0.9375\n",
      "2017-04-03T19:41:49.134634: step 6961, loss 0.47993, acc 0.8125\n",
      "2017-04-03T19:41:49.330697: step 6962, loss 0.846915, acc 0.75\n",
      "2017-04-03T19:41:49.539836: step 6963, loss 0.543829, acc 0.859375\n",
      "2017-04-03T19:41:49.741061: step 6964, loss 0.33026, acc 0.875\n",
      "2017-04-03T19:41:49.943247: step 6965, loss 0.410951, acc 0.859375\n",
      "2017-04-03T19:41:50.143343: step 6966, loss 0.448651, acc 0.796875\n",
      "2017-04-03T19:41:50.347792: step 6967, loss 0.33002, acc 0.90625\n",
      "2017-04-03T19:41:50.574553: step 6968, loss 0.413772, acc 0.859375\n",
      "2017-04-03T19:41:50.771307: step 6969, loss 0.459039, acc 0.84375\n",
      "2017-04-03T19:41:50.974147: step 6970, loss 0.532317, acc 0.78125\n",
      "2017-04-03T19:41:51.174666: step 6971, loss 0.419074, acc 0.84375\n",
      "2017-04-03T19:41:51.375597: step 6972, loss 0.489645, acc 0.859375\n",
      "2017-04-03T19:41:51.573589: step 6973, loss 0.67496, acc 0.75\n",
      "2017-04-03T19:41:51.770870: step 6974, loss 0.306286, acc 0.953125\n",
      "2017-04-03T19:41:51.973528: step 6975, loss 0.564304, acc 0.796875\n",
      "2017-04-03T19:41:52.184244: step 6976, loss 0.448966, acc 0.796875\n",
      "2017-04-03T19:41:52.396810: step 6977, loss 0.436442, acc 0.859375\n",
      "2017-04-03T19:41:52.604502: step 6978, loss 0.364986, acc 0.921875\n",
      "2017-04-03T19:41:52.811152: step 6979, loss 0.471206, acc 0.828125\n",
      "2017-04-03T19:41:53.024675: step 6980, loss 0.339342, acc 0.875\n",
      "2017-04-03T19:41:53.235940: step 6981, loss 0.382173, acc 0.90625\n",
      "2017-04-03T19:41:53.443018: step 6982, loss 0.479845, acc 0.859375\n",
      "2017-04-03T19:41:53.645394: step 6983, loss 0.441168, acc 0.890625\n",
      "2017-04-03T19:41:53.846120: step 6984, loss 0.477544, acc 0.875\n",
      "2017-04-03T19:41:54.045729: step 6985, loss 0.459313, acc 0.875\n",
      "2017-04-03T19:41:54.245210: step 6986, loss 0.459849, acc 0.8125\n",
      "2017-04-03T19:41:54.442677: step 6987, loss 0.381531, acc 0.875\n",
      "2017-04-03T19:41:54.652405: step 6988, loss 0.364895, acc 0.890625\n",
      "2017-04-03T19:41:54.851866: step 6989, loss 0.443831, acc 0.859375\n",
      "2017-04-03T19:41:55.053454: step 6990, loss 0.460846, acc 0.828125\n",
      "2017-04-03T19:41:55.251091: step 6991, loss 0.479932, acc 0.859375\n",
      "2017-04-03T19:41:55.467336: step 6992, loss 0.399005, acc 0.859375\n",
      "2017-04-03T19:41:55.669936: step 6993, loss 0.432341, acc 0.890625\n",
      "2017-04-03T19:41:55.869105: step 6994, loss 0.444718, acc 0.828125\n",
      "2017-04-03T19:41:56.068871: step 6995, loss 0.443629, acc 0.828125\n",
      "2017-04-03T19:41:56.269794: step 6996, loss 0.450632, acc 0.8125\n",
      "2017-04-03T19:41:56.471951: step 6997, loss 0.320637, acc 0.953125\n",
      "2017-04-03T19:41:56.674932: step 6998, loss 0.503471, acc 0.828125\n",
      "2017-04-03T19:41:56.877953: step 6999, loss 0.438884, acc 0.859375\n",
      "2017-04-03T19:41:57.123065: step 7000, loss 0.555218, acc 0.796875\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:41:59.152285: step 7000, loss 2.9674, acc 0.31625\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-7000\n",
      "\n",
      "2017-04-03T19:41:59.480558: step 7001, loss 0.446093, acc 0.859375\n",
      "2017-04-03T19:41:59.681738: step 7002, loss 0.395344, acc 0.859375\n",
      "2017-04-03T19:41:59.881733: step 7003, loss 0.600071, acc 0.828125\n",
      "2017-04-03T19:42:00.081303: step 7004, loss 0.492286, acc 0.859375\n",
      "2017-04-03T19:42:00.286957: step 7005, loss 0.559899, acc 0.78125\n",
      "2017-04-03T19:42:00.489049: step 7006, loss 0.491901, acc 0.796875\n",
      "2017-04-03T19:42:00.688900: step 7007, loss 0.59855, acc 0.8125\n",
      "2017-04-03T19:42:00.899569: step 7008, loss 0.34992, acc 0.90625\n",
      "2017-04-03T19:42:01.102462: step 7009, loss 0.421617, acc 0.890625\n",
      "2017-04-03T19:42:01.303574: step 7010, loss 0.44364, acc 0.84375\n",
      "2017-04-03T19:42:01.503950: step 7011, loss 0.48199, acc 0.875\n",
      "2017-04-03T19:42:01.754183: step 7012, loss 0.347417, acc 0.890625\n",
      "2017-04-03T19:42:01.955411: step 7013, loss 0.477659, acc 0.890625\n",
      "2017-04-03T19:42:02.156222: step 7014, loss 0.397541, acc 0.859375\n",
      "2017-04-03T19:42:02.360426: step 7015, loss 0.575811, acc 0.78125\n",
      "2017-04-03T19:42:02.568306: step 7016, loss 0.482393, acc 0.84375\n",
      "2017-04-03T19:42:02.771419: step 7017, loss 0.379919, acc 0.921875\n",
      "2017-04-03T19:42:02.979587: step 7018, loss 0.540988, acc 0.84375\n",
      "2017-04-03T19:42:03.222289: step 7019, loss 0.43749, acc 0.859375\n",
      "2017-04-03T19:42:03.422669: step 7020, loss 0.327304, acc 0.84375\n",
      "2017-04-03T19:42:03.622815: step 7021, loss 0.501022, acc 0.859375\n",
      "2017-04-03T19:42:03.825756: step 7022, loss 0.293379, acc 0.921875\n",
      "2017-04-03T19:42:04.037631: step 7023, loss 0.447267, acc 0.78125\n",
      "2017-04-03T19:42:04.253789: step 7024, loss 0.5803, acc 0.84375\n",
      "2017-04-03T19:42:04.454181: step 7025, loss 0.678985, acc 0.703125\n",
      "2017-04-03T19:42:04.693779: step 7026, loss 0.637165, acc 0.765625\n",
      "2017-04-03T19:42:04.898779: step 7027, loss 0.510221, acc 0.796875\n",
      "2017-04-03T19:42:05.100170: step 7028, loss 0.415442, acc 0.828125\n",
      "2017-04-03T19:42:05.312757: step 7029, loss 0.408697, acc 0.875\n",
      "2017-04-03T19:42:05.515319: step 7030, loss 0.478391, acc 0.78125\n",
      "2017-04-03T19:42:05.713855: step 7031, loss 0.416072, acc 0.8125\n",
      "2017-04-03T19:42:05.915219: step 7032, loss 0.50879, acc 0.84375\n",
      "2017-04-03T19:42:06.117405: step 7033, loss 0.586149, acc 0.796875\n",
      "2017-04-03T19:42:06.320042: step 7034, loss 0.548869, acc 0.8125\n",
      "2017-04-03T19:42:06.527941: step 7035, loss 0.462189, acc 0.828125\n",
      "2017-04-03T19:42:06.728833: step 7036, loss 0.325857, acc 0.90625\n",
      "2017-04-03T19:42:06.929748: step 7037, loss 0.359713, acc 0.859375\n",
      "2017-04-03T19:42:07.139304: step 7038, loss 0.541575, acc 0.796875\n",
      "2017-04-03T19:42:07.339937: step 7039, loss 0.6254, acc 0.734375\n",
      "2017-04-03T19:42:07.538987: step 7040, loss 0.387292, acc 0.828125\n",
      "2017-04-03T19:42:07.737453: step 7041, loss 0.350752, acc 0.84375\n",
      "2017-04-03T19:42:07.941011: step 7042, loss 0.495276, acc 0.828125\n",
      "2017-04-03T19:42:08.146611: step 7043, loss 0.368768, acc 0.890625\n",
      "2017-04-03T19:42:08.348901: step 7044, loss 0.468093, acc 0.859375\n",
      "2017-04-03T19:42:08.551651: step 7045, loss 0.433566, acc 0.875\n",
      "2017-04-03T19:42:08.795956: step 7046, loss 0.509783, acc 0.828125\n",
      "2017-04-03T19:42:08.999423: step 7047, loss 0.570197, acc 0.796875\n",
      "2017-04-03T19:42:09.206380: step 7048, loss 0.530964, acc 0.828125\n",
      "2017-04-03T19:42:09.406585: step 7049, loss 0.524866, acc 0.859375\n",
      "2017-04-03T19:42:09.618835: step 7050, loss 0.653822, acc 0.78125\n",
      "2017-04-03T19:42:09.830868: step 7051, loss 0.442863, acc 0.84375\n",
      "2017-04-03T19:42:10.031204: step 7052, loss 0.508469, acc 0.828125\n",
      "2017-04-03T19:42:10.234958: step 7053, loss 0.502462, acc 0.84375\n",
      "2017-04-03T19:42:10.433074: step 7054, loss 0.437241, acc 0.84375\n",
      "2017-04-03T19:42:10.634218: step 7055, loss 0.504621, acc 0.8125\n",
      "2017-04-03T19:42:10.837018: step 7056, loss 0.436351, acc 0.875\n",
      "2017-04-03T19:42:11.036158: step 7057, loss 0.428474, acc 0.84375\n",
      "2017-04-03T19:42:11.238610: step 7058, loss 0.391437, acc 0.90625\n",
      "2017-04-03T19:42:11.442525: step 7059, loss 0.419294, acc 0.859375\n",
      "2017-04-03T19:42:11.647019: step 7060, loss 0.524702, acc 0.828125\n",
      "2017-04-03T19:42:11.850296: step 7061, loss 0.454094, acc 0.875\n",
      "2017-04-03T19:42:12.051455: step 7062, loss 0.389805, acc 0.875\n",
      "2017-04-03T19:42:12.254017: step 7063, loss 0.55641, acc 0.796875\n",
      "2017-04-03T19:42:12.457588: step 7064, loss 0.44579, acc 0.84375\n",
      "2017-04-03T19:42:12.666128: step 7065, loss 0.398042, acc 0.890625\n",
      "2017-04-03T19:42:12.864764: step 7066, loss 0.314532, acc 0.921875\n",
      "2017-04-03T19:42:13.067128: step 7067, loss 0.580048, acc 0.828125\n",
      "2017-04-03T19:42:13.271257: step 7068, loss 0.675684, acc 0.71875\n",
      "2017-04-03T19:42:13.509297: step 7069, loss 0.363488, acc 0.875\n",
      "2017-04-03T19:42:13.713467: step 7070, loss 0.744881, acc 0.71875\n",
      "2017-04-03T19:42:13.922836: step 7071, loss 0.58047, acc 0.84375\n",
      "2017-04-03T19:42:14.123535: step 7072, loss 0.43484, acc 0.890625\n",
      "2017-04-03T19:42:14.334711: step 7073, loss 0.513905, acc 0.84375\n",
      "2017-04-03T19:42:14.547011: step 7074, loss 0.60747, acc 0.765625\n",
      "2017-04-03T19:42:14.749545: step 7075, loss 0.358134, acc 0.90625\n",
      "2017-04-03T19:42:14.953648: step 7076, loss 0.505276, acc 0.796875\n",
      "2017-04-03T19:42:15.152062: step 7077, loss 0.295723, acc 0.890625\n",
      "2017-04-03T19:42:15.359454: step 7078, loss 0.319452, acc 0.859375\n",
      "2017-04-03T19:42:15.566012: step 7079, loss 0.621592, acc 0.8125\n",
      "2017-04-03T19:42:15.765578: step 7080, loss 0.553737, acc 0.8125\n",
      "2017-04-03T19:42:15.968939: step 7081, loss 0.47494, acc 0.859375\n",
      "2017-04-03T19:42:16.171337: step 7082, loss 0.519798, acc 0.84375\n",
      "2017-04-03T19:42:16.374378: step 7083, loss 0.370038, acc 0.875\n",
      "2017-04-03T19:42:16.580509: step 7084, loss 0.426437, acc 0.828125\n",
      "2017-04-03T19:42:16.782729: step 7085, loss 0.460929, acc 0.828125\n",
      "2017-04-03T19:42:16.985043: step 7086, loss 0.378966, acc 0.859375\n",
      "2017-04-03T19:42:17.186539: step 7087, loss 0.288273, acc 0.875\n",
      "2017-04-03T19:42:17.386667: step 7088, loss 0.395328, acc 0.84375\n",
      "2017-04-03T19:42:17.587628: step 7089, loss 0.399331, acc 0.90625\n",
      "2017-04-03T19:42:17.789947: step 7090, loss 0.340416, acc 0.875\n",
      "2017-04-03T19:42:17.996894: step 7091, loss 0.719837, acc 0.765625\n",
      "2017-04-03T19:42:18.193713: step 7092, loss 0.485669, acc 0.84375\n",
      "2017-04-03T19:42:18.401203: step 7093, loss 0.455801, acc 0.875\n",
      "2017-04-03T19:42:18.602102: step 7094, loss 0.51188, acc 0.765625\n",
      "2017-04-03T19:42:18.804959: step 7095, loss 0.468391, acc 0.828125\n",
      "2017-04-03T19:42:19.014148: step 7096, loss 0.496091, acc 0.890625\n",
      "2017-04-03T19:42:19.221630: step 7097, loss 0.250457, acc 0.921875\n",
      "2017-04-03T19:42:19.422732: step 7098, loss 0.449195, acc 0.875\n",
      "2017-04-03T19:42:19.664321: step 7099, loss 0.604493, acc 0.765625\n",
      "2017-04-03T19:42:19.867173: step 7100, loss 0.5827, acc 0.796875\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:42:21.907322: step 7100, loss 3.03883, acc 0.31525\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-7100\n",
      "\n",
      "2017-04-03T19:42:22.234905: step 7101, loss 0.407233, acc 0.859375\n",
      "2017-04-03T19:42:22.467545: step 7102, loss 0.338656, acc 0.890625\n",
      "2017-04-03T19:42:22.675019: step 7103, loss 0.414782, acc 0.875\n",
      "2017-04-03T19:42:22.876231: step 7104, loss 0.35836, acc 0.890625\n",
      "2017-04-03T19:42:23.089138: step 7105, loss 0.597589, acc 0.765625\n",
      "2017-04-03T19:42:23.337321: step 7106, loss 0.373474, acc 0.875\n",
      "2017-04-03T19:42:23.582379: step 7107, loss 0.274077, acc 0.9375\n",
      "2017-04-03T19:42:23.794773: step 7108, loss 0.393826, acc 0.875\n",
      "2017-04-03T19:42:23.997048: step 7109, loss 0.552185, acc 0.859375\n",
      "2017-04-03T19:42:24.198389: step 7110, loss 0.473199, acc 0.8125\n",
      "2017-04-03T19:42:24.398183: step 7111, loss 0.356907, acc 0.890625\n",
      "2017-04-03T19:42:24.600176: step 7112, loss 0.390385, acc 0.890625\n",
      "2017-04-03T19:42:24.804628: step 7113, loss 0.334618, acc 0.90625\n",
      "2017-04-03T19:42:25.013910: step 7114, loss 0.396045, acc 0.90625\n",
      "2017-04-03T19:42:25.216977: step 7115, loss 0.318606, acc 0.890625\n",
      "2017-04-03T19:42:25.418227: step 7116, loss 0.418826, acc 0.828125\n",
      "2017-04-03T19:42:25.619205: step 7117, loss 0.40484, acc 0.875\n",
      "2017-04-03T19:42:25.818487: step 7118, loss 0.408457, acc 0.84375\n",
      "2017-04-03T19:42:26.019916: step 7119, loss 0.438475, acc 0.8125\n",
      "2017-04-03T19:42:26.225619: step 7120, loss 0.445411, acc 0.84375\n",
      "2017-04-03T19:42:26.425488: step 7121, loss 0.249435, acc 0.9375\n",
      "2017-04-03T19:42:26.625393: step 7122, loss 0.418529, acc 0.828125\n",
      "2017-04-03T19:42:26.826876: step 7123, loss 0.410831, acc 0.875\n",
      "2017-04-03T19:42:27.073713: step 7124, loss 0.236937, acc 0.9375\n",
      "2017-04-03T19:42:27.278502: step 7125, loss 0.365337, acc 0.875\n",
      "2017-04-03T19:42:27.482180: step 7126, loss 0.626593, acc 0.84375\n",
      "2017-04-03T19:42:27.685579: step 7127, loss 0.528361, acc 0.8125\n",
      "2017-04-03T19:42:27.929448: step 7128, loss 0.582714, acc 0.84375\n",
      "2017-04-03T19:42:28.131975: step 7129, loss 0.512109, acc 0.859375\n",
      "2017-04-03T19:42:28.378264: step 7130, loss 0.67546, acc 0.78125\n",
      "2017-04-03T19:42:28.579989: step 7131, loss 0.544405, acc 0.796875\n",
      "2017-04-03T19:42:28.782721: step 7132, loss 0.438773, acc 0.84375\n",
      "2017-04-03T19:42:28.982606: step 7133, loss 0.504122, acc 0.875\n",
      "2017-04-03T19:42:29.186588: step 7134, loss 0.560543, acc 0.765625\n",
      "2017-04-03T19:42:29.386411: step 7135, loss 0.314824, acc 0.875\n",
      "2017-04-03T19:42:29.595214: step 7136, loss 0.500842, acc 0.8125\n",
      "2017-04-03T19:42:29.801405: step 7137, loss 0.362272, acc 0.875\n",
      "2017-04-03T19:42:30.028528: step 7138, loss 0.31507, acc 0.890625\n",
      "2017-04-03T19:42:30.240546: step 7139, loss 0.583282, acc 0.8125\n",
      "2017-04-03T19:42:30.440583: step 7140, loss 0.50916, acc 0.8125\n",
      "2017-04-03T19:42:30.640501: step 7141, loss 0.306267, acc 0.90625\n",
      "2017-04-03T19:42:30.880439: step 7142, loss 0.446011, acc 0.875\n",
      "2017-04-03T19:42:31.087817: step 7143, loss 0.344459, acc 0.921875\n",
      "2017-04-03T19:42:31.291125: step 7144, loss 0.573268, acc 0.75\n",
      "2017-04-03T19:42:31.489331: step 7145, loss 0.31618, acc 0.90625\n",
      "2017-04-03T19:42:31.732271: step 7146, loss 0.409115, acc 0.890625\n",
      "2017-04-03T19:42:31.938755: step 7147, loss 0.667148, acc 0.796875\n",
      "2017-04-03T19:42:32.154605: step 7148, loss 0.363343, acc 0.875\n",
      "2017-04-03T19:42:32.358424: step 7149, loss 0.478424, acc 0.84375\n",
      "2017-04-03T19:42:32.560224: step 7150, loss 0.666753, acc 0.78125\n",
      "2017-04-03T19:42:32.763465: step 7151, loss 0.442758, acc 0.796875\n",
      "2017-04-03T19:42:32.976973: step 7152, loss 0.311221, acc 0.90625\n",
      "2017-04-03T19:42:33.187864: step 7153, loss 0.355642, acc 0.890625\n",
      "2017-04-03T19:42:33.389648: step 7154, loss 0.382316, acc 0.890625\n",
      "2017-04-03T19:42:33.593811: step 7155, loss 0.639673, acc 0.828125\n",
      "2017-04-03T19:42:33.795311: step 7156, loss 0.409275, acc 0.84375\n",
      "2017-04-03T19:42:34.037994: step 7157, loss 0.355717, acc 0.90625\n",
      "2017-04-03T19:42:34.244336: step 7158, loss 0.373481, acc 0.859375\n",
      "2017-04-03T19:42:34.449041: step 7159, loss 0.513631, acc 0.84375\n",
      "2017-04-03T19:42:34.651941: step 7160, loss 0.429445, acc 0.84375\n",
      "2017-04-03T19:42:34.852846: step 7161, loss 0.370729, acc 0.859375\n",
      "2017-04-03T19:42:35.052946: step 7162, loss 0.445088, acc 0.859375\n",
      "2017-04-03T19:42:35.255686: step 7163, loss 0.302249, acc 0.890625\n",
      "2017-04-03T19:42:35.455033: step 7164, loss 0.61215, acc 0.796875\n",
      "2017-04-03T19:42:35.660465: step 7165, loss 0.674759, acc 0.765625\n",
      "2017-04-03T19:42:35.860003: step 7166, loss 0.462832, acc 0.8125\n",
      "2017-04-03T19:42:36.060939: step 7167, loss 0.612392, acc 0.75\n",
      "2017-04-03T19:42:36.268140: step 7168, loss 0.360228, acc 0.84375\n",
      "2017-04-03T19:42:36.470749: step 7169, loss 0.612337, acc 0.75\n",
      "2017-04-03T19:42:36.675885: step 7170, loss 0.326305, acc 0.921875\n",
      "2017-04-03T19:42:36.884532: step 7171, loss 0.371911, acc 0.875\n",
      "2017-04-03T19:42:37.085796: step 7172, loss 0.501378, acc 0.796875\n",
      "2017-04-03T19:42:37.289590: step 7173, loss 0.466946, acc 0.859375\n",
      "2017-04-03T19:42:37.493273: step 7174, loss 0.523091, acc 0.875\n",
      "2017-04-03T19:42:37.697596: step 7175, loss 0.43379, acc 0.828125\n",
      "2017-04-03T19:42:37.901874: step 7176, loss 0.397738, acc 0.84375\n",
      "2017-04-03T19:42:38.126967: step 7177, loss 0.563174, acc 0.796875\n",
      "2017-04-03T19:42:38.344907: step 7178, loss 0.522299, acc 0.84375\n",
      "2017-04-03T19:42:38.548007: step 7179, loss 0.481938, acc 0.828125\n",
      "2017-04-03T19:42:38.751832: step 7180, loss 0.711705, acc 0.71875\n",
      "2017-04-03T19:42:38.951259: step 7181, loss 0.656968, acc 0.765625\n",
      "2017-04-03T19:42:39.156426: step 7182, loss 0.415278, acc 0.84375\n",
      "2017-04-03T19:42:39.360153: step 7183, loss 0.545099, acc 0.78125\n",
      "2017-04-03T19:42:39.591232: step 7184, loss 0.35663, acc 0.890625\n",
      "2017-04-03T19:42:39.789910: step 7185, loss 0.479349, acc 0.828125\n",
      "2017-04-03T19:42:39.990948: step 7186, loss 0.527319, acc 0.796875\n",
      "2017-04-03T19:42:40.193206: step 7187, loss 0.409485, acc 0.84375\n",
      "2017-04-03T19:42:40.399374: step 7188, loss 0.317955, acc 0.90625\n",
      "2017-04-03T19:42:40.603424: step 7189, loss 0.616541, acc 0.796875\n",
      "2017-04-03T19:42:40.809638: step 7190, loss 0.521641, acc 0.84375\n",
      "2017-04-03T19:42:41.010183: step 7191, loss 0.514694, acc 0.84375\n",
      "2017-04-03T19:42:41.211956: step 7192, loss 0.587916, acc 0.734375\n",
      "2017-04-03T19:42:41.416403: step 7193, loss 0.374157, acc 0.859375\n",
      "2017-04-03T19:42:41.620521: step 7194, loss 0.500917, acc 0.8125\n",
      "2017-04-03T19:42:41.823589: step 7195, loss 0.363984, acc 0.890625\n",
      "2017-04-03T19:42:42.030731: step 7196, loss 0.537634, acc 0.828125\n",
      "2017-04-03T19:42:42.231293: step 7197, loss 0.464402, acc 0.859375\n",
      "2017-04-03T19:42:42.437184: step 7198, loss 0.488561, acc 0.828125\n",
      "2017-04-03T19:42:42.641158: step 7199, loss 0.27776, acc 0.875\n",
      "2017-04-03T19:42:42.843852: step 7200, loss 0.500033, acc 0.828125\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:42:44.852074: step 7200, loss 3.04644, acc 0.315\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-7200\n",
      "\n",
      "2017-04-03T19:42:45.176371: step 7201, loss 0.40146, acc 0.875\n",
      "2017-04-03T19:42:45.376121: step 7202, loss 0.44909, acc 0.859375\n",
      "2017-04-03T19:42:45.578018: step 7203, loss 0.494559, acc 0.84375\n",
      "2017-04-03T19:42:45.776146: step 7204, loss 0.317332, acc 0.890625\n",
      "2017-04-03T19:42:45.977541: step 7205, loss 0.520389, acc 0.796875\n",
      "2017-04-03T19:42:46.197493: step 7206, loss 0.329432, acc 0.890625\n",
      "2017-04-03T19:42:46.399185: step 7207, loss 0.313865, acc 0.90625\n",
      "2017-04-03T19:42:46.600660: step 7208, loss 0.449418, acc 0.84375\n",
      "2017-04-03T19:42:46.805301: step 7209, loss 0.509347, acc 0.796875\n",
      "2017-04-03T19:42:47.008386: step 7210, loss 0.419501, acc 0.859375\n",
      "2017-04-03T19:42:47.207906: step 7211, loss 0.484079, acc 0.84375\n",
      "2017-04-03T19:42:47.408224: step 7212, loss 0.461672, acc 0.859375\n",
      "2017-04-03T19:42:47.624823: step 7213, loss 0.40436, acc 0.875\n",
      "2017-04-03T19:42:47.868907: step 7214, loss 0.420401, acc 0.859375\n",
      "2017-04-03T19:42:48.114916: step 7215, loss 0.535538, acc 0.875\n",
      "2017-04-03T19:42:48.310616: step 7216, loss 0.461222, acc 0.84375\n",
      "2017-04-03T19:42:48.513068: step 7217, loss 0.415734, acc 0.875\n",
      "2017-04-03T19:42:48.724692: step 7218, loss 0.408007, acc 0.875\n",
      "2017-04-03T19:42:48.925700: step 7219, loss 0.34541, acc 0.9375\n",
      "2017-04-03T19:42:49.126500: step 7220, loss 0.567755, acc 0.78125\n",
      "2017-04-03T19:42:49.328087: step 7221, loss 0.445778, acc 0.84375\n",
      "2017-04-03T19:42:49.531569: step 7222, loss 0.246264, acc 0.953125\n",
      "2017-04-03T19:42:49.732967: step 7223, loss 0.718182, acc 0.796875\n",
      "2017-04-03T19:42:49.936284: step 7224, loss 0.296109, acc 0.921875\n",
      "2017-04-03T19:42:50.136431: step 7225, loss 0.53363, acc 0.78125\n",
      "2017-04-03T19:42:50.342077: step 7226, loss 0.414097, acc 0.875\n",
      "2017-04-03T19:42:50.543440: step 7227, loss 0.372041, acc 0.859375\n",
      "2017-04-03T19:42:50.746191: step 7228, loss 0.586039, acc 0.765625\n",
      "2017-04-03T19:42:50.948274: step 7229, loss 0.46388, acc 0.859375\n",
      "2017-04-03T19:42:51.152853: step 7230, loss 0.505721, acc 0.828125\n",
      "2017-04-03T19:42:51.355098: step 7231, loss 0.603149, acc 0.90625\n",
      "2017-04-03T19:42:51.557559: step 7232, loss 0.403551, acc 0.875\n",
      "2017-04-03T19:42:51.759760: step 7233, loss 0.550762, acc 0.859375\n",
      "2017-04-03T19:42:52.008439: step 7234, loss 0.603096, acc 0.796875\n",
      "2017-04-03T19:42:52.218632: step 7235, loss 0.500647, acc 0.859375\n",
      "2017-04-03T19:42:52.422106: step 7236, loss 0.552078, acc 0.828125\n",
      "2017-04-03T19:42:52.627694: step 7237, loss 0.393189, acc 0.9375\n",
      "2017-04-03T19:42:52.835929: step 7238, loss 0.503603, acc 0.859375\n",
      "2017-04-03T19:42:53.036274: step 7239, loss 0.45776, acc 0.875\n",
      "2017-04-03T19:42:53.249462: step 7240, loss 0.422727, acc 0.84375\n",
      "2017-04-03T19:42:53.449172: step 7241, loss 0.365925, acc 0.90625\n",
      "2017-04-03T19:42:53.653320: step 7242, loss 0.420494, acc 0.875\n",
      "2017-04-03T19:42:53.852810: step 7243, loss 0.599972, acc 0.8125\n",
      "2017-04-03T19:42:54.053683: step 7244, loss 0.385994, acc 0.859375\n",
      "2017-04-03T19:42:54.270260: step 7245, loss 0.597672, acc 0.828125\n",
      "2017-04-03T19:42:54.476830: step 7246, loss 0.372236, acc 0.859375\n",
      "2017-04-03T19:42:54.689018: step 7247, loss 0.409128, acc 0.875\n",
      "2017-04-03T19:42:54.888859: step 7248, loss 0.447919, acc 0.859375\n",
      "2017-04-03T19:42:55.092074: step 7249, loss 0.518056, acc 0.828125\n",
      "2017-04-03T19:42:55.294289: step 7250, loss 0.43847, acc 0.859375\n",
      "2017-04-03T19:42:55.495332: step 7251, loss 0.467344, acc 0.90625\n",
      "2017-04-03T19:42:55.696169: step 7252, loss 0.668826, acc 0.8125\n",
      "2017-04-03T19:42:55.898633: step 7253, loss 0.453837, acc 0.828125\n",
      "2017-04-03T19:42:56.100954: step 7254, loss 0.56203, acc 0.84375\n",
      "2017-04-03T19:42:56.306418: step 7255, loss 0.501733, acc 0.828125\n",
      "2017-04-03T19:42:56.504392: step 7256, loss 0.48124, acc 0.828125\n",
      "2017-04-03T19:42:56.714546: step 7257, loss 0.461739, acc 0.875\n",
      "2017-04-03T19:42:56.928550: step 7258, loss 0.440903, acc 0.828125\n",
      "2017-04-03T19:42:57.130746: step 7259, loss 0.69325, acc 0.8125\n",
      "2017-04-03T19:42:57.331198: step 7260, loss 0.359818, acc 0.90625\n",
      "2017-04-03T19:42:57.544474: step 7261, loss 0.517141, acc 0.84375\n",
      "2017-04-03T19:42:57.748390: step 7262, loss 0.448992, acc 0.859375\n",
      "2017-04-03T19:42:57.996411: step 7263, loss 0.557469, acc 0.8125\n",
      "2017-04-03T19:42:58.202921: step 7264, loss 0.591457, acc 0.796875\n",
      "2017-04-03T19:42:58.415624: step 7265, loss 0.350013, acc 0.890625\n",
      "2017-04-03T19:42:58.622731: step 7266, loss 0.542707, acc 0.796875\n",
      "2017-04-03T19:42:58.829944: step 7267, loss 0.596183, acc 0.8125\n",
      "2017-04-03T19:42:59.036486: step 7268, loss 0.488956, acc 0.84375\n",
      "2017-04-03T19:42:59.243832: step 7269, loss 0.517345, acc 0.828125\n",
      "2017-04-03T19:42:59.453935: step 7270, loss 0.320509, acc 0.90625\n",
      "2017-04-03T19:42:59.656586: step 7271, loss 0.491426, acc 0.828125\n",
      "2017-04-03T19:42:59.860992: step 7272, loss 0.39482, acc 0.828125\n",
      "2017-04-03T19:43:00.064987: step 7273, loss 0.489819, acc 0.796875\n",
      "2017-04-03T19:43:00.270074: step 7274, loss 0.439841, acc 0.859375\n",
      "2017-04-03T19:43:00.471062: step 7275, loss 0.638202, acc 0.796875\n",
      "2017-04-03T19:43:00.681513: step 7276, loss 0.506053, acc 0.890625\n",
      "2017-04-03T19:43:00.892372: step 7277, loss 0.382394, acc 0.921875\n",
      "2017-04-03T19:43:01.097589: step 7278, loss 0.510228, acc 0.796875\n",
      "2017-04-03T19:43:01.344646: step 7279, loss 0.266897, acc 0.9375\n",
      "2017-04-03T19:43:01.548085: step 7280, loss 0.419328, acc 0.859375\n",
      "2017-04-03T19:43:01.748686: step 7281, loss 0.394066, acc 0.8125\n",
      "2017-04-03T19:43:01.955947: step 7282, loss 0.52067, acc 0.859375\n",
      "2017-04-03T19:43:02.159604: step 7283, loss 0.516238, acc 0.84375\n",
      "2017-04-03T19:43:02.365228: step 7284, loss 0.595441, acc 0.828125\n",
      "2017-04-03T19:43:02.573359: step 7285, loss 0.633607, acc 0.765625\n",
      "2017-04-03T19:43:02.783056: step 7286, loss 0.496803, acc 0.828125\n",
      "2017-04-03T19:43:02.988857: step 7287, loss 0.429247, acc 0.828125\n",
      "2017-04-03T19:43:03.198770: step 7288, loss 0.281132, acc 0.9375\n",
      "2017-04-03T19:43:03.448023: step 7289, loss 0.663879, acc 0.75\n",
      "2017-04-03T19:43:03.664148: step 7290, loss 0.510606, acc 0.828125\n",
      "2017-04-03T19:43:03.868738: step 7291, loss 0.688272, acc 0.8125\n",
      "2017-04-03T19:43:04.073272: step 7292, loss 0.6555, acc 0.78125\n",
      "2017-04-03T19:43:04.273197: step 7293, loss 0.489477, acc 0.84375\n",
      "2017-04-03T19:43:04.474390: step 7294, loss 0.487662, acc 0.796875\n",
      "2017-04-03T19:43:04.693767: step 7295, loss 0.351597, acc 0.890625\n",
      "2017-04-03T19:43:04.908004: step 7296, loss 0.488496, acc 0.828125\n",
      "2017-04-03T19:43:05.120223: step 7297, loss 0.648128, acc 0.828125\n",
      "2017-04-03T19:43:05.321742: step 7298, loss 0.511867, acc 0.84375\n",
      "2017-04-03T19:43:05.525150: step 7299, loss 0.544683, acc 0.828125\n",
      "2017-04-03T19:43:05.725224: step 7300, loss 0.460118, acc 0.828125\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:43:07.773322: step 7300, loss 3.10409, acc 0.31475\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-7300\n",
      "\n",
      "2017-04-03T19:43:08.095378: step 7301, loss 0.583753, acc 0.796875\n",
      "2017-04-03T19:43:08.300065: step 7302, loss 0.229982, acc 0.953125\n",
      "2017-04-03T19:43:08.503359: step 7303, loss 0.481312, acc 0.796875\n",
      "2017-04-03T19:43:08.706536: step 7304, loss 0.590537, acc 0.78125\n",
      "2017-04-03T19:43:08.912622: step 7305, loss 0.53018, acc 0.875\n",
      "2017-04-03T19:43:09.117629: step 7306, loss 0.398781, acc 0.859375\n",
      "2017-04-03T19:43:09.321623: step 7307, loss 0.327871, acc 0.859375\n",
      "2017-04-03T19:43:09.525241: step 7308, loss 0.470829, acc 0.78125\n",
      "2017-04-03T19:43:09.745085: step 7309, loss 0.337249, acc 0.90625\n",
      "2017-04-03T19:43:09.952425: step 7310, loss 0.437571, acc 0.859375\n",
      "2017-04-03T19:43:10.155584: step 7311, loss 0.614767, acc 0.765625\n",
      "2017-04-03T19:43:10.361832: step 7312, loss 0.392196, acc 0.859375\n",
      "2017-04-03T19:43:10.568322: step 7313, loss 0.481529, acc 0.828125\n",
      "2017-04-03T19:43:10.782910: step 7314, loss 0.546189, acc 0.84375\n",
      "2017-04-03T19:43:10.992387: step 7315, loss 0.393795, acc 0.84375\n",
      "2017-04-03T19:43:11.199736: step 7316, loss 0.459591, acc 0.796875\n",
      "2017-04-03T19:43:11.413300: step 7317, loss 0.613524, acc 0.75\n",
      "2017-04-03T19:43:11.615487: step 7318, loss 0.504443, acc 0.78125\n",
      "2017-04-03T19:43:11.764479: step 7319, loss 0.789817, acc 0.6875\n",
      "2017-04-03T19:43:12.015991: step 7320, loss 0.367271, acc 0.875\n",
      "2017-04-03T19:43:12.218617: step 7321, loss 0.330758, acc 0.90625\n",
      "2017-04-03T19:43:12.423431: step 7322, loss 0.283164, acc 0.890625\n",
      "2017-04-03T19:43:12.626396: step 7323, loss 0.234275, acc 0.90625\n",
      "2017-04-03T19:43:12.834599: step 7324, loss 0.483962, acc 0.859375\n",
      "2017-04-03T19:43:13.046866: step 7325, loss 0.206022, acc 0.9375\n",
      "2017-04-03T19:43:13.254421: step 7326, loss 0.260466, acc 0.921875\n",
      "2017-04-03T19:43:13.464350: step 7327, loss 0.330941, acc 0.890625\n",
      "2017-04-03T19:43:13.666417: step 7328, loss 0.470277, acc 0.84375\n",
      "2017-04-03T19:43:13.881772: step 7329, loss 0.447724, acc 0.859375\n",
      "2017-04-03T19:43:14.090458: step 7330, loss 0.383201, acc 0.859375\n",
      "2017-04-03T19:43:14.295579: step 7331, loss 0.344723, acc 0.921875\n",
      "2017-04-03T19:43:14.497685: step 7332, loss 0.362539, acc 0.90625\n",
      "2017-04-03T19:43:14.702872: step 7333, loss 0.317379, acc 0.921875\n",
      "2017-04-03T19:43:14.909954: step 7334, loss 0.387297, acc 0.90625\n",
      "2017-04-03T19:43:15.112114: step 7335, loss 0.412376, acc 0.84375\n",
      "2017-04-03T19:43:15.323302: step 7336, loss 0.390609, acc 0.828125\n",
      "2017-04-03T19:43:15.529083: step 7337, loss 0.412611, acc 0.859375\n",
      "2017-04-03T19:43:15.738546: step 7338, loss 0.396177, acc 0.859375\n",
      "2017-04-03T19:43:15.979550: step 7339, loss 0.38253, acc 0.84375\n",
      "2017-04-03T19:43:16.194327: step 7340, loss 0.422424, acc 0.828125\n",
      "2017-04-03T19:43:16.397253: step 7341, loss 0.232249, acc 0.921875\n",
      "2017-04-03T19:43:16.599958: step 7342, loss 0.458287, acc 0.828125\n",
      "2017-04-03T19:43:16.801053: step 7343, loss 0.253813, acc 0.921875\n",
      "2017-04-03T19:43:17.013154: step 7344, loss 0.292995, acc 0.921875\n",
      "2017-04-03T19:43:17.214752: step 7345, loss 0.312257, acc 0.875\n",
      "2017-04-03T19:43:17.422733: step 7346, loss 0.313685, acc 0.890625\n",
      "2017-04-03T19:43:17.627478: step 7347, loss 0.275147, acc 0.9375\n",
      "2017-04-03T19:43:17.833604: step 7348, loss 0.339177, acc 0.875\n",
      "2017-04-03T19:43:18.039930: step 7349, loss 0.226577, acc 0.90625\n",
      "2017-04-03T19:43:18.248175: step 7350, loss 0.421931, acc 0.859375\n",
      "2017-04-03T19:43:18.451326: step 7351, loss 0.549497, acc 0.8125\n",
      "2017-04-03T19:43:18.654402: step 7352, loss 0.287343, acc 0.90625\n",
      "2017-04-03T19:43:18.863647: step 7353, loss 0.392365, acc 0.875\n",
      "2017-04-03T19:43:19.065484: step 7354, loss 0.332233, acc 0.90625\n",
      "2017-04-03T19:43:19.264026: step 7355, loss 0.297302, acc 0.90625\n",
      "2017-04-03T19:43:19.465501: step 7356, loss 0.359631, acc 0.84375\n",
      "2017-04-03T19:43:19.669937: step 7357, loss 0.251487, acc 0.921875\n",
      "2017-04-03T19:43:19.873766: step 7358, loss 0.251937, acc 0.9375\n",
      "2017-04-03T19:43:20.086353: step 7359, loss 0.399051, acc 0.859375\n",
      "2017-04-03T19:43:20.290299: step 7360, loss 0.456104, acc 0.8125\n",
      "2017-04-03T19:43:20.498074: step 7361, loss 0.210028, acc 0.953125\n",
      "2017-04-03T19:43:20.704237: step 7362, loss 0.38067, acc 0.875\n",
      "2017-04-03T19:43:20.905266: step 7363, loss 0.311781, acc 0.90625\n",
      "2017-04-03T19:43:21.151074: step 7364, loss 0.358318, acc 0.921875\n",
      "2017-04-03T19:43:21.359358: step 7365, loss 0.483924, acc 0.890625\n",
      "2017-04-03T19:43:21.561720: step 7366, loss 0.657622, acc 0.78125\n",
      "2017-04-03T19:43:21.769691: step 7367, loss 0.452611, acc 0.84375\n",
      "2017-04-03T19:43:21.975974: step 7368, loss 0.264684, acc 0.9375\n",
      "2017-04-03T19:43:22.175684: step 7369, loss 0.361865, acc 0.859375\n",
      "2017-04-03T19:43:22.426361: step 7370, loss 0.412369, acc 0.828125\n",
      "2017-04-03T19:43:22.637899: step 7371, loss 0.496312, acc 0.84375\n",
      "2017-04-03T19:43:22.852519: step 7372, loss 0.451818, acc 0.859375\n",
      "2017-04-03T19:43:23.055065: step 7373, loss 0.254489, acc 0.90625\n",
      "2017-04-03T19:43:23.261275: step 7374, loss 0.333888, acc 0.90625\n",
      "2017-04-03T19:43:23.467203: step 7375, loss 0.341847, acc 0.90625\n",
      "2017-04-03T19:43:23.677064: step 7376, loss 0.312407, acc 0.890625\n",
      "2017-04-03T19:43:23.881705: step 7377, loss 0.322354, acc 0.90625\n",
      "2017-04-03T19:43:24.085205: step 7378, loss 0.365508, acc 0.9375\n",
      "2017-04-03T19:43:24.290941: step 7379, loss 0.270752, acc 0.90625\n",
      "2017-04-03T19:43:24.494648: step 7380, loss 0.468062, acc 0.84375\n",
      "2017-04-03T19:43:24.697933: step 7381, loss 0.392997, acc 0.859375\n",
      "2017-04-03T19:43:24.902414: step 7382, loss 0.425538, acc 0.84375\n",
      "2017-04-03T19:43:25.103355: step 7383, loss 0.307444, acc 0.890625\n",
      "2017-04-03T19:43:25.308855: step 7384, loss 0.680794, acc 0.78125\n",
      "2017-04-03T19:43:25.512645: step 7385, loss 0.280476, acc 0.921875\n",
      "2017-04-03T19:43:25.714656: step 7386, loss 0.4851, acc 0.8125\n",
      "2017-04-03T19:43:25.918054: step 7387, loss 0.431482, acc 0.84375\n",
      "2017-04-03T19:43:26.117286: step 7388, loss 0.376076, acc 0.875\n",
      "2017-04-03T19:43:26.330893: step 7389, loss 0.351108, acc 0.875\n",
      "2017-04-03T19:43:26.537819: step 7390, loss 0.385868, acc 0.875\n",
      "2017-04-03T19:43:26.742460: step 7391, loss 0.297781, acc 0.90625\n",
      "2017-04-03T19:43:26.949552: step 7392, loss 0.383073, acc 0.859375\n",
      "2017-04-03T19:43:27.157745: step 7393, loss 0.527511, acc 0.828125\n",
      "2017-04-03T19:43:27.362266: step 7394, loss 0.266916, acc 0.890625\n",
      "2017-04-03T19:43:27.575869: step 7395, loss 0.239429, acc 0.9375\n",
      "2017-04-03T19:43:27.780137: step 7396, loss 0.307725, acc 0.90625\n",
      "2017-04-03T19:43:27.987493: step 7397, loss 0.432436, acc 0.90625\n",
      "2017-04-03T19:43:28.187388: step 7398, loss 0.334644, acc 0.890625\n",
      "2017-04-03T19:43:28.396774: step 7399, loss 0.446766, acc 0.859375\n",
      "2017-04-03T19:43:28.647414: step 7400, loss 0.397287, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:43:30.635861: step 7400, loss 3.12735, acc 0.31775\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-7400\n",
      "\n",
      "2017-04-03T19:43:30.968198: step 7401, loss 0.230975, acc 0.90625\n",
      "2017-04-03T19:43:31.179458: step 7402, loss 0.390565, acc 0.828125\n",
      "2017-04-03T19:43:31.386596: step 7403, loss 0.360649, acc 0.921875\n",
      "2017-04-03T19:43:31.590918: step 7404, loss 0.315406, acc 0.875\n",
      "2017-04-03T19:43:31.788437: step 7405, loss 0.383007, acc 0.890625\n",
      "2017-04-03T19:43:31.993111: step 7406, loss 0.339317, acc 0.90625\n",
      "2017-04-03T19:43:32.204885: step 7407, loss 0.292156, acc 0.890625\n",
      "2017-04-03T19:43:32.461331: step 7408, loss 0.248122, acc 0.9375\n",
      "2017-04-03T19:43:32.665332: step 7409, loss 0.339767, acc 0.890625\n",
      "2017-04-03T19:43:32.870152: step 7410, loss 0.366568, acc 0.890625\n",
      "2017-04-03T19:43:33.074097: step 7411, loss 0.403297, acc 0.859375\n",
      "2017-04-03T19:43:33.276294: step 7412, loss 0.392647, acc 0.859375\n",
      "2017-04-03T19:43:33.477730: step 7413, loss 0.226879, acc 0.953125\n",
      "2017-04-03T19:43:33.676799: step 7414, loss 0.451136, acc 0.921875\n",
      "2017-04-03T19:43:33.885546: step 7415, loss 0.299367, acc 0.890625\n",
      "2017-04-03T19:43:34.088275: step 7416, loss 0.301757, acc 0.90625\n",
      "2017-04-03T19:43:34.294109: step 7417, loss 0.342457, acc 0.859375\n",
      "2017-04-03T19:43:34.499803: step 7418, loss 0.411204, acc 0.890625\n",
      "2017-04-03T19:43:34.703245: step 7419, loss 0.27333, acc 0.90625\n",
      "2017-04-03T19:43:34.914504: step 7420, loss 0.227057, acc 0.921875\n",
      "2017-04-03T19:43:35.120757: step 7421, loss 0.396203, acc 0.859375\n",
      "2017-04-03T19:43:35.323285: step 7422, loss 0.37247, acc 0.890625\n",
      "2017-04-03T19:43:35.528822: step 7423, loss 0.234103, acc 0.890625\n",
      "2017-04-03T19:43:35.733077: step 7424, loss 0.44566, acc 0.890625\n",
      "2017-04-03T19:43:35.935778: step 7425, loss 0.416423, acc 0.875\n",
      "2017-04-03T19:43:36.137047: step 7426, loss 0.554169, acc 0.765625\n",
      "2017-04-03T19:43:36.361383: step 7427, loss 0.244588, acc 0.9375\n",
      "2017-04-03T19:43:36.572957: step 7428, loss 0.263509, acc 0.890625\n",
      "2017-04-03T19:43:36.786117: step 7429, loss 0.248499, acc 0.921875\n",
      "2017-04-03T19:43:37.043596: step 7430, loss 0.331472, acc 0.921875\n",
      "2017-04-03T19:43:37.242149: step 7431, loss 0.323215, acc 0.875\n",
      "2017-04-03T19:43:37.483697: step 7432, loss 0.376604, acc 0.859375\n",
      "2017-04-03T19:43:37.702661: step 7433, loss 0.364722, acc 0.890625\n",
      "2017-04-03T19:43:37.907489: step 7434, loss 0.419118, acc 0.90625\n",
      "2017-04-03T19:43:38.114614: step 7435, loss 0.422259, acc 0.875\n",
      "2017-04-03T19:43:38.321399: step 7436, loss 0.34317, acc 0.859375\n",
      "2017-04-03T19:43:38.524784: step 7437, loss 0.328653, acc 0.90625\n",
      "2017-04-03T19:43:38.723126: step 7438, loss 0.366562, acc 0.859375\n",
      "2017-04-03T19:43:38.935996: step 7439, loss 0.194171, acc 0.9375\n",
      "2017-04-03T19:43:39.138998: step 7440, loss 0.26455, acc 0.921875\n",
      "2017-04-03T19:43:39.341431: step 7441, loss 0.58211, acc 0.796875\n",
      "2017-04-03T19:43:39.542479: step 7442, loss 0.345529, acc 0.875\n",
      "2017-04-03T19:43:39.751488: step 7443, loss 0.364517, acc 0.859375\n",
      "2017-04-03T19:43:39.953518: step 7444, loss 0.342792, acc 0.90625\n",
      "2017-04-03T19:43:40.162985: step 7445, loss 0.401251, acc 0.890625\n",
      "2017-04-03T19:43:40.365728: step 7446, loss 0.301706, acc 0.90625\n",
      "2017-04-03T19:43:40.563782: step 7447, loss 0.358123, acc 0.890625\n",
      "2017-04-03T19:43:40.768632: step 7448, loss 0.299249, acc 0.953125\n",
      "2017-04-03T19:43:40.978646: step 7449, loss 0.446346, acc 0.828125\n",
      "2017-04-03T19:43:41.229800: step 7450, loss 0.498732, acc 0.890625\n",
      "2017-04-03T19:43:41.470651: step 7451, loss 0.471081, acc 0.84375\n",
      "2017-04-03T19:43:41.674952: step 7452, loss 0.30782, acc 0.90625\n",
      "2017-04-03T19:43:41.877358: step 7453, loss 0.278082, acc 0.90625\n",
      "2017-04-03T19:43:42.078245: step 7454, loss 0.253109, acc 0.921875\n",
      "2017-04-03T19:43:42.280322: step 7455, loss 0.413732, acc 0.875\n",
      "2017-04-03T19:43:42.489384: step 7456, loss 0.414158, acc 0.90625\n",
      "2017-04-03T19:43:42.689628: step 7457, loss 0.390889, acc 0.875\n",
      "2017-04-03T19:43:42.892880: step 7458, loss 0.453078, acc 0.890625\n",
      "2017-04-03T19:43:43.092040: step 7459, loss 0.411931, acc 0.875\n",
      "2017-04-03T19:43:43.294703: step 7460, loss 0.36326, acc 0.90625\n",
      "2017-04-03T19:43:43.498013: step 7461, loss 0.387621, acc 0.90625\n",
      "2017-04-03T19:43:43.700279: step 7462, loss 0.460514, acc 0.828125\n",
      "2017-04-03T19:43:43.900305: step 7463, loss 0.501751, acc 0.78125\n",
      "2017-04-03T19:43:44.148447: step 7464, loss 0.443304, acc 0.84375\n",
      "2017-04-03T19:43:44.353204: step 7465, loss 0.24104, acc 0.9375\n",
      "2017-04-03T19:43:44.553228: step 7466, loss 0.546072, acc 0.78125\n",
      "2017-04-03T19:43:44.754016: step 7467, loss 0.267906, acc 0.921875\n",
      "2017-04-03T19:43:44.961829: step 7468, loss 0.457788, acc 0.84375\n",
      "2017-04-03T19:43:45.161563: step 7469, loss 0.229871, acc 0.90625\n",
      "2017-04-03T19:43:45.406523: step 7470, loss 0.357485, acc 0.890625\n",
      "2017-04-03T19:43:45.608914: step 7471, loss 0.36749, acc 0.890625\n",
      "2017-04-03T19:43:45.850363: step 7472, loss 0.339796, acc 0.921875\n",
      "2017-04-03T19:43:46.101446: step 7473, loss 0.277166, acc 0.90625\n",
      "2017-04-03T19:43:46.302941: step 7474, loss 0.331125, acc 0.90625\n",
      "2017-04-03T19:43:46.514954: step 7475, loss 0.45048, acc 0.828125\n",
      "2017-04-03T19:43:46.715544: step 7476, loss 0.375392, acc 0.875\n",
      "2017-04-03T19:43:46.928627: step 7477, loss 0.396981, acc 0.859375\n",
      "2017-04-03T19:43:47.129119: step 7478, loss 0.317533, acc 0.921875\n",
      "2017-04-03T19:43:47.332901: step 7479, loss 0.518056, acc 0.875\n",
      "2017-04-03T19:43:47.532852: step 7480, loss 0.223757, acc 0.921875\n",
      "2017-04-03T19:43:47.731468: step 7481, loss 0.363449, acc 0.859375\n",
      "2017-04-03T19:43:47.932412: step 7482, loss 0.278558, acc 0.90625\n",
      "2017-04-03T19:43:48.134150: step 7483, loss 0.495181, acc 0.78125\n",
      "2017-04-03T19:43:48.337161: step 7484, loss 0.378201, acc 0.890625\n",
      "2017-04-03T19:43:48.542229: step 7485, loss 0.524512, acc 0.8125\n",
      "2017-04-03T19:43:48.748180: step 7486, loss 0.292176, acc 0.9375\n",
      "2017-04-03T19:43:48.947774: step 7487, loss 0.183799, acc 0.96875\n",
      "2017-04-03T19:43:49.149616: step 7488, loss 0.439897, acc 0.859375\n",
      "2017-04-03T19:43:49.350438: step 7489, loss 0.407504, acc 0.859375\n",
      "2017-04-03T19:43:49.558524: step 7490, loss 0.367682, acc 0.859375\n",
      "2017-04-03T19:43:49.763357: step 7491, loss 0.341749, acc 0.890625\n",
      "2017-04-03T19:43:49.972205: step 7492, loss 0.217684, acc 0.9375\n",
      "2017-04-03T19:43:50.179105: step 7493, loss 0.271614, acc 0.90625\n",
      "2017-04-03T19:43:50.384224: step 7494, loss 0.194854, acc 0.9375\n",
      "2017-04-03T19:43:50.585826: step 7495, loss 0.321913, acc 0.9375\n",
      "2017-04-03T19:43:50.787657: step 7496, loss 0.211891, acc 0.9375\n",
      "2017-04-03T19:43:51.000860: step 7497, loss 0.359076, acc 0.90625\n",
      "2017-04-03T19:43:51.203815: step 7498, loss 0.372192, acc 0.84375\n",
      "2017-04-03T19:43:51.409991: step 7499, loss 0.492737, acc 0.796875\n",
      "2017-04-03T19:43:51.610290: step 7500, loss 0.289763, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:43:53.645584: step 7500, loss 3.22606, acc 0.31875\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-7500\n",
      "\n",
      "2017-04-03T19:43:53.972474: step 7501, loss 0.322809, acc 0.9375\n",
      "2017-04-03T19:43:54.186080: step 7502, loss 0.385901, acc 0.90625\n",
      "2017-04-03T19:43:54.390212: step 7503, loss 0.347607, acc 0.859375\n",
      "2017-04-03T19:43:54.591848: step 7504, loss 0.324953, acc 0.890625\n",
      "2017-04-03T19:43:54.790749: step 7505, loss 0.464756, acc 0.875\n",
      "2017-04-03T19:43:54.988083: step 7506, loss 0.321278, acc 0.90625\n",
      "2017-04-03T19:43:55.190849: step 7507, loss 0.5843, acc 0.828125\n",
      "2017-04-03T19:43:55.395445: step 7508, loss 0.424842, acc 0.890625\n",
      "2017-04-03T19:43:55.596835: step 7509, loss 0.246638, acc 0.90625\n",
      "2017-04-03T19:43:55.793917: step 7510, loss 0.453362, acc 0.859375\n",
      "2017-04-03T19:43:56.042677: step 7511, loss 0.357036, acc 0.828125\n",
      "2017-04-03T19:43:56.249288: step 7512, loss 0.456767, acc 0.828125\n",
      "2017-04-03T19:43:56.493974: step 7513, loss 0.390506, acc 0.84375\n",
      "2017-04-03T19:43:56.695737: step 7514, loss 0.442926, acc 0.875\n",
      "2017-04-03T19:43:56.897311: step 7515, loss 0.707751, acc 0.734375\n",
      "2017-04-03T19:43:57.098751: step 7516, loss 0.554338, acc 0.8125\n",
      "2017-04-03T19:43:57.305518: step 7517, loss 0.585301, acc 0.796875\n",
      "2017-04-03T19:43:57.514058: step 7518, loss 0.459275, acc 0.875\n",
      "2017-04-03T19:43:57.717660: step 7519, loss 0.604775, acc 0.8125\n",
      "2017-04-03T19:43:57.920883: step 7520, loss 0.450251, acc 0.84375\n",
      "2017-04-03T19:43:58.121949: step 7521, loss 0.356392, acc 0.84375\n",
      "2017-04-03T19:43:58.322087: step 7522, loss 0.34716, acc 0.890625\n",
      "2017-04-03T19:43:58.525638: step 7523, loss 0.349393, acc 0.890625\n",
      "2017-04-03T19:43:58.727605: step 7524, loss 0.453517, acc 0.875\n",
      "2017-04-03T19:43:58.927099: step 7525, loss 0.435427, acc 0.84375\n",
      "2017-04-03T19:43:59.127387: step 7526, loss 0.384027, acc 0.90625\n",
      "2017-04-03T19:43:59.328038: step 7527, loss 0.43561, acc 0.84375\n",
      "2017-04-03T19:43:59.525080: step 7528, loss 0.727639, acc 0.765625\n",
      "2017-04-03T19:43:59.728816: step 7529, loss 0.673253, acc 0.8125\n",
      "2017-04-03T19:43:59.926060: step 7530, loss 0.387324, acc 0.828125\n",
      "2017-04-03T19:44:00.127660: step 7531, loss 0.273852, acc 0.921875\n",
      "2017-04-03T19:44:00.373236: step 7532, loss 0.321285, acc 0.890625\n",
      "2017-04-03T19:44:00.574935: step 7533, loss 0.450292, acc 0.890625\n",
      "2017-04-03T19:44:00.774032: step 7534, loss 0.372235, acc 0.875\n",
      "2017-04-03T19:44:00.975037: step 7535, loss 0.320845, acc 0.921875\n",
      "2017-04-03T19:44:01.173844: step 7536, loss 0.175779, acc 0.984375\n",
      "2017-04-03T19:44:01.377813: step 7537, loss 0.373646, acc 0.8125\n",
      "2017-04-03T19:44:01.623152: step 7538, loss 0.38979, acc 0.890625\n",
      "2017-04-03T19:44:01.871894: step 7539, loss 0.576191, acc 0.8125\n",
      "2017-04-03T19:44:02.079275: step 7540, loss 0.442521, acc 0.828125\n",
      "2017-04-03T19:44:02.281861: step 7541, loss 0.263667, acc 0.9375\n",
      "2017-04-03T19:44:02.484606: step 7542, loss 0.345128, acc 0.859375\n",
      "2017-04-03T19:44:02.731831: step 7543, loss 0.375694, acc 0.859375\n",
      "2017-04-03T19:44:02.939535: step 7544, loss 0.418118, acc 0.859375\n",
      "2017-04-03T19:44:03.144690: step 7545, loss 0.501478, acc 0.8125\n",
      "2017-04-03T19:44:03.350696: step 7546, loss 0.470106, acc 0.828125\n",
      "2017-04-03T19:44:03.553086: step 7547, loss 0.332261, acc 0.890625\n",
      "2017-04-03T19:44:03.755531: step 7548, loss 0.184586, acc 0.953125\n",
      "2017-04-03T19:44:03.998045: step 7549, loss 0.310024, acc 0.859375\n",
      "2017-04-03T19:44:04.216165: step 7550, loss 0.339989, acc 0.875\n",
      "2017-04-03T19:44:04.429839: step 7551, loss 0.578882, acc 0.765625\n",
      "2017-04-03T19:44:04.626291: step 7552, loss 0.587646, acc 0.796875\n",
      "2017-04-03T19:44:04.832219: step 7553, loss 0.532062, acc 0.84375\n",
      "2017-04-03T19:44:05.038097: step 7554, loss 0.283915, acc 0.921875\n",
      "2017-04-03T19:44:05.268017: step 7555, loss 0.422199, acc 0.859375\n",
      "2017-04-03T19:44:05.475844: step 7556, loss 0.406664, acc 0.859375\n",
      "2017-04-03T19:44:05.716703: step 7557, loss 0.513384, acc 0.796875\n",
      "2017-04-03T19:44:05.919564: step 7558, loss 0.440466, acc 0.828125\n",
      "2017-04-03T19:44:06.159151: step 7559, loss 0.396733, acc 0.890625\n",
      "2017-04-03T19:44:06.358260: step 7560, loss 0.270221, acc 0.890625\n",
      "2017-04-03T19:44:06.561909: step 7561, loss 0.40164, acc 0.859375\n",
      "2017-04-03T19:44:06.763677: step 7562, loss 0.300893, acc 0.890625\n",
      "2017-04-03T19:44:06.966911: step 7563, loss 0.417137, acc 0.921875\n",
      "2017-04-03T19:44:07.170558: step 7564, loss 0.475697, acc 0.84375\n",
      "2017-04-03T19:44:07.369831: step 7565, loss 0.434792, acc 0.875\n",
      "2017-04-03T19:44:07.571459: step 7566, loss 0.29637, acc 0.921875\n",
      "2017-04-03T19:44:07.774788: step 7567, loss 0.512959, acc 0.875\n",
      "2017-04-03T19:44:07.973717: step 7568, loss 0.520963, acc 0.875\n",
      "2017-04-03T19:44:08.174304: step 7569, loss 0.444069, acc 0.84375\n",
      "2017-04-03T19:44:08.376391: step 7570, loss 0.434407, acc 0.859375\n",
      "2017-04-03T19:44:08.579104: step 7571, loss 0.510477, acc 0.796875\n",
      "2017-04-03T19:44:08.785530: step 7572, loss 0.506714, acc 0.84375\n",
      "2017-04-03T19:44:08.991258: step 7573, loss 0.303751, acc 0.921875\n",
      "2017-04-03T19:44:09.235079: step 7574, loss 0.369755, acc 0.890625\n",
      "2017-04-03T19:44:09.434132: step 7575, loss 0.34005, acc 0.875\n",
      "2017-04-03T19:44:09.635655: step 7576, loss 0.354302, acc 0.875\n",
      "2017-04-03T19:44:09.839887: step 7577, loss 0.50205, acc 0.828125\n",
      "2017-04-03T19:44:10.039648: step 7578, loss 0.350427, acc 0.84375\n",
      "2017-04-03T19:44:10.241784: step 7579, loss 0.381579, acc 0.875\n",
      "2017-04-03T19:44:10.446386: step 7580, loss 0.344989, acc 0.875\n",
      "2017-04-03T19:44:10.647259: step 7581, loss 0.373827, acc 0.890625\n",
      "2017-04-03T19:44:10.848535: step 7582, loss 0.280649, acc 0.90625\n",
      "2017-04-03T19:44:11.052659: step 7583, loss 0.368496, acc 0.875\n",
      "2017-04-03T19:44:11.259264: step 7584, loss 0.455039, acc 0.84375\n",
      "2017-04-03T19:44:11.456346: step 7585, loss 0.352286, acc 0.90625\n",
      "2017-04-03T19:44:11.660001: step 7586, loss 0.357902, acc 0.859375\n",
      "2017-04-03T19:44:11.859694: step 7587, loss 0.372305, acc 0.90625\n",
      "2017-04-03T19:44:12.063812: step 7588, loss 0.517083, acc 0.859375\n",
      "2017-04-03T19:44:12.259587: step 7589, loss 0.330355, acc 0.90625\n",
      "2017-04-03T19:44:12.463545: step 7590, loss 0.363214, acc 0.859375\n",
      "2017-04-03T19:44:12.664252: step 7591, loss 0.406234, acc 0.84375\n",
      "2017-04-03T19:44:12.865339: step 7592, loss 0.368874, acc 0.921875\n",
      "2017-04-03T19:44:13.107817: step 7593, loss 0.246757, acc 0.96875\n",
      "2017-04-03T19:44:13.313149: step 7594, loss 0.60746, acc 0.765625\n",
      "2017-04-03T19:44:13.513194: step 7595, loss 0.328326, acc 0.890625\n",
      "2017-04-03T19:44:13.711287: step 7596, loss 0.49877, acc 0.84375\n",
      "2017-04-03T19:44:13.913368: step 7597, loss 0.377527, acc 0.859375\n",
      "2017-04-03T19:44:14.118814: step 7598, loss 0.417418, acc 0.84375\n",
      "2017-04-03T19:44:14.323393: step 7599, loss 0.389501, acc 0.859375\n",
      "2017-04-03T19:44:14.527146: step 7600, loss 0.434175, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:44:16.542417: step 7600, loss 3.21456, acc 0.32\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-7600\n",
      "\n",
      "2017-04-03T19:44:16.872842: step 7601, loss 0.429057, acc 0.859375\n",
      "2017-04-03T19:44:17.077266: step 7602, loss 0.465633, acc 0.90625\n",
      "2017-04-03T19:44:17.283583: step 7603, loss 0.524469, acc 0.828125\n",
      "2017-04-03T19:44:17.480180: step 7604, loss 0.391835, acc 0.875\n",
      "2017-04-03T19:44:17.679942: step 7605, loss 0.317922, acc 0.875\n",
      "2017-04-03T19:44:17.885687: step 7606, loss 0.363767, acc 0.90625\n",
      "2017-04-03T19:44:18.087874: step 7607, loss 0.387086, acc 0.84375\n",
      "2017-04-03T19:44:18.292995: step 7608, loss 0.574792, acc 0.8125\n",
      "2017-04-03T19:44:18.494597: step 7609, loss 0.373321, acc 0.828125\n",
      "2017-04-03T19:44:18.695567: step 7610, loss 0.368455, acc 0.859375\n",
      "2017-04-03T19:44:18.897435: step 7611, loss 0.248151, acc 0.953125\n",
      "2017-04-03T19:44:19.100462: step 7612, loss 0.376916, acc 0.890625\n",
      "2017-04-03T19:44:19.301057: step 7613, loss 0.473731, acc 0.875\n",
      "2017-04-03T19:44:19.504185: step 7614, loss 0.487648, acc 0.828125\n",
      "2017-04-03T19:44:19.748400: step 7615, loss 0.464521, acc 0.828125\n",
      "2017-04-03T19:44:19.993520: step 7616, loss 0.433114, acc 0.828125\n",
      "2017-04-03T19:44:20.193097: step 7617, loss 0.371899, acc 0.859375\n",
      "2017-04-03T19:44:20.393615: step 7618, loss 0.675326, acc 0.796875\n",
      "2017-04-03T19:44:20.602682: step 7619, loss 0.402584, acc 0.890625\n",
      "2017-04-03T19:44:20.808621: step 7620, loss 0.303053, acc 0.90625\n",
      "2017-04-03T19:44:21.008548: step 7621, loss 0.394356, acc 0.8125\n",
      "2017-04-03T19:44:21.208161: step 7622, loss 0.392526, acc 0.90625\n",
      "2017-04-03T19:44:21.413760: step 7623, loss 0.348107, acc 0.921875\n",
      "2017-04-03T19:44:21.615374: step 7624, loss 0.371348, acc 0.90625\n",
      "2017-04-03T19:44:21.821035: step 7625, loss 0.376112, acc 0.859375\n",
      "2017-04-03T19:44:22.024396: step 7626, loss 0.368663, acc 0.875\n",
      "2017-04-03T19:44:22.223087: step 7627, loss 0.433847, acc 0.84375\n",
      "2017-04-03T19:44:22.466428: step 7628, loss 0.489667, acc 0.828125\n",
      "2017-04-03T19:44:22.664530: step 7629, loss 0.429529, acc 0.875\n",
      "2017-04-03T19:44:22.908264: step 7630, loss 0.49138, acc 0.796875\n",
      "2017-04-03T19:44:23.107523: step 7631, loss 0.361345, acc 0.875\n",
      "2017-04-03T19:44:23.310720: step 7632, loss 0.458246, acc 0.84375\n",
      "2017-04-03T19:44:23.517277: step 7633, loss 0.620489, acc 0.765625\n",
      "2017-04-03T19:44:23.734275: step 7634, loss 0.412161, acc 0.84375\n",
      "2017-04-03T19:44:23.937405: step 7635, loss 0.363719, acc 0.890625\n",
      "2017-04-03T19:44:24.139221: step 7636, loss 0.285271, acc 0.90625\n",
      "2017-04-03T19:44:24.338782: step 7637, loss 0.39599, acc 0.875\n",
      "2017-04-03T19:44:24.542774: step 7638, loss 0.470331, acc 0.859375\n",
      "2017-04-03T19:44:24.745242: step 7639, loss 0.45691, acc 0.796875\n",
      "2017-04-03T19:44:24.946127: step 7640, loss 0.26792, acc 0.890625\n",
      "2017-04-03T19:44:25.146642: step 7641, loss 0.448965, acc 0.84375\n",
      "2017-04-03T19:44:25.349302: step 7642, loss 0.407735, acc 0.890625\n",
      "2017-04-03T19:44:25.544684: step 7643, loss 0.476029, acc 0.859375\n",
      "2017-04-03T19:44:25.748410: step 7644, loss 0.501911, acc 0.84375\n",
      "2017-04-03T19:44:25.990316: step 7645, loss 0.412009, acc 0.84375\n",
      "2017-04-03T19:44:26.193417: step 7646, loss 0.431743, acc 0.859375\n",
      "2017-04-03T19:44:26.432157: step 7647, loss 0.541836, acc 0.890625\n",
      "2017-04-03T19:44:26.634125: step 7648, loss 0.298249, acc 0.90625\n",
      "2017-04-03T19:44:26.836699: step 7649, loss 0.442711, acc 0.875\n",
      "2017-04-03T19:44:27.036073: step 7650, loss 0.351943, acc 0.890625\n",
      "2017-04-03T19:44:27.245095: step 7651, loss 0.492167, acc 0.875\n",
      "2017-04-03T19:44:27.492087: step 7652, loss 0.488288, acc 0.84375\n",
      "2017-04-03T19:44:27.695658: step 7653, loss 0.345134, acc 0.84375\n",
      "2017-04-03T19:44:27.899148: step 7654, loss 0.289417, acc 0.921875\n",
      "2017-04-03T19:44:28.106487: step 7655, loss 0.323165, acc 0.890625\n",
      "2017-04-03T19:44:28.310709: step 7656, loss 0.279338, acc 0.9375\n",
      "2017-04-03T19:44:28.514625: step 7657, loss 0.506814, acc 0.859375\n",
      "2017-04-03T19:44:28.743768: step 7658, loss 0.385935, acc 0.875\n",
      "2017-04-03T19:44:28.951147: step 7659, loss 0.286138, acc 0.90625\n",
      "2017-04-03T19:44:29.154178: step 7660, loss 0.416237, acc 0.84375\n",
      "2017-04-03T19:44:29.359109: step 7661, loss 0.579462, acc 0.8125\n",
      "2017-04-03T19:44:29.559113: step 7662, loss 0.392165, acc 0.875\n",
      "2017-04-03T19:44:29.802147: step 7663, loss 0.451527, acc 0.875\n",
      "2017-04-03T19:44:30.008339: step 7664, loss 0.50615, acc 0.828125\n",
      "2017-04-03T19:44:30.208506: step 7665, loss 0.358985, acc 0.9375\n",
      "2017-04-03T19:44:30.411335: step 7666, loss 0.271596, acc 0.921875\n",
      "2017-04-03T19:44:30.615676: step 7667, loss 0.508586, acc 0.796875\n",
      "2017-04-03T19:44:30.816003: step 7668, loss 0.391391, acc 0.859375\n",
      "2017-04-03T19:44:31.014846: step 7669, loss 0.391593, acc 0.84375\n",
      "2017-04-03T19:44:31.215503: step 7670, loss 0.386942, acc 0.875\n",
      "2017-04-03T19:44:31.416135: step 7671, loss 0.429335, acc 0.84375\n",
      "2017-04-03T19:44:31.620973: step 7672, loss 0.475645, acc 0.875\n",
      "2017-04-03T19:44:31.821267: step 7673, loss 0.411149, acc 0.84375\n",
      "2017-04-03T19:44:32.023004: step 7674, loss 0.454542, acc 0.90625\n",
      "2017-04-03T19:44:32.231358: step 7675, loss 0.380751, acc 0.859375\n",
      "2017-04-03T19:44:32.430749: step 7676, loss 0.498543, acc 0.859375\n",
      "2017-04-03T19:44:32.637513: step 7677, loss 0.622234, acc 0.828125\n",
      "2017-04-03T19:44:32.838717: step 7678, loss 0.576781, acc 0.8125\n",
      "2017-04-03T19:44:33.040260: step 7679, loss 0.531034, acc 0.828125\n",
      "2017-04-03T19:44:33.247480: step 7680, loss 0.481866, acc 0.796875\n",
      "2017-04-03T19:44:33.490860: step 7681, loss 0.531575, acc 0.796875\n",
      "2017-04-03T19:44:33.694947: step 7682, loss 0.467705, acc 0.8125\n",
      "2017-04-03T19:44:33.897790: step 7683, loss 0.355964, acc 0.84375\n",
      "2017-04-03T19:44:34.105716: step 7684, loss 0.350858, acc 0.859375\n",
      "2017-04-03T19:44:34.349902: step 7685, loss 0.465151, acc 0.875\n",
      "2017-04-03T19:44:34.555313: step 7686, loss 0.610048, acc 0.796875\n",
      "2017-04-03T19:44:34.758561: step 7687, loss 0.27322, acc 0.90625\n",
      "2017-04-03T19:44:34.963326: step 7688, loss 0.47828, acc 0.859375\n",
      "2017-04-03T19:44:35.206024: step 7689, loss 0.354578, acc 0.875\n",
      "2017-04-03T19:44:35.412091: step 7690, loss 0.373049, acc 0.90625\n",
      "2017-04-03T19:44:35.611466: step 7691, loss 0.394789, acc 0.90625\n",
      "2017-04-03T19:44:35.829362: step 7692, loss 0.249192, acc 0.9375\n",
      "2017-04-03T19:44:36.044810: step 7693, loss 0.327437, acc 0.875\n",
      "2017-04-03T19:44:36.260465: step 7694, loss 0.553021, acc 0.828125\n",
      "2017-04-03T19:44:36.464856: step 7695, loss 0.355415, acc 0.890625\n",
      "2017-04-03T19:44:36.669529: step 7696, loss 0.27255, acc 0.921875\n",
      "2017-04-03T19:44:36.869649: step 7697, loss 0.511193, acc 0.859375\n",
      "2017-04-03T19:44:37.072674: step 7698, loss 0.291097, acc 0.890625\n",
      "2017-04-03T19:44:37.274806: step 7699, loss 0.247802, acc 0.921875\n",
      "2017-04-03T19:44:37.474599: step 7700, loss 0.496258, acc 0.84375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:44:39.539683: step 7700, loss 3.25439, acc 0.313\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-7700\n",
      "\n",
      "2017-04-03T19:44:39.878935: step 7701, loss 0.62655, acc 0.828125\n",
      "2017-04-03T19:44:40.083503: step 7702, loss 0.349283, acc 0.890625\n",
      "2017-04-03T19:44:40.283021: step 7703, loss 0.296956, acc 0.875\n",
      "2017-04-03T19:44:40.490626: step 7704, loss 0.483178, acc 0.796875\n",
      "2017-04-03T19:44:40.693780: step 7705, loss 0.462869, acc 0.859375\n",
      "2017-04-03T19:44:40.901569: step 7706, loss 0.39998, acc 0.890625\n",
      "2017-04-03T19:44:41.102675: step 7707, loss 0.428064, acc 0.859375\n",
      "2017-04-03T19:44:41.306143: step 7708, loss 0.484698, acc 0.859375\n",
      "2017-04-03T19:44:41.508357: step 7709, loss 0.438474, acc 0.90625\n",
      "2017-04-03T19:44:41.716931: step 7710, loss 0.402392, acc 0.890625\n",
      "2017-04-03T19:44:41.913440: step 7711, loss 0.43016, acc 0.875\n",
      "2017-04-03T19:44:42.116541: step 7712, loss 0.385435, acc 0.890625\n",
      "2017-04-03T19:44:42.315748: step 7713, loss 0.399224, acc 0.890625\n",
      "2017-04-03T19:44:42.516886: step 7714, loss 0.37302, acc 0.84375\n",
      "2017-04-03T19:44:42.729039: step 7715, loss 0.551214, acc 0.78125\n",
      "2017-04-03T19:44:42.938671: step 7716, loss 0.433212, acc 0.859375\n",
      "2017-04-03T19:44:43.142209: step 7717, loss 0.40192, acc 0.90625\n",
      "2017-04-03T19:44:43.344788: step 7718, loss 0.41451, acc 0.859375\n",
      "2017-04-03T19:44:43.542127: step 7719, loss 0.471597, acc 0.828125\n",
      "2017-04-03T19:44:43.745686: step 7720, loss 0.540998, acc 0.84375\n",
      "2017-04-03T19:44:43.944807: step 7721, loss 0.628841, acc 0.828125\n",
      "2017-04-03T19:44:44.162920: step 7722, loss 0.504553, acc 0.828125\n",
      "2017-04-03T19:44:44.360641: step 7723, loss 0.280774, acc 0.875\n",
      "2017-04-03T19:44:44.566906: step 7724, loss 0.331424, acc 0.90625\n",
      "2017-04-03T19:44:44.774595: step 7725, loss 0.382523, acc 0.859375\n",
      "2017-04-03T19:44:44.976577: step 7726, loss 0.34041, acc 0.875\n",
      "2017-04-03T19:44:45.178318: step 7727, loss 0.400456, acc 0.875\n",
      "2017-04-03T19:44:45.379047: step 7728, loss 0.427323, acc 0.859375\n",
      "2017-04-03T19:44:45.582083: step 7729, loss 0.298087, acc 0.90625\n",
      "2017-04-03T19:44:45.786096: step 7730, loss 0.411789, acc 0.84375\n",
      "2017-04-03T19:44:45.992851: step 7731, loss 0.355303, acc 0.84375\n",
      "2017-04-03T19:44:46.194870: step 7732, loss 0.526868, acc 0.84375\n",
      "2017-04-03T19:44:46.398513: step 7733, loss 0.495606, acc 0.8125\n",
      "2017-04-03T19:44:46.599701: step 7734, loss 0.409394, acc 0.875\n",
      "2017-04-03T19:44:46.798734: step 7735, loss 0.441065, acc 0.90625\n",
      "2017-04-03T19:44:47.002960: step 7736, loss 0.618549, acc 0.796875\n",
      "2017-04-03T19:44:47.251261: step 7737, loss 0.38939, acc 0.875\n",
      "2017-04-03T19:44:47.454178: step 7738, loss 0.56372, acc 0.765625\n",
      "2017-04-03T19:44:47.662668: step 7739, loss 0.467624, acc 0.796875\n",
      "2017-04-03T19:44:47.866469: step 7740, loss 0.391078, acc 0.828125\n",
      "2017-04-03T19:44:48.065237: step 7741, loss 0.302526, acc 0.953125\n",
      "2017-04-03T19:44:48.269365: step 7742, loss 0.459152, acc 0.859375\n",
      "2017-04-03T19:44:48.466304: step 7743, loss 0.411, acc 0.875\n",
      "2017-04-03T19:44:48.672702: step 7744, loss 0.48843, acc 0.796875\n",
      "2017-04-03T19:44:48.875267: step 7745, loss 0.306902, acc 0.921875\n",
      "2017-04-03T19:44:49.076961: step 7746, loss 0.52289, acc 0.859375\n",
      "2017-04-03T19:44:49.276413: step 7747, loss 0.265129, acc 0.921875\n",
      "2017-04-03T19:44:49.479594: step 7748, loss 0.445407, acc 0.828125\n",
      "2017-04-03T19:44:49.685088: step 7749, loss 0.354884, acc 0.90625\n",
      "2017-04-03T19:44:49.882614: step 7750, loss 0.533955, acc 0.875\n",
      "2017-04-03T19:44:50.086723: step 7751, loss 0.483985, acc 0.859375\n",
      "2017-04-03T19:44:50.295334: step 7752, loss 0.249757, acc 0.9375\n",
      "2017-04-03T19:44:50.495490: step 7753, loss 0.34928, acc 0.875\n",
      "2017-04-03T19:44:50.700716: step 7754, loss 0.315804, acc 0.921875\n",
      "2017-04-03T19:44:50.906293: step 7755, loss 0.365562, acc 0.859375\n",
      "2017-04-03T19:44:51.109481: step 7756, loss 0.447251, acc 0.90625\n",
      "2017-04-03T19:44:51.312122: step 7757, loss 0.350556, acc 0.859375\n",
      "2017-04-03T19:44:51.523265: step 7758, loss 0.47921, acc 0.796875\n",
      "2017-04-03T19:44:51.725408: step 7759, loss 0.361345, acc 0.921875\n",
      "2017-04-03T19:44:51.926871: step 7760, loss 0.271327, acc 0.890625\n",
      "2017-04-03T19:44:52.130127: step 7761, loss 0.268424, acc 0.921875\n",
      "2017-04-03T19:44:52.334943: step 7762, loss 0.224109, acc 0.9375\n",
      "2017-04-03T19:44:52.538594: step 7763, loss 0.444745, acc 0.859375\n",
      "2017-04-03T19:44:52.739206: step 7764, loss 0.477857, acc 0.859375\n",
      "2017-04-03T19:44:52.949223: step 7765, loss 0.501245, acc 0.8125\n",
      "2017-04-03T19:44:53.154545: step 7766, loss 0.322016, acc 0.890625\n",
      "2017-04-03T19:44:53.359816: step 7767, loss 0.419804, acc 0.890625\n",
      "2017-04-03T19:44:53.559885: step 7768, loss 0.425432, acc 0.84375\n",
      "2017-04-03T19:44:53.761170: step 7769, loss 0.258825, acc 0.921875\n",
      "2017-04-03T19:44:53.959756: step 7770, loss 0.582939, acc 0.8125\n",
      "2017-04-03T19:44:54.165638: step 7771, loss 0.368717, acc 0.90625\n",
      "2017-04-03T19:44:54.370104: step 7772, loss 0.41308, acc 0.84375\n",
      "2017-04-03T19:44:54.572235: step 7773, loss 0.248325, acc 0.921875\n",
      "2017-04-03T19:44:54.814606: step 7774, loss 0.357458, acc 0.90625\n",
      "2017-04-03T19:44:55.017429: step 7775, loss 0.429576, acc 0.8125\n",
      "2017-04-03T19:44:55.217577: step 7776, loss 0.226301, acc 0.9375\n",
      "2017-04-03T19:44:55.426863: step 7777, loss 0.330554, acc 0.859375\n",
      "2017-04-03T19:44:55.630831: step 7778, loss 0.327161, acc 0.90625\n",
      "2017-04-03T19:44:55.830307: step 7779, loss 0.447596, acc 0.84375\n",
      "2017-04-03T19:44:56.033743: step 7780, loss 0.435103, acc 0.84375\n",
      "2017-04-03T19:44:56.237060: step 7781, loss 0.587394, acc 0.828125\n",
      "2017-04-03T19:44:56.438082: step 7782, loss 0.396103, acc 0.796875\n",
      "2017-04-03T19:44:56.647114: step 7783, loss 0.323604, acc 0.90625\n",
      "2017-04-03T19:44:56.854001: step 7784, loss 0.503643, acc 0.875\n",
      "2017-04-03T19:44:57.055224: step 7785, loss 0.455797, acc 0.8125\n",
      "2017-04-03T19:44:57.259318: step 7786, loss 0.44278, acc 0.84375\n",
      "2017-04-03T19:44:57.462105: step 7787, loss 0.412673, acc 0.84375\n",
      "2017-04-03T19:44:57.668035: step 7788, loss 0.706391, acc 0.71875\n",
      "2017-04-03T19:44:57.873829: step 7789, loss 0.48439, acc 0.859375\n",
      "2017-04-03T19:44:58.076153: step 7790, loss 0.378549, acc 0.953125\n",
      "2017-04-03T19:44:58.282561: step 7791, loss 0.532507, acc 0.921875\n",
      "2017-04-03T19:44:58.487631: step 7792, loss 0.344875, acc 0.890625\n",
      "2017-04-03T19:44:58.739533: step 7793, loss 0.376194, acc 0.875\n",
      "2017-04-03T19:44:58.983333: step 7794, loss 0.424171, acc 0.859375\n",
      "2017-04-03T19:44:59.186754: step 7795, loss 0.584993, acc 0.75\n",
      "2017-04-03T19:44:59.395802: step 7796, loss 0.291829, acc 0.921875\n",
      "2017-04-03T19:44:59.594864: step 7797, loss 0.452513, acc 0.84375\n",
      "2017-04-03T19:44:59.833487: step 7798, loss 0.438727, acc 0.875\n",
      "2017-04-03T19:45:00.048532: step 7799, loss 0.428711, acc 0.90625\n",
      "2017-04-03T19:45:00.251641: step 7800, loss 0.287349, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:45:02.238295: step 7800, loss 3.28, acc 0.31475\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-7800\n",
      "\n",
      "2017-04-03T19:45:02.560032: step 7801, loss 0.433929, acc 0.875\n",
      "2017-04-03T19:45:02.804259: step 7802, loss 0.350229, acc 0.890625\n",
      "2017-04-03T19:45:03.005633: step 7803, loss 0.469975, acc 0.953125\n",
      "2017-04-03T19:45:03.210715: step 7804, loss 0.380737, acc 0.90625\n",
      "2017-04-03T19:45:03.462986: step 7805, loss 0.387778, acc 0.859375\n",
      "2017-04-03T19:45:03.706018: step 7806, loss 0.300832, acc 0.9375\n",
      "2017-04-03T19:45:03.911344: step 7807, loss 0.302039, acc 0.890625\n",
      "2017-04-03T19:45:04.111176: step 7808, loss 0.399035, acc 0.859375\n",
      "2017-04-03T19:45:04.351577: step 7809, loss 0.233841, acc 0.9375\n",
      "2017-04-03T19:45:04.557966: step 7810, loss 0.476852, acc 0.84375\n",
      "2017-04-03T19:45:04.761704: step 7811, loss 0.334039, acc 0.890625\n",
      "2017-04-03T19:45:04.972815: step 7812, loss 0.331497, acc 0.859375\n",
      "2017-04-03T19:45:05.176651: step 7813, loss 0.628495, acc 0.875\n",
      "2017-04-03T19:45:05.379875: step 7814, loss 0.505646, acc 0.828125\n",
      "2017-04-03T19:45:05.581279: step 7815, loss 0.431904, acc 0.859375\n",
      "2017-04-03T19:45:05.778805: step 7816, loss 0.38905, acc 0.859375\n",
      "2017-04-03T19:45:05.978693: step 7817, loss 0.278649, acc 0.890625\n",
      "2017-04-03T19:45:06.177925: step 7818, loss 0.523882, acc 0.8125\n",
      "2017-04-03T19:45:06.383253: step 7819, loss 0.425641, acc 0.890625\n",
      "2017-04-03T19:45:06.589379: step 7820, loss 0.320899, acc 0.859375\n",
      "2017-04-03T19:45:06.832957: step 7821, loss 0.395453, acc 0.859375\n",
      "2017-04-03T19:45:07.080479: step 7822, loss 0.351458, acc 0.875\n",
      "2017-04-03T19:45:07.286295: step 7823, loss 0.248442, acc 0.921875\n",
      "2017-04-03T19:45:07.487415: step 7824, loss 0.575392, acc 0.84375\n",
      "2017-04-03T19:45:07.702013: step 7825, loss 0.445619, acc 0.859375\n",
      "2017-04-03T19:45:07.902979: step 7826, loss 0.42756, acc 0.84375\n",
      "2017-04-03T19:45:08.104109: step 7827, loss 0.47264, acc 0.84375\n",
      "2017-04-03T19:45:08.309219: step 7828, loss 0.325685, acc 0.890625\n",
      "2017-04-03T19:45:08.509334: step 7829, loss 0.56453, acc 0.765625\n",
      "2017-04-03T19:45:08.719421: step 7830, loss 0.21575, acc 0.90625\n",
      "2017-04-03T19:45:08.925023: step 7831, loss 0.326973, acc 0.90625\n",
      "2017-04-03T19:45:09.133241: step 7832, loss 0.322625, acc 0.90625\n",
      "2017-04-03T19:45:09.335899: step 7833, loss 0.432727, acc 0.828125\n",
      "2017-04-03T19:45:09.550038: step 7834, loss 0.379715, acc 0.890625\n",
      "2017-04-03T19:45:09.755161: step 7835, loss 0.504772, acc 0.828125\n",
      "2017-04-03T19:45:09.960075: step 7836, loss 0.367992, acc 0.828125\n",
      "2017-04-03T19:45:10.164691: step 7837, loss 0.501841, acc 0.84375\n",
      "2017-04-03T19:45:10.410738: step 7838, loss 0.411328, acc 0.84375\n",
      "2017-04-03T19:45:10.624652: step 7839, loss 0.521938, acc 0.84375\n",
      "2017-04-03T19:45:10.876331: step 7840, loss 0.627659, acc 0.828125\n",
      "2017-04-03T19:45:11.084152: step 7841, loss 0.39345, acc 0.890625\n",
      "2017-04-03T19:45:11.289144: step 7842, loss 0.39354, acc 0.875\n",
      "2017-04-03T19:45:11.496161: step 7843, loss 0.314514, acc 0.890625\n",
      "2017-04-03T19:45:11.696737: step 7844, loss 0.293295, acc 0.90625\n",
      "2017-04-03T19:45:11.907827: step 7845, loss 0.332725, acc 0.921875\n",
      "2017-04-03T19:45:12.107808: step 7846, loss 0.607366, acc 0.78125\n",
      "2017-04-03T19:45:12.302910: step 7847, loss 0.647376, acc 0.828125\n",
      "2017-04-03T19:45:12.510135: step 7848, loss 0.186834, acc 0.953125\n",
      "2017-04-03T19:45:12.714947: step 7849, loss 0.475689, acc 0.859375\n",
      "2017-04-03T19:45:12.924163: step 7850, loss 0.425941, acc 0.890625\n",
      "2017-04-03T19:45:13.127705: step 7851, loss 0.541343, acc 0.828125\n",
      "2017-04-03T19:45:13.330664: step 7852, loss 0.574943, acc 0.84375\n",
      "2017-04-03T19:45:13.539123: step 7853, loss 0.375444, acc 0.921875\n",
      "2017-04-03T19:45:13.783443: step 7854, loss 0.435139, acc 0.875\n",
      "2017-04-03T19:45:13.986257: step 7855, loss 0.405405, acc 0.859375\n",
      "2017-04-03T19:45:14.190479: step 7856, loss 0.332241, acc 0.859375\n",
      "2017-04-03T19:45:14.399603: step 7857, loss 0.451288, acc 0.828125\n",
      "2017-04-03T19:45:14.603327: step 7858, loss 0.349104, acc 0.875\n",
      "2017-04-03T19:45:14.814427: step 7859, loss 0.323326, acc 0.890625\n",
      "2017-04-03T19:45:15.059580: step 7860, loss 0.376276, acc 0.859375\n",
      "2017-04-03T19:45:15.304216: step 7861, loss 0.302297, acc 0.90625\n",
      "2017-04-03T19:45:15.505540: step 7862, loss 0.360889, acc 0.84375\n",
      "2017-04-03T19:45:15.711742: step 7863, loss 0.432499, acc 0.84375\n",
      "2017-04-03T19:45:15.918380: step 7864, loss 0.364189, acc 0.84375\n",
      "2017-04-03T19:45:16.118981: step 7865, loss 0.527263, acc 0.84375\n",
      "2017-04-03T19:45:16.325939: step 7866, loss 0.412291, acc 0.90625\n",
      "2017-04-03T19:45:16.541449: step 7867, loss 0.15743, acc 0.96875\n",
      "2017-04-03T19:45:16.750307: step 7868, loss 0.46955, acc 0.8125\n",
      "2017-04-03T19:45:16.956006: step 7869, loss 0.416277, acc 0.859375\n",
      "2017-04-03T19:45:17.163517: step 7870, loss 0.61655, acc 0.734375\n",
      "2017-04-03T19:45:17.368549: step 7871, loss 0.417155, acc 0.859375\n",
      "2017-04-03T19:45:17.570175: step 7872, loss 0.321073, acc 0.890625\n",
      "2017-04-03T19:45:17.782559: step 7873, loss 0.316058, acc 0.90625\n",
      "2017-04-03T19:45:17.996017: step 7874, loss 0.380052, acc 0.859375\n",
      "2017-04-03T19:45:18.213464: step 7875, loss 0.37822, acc 0.90625\n",
      "2017-04-03T19:45:18.417126: step 7876, loss 0.277258, acc 0.890625\n",
      "2017-04-03T19:45:18.662770: step 7877, loss 0.342671, acc 0.875\n",
      "2017-04-03T19:45:18.864846: step 7878, loss 0.375676, acc 0.890625\n",
      "2017-04-03T19:45:19.077617: step 7879, loss 0.32456, acc 0.890625\n",
      "2017-04-03T19:45:19.325112: step 7880, loss 0.263253, acc 0.921875\n",
      "2017-04-03T19:45:19.575105: step 7881, loss 0.472784, acc 0.84375\n",
      "2017-04-03T19:45:19.724670: step 7882, loss 0.392241, acc 0.84375\n",
      "2017-04-03T19:45:19.930990: step 7883, loss 0.283654, acc 0.921875\n",
      "2017-04-03T19:45:20.131379: step 7884, loss 0.290743, acc 0.921875\n",
      "2017-04-03T19:45:20.332563: step 7885, loss 0.410884, acc 0.859375\n",
      "2017-04-03T19:45:20.532970: step 7886, loss 0.285674, acc 0.890625\n",
      "2017-04-03T19:45:20.734930: step 7887, loss 0.396119, acc 0.859375\n",
      "2017-04-03T19:45:20.947041: step 7888, loss 0.392502, acc 0.84375\n",
      "2017-04-03T19:45:21.198202: step 7889, loss 0.372547, acc 0.859375\n",
      "2017-04-03T19:45:21.394474: step 7890, loss 0.255479, acc 0.875\n",
      "2017-04-03T19:45:21.603669: step 7891, loss 0.406794, acc 0.859375\n",
      "2017-04-03T19:45:21.814644: step 7892, loss 0.349603, acc 0.875\n",
      "2017-04-03T19:45:22.030586: step 7893, loss 0.263173, acc 0.90625\n",
      "2017-04-03T19:45:22.233509: step 7894, loss 0.229888, acc 0.90625\n",
      "2017-04-03T19:45:22.433330: step 7895, loss 0.279699, acc 0.921875\n",
      "2017-04-03T19:45:22.636235: step 7896, loss 0.263278, acc 0.890625\n",
      "2017-04-03T19:45:22.839862: step 7897, loss 0.403575, acc 0.828125\n",
      "2017-04-03T19:45:23.043089: step 7898, loss 0.346641, acc 0.890625\n",
      "2017-04-03T19:45:23.249865: step 7899, loss 0.25797, acc 0.953125\n",
      "2017-04-03T19:45:23.454248: step 7900, loss 0.171025, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:45:25.489612: step 7900, loss 3.35028, acc 0.31\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-7900\n",
      "\n",
      "2017-04-03T19:45:25.822670: step 7901, loss 0.283522, acc 0.90625\n",
      "2017-04-03T19:45:26.024635: step 7902, loss 0.326746, acc 0.875\n",
      "2017-04-03T19:45:26.232788: step 7903, loss 0.203017, acc 0.96875\n",
      "2017-04-03T19:45:26.434946: step 7904, loss 0.254608, acc 0.953125\n",
      "2017-04-03T19:45:26.681343: step 7905, loss 0.315191, acc 0.90625\n",
      "2017-04-03T19:45:26.893638: step 7906, loss 0.254467, acc 0.9375\n",
      "2017-04-03T19:45:27.097652: step 7907, loss 0.313197, acc 0.875\n",
      "2017-04-03T19:45:27.306401: step 7908, loss 0.508717, acc 0.859375\n",
      "2017-04-03T19:45:27.523790: step 7909, loss 0.40702, acc 0.90625\n",
      "2017-04-03T19:45:27.773567: step 7910, loss 0.253595, acc 0.890625\n",
      "2017-04-03T19:45:27.983785: step 7911, loss 0.34952, acc 0.875\n",
      "2017-04-03T19:45:28.181183: step 7912, loss 0.26206, acc 0.921875\n",
      "2017-04-03T19:45:28.385496: step 7913, loss 0.291611, acc 0.90625\n",
      "2017-04-03T19:45:28.635101: step 7914, loss 0.214965, acc 0.90625\n",
      "2017-04-03T19:45:28.842943: step 7915, loss 0.190153, acc 0.953125\n",
      "2017-04-03T19:45:29.044812: step 7916, loss 0.35192, acc 0.875\n",
      "2017-04-03T19:45:29.292213: step 7917, loss 0.299874, acc 0.90625\n",
      "2017-04-03T19:45:29.491899: step 7918, loss 0.27927, acc 0.90625\n",
      "2017-04-03T19:45:29.700970: step 7919, loss 0.366534, acc 0.90625\n",
      "2017-04-03T19:45:29.923536: step 7920, loss 0.533585, acc 0.796875\n",
      "2017-04-03T19:45:30.125698: step 7921, loss 0.285078, acc 0.90625\n",
      "2017-04-03T19:45:30.329091: step 7922, loss 0.415203, acc 0.859375\n",
      "2017-04-03T19:45:30.532363: step 7923, loss 0.354127, acc 0.890625\n",
      "2017-04-03T19:45:30.740746: step 7924, loss 0.22338, acc 0.875\n",
      "2017-04-03T19:45:30.941751: step 7925, loss 0.287817, acc 0.953125\n",
      "2017-04-03T19:45:31.149691: step 7926, loss 0.241641, acc 0.953125\n",
      "2017-04-03T19:45:31.351017: step 7927, loss 0.472347, acc 0.875\n",
      "2017-04-03T19:45:31.555075: step 7928, loss 0.269594, acc 0.90625\n",
      "2017-04-03T19:45:31.757247: step 7929, loss 0.357834, acc 0.875\n",
      "2017-04-03T19:45:31.964019: step 7930, loss 0.336121, acc 0.875\n",
      "2017-04-03T19:45:32.168314: step 7931, loss 0.266673, acc 0.921875\n",
      "2017-04-03T19:45:32.378113: step 7932, loss 0.295406, acc 0.921875\n",
      "2017-04-03T19:45:32.623456: step 7933, loss 0.268282, acc 0.875\n",
      "2017-04-03T19:45:32.823404: step 7934, loss 0.288083, acc 0.890625\n",
      "2017-04-03T19:45:33.032262: step 7935, loss 0.548249, acc 0.796875\n",
      "2017-04-03T19:45:33.236912: step 7936, loss 0.332618, acc 0.921875\n",
      "2017-04-03T19:45:33.446443: step 7937, loss 0.294108, acc 0.90625\n",
      "2017-04-03T19:45:33.649836: step 7938, loss 0.299598, acc 0.921875\n",
      "2017-04-03T19:45:33.859233: step 7939, loss 0.36511, acc 0.890625\n",
      "2017-04-03T19:45:34.061362: step 7940, loss 0.300649, acc 0.859375\n",
      "2017-04-03T19:45:34.267664: step 7941, loss 0.447789, acc 0.84375\n",
      "2017-04-03T19:45:34.472643: step 7942, loss 0.271099, acc 0.9375\n",
      "2017-04-03T19:45:34.680044: step 7943, loss 0.293508, acc 0.90625\n",
      "2017-04-03T19:45:34.888139: step 7944, loss 0.298976, acc 0.875\n",
      "2017-04-03T19:45:35.087100: step 7945, loss 0.349404, acc 0.90625\n",
      "2017-04-03T19:45:35.293863: step 7946, loss 0.216748, acc 0.921875\n",
      "2017-04-03T19:45:35.501022: step 7947, loss 0.303803, acc 0.921875\n",
      "2017-04-03T19:45:35.709583: step 7948, loss 0.370894, acc 0.859375\n",
      "2017-04-03T19:45:35.916879: step 7949, loss 0.407298, acc 0.890625\n",
      "2017-04-03T19:45:36.120030: step 7950, loss 0.346087, acc 0.921875\n",
      "2017-04-03T19:45:36.321293: step 7951, loss 0.264463, acc 0.921875\n",
      "2017-04-03T19:45:36.523410: step 7952, loss 0.476967, acc 0.90625\n",
      "2017-04-03T19:45:36.725573: step 7953, loss 0.494534, acc 0.78125\n",
      "2017-04-03T19:45:36.936253: step 7954, loss 0.251955, acc 0.921875\n",
      "2017-04-03T19:45:37.137808: step 7955, loss 0.240998, acc 0.9375\n",
      "2017-04-03T19:45:37.340287: step 7956, loss 0.231778, acc 0.921875\n",
      "2017-04-03T19:45:37.545975: step 7957, loss 0.327406, acc 0.890625\n",
      "2017-04-03T19:45:37.750423: step 7958, loss 0.416506, acc 0.875\n",
      "2017-04-03T19:45:37.955375: step 7959, loss 0.552125, acc 0.828125\n",
      "2017-04-03T19:45:38.170887: step 7960, loss 0.29642, acc 0.921875\n",
      "2017-04-03T19:45:38.375856: step 7961, loss 0.215266, acc 0.9375\n",
      "2017-04-03T19:45:38.577559: step 7962, loss 0.31922, acc 0.90625\n",
      "2017-04-03T19:45:38.830245: step 7963, loss 0.18522, acc 0.9375\n",
      "2017-04-03T19:45:39.039168: step 7964, loss 0.333945, acc 0.890625\n",
      "2017-04-03T19:45:39.249501: step 7965, loss 0.216158, acc 0.90625\n",
      "2017-04-03T19:45:39.449039: step 7966, loss 0.296659, acc 0.921875\n",
      "2017-04-03T19:45:39.652673: step 7967, loss 0.392791, acc 0.875\n",
      "2017-04-03T19:45:39.855133: step 7968, loss 0.388436, acc 0.84375\n",
      "2017-04-03T19:45:40.101025: step 7969, loss 0.318262, acc 0.890625\n",
      "2017-04-03T19:45:40.307540: step 7970, loss 0.467147, acc 0.84375\n",
      "2017-04-03T19:45:40.510592: step 7971, loss 0.215976, acc 0.921875\n",
      "2017-04-03T19:45:40.718980: step 7972, loss 0.245698, acc 0.90625\n",
      "2017-04-03T19:45:40.924777: step 7973, loss 0.312505, acc 0.90625\n",
      "2017-04-03T19:45:41.127502: step 7974, loss 0.315661, acc 0.90625\n",
      "2017-04-03T19:45:41.379664: step 7975, loss 0.293313, acc 0.921875\n",
      "2017-04-03T19:45:41.582936: step 7976, loss 0.30408, acc 0.90625\n",
      "2017-04-03T19:45:41.785357: step 7977, loss 0.220632, acc 0.9375\n",
      "2017-04-03T19:45:41.993286: step 7978, loss 0.390417, acc 0.921875\n",
      "2017-04-03T19:45:42.197351: step 7979, loss 0.203983, acc 0.890625\n",
      "2017-04-03T19:45:42.400366: step 7980, loss 0.329591, acc 0.90625\n",
      "2017-04-03T19:45:42.606659: step 7981, loss 0.575179, acc 0.828125\n",
      "2017-04-03T19:45:42.822565: step 7982, loss 0.353588, acc 0.890625\n",
      "2017-04-03T19:45:43.029854: step 7983, loss 0.224824, acc 0.953125\n",
      "2017-04-03T19:45:43.232895: step 7984, loss 0.460355, acc 0.8125\n",
      "2017-04-03T19:45:43.439327: step 7985, loss 0.257854, acc 0.90625\n",
      "2017-04-03T19:45:43.642639: step 7986, loss 0.38249, acc 0.859375\n",
      "2017-04-03T19:45:43.853579: step 7987, loss 0.280806, acc 0.921875\n",
      "2017-04-03T19:45:44.055000: step 7988, loss 0.425104, acc 0.859375\n",
      "2017-04-03T19:45:44.257993: step 7989, loss 0.22205, acc 0.90625\n",
      "2017-04-03T19:45:44.461103: step 7990, loss 0.43279, acc 0.859375\n",
      "2017-04-03T19:45:44.669766: step 7991, loss 0.293685, acc 0.890625\n",
      "2017-04-03T19:45:44.870583: step 7992, loss 0.367712, acc 0.90625\n",
      "2017-04-03T19:45:45.072066: step 7993, loss 0.451776, acc 0.859375\n",
      "2017-04-03T19:45:45.274428: step 7994, loss 0.244751, acc 0.921875\n",
      "2017-04-03T19:45:45.476400: step 7995, loss 0.213489, acc 0.9375\n",
      "2017-04-03T19:45:45.721500: step 7996, loss 0.334478, acc 0.859375\n",
      "2017-04-03T19:45:45.926543: step 7997, loss 0.247909, acc 0.90625\n",
      "2017-04-03T19:45:46.130898: step 7998, loss 0.410433, acc 0.859375\n",
      "2017-04-03T19:45:46.333983: step 7999, loss 0.318853, acc 0.890625\n",
      "2017-04-03T19:45:46.536320: step 8000, loss 0.311636, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:45:48.534683: step 8000, loss 3.4044, acc 0.31225\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-8000\n",
      "\n",
      "2017-04-03T19:45:48.867156: step 8001, loss 0.330967, acc 0.890625\n",
      "2017-04-03T19:45:49.115465: step 8002, loss 0.30585, acc 0.953125\n",
      "2017-04-03T19:45:49.318483: step 8003, loss 0.365943, acc 0.90625\n",
      "2017-04-03T19:45:49.522972: step 8004, loss 0.324505, acc 0.921875\n",
      "2017-04-03T19:45:49.726415: step 8005, loss 0.25065, acc 0.90625\n",
      "2017-04-03T19:45:49.928596: step 8006, loss 0.304653, acc 0.921875\n",
      "2017-04-03T19:45:50.125297: step 8007, loss 0.349111, acc 0.921875\n",
      "2017-04-03T19:45:50.327400: step 8008, loss 0.248651, acc 0.953125\n",
      "2017-04-03T19:45:50.531660: step 8009, loss 0.482455, acc 0.8125\n",
      "2017-04-03T19:45:50.733245: step 8010, loss 0.359287, acc 0.890625\n",
      "2017-04-03T19:45:50.987061: step 8011, loss 0.29631, acc 0.890625\n",
      "2017-04-03T19:45:51.194694: step 8012, loss 0.196004, acc 0.921875\n",
      "2017-04-03T19:45:51.392607: step 8013, loss 0.406396, acc 0.890625\n",
      "2017-04-03T19:45:51.604714: step 8014, loss 0.493186, acc 0.796875\n",
      "2017-04-03T19:45:51.807121: step 8015, loss 0.405537, acc 0.859375\n",
      "2017-04-03T19:45:52.011920: step 8016, loss 0.270935, acc 0.921875\n",
      "2017-04-03T19:45:52.213524: step 8017, loss 0.227393, acc 0.921875\n",
      "2017-04-03T19:45:52.414415: step 8018, loss 0.368189, acc 0.859375\n",
      "2017-04-03T19:45:52.614726: step 8019, loss 0.287762, acc 0.9375\n",
      "2017-04-03T19:45:52.869057: step 8020, loss 0.369213, acc 0.890625\n",
      "2017-04-03T19:45:53.077102: step 8021, loss 0.314668, acc 0.890625\n",
      "2017-04-03T19:45:53.283482: step 8022, loss 0.338571, acc 0.921875\n",
      "2017-04-03T19:45:53.487125: step 8023, loss 0.285846, acc 0.890625\n",
      "2017-04-03T19:45:53.685684: step 8024, loss 0.374872, acc 0.90625\n",
      "2017-04-03T19:45:53.886603: step 8025, loss 0.177368, acc 0.9375\n",
      "2017-04-03T19:45:54.096848: step 8026, loss 0.357207, acc 0.890625\n",
      "2017-04-03T19:45:54.315093: step 8027, loss 0.431709, acc 0.875\n",
      "2017-04-03T19:45:54.520639: step 8028, loss 0.344018, acc 0.9375\n",
      "2017-04-03T19:45:54.724626: step 8029, loss 0.582198, acc 0.8125\n",
      "2017-04-03T19:45:54.928413: step 8030, loss 0.343178, acc 0.890625\n",
      "2017-04-03T19:45:55.128047: step 8031, loss 0.252946, acc 0.921875\n",
      "2017-04-03T19:45:55.327505: step 8032, loss 0.290572, acc 0.890625\n",
      "2017-04-03T19:45:55.531247: step 8033, loss 0.274646, acc 0.9375\n",
      "2017-04-03T19:45:55.730026: step 8034, loss 0.274933, acc 0.90625\n",
      "2017-04-03T19:45:55.970584: step 8035, loss 0.323026, acc 0.9375\n",
      "2017-04-03T19:45:56.175511: step 8036, loss 0.499427, acc 0.859375\n",
      "2017-04-03T19:45:56.374656: step 8037, loss 0.379653, acc 0.875\n",
      "2017-04-03T19:45:56.578897: step 8038, loss 0.389981, acc 0.875\n",
      "2017-04-03T19:45:56.781274: step 8039, loss 0.421956, acc 0.859375\n",
      "2017-04-03T19:45:56.988684: step 8040, loss 0.370678, acc 0.890625\n",
      "2017-04-03T19:45:57.190890: step 8041, loss 0.493892, acc 0.875\n",
      "2017-04-03T19:45:57.388043: step 8042, loss 0.335366, acc 0.921875\n",
      "2017-04-03T19:45:57.629909: step 8043, loss 0.212058, acc 0.921875\n",
      "2017-04-03T19:45:57.839612: step 8044, loss 0.437752, acc 0.90625\n",
      "2017-04-03T19:45:58.039008: step 8045, loss 0.359537, acc 0.875\n",
      "2017-04-03T19:45:58.242221: step 8046, loss 0.352289, acc 0.875\n",
      "2017-04-03T19:45:58.443914: step 8047, loss 0.290736, acc 0.921875\n",
      "2017-04-03T19:45:58.643457: step 8048, loss 0.254424, acc 0.921875\n",
      "2017-04-03T19:45:58.886482: step 8049, loss 0.355265, acc 0.875\n",
      "2017-04-03T19:45:59.088914: step 8050, loss 0.260678, acc 0.921875\n",
      "2017-04-03T19:45:59.296822: step 8051, loss 0.359465, acc 0.875\n",
      "2017-04-03T19:45:59.502261: step 8052, loss 0.444423, acc 0.84375\n",
      "2017-04-03T19:45:59.703201: step 8053, loss 0.452317, acc 0.859375\n",
      "2017-04-03T19:45:59.912069: step 8054, loss 0.136218, acc 0.9375\n",
      "2017-04-03T19:46:00.113427: step 8055, loss 0.329046, acc 0.90625\n",
      "2017-04-03T19:46:00.316007: step 8056, loss 0.441416, acc 0.859375\n",
      "2017-04-03T19:46:00.514181: step 8057, loss 0.176668, acc 0.953125\n",
      "2017-04-03T19:46:00.709881: step 8058, loss 0.380031, acc 0.875\n",
      "2017-04-03T19:46:00.907962: step 8059, loss 0.30801, acc 0.875\n",
      "2017-04-03T19:46:01.109443: step 8060, loss 0.328201, acc 0.9375\n",
      "2017-04-03T19:46:01.312791: step 8061, loss 0.282703, acc 0.921875\n",
      "2017-04-03T19:46:01.514367: step 8062, loss 0.37429, acc 0.90625\n",
      "2017-04-03T19:46:01.720879: step 8063, loss 0.241484, acc 0.9375\n",
      "2017-04-03T19:46:01.917213: step 8064, loss 0.302879, acc 0.921875\n",
      "2017-04-03T19:46:02.121926: step 8065, loss 0.427786, acc 0.859375\n",
      "2017-04-03T19:46:02.366670: step 8066, loss 0.389135, acc 0.90625\n",
      "2017-04-03T19:46:02.570158: step 8067, loss 0.369064, acc 0.9375\n",
      "2017-04-03T19:46:02.772059: step 8068, loss 0.281667, acc 0.9375\n",
      "2017-04-03T19:46:02.978062: step 8069, loss 0.361624, acc 0.921875\n",
      "2017-04-03T19:46:03.179491: step 8070, loss 0.436738, acc 0.890625\n",
      "2017-04-03T19:46:03.380227: step 8071, loss 0.342933, acc 0.90625\n",
      "2017-04-03T19:46:03.585140: step 8072, loss 0.374956, acc 0.890625\n",
      "2017-04-03T19:46:03.789669: step 8073, loss 0.248738, acc 0.90625\n",
      "2017-04-03T19:46:03.988398: step 8074, loss 0.150519, acc 0.984375\n",
      "2017-04-03T19:46:04.188731: step 8075, loss 0.424395, acc 0.828125\n",
      "2017-04-03T19:46:04.389354: step 8076, loss 0.361504, acc 0.890625\n",
      "2017-04-03T19:46:04.592467: step 8077, loss 0.251505, acc 0.921875\n",
      "2017-04-03T19:46:04.799073: step 8078, loss 0.314171, acc 0.90625\n",
      "2017-04-03T19:46:05.002169: step 8079, loss 0.31933, acc 0.921875\n",
      "2017-04-03T19:46:05.206714: step 8080, loss 0.375588, acc 0.859375\n",
      "2017-04-03T19:46:05.448492: step 8081, loss 0.332548, acc 0.890625\n",
      "2017-04-03T19:46:05.647721: step 8082, loss 0.391454, acc 0.890625\n",
      "2017-04-03T19:46:05.854273: step 8083, loss 0.535397, acc 0.8125\n",
      "2017-04-03T19:46:06.060904: step 8084, loss 0.223415, acc 0.9375\n",
      "2017-04-03T19:46:06.269414: step 8085, loss 0.433637, acc 0.84375\n",
      "2017-04-03T19:46:06.474420: step 8086, loss 0.58872, acc 0.8125\n",
      "2017-04-03T19:46:06.690486: step 8087, loss 0.366499, acc 0.859375\n",
      "2017-04-03T19:46:06.886061: step 8088, loss 0.375902, acc 0.875\n",
      "2017-04-03T19:46:07.088969: step 8089, loss 0.378171, acc 0.921875\n",
      "2017-04-03T19:46:07.297274: step 8090, loss 0.196514, acc 0.96875\n",
      "2017-04-03T19:46:07.501467: step 8091, loss 0.469307, acc 0.8125\n",
      "2017-04-03T19:46:07.749042: step 8092, loss 0.321218, acc 0.859375\n",
      "2017-04-03T19:46:07.953498: step 8093, loss 0.300115, acc 0.90625\n",
      "2017-04-03T19:46:08.162071: step 8094, loss 0.302784, acc 0.890625\n",
      "2017-04-03T19:46:08.367265: step 8095, loss 0.205785, acc 0.921875\n",
      "2017-04-03T19:46:08.568339: step 8096, loss 0.329598, acc 0.90625\n",
      "2017-04-03T19:46:08.768273: step 8097, loss 0.38331, acc 0.875\n",
      "2017-04-03T19:46:08.970882: step 8098, loss 0.350923, acc 0.859375\n",
      "2017-04-03T19:46:09.212540: step 8099, loss 0.153537, acc 0.953125\n",
      "2017-04-03T19:46:09.416610: step 8100, loss 0.321927, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:46:11.457902: step 8100, loss 3.44158, acc 0.30325\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-8100\n",
      "\n",
      "2017-04-03T19:46:11.792637: step 8101, loss 0.272786, acc 0.890625\n",
      "2017-04-03T19:46:11.992016: step 8102, loss 0.283855, acc 0.90625\n",
      "2017-04-03T19:46:12.196951: step 8103, loss 0.559006, acc 0.796875\n",
      "2017-04-03T19:46:12.397485: step 8104, loss 0.291278, acc 0.890625\n",
      "2017-04-03T19:46:12.600146: step 8105, loss 0.4056, acc 0.875\n",
      "2017-04-03T19:46:12.802017: step 8106, loss 0.333658, acc 0.90625\n",
      "2017-04-03T19:46:13.006722: step 8107, loss 0.415635, acc 0.84375\n",
      "2017-04-03T19:46:13.208934: step 8108, loss 0.406251, acc 0.890625\n",
      "2017-04-03T19:46:13.406407: step 8109, loss 0.395631, acc 0.875\n",
      "2017-04-03T19:46:13.604926: step 8110, loss 0.34064, acc 0.859375\n",
      "2017-04-03T19:46:13.815858: step 8111, loss 0.225295, acc 0.9375\n",
      "2017-04-03T19:46:14.020575: step 8112, loss 0.321668, acc 0.890625\n",
      "2017-04-03T19:46:14.228904: step 8113, loss 0.193054, acc 0.953125\n",
      "2017-04-03T19:46:14.439855: step 8114, loss 0.266717, acc 0.9375\n",
      "2017-04-03T19:46:14.641233: step 8115, loss 0.218577, acc 0.9375\n",
      "2017-04-03T19:46:14.842399: step 8116, loss 0.261222, acc 0.921875\n",
      "2017-04-03T19:46:15.042428: step 8117, loss 0.34716, acc 0.90625\n",
      "2017-04-03T19:46:15.245247: step 8118, loss 0.359625, acc 0.890625\n",
      "2017-04-03T19:46:15.441932: step 8119, loss 0.291251, acc 0.9375\n",
      "2017-04-03T19:46:15.644978: step 8120, loss 0.357887, acc 0.875\n",
      "2017-04-03T19:46:15.850593: step 8121, loss 0.261841, acc 0.953125\n",
      "2017-04-03T19:46:16.054869: step 8122, loss 0.338177, acc 0.890625\n",
      "2017-04-03T19:46:16.254360: step 8123, loss 0.41721, acc 0.828125\n",
      "2017-04-03T19:46:16.501894: step 8124, loss 0.384253, acc 0.875\n",
      "2017-04-03T19:46:16.708446: step 8125, loss 0.345601, acc 0.890625\n",
      "2017-04-03T19:46:16.908273: step 8126, loss 0.317896, acc 0.90625\n",
      "2017-04-03T19:46:17.120361: step 8127, loss 0.263199, acc 0.921875\n",
      "2017-04-03T19:46:17.323046: step 8128, loss 0.35901, acc 0.90625\n",
      "2017-04-03T19:46:17.521026: step 8129, loss 0.360097, acc 0.859375\n",
      "2017-04-03T19:46:17.722040: step 8130, loss 0.397836, acc 0.890625\n",
      "2017-04-03T19:46:17.927033: step 8131, loss 0.58266, acc 0.796875\n",
      "2017-04-03T19:46:18.126695: step 8132, loss 0.278586, acc 0.921875\n",
      "2017-04-03T19:46:18.332747: step 8133, loss 0.421042, acc 0.828125\n",
      "2017-04-03T19:46:18.532717: step 8134, loss 0.302174, acc 0.90625\n",
      "2017-04-03T19:46:18.734005: step 8135, loss 0.349542, acc 0.890625\n",
      "2017-04-03T19:46:18.933918: step 8136, loss 0.344963, acc 0.859375\n",
      "2017-04-03T19:46:19.131775: step 8137, loss 0.314973, acc 0.890625\n",
      "2017-04-03T19:46:19.330458: step 8138, loss 0.294973, acc 0.90625\n",
      "2017-04-03T19:46:19.576012: step 8139, loss 0.334399, acc 0.859375\n",
      "2017-04-03T19:46:19.779484: step 8140, loss 0.312174, acc 0.890625\n",
      "2017-04-03T19:46:19.980884: step 8141, loss 0.203707, acc 0.921875\n",
      "2017-04-03T19:46:20.179568: step 8142, loss 0.266937, acc 0.890625\n",
      "2017-04-03T19:46:20.389238: step 8143, loss 0.266428, acc 0.875\n",
      "2017-04-03T19:46:20.627564: step 8144, loss 0.276447, acc 0.921875\n",
      "2017-04-03T19:46:20.828155: step 8145, loss 0.232293, acc 0.921875\n",
      "2017-04-03T19:46:21.029879: step 8146, loss 0.403755, acc 0.875\n",
      "2017-04-03T19:46:21.231236: step 8147, loss 0.408117, acc 0.890625\n",
      "2017-04-03T19:46:21.436371: step 8148, loss 0.506883, acc 0.859375\n",
      "2017-04-03T19:46:21.638038: step 8149, loss 0.299034, acc 0.890625\n",
      "2017-04-03T19:46:21.843317: step 8150, loss 0.276773, acc 0.921875\n",
      "2017-04-03T19:46:22.042979: step 8151, loss 0.225054, acc 0.9375\n",
      "2017-04-03T19:46:22.243857: step 8152, loss 0.271848, acc 0.90625\n",
      "2017-04-03T19:46:22.453548: step 8153, loss 0.272395, acc 0.890625\n",
      "2017-04-03T19:46:22.651783: step 8154, loss 0.171942, acc 0.9375\n",
      "2017-04-03T19:46:22.894062: step 8155, loss 0.331869, acc 0.875\n",
      "2017-04-03T19:46:23.100162: step 8156, loss 0.291367, acc 0.890625\n",
      "2017-04-03T19:46:23.341658: step 8157, loss 0.337606, acc 0.90625\n",
      "2017-04-03T19:46:23.547062: step 8158, loss 0.44537, acc 0.859375\n",
      "2017-04-03T19:46:23.753739: step 8159, loss 0.398904, acc 0.890625\n",
      "2017-04-03T19:46:23.994208: step 8160, loss 0.343151, acc 0.90625\n",
      "2017-04-03T19:46:24.193616: step 8161, loss 0.248729, acc 0.9375\n",
      "2017-04-03T19:46:24.396073: step 8162, loss 0.269794, acc 0.90625\n",
      "2017-04-03T19:46:24.638471: step 8163, loss 0.252386, acc 0.90625\n",
      "2017-04-03T19:46:24.840447: step 8164, loss 0.514187, acc 0.828125\n",
      "2017-04-03T19:46:25.043562: step 8165, loss 0.429878, acc 0.859375\n",
      "2017-04-03T19:46:25.282702: step 8166, loss 0.242497, acc 0.90625\n",
      "2017-04-03T19:46:25.485654: step 8167, loss 0.242357, acc 0.984375\n",
      "2017-04-03T19:46:25.687046: step 8168, loss 0.329682, acc 0.875\n",
      "2017-04-03T19:46:25.895289: step 8169, loss 0.559548, acc 0.8125\n",
      "2017-04-03T19:46:26.096875: step 8170, loss 0.454448, acc 0.828125\n",
      "2017-04-03T19:46:26.341103: step 8171, loss 0.238969, acc 0.9375\n",
      "2017-04-03T19:46:26.549053: step 8172, loss 0.346173, acc 0.890625\n",
      "2017-04-03T19:46:26.794879: step 8173, loss 0.295888, acc 0.90625\n",
      "2017-04-03T19:46:27.003213: step 8174, loss 0.219621, acc 0.90625\n",
      "2017-04-03T19:46:27.206678: step 8175, loss 0.318847, acc 0.90625\n",
      "2017-04-03T19:46:27.408468: step 8176, loss 0.446457, acc 0.859375\n",
      "2017-04-03T19:46:27.610982: step 8177, loss 0.336326, acc 0.875\n",
      "2017-04-03T19:46:27.808410: step 8178, loss 0.350617, acc 0.859375\n",
      "2017-04-03T19:46:28.062025: step 8179, loss 0.379972, acc 0.890625\n",
      "2017-04-03T19:46:28.260057: step 8180, loss 0.474517, acc 0.859375\n",
      "2017-04-03T19:46:28.461629: step 8181, loss 0.292756, acc 0.90625\n",
      "2017-04-03T19:46:28.665176: step 8182, loss 0.330068, acc 0.890625\n",
      "2017-04-03T19:46:28.868660: step 8183, loss 0.421477, acc 0.859375\n",
      "2017-04-03T19:46:29.074013: step 8184, loss 0.378147, acc 0.890625\n",
      "2017-04-03T19:46:29.273756: step 8185, loss 0.24167, acc 0.921875\n",
      "2017-04-03T19:46:29.476448: step 8186, loss 0.209195, acc 0.9375\n",
      "2017-04-03T19:46:29.679470: step 8187, loss 0.317041, acc 0.921875\n",
      "2017-04-03T19:46:29.888359: step 8188, loss 0.279688, acc 0.90625\n",
      "2017-04-03T19:46:30.092540: step 8189, loss 0.274213, acc 0.921875\n",
      "2017-04-03T19:46:30.296407: step 8190, loss 0.346839, acc 0.875\n",
      "2017-04-03T19:46:30.496662: step 8191, loss 0.269948, acc 0.90625\n",
      "2017-04-03T19:46:30.700249: step 8192, loss 0.318702, acc 0.90625\n",
      "2017-04-03T19:46:30.941002: step 8193, loss 0.337046, acc 0.890625\n",
      "2017-04-03T19:46:31.146456: step 8194, loss 0.372184, acc 0.875\n",
      "2017-04-03T19:46:31.395370: step 8195, loss 0.518526, acc 0.875\n",
      "2017-04-03T19:46:31.594379: step 8196, loss 0.401276, acc 0.890625\n",
      "2017-04-03T19:46:31.797391: step 8197, loss 0.380493, acc 0.859375\n",
      "2017-04-03T19:46:31.996852: step 8198, loss 0.319365, acc 0.890625\n",
      "2017-04-03T19:46:32.242432: step 8199, loss 0.372084, acc 0.84375\n",
      "2017-04-03T19:46:32.446198: step 8200, loss 0.394343, acc 0.84375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:46:34.492201: step 8200, loss 3.51271, acc 0.30875\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-8200\n",
      "\n",
      "2017-04-03T19:46:34.833336: step 8201, loss 0.265785, acc 0.90625\n",
      "2017-04-03T19:46:35.031748: step 8202, loss 0.226841, acc 0.9375\n",
      "2017-04-03T19:46:35.237748: step 8203, loss 0.238359, acc 0.9375\n",
      "2017-04-03T19:46:35.441198: step 8204, loss 0.393871, acc 0.859375\n",
      "2017-04-03T19:46:35.642971: step 8205, loss 0.480679, acc 0.859375\n",
      "2017-04-03T19:46:35.846412: step 8206, loss 0.353363, acc 0.890625\n",
      "2017-04-03T19:46:36.048189: step 8207, loss 0.401972, acc 0.859375\n",
      "2017-04-03T19:46:36.251274: step 8208, loss 0.177004, acc 0.953125\n",
      "2017-04-03T19:46:36.461662: step 8209, loss 0.442843, acc 0.875\n",
      "2017-04-03T19:46:36.671782: step 8210, loss 0.367173, acc 0.90625\n",
      "2017-04-03T19:46:36.878394: step 8211, loss 0.370743, acc 0.890625\n",
      "2017-04-03T19:46:37.083662: step 8212, loss 0.493005, acc 0.8125\n",
      "2017-04-03T19:46:37.287009: step 8213, loss 0.25532, acc 0.9375\n",
      "2017-04-03T19:46:37.489469: step 8214, loss 0.227077, acc 0.921875\n",
      "2017-04-03T19:46:37.690459: step 8215, loss 0.500377, acc 0.859375\n",
      "2017-04-03T19:46:37.895882: step 8216, loss 0.353165, acc 0.875\n",
      "2017-04-03T19:46:38.141793: step 8217, loss 0.437394, acc 0.875\n",
      "2017-04-03T19:46:38.348258: step 8218, loss 0.310853, acc 0.890625\n",
      "2017-04-03T19:46:38.549870: step 8219, loss 0.433606, acc 0.828125\n",
      "2017-04-03T19:46:38.752703: step 8220, loss 0.229662, acc 0.890625\n",
      "2017-04-03T19:46:38.963739: step 8221, loss 0.424436, acc 0.859375\n",
      "2017-04-03T19:46:39.165138: step 8222, loss 0.407636, acc 0.890625\n",
      "2017-04-03T19:46:39.363272: step 8223, loss 0.487586, acc 0.828125\n",
      "2017-04-03T19:46:39.561317: step 8224, loss 0.312617, acc 0.9375\n",
      "2017-04-03T19:46:39.759952: step 8225, loss 0.251103, acc 0.921875\n",
      "2017-04-03T19:46:39.964665: step 8226, loss 0.401958, acc 0.90625\n",
      "2017-04-03T19:46:40.166430: step 8227, loss 0.203128, acc 0.921875\n",
      "2017-04-03T19:46:40.365917: step 8228, loss 0.384221, acc 0.875\n",
      "2017-04-03T19:46:40.572784: step 8229, loss 0.390822, acc 0.828125\n",
      "2017-04-03T19:46:40.778724: step 8230, loss 0.261766, acc 0.890625\n",
      "2017-04-03T19:46:40.977307: step 8231, loss 0.388092, acc 0.90625\n",
      "2017-04-03T19:46:41.196246: step 8232, loss 0.289536, acc 0.90625\n",
      "2017-04-03T19:46:41.404735: step 8233, loss 0.331129, acc 0.875\n",
      "2017-04-03T19:46:41.606706: step 8234, loss 0.396467, acc 0.890625\n",
      "2017-04-03T19:46:41.816805: step 8235, loss 0.430038, acc 0.875\n",
      "2017-04-03T19:46:42.021160: step 8236, loss 0.41693, acc 0.875\n",
      "2017-04-03T19:46:42.221818: step 8237, loss 0.239026, acc 0.921875\n",
      "2017-04-03T19:46:42.467227: step 8238, loss 0.416028, acc 0.875\n",
      "2017-04-03T19:46:42.668445: step 8239, loss 0.244038, acc 0.90625\n",
      "2017-04-03T19:46:42.869737: step 8240, loss 0.243419, acc 0.921875\n",
      "2017-04-03T19:46:43.072752: step 8241, loss 0.269891, acc 0.953125\n",
      "2017-04-03T19:46:43.281614: step 8242, loss 0.284308, acc 0.875\n",
      "2017-04-03T19:46:43.489863: step 8243, loss 0.510093, acc 0.859375\n",
      "2017-04-03T19:46:43.689909: step 8244, loss 0.431276, acc 0.796875\n",
      "2017-04-03T19:46:43.891806: step 8245, loss 0.178478, acc 0.953125\n",
      "2017-04-03T19:46:44.096033: step 8246, loss 0.305298, acc 0.890625\n",
      "2017-04-03T19:46:44.295742: step 8247, loss 0.330024, acc 0.875\n",
      "2017-04-03T19:46:44.499439: step 8248, loss 0.346366, acc 0.859375\n",
      "2017-04-03T19:46:44.700129: step 8249, loss 0.348539, acc 0.875\n",
      "2017-04-03T19:46:44.956294: step 8250, loss 0.341675, acc 0.84375\n",
      "2017-04-03T19:46:45.157994: step 8251, loss 0.27065, acc 0.875\n",
      "2017-04-03T19:46:45.358941: step 8252, loss 0.220776, acc 0.921875\n",
      "2017-04-03T19:46:45.560390: step 8253, loss 0.295631, acc 0.890625\n",
      "2017-04-03T19:46:45.766146: step 8254, loss 0.32312, acc 0.859375\n",
      "2017-04-03T19:46:45.974354: step 8255, loss 0.375095, acc 0.890625\n",
      "2017-04-03T19:46:46.177276: step 8256, loss 0.23247, acc 0.90625\n",
      "2017-04-03T19:46:46.383932: step 8257, loss 0.309124, acc 0.875\n",
      "2017-04-03T19:46:46.593948: step 8258, loss 0.312733, acc 0.890625\n",
      "2017-04-03T19:46:46.799535: step 8259, loss 0.323885, acc 0.875\n",
      "2017-04-03T19:46:47.005487: step 8260, loss 0.537561, acc 0.828125\n",
      "2017-04-03T19:46:47.216422: step 8261, loss 0.401064, acc 0.84375\n",
      "2017-04-03T19:46:47.415855: step 8262, loss 0.45664, acc 0.875\n",
      "2017-04-03T19:46:47.622419: step 8263, loss 0.46184, acc 0.84375\n",
      "2017-04-03T19:46:47.821482: step 8264, loss 0.390935, acc 0.890625\n",
      "2017-04-03T19:46:48.069933: step 8265, loss 0.124853, acc 0.984375\n",
      "2017-04-03T19:46:48.277126: step 8266, loss 0.274798, acc 0.875\n",
      "2017-04-03T19:46:48.479417: step 8267, loss 0.425855, acc 0.859375\n",
      "2017-04-03T19:46:48.681212: step 8268, loss 0.33014, acc 0.890625\n",
      "2017-04-03T19:46:48.882074: step 8269, loss 0.341026, acc 0.859375\n",
      "2017-04-03T19:46:49.083854: step 8270, loss 0.448128, acc 0.828125\n",
      "2017-04-03T19:46:49.338040: step 8271, loss 0.304715, acc 0.859375\n",
      "2017-04-03T19:46:49.548966: step 8272, loss 0.456222, acc 0.84375\n",
      "2017-04-03T19:46:49.750338: step 8273, loss 0.265818, acc 0.953125\n",
      "2017-04-03T19:46:49.952536: step 8274, loss 0.399963, acc 0.875\n",
      "2017-04-03T19:46:50.155755: step 8275, loss 0.254445, acc 0.953125\n",
      "2017-04-03T19:46:50.356840: step 8276, loss 0.269545, acc 0.921875\n",
      "2017-04-03T19:46:50.555831: step 8277, loss 0.3572, acc 0.90625\n",
      "2017-04-03T19:46:50.760539: step 8278, loss 0.469959, acc 0.84375\n",
      "2017-04-03T19:46:50.961477: step 8279, loss 0.351281, acc 0.890625\n",
      "2017-04-03T19:46:51.159979: step 8280, loss 0.295191, acc 0.9375\n",
      "2017-04-03T19:46:51.363542: step 8281, loss 0.390472, acc 0.8125\n",
      "2017-04-03T19:46:51.563828: step 8282, loss 0.393742, acc 0.859375\n",
      "2017-04-03T19:46:51.766996: step 8283, loss 0.405749, acc 0.859375\n",
      "2017-04-03T19:46:51.969438: step 8284, loss 0.295177, acc 0.921875\n",
      "2017-04-03T19:46:52.173874: step 8285, loss 0.413423, acc 0.859375\n",
      "2017-04-03T19:46:52.382071: step 8286, loss 0.293251, acc 0.921875\n",
      "2017-04-03T19:46:52.625040: step 8287, loss 0.333495, acc 0.90625\n",
      "2017-04-03T19:46:52.866559: step 8288, loss 0.337235, acc 0.890625\n",
      "2017-04-03T19:46:53.068132: step 8289, loss 0.407115, acc 0.859375\n",
      "2017-04-03T19:46:53.271733: step 8290, loss 0.157279, acc 0.953125\n",
      "2017-04-03T19:46:53.473687: step 8291, loss 0.517934, acc 0.828125\n",
      "2017-04-03T19:46:53.677943: step 8292, loss 0.269014, acc 0.90625\n",
      "2017-04-03T19:46:53.881441: step 8293, loss 0.46885, acc 0.859375\n",
      "2017-04-03T19:46:54.084535: step 8294, loss 0.381124, acc 0.859375\n",
      "2017-04-03T19:46:54.288136: step 8295, loss 0.400617, acc 0.859375\n",
      "2017-04-03T19:46:54.491394: step 8296, loss 0.36476, acc 0.890625\n",
      "2017-04-03T19:46:54.694710: step 8297, loss 0.255041, acc 0.9375\n",
      "2017-04-03T19:46:54.899828: step 8298, loss 0.321115, acc 0.90625\n",
      "2017-04-03T19:46:55.113552: step 8299, loss 0.255489, acc 0.90625\n",
      "2017-04-03T19:46:55.313348: step 8300, loss 0.253974, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:46:57.363482: step 8300, loss 3.5264, acc 0.31275\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-8300\n",
      "\n",
      "2017-04-03T19:46:57.696687: step 8301, loss 0.369601, acc 0.890625\n",
      "2017-04-03T19:46:57.925390: step 8302, loss 0.366715, acc 0.875\n",
      "2017-04-03T19:46:58.137007: step 8303, loss 0.414001, acc 0.84375\n",
      "2017-04-03T19:46:58.335207: step 8304, loss 0.411187, acc 0.8125\n",
      "2017-04-03T19:46:58.535376: step 8305, loss 0.238756, acc 0.9375\n",
      "2017-04-03T19:46:58.738660: step 8306, loss 0.310259, acc 0.875\n",
      "2017-04-03T19:46:58.938466: step 8307, loss 0.313774, acc 0.875\n",
      "2017-04-03T19:46:59.144554: step 8308, loss 0.310931, acc 0.890625\n",
      "2017-04-03T19:46:59.346149: step 8309, loss 0.333108, acc 0.859375\n",
      "2017-04-03T19:46:59.556606: step 8310, loss 0.441937, acc 0.890625\n",
      "2017-04-03T19:46:59.757494: step 8311, loss 0.298843, acc 0.890625\n",
      "2017-04-03T19:46:59.958987: step 8312, loss 0.412412, acc 0.84375\n",
      "2017-04-03T19:47:00.163991: step 8313, loss 0.263062, acc 0.90625\n",
      "2017-04-03T19:47:00.365803: step 8314, loss 0.244541, acc 0.921875\n",
      "2017-04-03T19:47:00.570089: step 8315, loss 0.39175, acc 0.90625\n",
      "2017-04-03T19:47:00.777616: step 8316, loss 0.437628, acc 0.859375\n",
      "2017-04-03T19:47:00.981838: step 8317, loss 0.418742, acc 0.875\n",
      "2017-04-03T19:47:01.188006: step 8318, loss 0.321366, acc 0.84375\n",
      "2017-04-03T19:47:01.390665: step 8319, loss 0.252049, acc 0.921875\n",
      "2017-04-03T19:47:01.594586: step 8320, loss 0.299323, acc 0.921875\n",
      "2017-04-03T19:47:01.793727: step 8321, loss 0.342981, acc 0.890625\n",
      "2017-04-03T19:47:01.993696: step 8322, loss 0.257392, acc 0.921875\n",
      "2017-04-03T19:47:02.194477: step 8323, loss 0.36138, acc 0.921875\n",
      "2017-04-03T19:47:02.398352: step 8324, loss 0.411306, acc 0.875\n",
      "2017-04-03T19:47:02.594064: step 8325, loss 0.269358, acc 0.921875\n",
      "2017-04-03T19:47:02.797128: step 8326, loss 0.261392, acc 0.921875\n",
      "2017-04-03T19:47:02.999969: step 8327, loss 0.369684, acc 0.859375\n",
      "2017-04-03T19:47:03.202785: step 8328, loss 0.332906, acc 0.890625\n",
      "2017-04-03T19:47:03.402860: step 8329, loss 0.385258, acc 0.859375\n",
      "2017-04-03T19:47:03.613216: step 8330, loss 0.250411, acc 0.90625\n",
      "2017-04-03T19:47:03.817162: step 8331, loss 0.234121, acc 0.921875\n",
      "2017-04-03T19:47:04.024106: step 8332, loss 0.191571, acc 0.9375\n",
      "2017-04-03T19:47:04.227549: step 8333, loss 0.328223, acc 0.84375\n",
      "2017-04-03T19:47:04.428292: step 8334, loss 0.409019, acc 0.859375\n",
      "2017-04-03T19:47:04.632014: step 8335, loss 0.228006, acc 0.90625\n",
      "2017-04-03T19:47:04.834479: step 8336, loss 0.372767, acc 0.890625\n",
      "2017-04-03T19:47:05.078736: step 8337, loss 0.424015, acc 0.84375\n",
      "2017-04-03T19:47:05.282195: step 8338, loss 0.614525, acc 0.8125\n",
      "2017-04-03T19:47:05.485633: step 8339, loss 0.267608, acc 0.890625\n",
      "2017-04-03T19:47:05.685413: step 8340, loss 0.368415, acc 0.84375\n",
      "2017-04-03T19:47:05.889523: step 8341, loss 0.280073, acc 0.890625\n",
      "2017-04-03T19:47:06.090014: step 8342, loss 0.252337, acc 0.9375\n",
      "2017-04-03T19:47:06.321316: step 8343, loss 0.314087, acc 0.875\n",
      "2017-04-03T19:47:06.533604: step 8344, loss 0.402661, acc 0.84375\n",
      "2017-04-03T19:47:06.744859: step 8345, loss 0.403267, acc 0.828125\n",
      "2017-04-03T19:47:06.949815: step 8346, loss 0.473939, acc 0.84375\n",
      "2017-04-03T19:47:07.147040: step 8347, loss 0.291781, acc 0.90625\n",
      "2017-04-03T19:47:07.354574: step 8348, loss 0.436225, acc 0.859375\n",
      "2017-04-03T19:47:07.558856: step 8349, loss 0.297493, acc 0.890625\n",
      "2017-04-03T19:47:07.760248: step 8350, loss 0.315061, acc 0.921875\n",
      "2017-04-03T19:47:07.962030: step 8351, loss 0.175641, acc 0.984375\n",
      "2017-04-03T19:47:08.169835: step 8352, loss 0.430926, acc 0.875\n",
      "2017-04-03T19:47:08.382206: step 8353, loss 0.384394, acc 0.921875\n",
      "2017-04-03T19:47:08.585760: step 8354, loss 0.313088, acc 0.90625\n",
      "2017-04-03T19:47:08.802509: step 8355, loss 0.455668, acc 0.828125\n",
      "2017-04-03T19:47:09.019973: step 8356, loss 0.308924, acc 0.890625\n",
      "2017-04-03T19:47:09.270437: step 8357, loss 0.288787, acc 0.953125\n",
      "2017-04-03T19:47:09.482008: step 8358, loss 0.359036, acc 0.921875\n",
      "2017-04-03T19:47:09.683031: step 8359, loss 0.303876, acc 0.875\n",
      "2017-04-03T19:47:09.889231: step 8360, loss 0.393085, acc 0.859375\n",
      "2017-04-03T19:47:10.093118: step 8361, loss 0.336737, acc 0.890625\n",
      "2017-04-03T19:47:10.299727: step 8362, loss 0.394116, acc 0.890625\n",
      "2017-04-03T19:47:10.543616: step 8363, loss 0.393463, acc 0.875\n",
      "2017-04-03T19:47:10.750915: step 8364, loss 0.283739, acc 0.890625\n",
      "2017-04-03T19:47:10.996915: step 8365, loss 0.362977, acc 0.859375\n",
      "2017-04-03T19:47:11.239278: step 8366, loss 0.415678, acc 0.84375\n",
      "2017-04-03T19:47:11.454131: step 8367, loss 0.42486, acc 0.875\n",
      "2017-04-03T19:47:11.698672: step 8368, loss 0.258511, acc 0.890625\n",
      "2017-04-03T19:47:11.898152: step 8369, loss 0.550166, acc 0.8125\n",
      "2017-04-03T19:47:12.108225: step 8370, loss 0.541456, acc 0.8125\n",
      "2017-04-03T19:47:12.308982: step 8371, loss 0.419053, acc 0.796875\n",
      "2017-04-03T19:47:12.517472: step 8372, loss 0.269267, acc 0.9375\n",
      "2017-04-03T19:47:12.730685: step 8373, loss 0.316492, acc 0.9375\n",
      "2017-04-03T19:47:12.937997: step 8374, loss 0.253115, acc 0.90625\n",
      "2017-04-03T19:47:13.138558: step 8375, loss 0.456012, acc 0.859375\n",
      "2017-04-03T19:47:13.341428: step 8376, loss 0.242474, acc 0.90625\n",
      "2017-04-03T19:47:13.548108: step 8377, loss 0.509756, acc 0.859375\n",
      "2017-04-03T19:47:13.752819: step 8378, loss 0.352221, acc 0.9375\n",
      "2017-04-03T19:47:13.955657: step 8379, loss 0.53441, acc 0.84375\n",
      "2017-04-03T19:47:14.204136: step 8380, loss 0.350598, acc 0.875\n",
      "2017-04-03T19:47:14.410352: step 8381, loss 0.368528, acc 0.84375\n",
      "2017-04-03T19:47:14.611851: step 8382, loss 0.34612, acc 0.859375\n",
      "2017-04-03T19:47:14.825524: step 8383, loss 0.432862, acc 0.84375\n",
      "2017-04-03T19:47:15.026916: step 8384, loss 0.418515, acc 0.875\n",
      "2017-04-03T19:47:15.230376: step 8385, loss 0.358628, acc 0.921875\n",
      "2017-04-03T19:47:15.473383: step 8386, loss 0.385252, acc 0.875\n",
      "2017-04-03T19:47:15.724249: step 8387, loss 0.325204, acc 0.890625\n",
      "2017-04-03T19:47:15.936961: step 8388, loss 0.336772, acc 0.890625\n",
      "2017-04-03T19:47:16.142470: step 8389, loss 0.312934, acc 0.90625\n",
      "2017-04-03T19:47:16.347317: step 8390, loss 0.636784, acc 0.8125\n",
      "2017-04-03T19:47:16.547959: step 8391, loss 0.369909, acc 0.890625\n",
      "2017-04-03T19:47:16.752643: step 8392, loss 0.255605, acc 0.9375\n",
      "2017-04-03T19:47:16.946372: step 8393, loss 0.502783, acc 0.8125\n",
      "2017-04-03T19:47:17.152847: step 8394, loss 0.465829, acc 0.90625\n",
      "2017-04-03T19:47:17.353462: step 8395, loss 0.344867, acc 0.890625\n",
      "2017-04-03T19:47:17.562869: step 8396, loss 0.407449, acc 0.875\n",
      "2017-04-03T19:47:17.782988: step 8397, loss 0.519729, acc 0.828125\n",
      "2017-04-03T19:47:17.990919: step 8398, loss 0.466053, acc 0.828125\n",
      "2017-04-03T19:47:18.193268: step 8399, loss 0.431022, acc 0.828125\n",
      "2017-04-03T19:47:18.395438: step 8400, loss 0.176056, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:47:20.445755: step 8400, loss 3.49557, acc 0.3075\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-8400\n",
      "\n",
      "2017-04-03T19:47:20.783477: step 8401, loss 0.431023, acc 0.875\n",
      "2017-04-03T19:47:20.989463: step 8402, loss 0.512894, acc 0.8125\n",
      "2017-04-03T19:47:21.194111: step 8403, loss 0.321339, acc 0.875\n",
      "2017-04-03T19:47:21.435199: step 8404, loss 0.337994, acc 0.859375\n",
      "2017-04-03T19:47:21.649258: step 8405, loss 0.459368, acc 0.828125\n",
      "2017-04-03T19:47:21.867844: step 8406, loss 0.255567, acc 0.90625\n",
      "2017-04-03T19:47:22.082562: step 8407, loss 0.332991, acc 0.859375\n",
      "2017-04-03T19:47:22.297937: step 8408, loss 0.448602, acc 0.875\n",
      "2017-04-03T19:47:22.506894: step 8409, loss 0.374613, acc 0.875\n",
      "2017-04-03T19:47:22.707343: step 8410, loss 0.425088, acc 0.8125\n",
      "2017-04-03T19:47:22.912697: step 8411, loss 0.241243, acc 0.9375\n",
      "2017-04-03T19:47:23.124740: step 8412, loss 0.296312, acc 0.90625\n",
      "2017-04-03T19:47:23.332678: step 8413, loss 0.331764, acc 0.890625\n",
      "2017-04-03T19:47:23.538774: step 8414, loss 0.248998, acc 0.921875\n",
      "2017-04-03T19:47:23.744930: step 8415, loss 0.318786, acc 0.875\n",
      "2017-04-03T19:47:23.949377: step 8416, loss 0.394577, acc 0.859375\n",
      "2017-04-03T19:47:24.157156: step 8417, loss 0.319518, acc 0.875\n",
      "2017-04-03T19:47:24.363798: step 8418, loss 0.351082, acc 0.890625\n",
      "2017-04-03T19:47:24.573743: step 8419, loss 0.267765, acc 0.890625\n",
      "2017-04-03T19:47:24.777223: step 8420, loss 0.483063, acc 0.859375\n",
      "2017-04-03T19:47:25.020653: step 8421, loss 0.218425, acc 0.921875\n",
      "2017-04-03T19:47:25.235552: step 8422, loss 0.282388, acc 0.890625\n",
      "2017-04-03T19:47:25.439192: step 8423, loss 0.319708, acc 0.90625\n",
      "2017-04-03T19:47:25.644979: step 8424, loss 0.30518, acc 0.875\n",
      "2017-04-03T19:47:25.891100: step 8425, loss 0.312484, acc 0.96875\n",
      "2017-04-03T19:47:26.091466: step 8426, loss 0.365658, acc 0.828125\n",
      "2017-04-03T19:47:26.322412: step 8427, loss 0.397284, acc 0.859375\n",
      "2017-04-03T19:47:26.533415: step 8428, loss 0.471265, acc 0.84375\n",
      "2017-04-03T19:47:26.777186: step 8429, loss 0.249222, acc 0.890625\n",
      "2017-04-03T19:47:26.978441: step 8430, loss 0.465245, acc 0.8125\n",
      "2017-04-03T19:47:27.185404: step 8431, loss 0.40901, acc 0.828125\n",
      "2017-04-03T19:47:27.433501: step 8432, loss 0.252547, acc 0.953125\n",
      "2017-04-03T19:47:27.640249: step 8433, loss 0.307007, acc 0.890625\n",
      "2017-04-03T19:47:27.844562: step 8434, loss 0.466749, acc 0.84375\n",
      "2017-04-03T19:47:28.051524: step 8435, loss 0.322033, acc 0.875\n",
      "2017-04-03T19:47:28.255907: step 8436, loss 0.457605, acc 0.84375\n",
      "2017-04-03T19:47:28.461833: step 8437, loss 0.397793, acc 0.875\n",
      "2017-04-03T19:47:28.666980: step 8438, loss 0.316857, acc 0.890625\n",
      "2017-04-03T19:47:28.872243: step 8439, loss 0.354469, acc 0.875\n",
      "2017-04-03T19:47:29.119513: step 8440, loss 0.28189, acc 0.9375\n",
      "2017-04-03T19:47:29.326621: step 8441, loss 0.299239, acc 0.890625\n",
      "2017-04-03T19:47:29.530268: step 8442, loss 0.319293, acc 0.890625\n",
      "2017-04-03T19:47:29.777587: step 8443, loss 0.364589, acc 0.890625\n",
      "2017-04-03T19:47:29.989557: step 8444, loss 0.343368, acc 0.875\n",
      "2017-04-03T19:47:30.143490: step 8445, loss 0.244222, acc 0.90625\n",
      "2017-04-03T19:47:30.353506: step 8446, loss 0.143858, acc 0.9375\n",
      "2017-04-03T19:47:30.561663: step 8447, loss 0.276374, acc 0.90625\n",
      "2017-04-03T19:47:30.812815: step 8448, loss 0.245972, acc 0.90625\n",
      "2017-04-03T19:47:31.017929: step 8449, loss 0.31161, acc 0.90625\n",
      "2017-04-03T19:47:31.223418: step 8450, loss 0.274429, acc 0.953125\n",
      "2017-04-03T19:47:31.428811: step 8451, loss 0.311601, acc 0.875\n",
      "2017-04-03T19:47:31.638035: step 8452, loss 0.132992, acc 1\n",
      "2017-04-03T19:47:31.840920: step 8453, loss 0.192552, acc 0.96875\n",
      "2017-04-03T19:47:32.043133: step 8454, loss 0.27713, acc 0.921875\n",
      "2017-04-03T19:47:32.249299: step 8455, loss 0.240393, acc 0.921875\n",
      "2017-04-03T19:47:32.491035: step 8456, loss 0.262638, acc 0.9375\n",
      "2017-04-03T19:47:32.696694: step 8457, loss 0.361904, acc 0.84375\n",
      "2017-04-03T19:47:32.904702: step 8458, loss 0.327169, acc 0.90625\n",
      "2017-04-03T19:47:33.154180: step 8459, loss 0.247944, acc 0.90625\n",
      "2017-04-03T19:47:33.357557: step 8460, loss 0.293061, acc 0.890625\n",
      "2017-04-03T19:47:33.557448: step 8461, loss 0.131005, acc 0.953125\n",
      "2017-04-03T19:47:33.763158: step 8462, loss 0.318529, acc 0.921875\n",
      "2017-04-03T19:47:33.968534: step 8463, loss 0.204051, acc 0.9375\n",
      "2017-04-03T19:47:34.171971: step 8464, loss 0.312795, acc 0.90625\n",
      "2017-04-03T19:47:34.404529: step 8465, loss 0.19428, acc 0.9375\n",
      "2017-04-03T19:47:34.613939: step 8466, loss 0.286749, acc 0.921875\n",
      "2017-04-03T19:47:34.814308: step 8467, loss 0.229209, acc 0.953125\n",
      "2017-04-03T19:47:35.016078: step 8468, loss 0.207619, acc 0.890625\n",
      "2017-04-03T19:47:35.218734: step 8469, loss 0.290863, acc 0.875\n",
      "2017-04-03T19:47:35.424674: step 8470, loss 0.329457, acc 0.875\n",
      "2017-04-03T19:47:35.628586: step 8471, loss 0.419735, acc 0.859375\n",
      "2017-04-03T19:47:35.834019: step 8472, loss 0.314118, acc 0.890625\n",
      "2017-04-03T19:47:36.039609: step 8473, loss 0.353445, acc 0.875\n",
      "2017-04-03T19:47:36.243083: step 8474, loss 0.225192, acc 0.953125\n",
      "2017-04-03T19:47:36.445378: step 8475, loss 0.208372, acc 0.921875\n",
      "2017-04-03T19:47:36.651702: step 8476, loss 0.253162, acc 0.90625\n",
      "2017-04-03T19:47:36.852512: step 8477, loss 0.249339, acc 0.890625\n",
      "2017-04-03T19:47:37.059441: step 8478, loss 0.305101, acc 0.90625\n",
      "2017-04-03T19:47:37.271035: step 8479, loss 0.206421, acc 0.96875\n",
      "2017-04-03T19:47:37.475491: step 8480, loss 0.353471, acc 0.859375\n",
      "2017-04-03T19:47:37.675360: step 8481, loss 0.326573, acc 0.90625\n",
      "2017-04-03T19:47:37.886575: step 8482, loss 0.307745, acc 0.890625\n",
      "2017-04-03T19:47:38.093683: step 8483, loss 0.109509, acc 0.96875\n",
      "2017-04-03T19:47:38.342397: step 8484, loss 0.315795, acc 0.90625\n",
      "2017-04-03T19:47:38.543742: step 8485, loss 0.199323, acc 0.96875\n",
      "2017-04-03T19:47:38.742489: step 8486, loss 0.252351, acc 0.921875\n",
      "2017-04-03T19:47:38.944161: step 8487, loss 0.370774, acc 0.890625\n",
      "2017-04-03T19:47:39.142497: step 8488, loss 0.189502, acc 0.953125\n",
      "2017-04-03T19:47:39.346288: step 8489, loss 0.297591, acc 0.90625\n",
      "2017-04-03T19:47:39.549033: step 8490, loss 0.277162, acc 0.875\n",
      "2017-04-03T19:47:39.751240: step 8491, loss 0.23679, acc 0.875\n",
      "2017-04-03T19:47:39.974707: step 8492, loss 0.422319, acc 0.875\n",
      "2017-04-03T19:47:40.192658: step 8493, loss 0.170666, acc 0.953125\n",
      "2017-04-03T19:47:40.434809: step 8494, loss 0.37909, acc 0.875\n",
      "2017-04-03T19:47:40.635972: step 8495, loss 0.310793, acc 0.859375\n",
      "2017-04-03T19:47:40.846354: step 8496, loss 0.354461, acc 0.859375\n",
      "2017-04-03T19:47:41.045529: step 8497, loss 0.222942, acc 0.953125\n",
      "2017-04-03T19:47:41.252117: step 8498, loss 0.353079, acc 0.890625\n",
      "2017-04-03T19:47:41.496135: step 8499, loss 0.219375, acc 0.953125\n",
      "2017-04-03T19:47:41.699935: step 8500, loss 0.330474, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:47:43.727915: step 8500, loss 3.58692, acc 0.305\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-8500\n",
      "\n",
      "2017-04-03T19:47:44.124185: step 8501, loss 0.250764, acc 0.90625\n",
      "2017-04-03T19:47:44.332703: step 8502, loss 0.346717, acc 0.90625\n",
      "2017-04-03T19:47:44.535027: step 8503, loss 0.330418, acc 0.859375\n",
      "2017-04-03T19:47:44.737727: step 8504, loss 0.3021, acc 0.921875\n",
      "2017-04-03T19:47:44.938147: step 8505, loss 0.315747, acc 0.921875\n",
      "2017-04-03T19:47:45.143494: step 8506, loss 0.341618, acc 0.921875\n",
      "2017-04-03T19:47:45.393336: step 8507, loss 0.251742, acc 0.921875\n",
      "2017-04-03T19:47:45.598960: step 8508, loss 0.336739, acc 0.890625\n",
      "2017-04-03T19:47:45.804552: step 8509, loss 0.456953, acc 0.890625\n",
      "2017-04-03T19:47:46.010164: step 8510, loss 0.334466, acc 0.859375\n",
      "2017-04-03T19:47:46.225255: step 8511, loss 0.316507, acc 0.84375\n",
      "2017-04-03T19:47:46.430072: step 8512, loss 0.197242, acc 0.921875\n",
      "2017-04-03T19:47:46.633773: step 8513, loss 0.391664, acc 0.875\n",
      "2017-04-03T19:47:46.846358: step 8514, loss 0.314396, acc 0.890625\n",
      "2017-04-03T19:47:47.050517: step 8515, loss 0.195507, acc 0.921875\n",
      "2017-04-03T19:47:47.265830: step 8516, loss 0.344513, acc 0.90625\n",
      "2017-04-03T19:47:47.467885: step 8517, loss 0.354241, acc 0.9375\n",
      "2017-04-03T19:47:47.666863: step 8518, loss 0.367952, acc 0.890625\n",
      "2017-04-03T19:47:47.867835: step 8519, loss 0.488821, acc 0.84375\n",
      "2017-04-03T19:47:48.076786: step 8520, loss 0.286044, acc 0.921875\n",
      "2017-04-03T19:47:48.330743: step 8521, loss 0.278285, acc 0.90625\n",
      "2017-04-03T19:47:48.536542: step 8522, loss 0.32354, acc 0.859375\n",
      "2017-04-03T19:47:48.738906: step 8523, loss 0.220865, acc 0.921875\n",
      "2017-04-03T19:47:48.943647: step 8524, loss 0.148682, acc 0.953125\n",
      "2017-04-03T19:47:49.154817: step 8525, loss 0.182371, acc 0.921875\n",
      "2017-04-03T19:47:49.392095: step 8526, loss 0.25735, acc 0.90625\n",
      "2017-04-03T19:47:49.599417: step 8527, loss 0.328173, acc 0.875\n",
      "2017-04-03T19:47:49.807784: step 8528, loss 0.401904, acc 0.875\n",
      "2017-04-03T19:47:50.009710: step 8529, loss 0.200828, acc 0.953125\n",
      "2017-04-03T19:47:50.211152: step 8530, loss 0.376298, acc 0.859375\n",
      "2017-04-03T19:47:50.414171: step 8531, loss 0.137859, acc 0.984375\n",
      "2017-04-03T19:47:50.614312: step 8532, loss 0.263298, acc 0.90625\n",
      "2017-04-03T19:47:50.825675: step 8533, loss 0.464976, acc 0.859375\n",
      "2017-04-03T19:47:51.028394: step 8534, loss 0.372549, acc 0.84375\n",
      "2017-04-03T19:47:51.241042: step 8535, loss 0.302274, acc 0.90625\n",
      "2017-04-03T19:47:51.457801: step 8536, loss 0.295213, acc 0.890625\n",
      "2017-04-03T19:47:51.662008: step 8537, loss 0.222838, acc 0.90625\n",
      "2017-04-03T19:47:51.865449: step 8538, loss 0.245322, acc 0.875\n",
      "2017-04-03T19:47:52.076852: step 8539, loss 0.44876, acc 0.84375\n",
      "2017-04-03T19:47:52.281344: step 8540, loss 0.248795, acc 0.921875\n",
      "2017-04-03T19:47:52.492987: step 8541, loss 0.303471, acc 0.890625\n",
      "2017-04-03T19:47:52.695984: step 8542, loss 0.227316, acc 0.9375\n",
      "2017-04-03T19:47:52.898550: step 8543, loss 0.153643, acc 0.984375\n",
      "2017-04-03T19:47:53.099772: step 8544, loss 0.152564, acc 0.96875\n",
      "2017-04-03T19:47:53.300483: step 8545, loss 0.29761, acc 0.875\n",
      "2017-04-03T19:47:53.504634: step 8546, loss 0.187093, acc 0.921875\n",
      "2017-04-03T19:47:53.706795: step 8547, loss 0.216481, acc 0.953125\n",
      "2017-04-03T19:47:53.911120: step 8548, loss 0.331613, acc 0.875\n",
      "2017-04-03T19:47:54.111328: step 8549, loss 0.36666, acc 0.875\n",
      "2017-04-03T19:47:54.312823: step 8550, loss 0.173269, acc 0.984375\n",
      "2017-04-03T19:47:54.512478: step 8551, loss 0.342076, acc 0.890625\n",
      "2017-04-03T19:47:54.721241: step 8552, loss 0.275816, acc 0.90625\n",
      "2017-04-03T19:47:54.923168: step 8553, loss 0.229002, acc 0.921875\n",
      "2017-04-03T19:47:55.119711: step 8554, loss 0.35781, acc 0.84375\n",
      "2017-04-03T19:47:55.327397: step 8555, loss 0.248465, acc 0.875\n",
      "2017-04-03T19:47:55.524955: step 8556, loss 0.168232, acc 0.9375\n",
      "2017-04-03T19:47:55.730505: step 8557, loss 0.206363, acc 0.921875\n",
      "2017-04-03T19:47:55.938804: step 8558, loss 0.418407, acc 0.84375\n",
      "2017-04-03T19:47:56.143015: step 8559, loss 0.136989, acc 0.96875\n",
      "2017-04-03T19:47:56.345030: step 8560, loss 0.259043, acc 0.890625\n",
      "2017-04-03T19:47:56.547110: step 8561, loss 0.480386, acc 0.859375\n",
      "2017-04-03T19:47:56.750641: step 8562, loss 0.370865, acc 0.890625\n",
      "2017-04-03T19:47:56.950169: step 8563, loss 0.377347, acc 0.875\n",
      "2017-04-03T19:47:57.160259: step 8564, loss 0.382262, acc 0.890625\n",
      "2017-04-03T19:47:57.377432: step 8565, loss 0.276004, acc 0.890625\n",
      "2017-04-03T19:47:57.618312: step 8566, loss 0.299997, acc 0.859375\n",
      "2017-04-03T19:47:57.825326: step 8567, loss 0.273842, acc 0.9375\n",
      "2017-04-03T19:47:58.070118: step 8568, loss 0.353989, acc 0.890625\n",
      "2017-04-03T19:47:58.274898: step 8569, loss 0.431298, acc 0.90625\n",
      "2017-04-03T19:47:58.473636: step 8570, loss 0.220126, acc 0.921875\n",
      "2017-04-03T19:47:58.680337: step 8571, loss 0.230399, acc 0.984375\n",
      "2017-04-03T19:47:58.885265: step 8572, loss 0.236027, acc 0.953125\n",
      "2017-04-03T19:47:59.088587: step 8573, loss 0.235955, acc 0.90625\n",
      "2017-04-03T19:47:59.291242: step 8574, loss 0.474768, acc 0.84375\n",
      "2017-04-03T19:47:59.503016: step 8575, loss 0.261887, acc 0.90625\n",
      "2017-04-03T19:47:59.723053: step 8576, loss 0.244014, acc 0.90625\n",
      "2017-04-03T19:47:59.919788: step 8577, loss 0.315471, acc 0.890625\n",
      "2017-04-03T19:48:00.160956: step 8578, loss 0.313735, acc 0.875\n",
      "2017-04-03T19:48:00.366962: step 8579, loss 0.248787, acc 0.921875\n",
      "2017-04-03T19:48:00.571555: step 8580, loss 0.258464, acc 0.90625\n",
      "2017-04-03T19:48:00.776248: step 8581, loss 0.452979, acc 0.921875\n",
      "2017-04-03T19:48:00.980964: step 8582, loss 0.423059, acc 0.90625\n",
      "2017-04-03T19:48:01.183967: step 8583, loss 0.520408, acc 0.890625\n",
      "2017-04-03T19:48:01.389005: step 8584, loss 0.281748, acc 0.875\n",
      "2017-04-03T19:48:01.591950: step 8585, loss 0.346456, acc 0.890625\n",
      "2017-04-03T19:48:01.796391: step 8586, loss 0.336892, acc 0.921875\n",
      "2017-04-03T19:48:02.002328: step 8587, loss 0.357696, acc 0.875\n",
      "2017-04-03T19:48:02.203704: step 8588, loss 0.328019, acc 0.921875\n",
      "2017-04-03T19:48:02.405030: step 8589, loss 0.204103, acc 0.9375\n",
      "2017-04-03T19:48:02.622854: step 8590, loss 0.295798, acc 0.90625\n",
      "2017-04-03T19:48:02.849159: step 8591, loss 0.240206, acc 0.890625\n",
      "2017-04-03T19:48:03.046567: step 8592, loss 0.269852, acc 0.9375\n",
      "2017-04-03T19:48:03.258368: step 8593, loss 0.320485, acc 0.921875\n",
      "2017-04-03T19:48:03.505252: step 8594, loss 0.241476, acc 0.921875\n",
      "2017-04-03T19:48:03.714032: step 8595, loss 0.352255, acc 0.890625\n",
      "2017-04-03T19:48:03.913196: step 8596, loss 0.506178, acc 0.84375\n",
      "2017-04-03T19:48:04.118259: step 8597, loss 0.272758, acc 0.921875\n",
      "2017-04-03T19:48:04.319138: step 8598, loss 0.2297, acc 0.96875\n",
      "2017-04-03T19:48:04.522043: step 8599, loss 0.228527, acc 0.90625\n",
      "2017-04-03T19:48:04.732769: step 8600, loss 0.369317, acc 0.828125\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:48:06.783270: step 8600, loss 3.62289, acc 0.30075\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-8600\n",
      "\n",
      "2017-04-03T19:48:07.113919: step 8601, loss 0.225121, acc 0.921875\n",
      "2017-04-03T19:48:07.315429: step 8602, loss 0.251318, acc 0.890625\n",
      "2017-04-03T19:48:07.517755: step 8603, loss 0.095045, acc 0.984375\n",
      "2017-04-03T19:48:07.720366: step 8604, loss 0.218607, acc 0.96875\n",
      "2017-04-03T19:48:07.926943: step 8605, loss 0.311329, acc 0.921875\n",
      "2017-04-03T19:48:08.127475: step 8606, loss 0.241732, acc 0.921875\n",
      "2017-04-03T19:48:08.339322: step 8607, loss 0.150259, acc 0.96875\n",
      "2017-04-03T19:48:08.540075: step 8608, loss 0.20982, acc 0.921875\n",
      "2017-04-03T19:48:08.750092: step 8609, loss 0.271388, acc 0.90625\n",
      "2017-04-03T19:48:08.950367: step 8610, loss 0.203524, acc 0.9375\n",
      "2017-04-03T19:48:09.158224: step 8611, loss 0.319415, acc 0.9375\n",
      "2017-04-03T19:48:09.367795: step 8612, loss 0.316361, acc 0.90625\n",
      "2017-04-03T19:48:09.571839: step 8613, loss 0.339644, acc 0.875\n",
      "2017-04-03T19:48:09.775506: step 8614, loss 0.326492, acc 0.90625\n",
      "2017-04-03T19:48:09.976700: step 8615, loss 0.28262, acc 0.9375\n",
      "2017-04-03T19:48:10.187749: step 8616, loss 0.197188, acc 0.9375\n",
      "2017-04-03T19:48:10.390311: step 8617, loss 0.333631, acc 0.890625\n",
      "2017-04-03T19:48:10.604791: step 8618, loss 0.300937, acc 0.921875\n",
      "2017-04-03T19:48:10.810770: step 8619, loss 0.163896, acc 0.96875\n",
      "2017-04-03T19:48:11.016222: step 8620, loss 0.569747, acc 0.84375\n",
      "2017-04-03T19:48:11.220588: step 8621, loss 0.292646, acc 0.921875\n",
      "2017-04-03T19:48:11.425062: step 8622, loss 0.23868, acc 0.921875\n",
      "2017-04-03T19:48:11.625352: step 8623, loss 0.332131, acc 0.859375\n",
      "2017-04-03T19:48:11.829623: step 8624, loss 0.462024, acc 0.828125\n",
      "2017-04-03T19:48:12.035621: step 8625, loss 0.236049, acc 0.90625\n",
      "2017-04-03T19:48:12.242403: step 8626, loss 0.270889, acc 0.90625\n",
      "2017-04-03T19:48:12.469367: step 8627, loss 0.217798, acc 0.9375\n",
      "2017-04-03T19:48:12.671548: step 8628, loss 0.283064, acc 0.90625\n",
      "2017-04-03T19:48:12.876346: step 8629, loss 0.21781, acc 0.90625\n",
      "2017-04-03T19:48:13.078892: step 8630, loss 0.336495, acc 0.90625\n",
      "2017-04-03T19:48:13.285085: step 8631, loss 0.221487, acc 0.921875\n",
      "2017-04-03T19:48:13.491835: step 8632, loss 0.30417, acc 0.890625\n",
      "2017-04-03T19:48:13.693136: step 8633, loss 0.269895, acc 0.890625\n",
      "2017-04-03T19:48:13.896514: step 8634, loss 0.457606, acc 0.796875\n",
      "2017-04-03T19:48:14.100047: step 8635, loss 0.234561, acc 0.921875\n",
      "2017-04-03T19:48:14.311186: step 8636, loss 0.265292, acc 0.921875\n",
      "2017-04-03T19:48:14.515795: step 8637, loss 0.125498, acc 1\n",
      "2017-04-03T19:48:14.715644: step 8638, loss 0.216393, acc 0.90625\n",
      "2017-04-03T19:48:14.923197: step 8639, loss 0.268506, acc 0.90625\n",
      "2017-04-03T19:48:15.163074: step 8640, loss 0.252086, acc 0.921875\n",
      "2017-04-03T19:48:15.369261: step 8641, loss 0.250324, acc 0.921875\n",
      "2017-04-03T19:48:15.615714: step 8642, loss 0.249142, acc 0.9375\n",
      "2017-04-03T19:48:15.817249: step 8643, loss 0.265926, acc 0.9375\n",
      "2017-04-03T19:48:16.033676: step 8644, loss 0.196087, acc 0.953125\n",
      "2017-04-03T19:48:16.246955: step 8645, loss 0.137815, acc 0.984375\n",
      "2017-04-03T19:48:16.456839: step 8646, loss 0.231545, acc 0.921875\n",
      "2017-04-03T19:48:16.666898: step 8647, loss 0.234466, acc 0.90625\n",
      "2017-04-03T19:48:16.871255: step 8648, loss 0.336066, acc 0.890625\n",
      "2017-04-03T19:48:17.073107: step 8649, loss 0.221348, acc 0.90625\n",
      "2017-04-03T19:48:17.276551: step 8650, loss 0.293156, acc 0.90625\n",
      "2017-04-03T19:48:17.476942: step 8651, loss 0.278569, acc 0.890625\n",
      "2017-04-03T19:48:17.679884: step 8652, loss 0.273779, acc 0.9375\n",
      "2017-04-03T19:48:17.879200: step 8653, loss 0.323807, acc 0.890625\n",
      "2017-04-03T19:48:18.081630: step 8654, loss 0.293438, acc 0.90625\n",
      "2017-04-03T19:48:18.329481: step 8655, loss 0.177098, acc 0.984375\n",
      "2017-04-03T19:48:18.541021: step 8656, loss 0.223194, acc 0.921875\n",
      "2017-04-03T19:48:18.746084: step 8657, loss 0.3175, acc 0.890625\n",
      "2017-04-03T19:48:18.948921: step 8658, loss 0.180834, acc 0.953125\n",
      "2017-04-03T19:48:19.156618: step 8659, loss 0.133714, acc 0.984375\n",
      "2017-04-03T19:48:19.364983: step 8660, loss 0.190484, acc 0.953125\n",
      "2017-04-03T19:48:19.565112: step 8661, loss 0.506208, acc 0.84375\n",
      "2017-04-03T19:48:19.771539: step 8662, loss 0.205936, acc 0.953125\n",
      "2017-04-03T19:48:19.971825: step 8663, loss 0.371313, acc 0.90625\n",
      "2017-04-03T19:48:20.175028: step 8664, loss 0.282968, acc 0.890625\n",
      "2017-04-03T19:48:20.418722: step 8665, loss 0.265726, acc 0.9375\n",
      "2017-04-03T19:48:20.619887: step 8666, loss 0.261514, acc 0.921875\n",
      "2017-04-03T19:48:20.828128: step 8667, loss 0.256311, acc 0.9375\n",
      "2017-04-03T19:48:21.029332: step 8668, loss 0.323805, acc 0.90625\n",
      "2017-04-03T19:48:21.231973: step 8669, loss 0.248805, acc 0.90625\n",
      "2017-04-03T19:48:21.439085: step 8670, loss 0.360915, acc 0.890625\n",
      "2017-04-03T19:48:21.678914: step 8671, loss 0.169957, acc 0.984375\n",
      "2017-04-03T19:48:21.925761: step 8672, loss 0.401415, acc 0.875\n",
      "2017-04-03T19:48:22.133950: step 8673, loss 0.183433, acc 0.9375\n",
      "2017-04-03T19:48:22.333526: step 8674, loss 0.387465, acc 0.875\n",
      "2017-04-03T19:48:22.536373: step 8675, loss 0.341955, acc 0.890625\n",
      "2017-04-03T19:48:22.736556: step 8676, loss 0.278718, acc 0.875\n",
      "2017-04-03T19:48:22.934439: step 8677, loss 0.446331, acc 0.828125\n",
      "2017-04-03T19:48:23.134779: step 8678, loss 0.485751, acc 0.859375\n",
      "2017-04-03T19:48:23.341442: step 8679, loss 0.252263, acc 0.921875\n",
      "2017-04-03T19:48:23.545885: step 8680, loss 0.451104, acc 0.859375\n",
      "2017-04-03T19:48:23.747766: step 8681, loss 0.329141, acc 0.890625\n",
      "2017-04-03T19:48:23.947201: step 8682, loss 0.152674, acc 0.984375\n",
      "2017-04-03T19:48:24.150646: step 8683, loss 0.197034, acc 0.953125\n",
      "2017-04-03T19:48:24.373634: step 8684, loss 0.200538, acc 0.921875\n",
      "2017-04-03T19:48:24.620046: step 8685, loss 0.190995, acc 0.921875\n",
      "2017-04-03T19:48:24.825461: step 8686, loss 0.279253, acc 0.9375\n",
      "2017-04-03T19:48:25.026014: step 8687, loss 0.153341, acc 0.96875\n",
      "2017-04-03T19:48:25.228760: step 8688, loss 0.387935, acc 0.90625\n",
      "2017-04-03T19:48:25.433277: step 8689, loss 0.342154, acc 0.859375\n",
      "2017-04-03T19:48:25.638105: step 8690, loss 0.120388, acc 1\n",
      "2017-04-03T19:48:25.836713: step 8691, loss 0.393178, acc 0.890625\n",
      "2017-04-03T19:48:26.083141: step 8692, loss 0.255763, acc 0.90625\n",
      "2017-04-03T19:48:26.283934: step 8693, loss 0.369167, acc 0.921875\n",
      "2017-04-03T19:48:26.532501: step 8694, loss 0.392296, acc 0.875\n",
      "2017-04-03T19:48:26.732018: step 8695, loss 0.194709, acc 0.953125\n",
      "2017-04-03T19:48:26.955217: step 8696, loss 0.226867, acc 0.90625\n",
      "2017-04-03T19:48:27.173308: step 8697, loss 0.429969, acc 0.875\n",
      "2017-04-03T19:48:27.420410: step 8698, loss 0.313258, acc 0.9375\n",
      "2017-04-03T19:48:27.623014: step 8699, loss 0.350958, acc 0.859375\n",
      "2017-04-03T19:48:27.826954: step 8700, loss 0.323882, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:48:29.905499: step 8700, loss 3.69955, acc 0.3105\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-8700\n",
      "\n",
      "2017-04-03T19:48:30.240174: step 8701, loss 0.403485, acc 0.859375\n",
      "2017-04-03T19:48:30.446922: step 8702, loss 0.190851, acc 0.953125\n",
      "2017-04-03T19:48:30.646747: step 8703, loss 0.329518, acc 0.890625\n",
      "2017-04-03T19:48:30.897598: step 8704, loss 0.345133, acc 0.90625\n",
      "2017-04-03T19:48:31.098961: step 8705, loss 0.395811, acc 0.890625\n",
      "2017-04-03T19:48:31.311909: step 8706, loss 0.24744, acc 0.890625\n",
      "2017-04-03T19:48:31.513782: step 8707, loss 0.438299, acc 0.859375\n",
      "2017-04-03T19:48:31.714556: step 8708, loss 0.224108, acc 0.9375\n",
      "2017-04-03T19:48:31.911608: step 8709, loss 0.227057, acc 0.953125\n",
      "2017-04-03T19:48:32.111739: step 8710, loss 0.377953, acc 0.921875\n",
      "2017-04-03T19:48:32.310295: step 8711, loss 0.18189, acc 0.953125\n",
      "2017-04-03T19:48:32.519403: step 8712, loss 0.474489, acc 0.8125\n",
      "2017-04-03T19:48:32.723001: step 8713, loss 0.342586, acc 0.890625\n",
      "2017-04-03T19:48:32.925280: step 8714, loss 0.336657, acc 0.90625\n",
      "2017-04-03T19:48:33.124178: step 8715, loss 0.273773, acc 0.890625\n",
      "2017-04-03T19:48:33.322532: step 8716, loss 0.489303, acc 0.8125\n",
      "2017-04-03T19:48:33.527347: step 8717, loss 0.210885, acc 0.96875\n",
      "2017-04-03T19:48:33.727814: step 8718, loss 0.452081, acc 0.859375\n",
      "2017-04-03T19:48:33.928556: step 8719, loss 0.263571, acc 0.90625\n",
      "2017-04-03T19:48:34.129928: step 8720, loss 0.227343, acc 0.921875\n",
      "2017-04-03T19:48:34.329081: step 8721, loss 0.418452, acc 0.875\n",
      "2017-04-03T19:48:34.532271: step 8722, loss 0.218746, acc 0.9375\n",
      "2017-04-03T19:48:34.733189: step 8723, loss 0.272644, acc 0.875\n",
      "2017-04-03T19:48:34.932959: step 8724, loss 0.378524, acc 0.875\n",
      "2017-04-03T19:48:35.129257: step 8725, loss 0.324263, acc 0.875\n",
      "2017-04-03T19:48:35.336130: step 8726, loss 0.235199, acc 0.890625\n",
      "2017-04-03T19:48:35.537197: step 8727, loss 0.353705, acc 0.90625\n",
      "2017-04-03T19:48:35.775410: step 8728, loss 0.368079, acc 0.859375\n",
      "2017-04-03T19:48:35.979367: step 8729, loss 0.311998, acc 0.875\n",
      "2017-04-03T19:48:36.183714: step 8730, loss 0.383814, acc 0.890625\n",
      "2017-04-03T19:48:36.388723: step 8731, loss 0.3812, acc 0.875\n",
      "2017-04-03T19:48:36.623414: step 8732, loss 0.449827, acc 0.828125\n",
      "2017-04-03T19:48:36.822910: step 8733, loss 0.260153, acc 0.9375\n",
      "2017-04-03T19:48:37.023197: step 8734, loss 0.392643, acc 0.859375\n",
      "2017-04-03T19:48:37.221394: step 8735, loss 0.246083, acc 0.9375\n",
      "2017-04-03T19:48:37.421708: step 8736, loss 0.440387, acc 0.859375\n",
      "2017-04-03T19:48:37.622281: step 8737, loss 0.262484, acc 0.9375\n",
      "2017-04-03T19:48:37.829530: step 8738, loss 0.330932, acc 0.875\n",
      "2017-04-03T19:48:38.033320: step 8739, loss 0.381137, acc 0.859375\n",
      "2017-04-03T19:48:38.237253: step 8740, loss 0.298313, acc 0.90625\n",
      "2017-04-03T19:48:38.434915: step 8741, loss 0.282714, acc 0.9375\n",
      "2017-04-03T19:48:38.641500: step 8742, loss 0.259159, acc 0.90625\n",
      "2017-04-03T19:48:38.846571: step 8743, loss 0.204096, acc 0.953125\n",
      "2017-04-03T19:48:39.047795: step 8744, loss 0.406477, acc 0.890625\n",
      "2017-04-03T19:48:39.248239: step 8745, loss 0.245645, acc 0.9375\n",
      "2017-04-03T19:48:39.484507: step 8746, loss 0.396019, acc 0.828125\n",
      "2017-04-03T19:48:39.685067: step 8747, loss 0.346912, acc 0.90625\n",
      "2017-04-03T19:48:39.890346: step 8748, loss 0.396025, acc 0.875\n",
      "2017-04-03T19:48:40.097783: step 8749, loss 0.242831, acc 0.890625\n",
      "2017-04-03T19:48:40.300361: step 8750, loss 0.392934, acc 0.84375\n",
      "2017-04-03T19:48:40.500273: step 8751, loss 0.307496, acc 0.84375\n",
      "2017-04-03T19:48:40.703521: step 8752, loss 0.251633, acc 0.90625\n",
      "2017-04-03T19:48:40.907069: step 8753, loss 0.373502, acc 0.875\n",
      "2017-04-03T19:48:41.116643: step 8754, loss 0.220502, acc 0.921875\n",
      "2017-04-03T19:48:41.322583: step 8755, loss 0.29053, acc 0.90625\n",
      "2017-04-03T19:48:41.527349: step 8756, loss 0.259963, acc 0.921875\n",
      "2017-04-03T19:48:41.728843: step 8757, loss 0.247477, acc 0.9375\n",
      "2017-04-03T19:48:41.931928: step 8758, loss 0.358753, acc 0.859375\n",
      "2017-04-03T19:48:42.180880: step 8759, loss 0.272255, acc 0.875\n",
      "2017-04-03T19:48:42.384651: step 8760, loss 0.498699, acc 0.84375\n",
      "2017-04-03T19:48:42.584441: step 8761, loss 0.344875, acc 0.890625\n",
      "2017-04-03T19:48:42.786811: step 8762, loss 0.278128, acc 0.890625\n",
      "2017-04-03T19:48:43.033733: step 8763, loss 0.251606, acc 0.921875\n",
      "2017-04-03T19:48:43.237694: step 8764, loss 0.632234, acc 0.84375\n",
      "2017-04-03T19:48:43.480785: step 8765, loss 0.222453, acc 0.90625\n",
      "2017-04-03T19:48:43.687950: step 8766, loss 0.230989, acc 0.921875\n",
      "2017-04-03T19:48:43.887109: step 8767, loss 0.331166, acc 0.875\n",
      "2017-04-03T19:48:44.114844: step 8768, loss 0.207992, acc 0.921875\n",
      "2017-04-03T19:48:44.322963: step 8769, loss 0.319791, acc 0.890625\n",
      "2017-04-03T19:48:44.523732: step 8770, loss 0.212781, acc 0.953125\n",
      "2017-04-03T19:48:44.728011: step 8771, loss 0.294223, acc 0.875\n",
      "2017-04-03T19:48:44.941450: step 8772, loss 0.252447, acc 0.921875\n",
      "2017-04-03T19:48:45.142636: step 8773, loss 0.371332, acc 0.890625\n",
      "2017-04-03T19:48:45.346816: step 8774, loss 0.402621, acc 0.859375\n",
      "2017-04-03T19:48:45.550302: step 8775, loss 0.330189, acc 0.890625\n",
      "2017-04-03T19:48:45.751054: step 8776, loss 0.265223, acc 0.890625\n",
      "2017-04-03T19:48:45.955399: step 8777, loss 0.241264, acc 0.921875\n",
      "2017-04-03T19:48:46.154480: step 8778, loss 0.267321, acc 0.921875\n",
      "2017-04-03T19:48:46.356621: step 8779, loss 0.260589, acc 0.921875\n",
      "2017-04-03T19:48:46.557082: step 8780, loss 0.330402, acc 0.90625\n",
      "2017-04-03T19:48:46.757847: step 8781, loss 0.436087, acc 0.84375\n",
      "2017-04-03T19:48:46.960785: step 8782, loss 0.316883, acc 0.859375\n",
      "2017-04-03T19:48:47.159224: step 8783, loss 0.582152, acc 0.8125\n",
      "2017-04-03T19:48:47.357562: step 8784, loss 0.188139, acc 0.953125\n",
      "2017-04-03T19:48:47.557600: step 8785, loss 0.606984, acc 0.84375\n",
      "2017-04-03T19:48:47.756416: step 8786, loss 0.121326, acc 0.953125\n",
      "2017-04-03T19:48:47.955892: step 8787, loss 0.362986, acc 0.859375\n",
      "2017-04-03T19:48:48.158744: step 8788, loss 0.193583, acc 0.953125\n",
      "2017-04-03T19:48:48.386713: step 8789, loss 0.343672, acc 0.953125\n",
      "2017-04-03T19:48:48.628762: step 8790, loss 0.280237, acc 0.90625\n",
      "2017-04-03T19:48:48.829180: step 8791, loss 0.261539, acc 0.9375\n",
      "2017-04-03T19:48:49.041685: step 8792, loss 0.40314, acc 0.859375\n",
      "2017-04-03T19:48:49.249041: step 8793, loss 0.394555, acc 0.859375\n",
      "2017-04-03T19:48:49.450033: step 8794, loss 0.265608, acc 0.90625\n",
      "2017-04-03T19:48:49.652649: step 8795, loss 0.193549, acc 0.96875\n",
      "2017-04-03T19:48:49.855002: step 8796, loss 0.166533, acc 0.9375\n",
      "2017-04-03T19:48:50.058691: step 8797, loss 0.198638, acc 0.96875\n",
      "2017-04-03T19:48:50.266726: step 8798, loss 0.333688, acc 0.921875\n",
      "2017-04-03T19:48:50.505904: step 8799, loss 0.30738, acc 0.90625\n",
      "2017-04-03T19:48:50.703972: step 8800, loss 0.224832, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:48:52.726573: step 8800, loss 3.74846, acc 0.3115\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-8800\n",
      "\n",
      "2017-04-03T19:48:53.055263: step 8801, loss 0.249168, acc 0.859375\n",
      "2017-04-03T19:48:53.301293: step 8802, loss 0.215024, acc 0.90625\n",
      "2017-04-03T19:48:53.512000: step 8803, loss 0.324595, acc 0.859375\n",
      "2017-04-03T19:48:53.712990: step 8804, loss 0.227524, acc 0.890625\n",
      "2017-04-03T19:48:53.953590: step 8805, loss 0.329642, acc 0.890625\n",
      "2017-04-03T19:48:54.167075: step 8806, loss 0.323373, acc 0.875\n",
      "2017-04-03T19:48:54.371201: step 8807, loss 0.401218, acc 0.890625\n",
      "2017-04-03T19:48:54.571695: step 8808, loss 0.391473, acc 0.875\n",
      "2017-04-03T19:48:54.767440: step 8809, loss 0.2851, acc 0.90625\n",
      "2017-04-03T19:48:54.969360: step 8810, loss 0.415406, acc 0.84375\n",
      "2017-04-03T19:48:55.174810: step 8811, loss 0.341792, acc 0.890625\n",
      "2017-04-03T19:48:55.385208: step 8812, loss 0.388597, acc 0.828125\n",
      "2017-04-03T19:48:55.583243: step 8813, loss 0.274621, acc 0.90625\n",
      "2017-04-03T19:48:55.788096: step 8814, loss 0.242017, acc 0.953125\n",
      "2017-04-03T19:48:55.988680: step 8815, loss 0.360915, acc 0.859375\n",
      "2017-04-03T19:48:56.195245: step 8816, loss 0.472797, acc 0.8125\n",
      "2017-04-03T19:48:56.397586: step 8817, loss 0.264422, acc 0.921875\n",
      "2017-04-03T19:48:56.599029: step 8818, loss 0.244659, acc 0.90625\n",
      "2017-04-03T19:48:56.805455: step 8819, loss 0.307545, acc 0.890625\n",
      "2017-04-03T19:48:57.004766: step 8820, loss 0.262619, acc 0.890625\n",
      "2017-04-03T19:48:57.205927: step 8821, loss 0.548137, acc 0.84375\n",
      "2017-04-03T19:48:57.458315: step 8822, loss 0.48059, acc 0.859375\n",
      "2017-04-03T19:48:57.663132: step 8823, loss 0.326885, acc 0.890625\n",
      "2017-04-03T19:48:57.866571: step 8824, loss 0.359025, acc 0.921875\n",
      "2017-04-03T19:48:58.079514: step 8825, loss 0.323538, acc 0.859375\n",
      "2017-04-03T19:48:58.279953: step 8826, loss 0.217289, acc 0.921875\n",
      "2017-04-03T19:48:58.475513: step 8827, loss 0.255315, acc 0.90625\n",
      "2017-04-03T19:48:58.679576: step 8828, loss 0.240478, acc 0.90625\n",
      "2017-04-03T19:48:58.879973: step 8829, loss 0.172947, acc 0.953125\n",
      "2017-04-03T19:48:59.083541: step 8830, loss 0.308007, acc 0.84375\n",
      "2017-04-03T19:48:59.284038: step 8831, loss 0.359557, acc 0.90625\n",
      "2017-04-03T19:48:59.491754: step 8832, loss 0.347802, acc 0.859375\n",
      "2017-04-03T19:48:59.692118: step 8833, loss 0.368696, acc 0.84375\n",
      "2017-04-03T19:48:59.893865: step 8834, loss 0.342343, acc 0.859375\n",
      "2017-04-03T19:49:00.137154: step 8835, loss 0.343598, acc 0.90625\n",
      "2017-04-03T19:49:00.345475: step 8836, loss 0.446893, acc 0.890625\n",
      "2017-04-03T19:49:00.545182: step 8837, loss 0.250203, acc 0.890625\n",
      "2017-04-03T19:49:00.762989: step 8838, loss 0.381314, acc 0.90625\n",
      "2017-04-03T19:49:00.978333: step 8839, loss 0.364119, acc 0.921875\n",
      "2017-04-03T19:49:01.193637: step 8840, loss 0.370133, acc 0.875\n",
      "2017-04-03T19:49:01.411778: step 8841, loss 0.289428, acc 0.90625\n",
      "2017-04-03T19:49:01.627491: step 8842, loss 0.367706, acc 0.9375\n",
      "2017-04-03T19:49:01.875352: step 8843, loss 0.358474, acc 0.875\n",
      "2017-04-03T19:49:02.082157: step 8844, loss 0.257694, acc 0.921875\n",
      "2017-04-03T19:49:02.285472: step 8845, loss 0.328837, acc 0.921875\n",
      "2017-04-03T19:49:02.536171: step 8846, loss 0.269991, acc 0.90625\n",
      "2017-04-03T19:49:02.745724: step 8847, loss 0.322624, acc 0.921875\n",
      "2017-04-03T19:49:02.946124: step 8848, loss 0.306523, acc 0.859375\n",
      "2017-04-03T19:49:03.149142: step 8849, loss 0.234173, acc 0.90625\n",
      "2017-04-03T19:49:03.349419: step 8850, loss 0.397039, acc 0.90625\n",
      "2017-04-03T19:49:03.552404: step 8851, loss 0.316145, acc 0.9375\n",
      "2017-04-03T19:49:03.756898: step 8852, loss 0.217364, acc 0.953125\n",
      "2017-04-03T19:49:03.960903: step 8853, loss 0.307025, acc 0.9375\n",
      "2017-04-03T19:49:04.171240: step 8854, loss 0.421649, acc 0.875\n",
      "2017-04-03T19:49:04.371706: step 8855, loss 0.329436, acc 0.90625\n",
      "2017-04-03T19:49:04.571682: step 8856, loss 0.232388, acc 0.953125\n",
      "2017-04-03T19:49:04.777097: step 8857, loss 0.453921, acc 0.84375\n",
      "2017-04-03T19:49:04.976015: step 8858, loss 0.310241, acc 0.9375\n",
      "2017-04-03T19:49:05.181108: step 8859, loss 0.349548, acc 0.875\n",
      "2017-04-03T19:49:05.387051: step 8860, loss 0.481536, acc 0.765625\n",
      "2017-04-03T19:49:05.587910: step 8861, loss 0.288726, acc 0.90625\n",
      "2017-04-03T19:49:05.790939: step 8862, loss 0.26369, acc 0.921875\n",
      "2017-04-03T19:49:05.989242: step 8863, loss 0.235216, acc 0.921875\n",
      "2017-04-03T19:49:06.191430: step 8864, loss 0.270641, acc 0.921875\n",
      "2017-04-03T19:49:06.394230: step 8865, loss 0.438567, acc 0.859375\n",
      "2017-04-03T19:49:06.596813: step 8866, loss 0.248609, acc 0.90625\n",
      "2017-04-03T19:49:06.801773: step 8867, loss 0.24492, acc 0.921875\n",
      "2017-04-03T19:49:07.004806: step 8868, loss 0.404437, acc 0.90625\n",
      "2017-04-03T19:49:07.221042: step 8869, loss 0.27301, acc 0.953125\n",
      "2017-04-03T19:49:07.425644: step 8870, loss 0.418284, acc 0.84375\n",
      "2017-04-03T19:49:07.662414: step 8871, loss 0.331827, acc 0.890625\n",
      "2017-04-03T19:49:07.868112: step 8872, loss 0.257762, acc 0.921875\n",
      "2017-04-03T19:49:08.076410: step 8873, loss 0.556325, acc 0.84375\n",
      "2017-04-03T19:49:08.274956: step 8874, loss 0.428764, acc 0.875\n",
      "2017-04-03T19:49:08.480633: step 8875, loss 0.314998, acc 0.859375\n",
      "2017-04-03T19:49:08.689957: step 8876, loss 0.391467, acc 0.84375\n",
      "2017-04-03T19:49:08.900682: step 8877, loss 0.3104, acc 0.875\n",
      "2017-04-03T19:49:09.100124: step 8878, loss 0.241892, acc 0.921875\n",
      "2017-04-03T19:49:09.303567: step 8879, loss 0.226681, acc 0.890625\n",
      "2017-04-03T19:49:09.502402: step 8880, loss 0.382508, acc 0.875\n",
      "2017-04-03T19:49:09.705452: step 8881, loss 0.346187, acc 0.90625\n",
      "2017-04-03T19:49:09.903120: step 8882, loss 0.301152, acc 0.890625\n",
      "2017-04-03T19:49:10.102562: step 8883, loss 0.177997, acc 0.953125\n",
      "2017-04-03T19:49:10.314970: step 8884, loss 0.28156, acc 0.90625\n",
      "2017-04-03T19:49:10.575536: step 8885, loss 0.417429, acc 0.828125\n",
      "2017-04-03T19:49:10.778283: step 8886, loss 0.404896, acc 0.84375\n",
      "2017-04-03T19:49:11.031125: step 8887, loss 0.432743, acc 0.828125\n",
      "2017-04-03T19:49:11.249897: step 8888, loss 0.322529, acc 0.90625\n",
      "2017-04-03T19:49:11.451292: step 8889, loss 0.412209, acc 0.875\n",
      "2017-04-03T19:49:11.661580: step 8890, loss 0.242773, acc 0.90625\n",
      "2017-04-03T19:49:11.863383: step 8891, loss 0.326591, acc 0.890625\n",
      "2017-04-03T19:49:12.066646: step 8892, loss 0.327691, acc 0.921875\n",
      "2017-04-03T19:49:12.268549: step 8893, loss 0.161966, acc 0.984375\n",
      "2017-04-03T19:49:12.474066: step 8894, loss 0.304766, acc 0.9375\n",
      "2017-04-03T19:49:12.719785: step 8895, loss 0.314831, acc 0.90625\n",
      "2017-04-03T19:49:12.920577: step 8896, loss 0.377699, acc 0.875\n",
      "2017-04-03T19:49:13.122650: step 8897, loss 0.348595, acc 0.890625\n",
      "2017-04-03T19:49:13.328036: step 8898, loss 0.348739, acc 0.875\n",
      "2017-04-03T19:49:13.529396: step 8899, loss 0.252903, acc 0.90625\n",
      "2017-04-03T19:49:13.729585: step 8900, loss 0.309079, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:49:15.851443: step 8900, loss 3.78013, acc 0.3125\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-8900\n",
      "\n",
      "2017-04-03T19:49:16.191552: step 8901, loss 0.271703, acc 0.90625\n",
      "2017-04-03T19:49:16.393248: step 8902, loss 0.274402, acc 0.90625\n",
      "2017-04-03T19:49:16.593987: step 8903, loss 0.134695, acc 0.96875\n",
      "2017-04-03T19:49:16.834793: step 8904, loss 0.191814, acc 0.921875\n",
      "2017-04-03T19:49:17.037638: step 8905, loss 0.246773, acc 0.9375\n",
      "2017-04-03T19:49:17.240791: step 8906, loss 0.313814, acc 0.875\n",
      "2017-04-03T19:49:17.443842: step 8907, loss 0.218546, acc 0.9375\n",
      "2017-04-03T19:49:17.649319: step 8908, loss 0.340163, acc 0.859375\n",
      "2017-04-03T19:49:17.858854: step 8909, loss 0.338213, acc 0.859375\n",
      "2017-04-03T19:49:18.059180: step 8910, loss 0.258651, acc 0.90625\n",
      "2017-04-03T19:49:18.267623: step 8911, loss 0.368645, acc 0.90625\n",
      "2017-04-03T19:49:18.470228: step 8912, loss 0.39267, acc 0.828125\n",
      "2017-04-03T19:49:18.672398: step 8913, loss 0.288243, acc 0.90625\n",
      "2017-04-03T19:49:18.875503: step 8914, loss 0.504456, acc 0.921875\n",
      "2017-04-03T19:49:19.078325: step 8915, loss 0.263933, acc 0.9375\n",
      "2017-04-03T19:49:19.278066: step 8916, loss 0.310331, acc 0.875\n",
      "2017-04-03T19:49:19.487685: step 8917, loss 0.41666, acc 0.875\n",
      "2017-04-03T19:49:19.696858: step 8918, loss 0.283116, acc 0.921875\n",
      "2017-04-03T19:49:19.900862: step 8919, loss 0.311855, acc 0.890625\n",
      "2017-04-03T19:49:20.102014: step 8920, loss 0.242621, acc 0.921875\n",
      "2017-04-03T19:49:20.305354: step 8921, loss 0.428575, acc 0.8125\n",
      "2017-04-03T19:49:20.507791: step 8922, loss 0.253698, acc 0.90625\n",
      "2017-04-03T19:49:20.712406: step 8923, loss 0.346954, acc 0.890625\n",
      "2017-04-03T19:49:20.933090: step 8924, loss 0.34318, acc 0.890625\n",
      "2017-04-03T19:49:21.134002: step 8925, loss 0.264326, acc 0.890625\n",
      "2017-04-03T19:49:21.340850: step 8926, loss 0.344614, acc 0.9375\n",
      "2017-04-03T19:49:21.542155: step 8927, loss 0.23274, acc 0.9375\n",
      "2017-04-03T19:49:21.746929: step 8928, loss 0.209561, acc 0.9375\n",
      "2017-04-03T19:49:21.945194: step 8929, loss 0.250491, acc 0.9375\n",
      "2017-04-03T19:49:22.149250: step 8930, loss 0.300044, acc 0.890625\n",
      "2017-04-03T19:49:22.351993: step 8931, loss 0.258278, acc 0.90625\n",
      "2017-04-03T19:49:22.555435: step 8932, loss 0.275601, acc 0.9375\n",
      "2017-04-03T19:49:22.793162: step 8933, loss 0.299505, acc 0.90625\n",
      "2017-04-03T19:49:22.994771: step 8934, loss 0.3942, acc 0.890625\n",
      "2017-04-03T19:49:23.200065: step 8935, loss 0.220123, acc 0.90625\n",
      "2017-04-03T19:49:23.399602: step 8936, loss 0.447534, acc 0.84375\n",
      "2017-04-03T19:49:23.604696: step 8937, loss 0.36953, acc 0.921875\n",
      "2017-04-03T19:49:23.808534: step 8938, loss 0.473112, acc 0.84375\n",
      "2017-04-03T19:49:24.049632: step 8939, loss 0.428962, acc 0.84375\n",
      "2017-04-03T19:49:24.257721: step 8940, loss 0.156059, acc 0.953125\n",
      "2017-04-03T19:49:24.458543: step 8941, loss 0.387259, acc 0.875\n",
      "2017-04-03T19:49:24.663525: step 8942, loss 0.275007, acc 0.90625\n",
      "2017-04-03T19:49:24.878892: step 8943, loss 0.464296, acc 0.796875\n",
      "2017-04-03T19:49:25.106625: step 8944, loss 0.438308, acc 0.875\n",
      "2017-04-03T19:49:25.366161: step 8945, loss 0.414067, acc 0.84375\n",
      "2017-04-03T19:49:25.568232: step 8946, loss 0.248923, acc 0.9375\n",
      "2017-04-03T19:49:25.775506: step 8947, loss 0.358318, acc 0.875\n",
      "2017-04-03T19:49:25.976323: step 8948, loss 0.226931, acc 0.96875\n",
      "2017-04-03T19:49:26.179749: step 8949, loss 0.184902, acc 0.953125\n",
      "2017-04-03T19:49:26.380245: step 8950, loss 0.406785, acc 0.859375\n",
      "2017-04-03T19:49:26.584354: step 8951, loss 0.312958, acc 0.875\n",
      "2017-04-03T19:49:26.792414: step 8952, loss 0.237034, acc 0.921875\n",
      "2017-04-03T19:49:26.996653: step 8953, loss 0.264326, acc 0.90625\n",
      "2017-04-03T19:49:27.199495: step 8954, loss 0.204777, acc 0.953125\n",
      "2017-04-03T19:49:27.400922: step 8955, loss 0.282818, acc 0.90625\n",
      "2017-04-03T19:49:27.603722: step 8956, loss 0.198615, acc 0.921875\n",
      "2017-04-03T19:49:27.807854: step 8957, loss 0.300021, acc 0.921875\n",
      "2017-04-03T19:49:28.021995: step 8958, loss 0.415613, acc 0.828125\n",
      "2017-04-03T19:49:28.269142: step 8959, loss 0.264277, acc 0.9375\n",
      "2017-04-03T19:49:28.477682: step 8960, loss 0.342835, acc 0.90625\n",
      "2017-04-03T19:49:28.681841: step 8961, loss 0.435604, acc 0.84375\n",
      "2017-04-03T19:49:28.889536: step 8962, loss 0.509037, acc 0.828125\n",
      "2017-04-03T19:49:29.095441: step 8963, loss 0.262968, acc 0.90625\n",
      "2017-04-03T19:49:29.302324: step 8964, loss 0.570462, acc 0.796875\n",
      "2017-04-03T19:49:29.508660: step 8965, loss 0.300829, acc 0.921875\n",
      "2017-04-03T19:49:29.713162: step 8966, loss 0.294019, acc 0.90625\n",
      "2017-04-03T19:49:29.910816: step 8967, loss 0.400417, acc 0.84375\n",
      "2017-04-03T19:49:30.112767: step 8968, loss 0.488573, acc 0.875\n",
      "2017-04-03T19:49:30.319583: step 8969, loss 0.369214, acc 0.890625\n",
      "2017-04-03T19:49:30.520717: step 8970, loss 0.552032, acc 0.890625\n",
      "2017-04-03T19:49:30.720353: step 8971, loss 0.363278, acc 0.90625\n",
      "2017-04-03T19:49:30.926399: step 8972, loss 0.20832, acc 0.953125\n",
      "2017-04-03T19:49:31.138066: step 8973, loss 0.362445, acc 0.859375\n",
      "2017-04-03T19:49:31.339538: step 8974, loss 0.264888, acc 0.921875\n",
      "2017-04-03T19:49:31.540523: step 8975, loss 0.31094, acc 0.890625\n",
      "2017-04-03T19:49:31.740850: step 8976, loss 0.463274, acc 0.78125\n",
      "2017-04-03T19:49:31.949385: step 8977, loss 0.213589, acc 0.9375\n",
      "2017-04-03T19:49:32.149348: step 8978, loss 0.297262, acc 0.9375\n",
      "2017-04-03T19:49:32.350640: step 8979, loss 0.388346, acc 0.859375\n",
      "2017-04-03T19:49:32.552402: step 8980, loss 0.540888, acc 0.796875\n",
      "2017-04-03T19:49:32.798213: step 8981, loss 0.47276, acc 0.859375\n",
      "2017-04-03T19:49:33.012713: step 8982, loss 0.260226, acc 0.921875\n",
      "2017-04-03T19:49:33.217011: step 8983, loss 0.243057, acc 0.9375\n",
      "2017-04-03T19:49:33.425434: step 8984, loss 0.282124, acc 0.9375\n",
      "2017-04-03T19:49:33.626601: step 8985, loss 0.299019, acc 0.890625\n",
      "2017-04-03T19:49:33.826371: step 8986, loss 0.377415, acc 0.859375\n",
      "2017-04-03T19:49:34.026987: step 8987, loss 0.283054, acc 0.875\n",
      "2017-04-03T19:49:34.227437: step 8988, loss 0.534724, acc 0.8125\n",
      "2017-04-03T19:49:34.435277: step 8989, loss 0.325783, acc 0.890625\n",
      "2017-04-03T19:49:34.680548: step 8990, loss 0.435435, acc 0.875\n",
      "2017-04-03T19:49:34.929159: step 8991, loss 0.382222, acc 0.921875\n",
      "2017-04-03T19:49:35.133509: step 8992, loss 0.265479, acc 0.9375\n",
      "2017-04-03T19:49:35.333858: step 8993, loss 0.200146, acc 0.921875\n",
      "2017-04-03T19:49:35.535148: step 8994, loss 0.252712, acc 0.890625\n",
      "2017-04-03T19:49:35.747713: step 8995, loss 0.445015, acc 0.84375\n",
      "2017-04-03T19:49:35.954342: step 8996, loss 0.264053, acc 0.90625\n",
      "2017-04-03T19:49:36.159581: step 8997, loss 0.429844, acc 0.859375\n",
      "2017-04-03T19:49:36.402482: step 8998, loss 0.37394, acc 0.9375\n",
      "2017-04-03T19:49:36.603379: step 8999, loss 0.33039, acc 0.90625\n",
      "2017-04-03T19:49:36.849740: step 9000, loss 0.311778, acc 0.859375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:49:38.887494: step 9000, loss 3.77731, acc 0.30775\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-9000\n",
      "\n",
      "2017-04-03T19:49:39.222388: step 9001, loss 0.495156, acc 0.828125\n",
      "2017-04-03T19:49:39.428638: step 9002, loss 0.322298, acc 0.9375\n",
      "2017-04-03T19:49:39.637577: step 9003, loss 0.236945, acc 0.921875\n",
      "2017-04-03T19:49:39.842354: step 9004, loss 0.470001, acc 0.8125\n",
      "2017-04-03T19:49:40.050517: step 9005, loss 0.358147, acc 0.890625\n",
      "2017-04-03T19:49:40.254769: step 9006, loss 0.284585, acc 0.9375\n",
      "2017-04-03T19:49:40.459842: step 9007, loss 0.42917, acc 0.828125\n",
      "2017-04-03T19:49:40.608473: step 9008, loss 0.192694, acc 0.96875\n",
      "2017-04-03T19:49:40.818892: step 9009, loss 0.196268, acc 0.953125\n",
      "2017-04-03T19:49:41.019175: step 9010, loss 0.150504, acc 0.953125\n",
      "2017-04-03T19:49:41.262270: step 9011, loss 0.19367, acc 0.953125\n",
      "2017-04-03T19:49:41.471026: step 9012, loss 0.266642, acc 0.90625\n",
      "2017-04-03T19:49:41.679827: step 9013, loss 0.144005, acc 0.984375\n",
      "2017-04-03T19:49:41.928399: step 9014, loss 0.27424, acc 0.90625\n",
      "2017-04-03T19:49:42.135144: step 9015, loss 0.41197, acc 0.859375\n",
      "2017-04-03T19:49:42.336582: step 9016, loss 0.131795, acc 0.953125\n",
      "2017-04-03T19:49:42.539532: step 9017, loss 0.323185, acc 0.875\n",
      "2017-04-03T19:49:42.753460: step 9018, loss 0.230146, acc 0.953125\n",
      "2017-04-03T19:49:42.960455: step 9019, loss 0.237058, acc 0.921875\n",
      "2017-04-03T19:49:43.207686: step 9020, loss 0.197755, acc 0.9375\n",
      "2017-04-03T19:49:43.415355: step 9021, loss 0.180064, acc 0.953125\n",
      "2017-04-03T19:49:43.619573: step 9022, loss 0.191021, acc 0.953125\n",
      "2017-04-03T19:49:43.819327: step 9023, loss 0.217955, acc 0.921875\n",
      "2017-04-03T19:49:44.022344: step 9024, loss 0.232553, acc 0.890625\n",
      "2017-04-03T19:49:44.228355: step 9025, loss 0.23319, acc 0.9375\n",
      "2017-04-03T19:49:44.434632: step 9026, loss 0.18571, acc 0.953125\n",
      "2017-04-03T19:49:44.641190: step 9027, loss 0.303903, acc 0.90625\n",
      "2017-04-03T19:49:44.848599: step 9028, loss 0.20203, acc 0.921875\n",
      "2017-04-03T19:49:45.054719: step 9029, loss 0.255723, acc 0.921875\n",
      "2017-04-03T19:49:45.258545: step 9030, loss 0.307771, acc 0.90625\n",
      "2017-04-03T19:49:45.472390: step 9031, loss 0.27139, acc 0.921875\n",
      "2017-04-03T19:49:45.677744: step 9032, loss 0.174817, acc 0.921875\n",
      "2017-04-03T19:49:45.886240: step 9033, loss 0.25267, acc 0.90625\n",
      "2017-04-03T19:49:46.095008: step 9034, loss 0.270885, acc 0.921875\n",
      "2017-04-03T19:49:46.340870: step 9035, loss 0.380666, acc 0.84375\n",
      "2017-04-03T19:49:46.547878: step 9036, loss 0.165285, acc 0.953125\n",
      "2017-04-03T19:49:46.756118: step 9037, loss 0.240287, acc 0.90625\n",
      "2017-04-03T19:49:46.974946: step 9038, loss 0.405173, acc 0.875\n",
      "2017-04-03T19:49:47.174028: step 9039, loss 0.414188, acc 0.8125\n",
      "2017-04-03T19:49:47.384545: step 9040, loss 0.192392, acc 0.921875\n",
      "2017-04-03T19:49:47.593647: step 9041, loss 0.158016, acc 0.9375\n",
      "2017-04-03T19:49:47.800863: step 9042, loss 0.160906, acc 0.953125\n",
      "2017-04-03T19:49:48.009955: step 9043, loss 0.235809, acc 0.9375\n",
      "2017-04-03T19:49:48.217150: step 9044, loss 0.299986, acc 0.875\n",
      "2017-04-03T19:49:48.421082: step 9045, loss 0.250622, acc 0.96875\n",
      "2017-04-03T19:49:48.641652: step 9046, loss 0.19227, acc 0.9375\n",
      "2017-04-03T19:49:48.888351: step 9047, loss 0.163764, acc 0.953125\n",
      "2017-04-03T19:49:49.104454: step 9048, loss 0.357017, acc 0.828125\n",
      "2017-04-03T19:49:49.307488: step 9049, loss 0.24312, acc 0.9375\n",
      "2017-04-03T19:49:49.512741: step 9050, loss 0.163658, acc 0.953125\n",
      "2017-04-03T19:49:49.717688: step 9051, loss 0.284009, acc 0.921875\n",
      "2017-04-03T19:49:49.921661: step 9052, loss 0.249822, acc 0.9375\n",
      "2017-04-03T19:49:50.128560: step 9053, loss 0.310998, acc 0.890625\n",
      "2017-04-03T19:49:50.332943: step 9054, loss 0.408719, acc 0.875\n",
      "2017-04-03T19:49:50.536114: step 9055, loss 0.216812, acc 0.921875\n",
      "2017-04-03T19:49:50.737910: step 9056, loss 0.192907, acc 0.953125\n",
      "2017-04-03T19:49:50.969751: step 9057, loss 0.258753, acc 0.90625\n",
      "2017-04-03T19:49:51.183460: step 9058, loss 0.255115, acc 0.90625\n",
      "2017-04-03T19:49:51.393239: step 9059, loss 0.222074, acc 0.921875\n",
      "2017-04-03T19:49:51.593598: step 9060, loss 0.110941, acc 0.984375\n",
      "2017-04-03T19:49:51.792266: step 9061, loss 0.22484, acc 0.9375\n",
      "2017-04-03T19:49:51.993305: step 9062, loss 0.200929, acc 0.9375\n",
      "2017-04-03T19:49:52.192623: step 9063, loss 0.319301, acc 0.921875\n",
      "2017-04-03T19:49:52.400055: step 9064, loss 0.265841, acc 0.921875\n",
      "2017-04-03T19:49:52.601221: step 9065, loss 0.276171, acc 0.9375\n",
      "2017-04-03T19:49:52.802610: step 9066, loss 0.202524, acc 0.921875\n",
      "2017-04-03T19:49:53.004470: step 9067, loss 0.17992, acc 0.9375\n",
      "2017-04-03T19:49:53.249548: step 9068, loss 0.241813, acc 0.9375\n",
      "2017-04-03T19:49:53.455738: step 9069, loss 0.220211, acc 0.9375\n",
      "2017-04-03T19:49:53.658102: step 9070, loss 0.200219, acc 0.96875\n",
      "2017-04-03T19:49:53.862731: step 9071, loss 0.215533, acc 0.90625\n",
      "2017-04-03T19:49:54.063372: step 9072, loss 0.227347, acc 0.953125\n",
      "2017-04-03T19:49:54.267980: step 9073, loss 0.17928, acc 0.96875\n",
      "2017-04-03T19:49:54.474063: step 9074, loss 0.16723, acc 0.9375\n",
      "2017-04-03T19:49:54.675884: step 9075, loss 0.271439, acc 0.953125\n",
      "2017-04-03T19:49:54.876861: step 9076, loss 0.293002, acc 0.921875\n",
      "2017-04-03T19:49:55.085357: step 9077, loss 0.199272, acc 0.921875\n",
      "2017-04-03T19:49:55.289230: step 9078, loss 0.150477, acc 0.953125\n",
      "2017-04-03T19:49:55.495668: step 9079, loss 0.133864, acc 0.953125\n",
      "2017-04-03T19:49:55.696568: step 9080, loss 0.226735, acc 0.90625\n",
      "2017-04-03T19:49:55.907905: step 9081, loss 0.255378, acc 0.90625\n",
      "2017-04-03T19:49:56.115379: step 9082, loss 0.263934, acc 0.921875\n",
      "2017-04-03T19:49:56.322043: step 9083, loss 0.22346, acc 0.9375\n",
      "2017-04-03T19:49:56.523226: step 9084, loss 0.395931, acc 0.859375\n",
      "2017-04-03T19:49:56.730891: step 9085, loss 0.315767, acc 0.9375\n",
      "2017-04-03T19:49:56.936900: step 9086, loss 0.252939, acc 0.921875\n",
      "2017-04-03T19:49:57.179581: step 9087, loss 0.235849, acc 0.90625\n",
      "2017-04-03T19:49:57.383321: step 9088, loss 0.34654, acc 0.84375\n",
      "2017-04-03T19:49:57.589924: step 9089, loss 0.367133, acc 0.90625\n",
      "2017-04-03T19:49:57.793302: step 9090, loss 0.169714, acc 0.921875\n",
      "2017-04-03T19:49:57.995273: step 9091, loss 0.224214, acc 0.890625\n",
      "2017-04-03T19:49:58.196469: step 9092, loss 0.193997, acc 0.96875\n",
      "2017-04-03T19:49:58.393689: step 9093, loss 0.34025, acc 0.9375\n",
      "2017-04-03T19:49:58.608030: step 9094, loss 0.255844, acc 0.921875\n",
      "2017-04-03T19:49:58.823355: step 9095, loss 0.215885, acc 0.953125\n",
      "2017-04-03T19:49:59.028575: step 9096, loss 0.149869, acc 0.9375\n",
      "2017-04-03T19:49:59.233994: step 9097, loss 0.295784, acc 0.90625\n",
      "2017-04-03T19:49:59.440552: step 9098, loss 0.241436, acc 0.90625\n",
      "2017-04-03T19:49:59.644266: step 9099, loss 0.269185, acc 0.9375\n",
      "2017-04-03T19:49:59.850061: step 9100, loss 0.303885, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:50:01.999078: step 9100, loss 3.88161, acc 0.3045\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-9100\n",
      "\n",
      "2017-04-03T19:50:02.331893: step 9101, loss 0.241432, acc 0.953125\n",
      "2017-04-03T19:50:02.541446: step 9102, loss 0.126691, acc 0.96875\n",
      "2017-04-03T19:50:02.740523: step 9103, loss 0.213984, acc 0.9375\n",
      "2017-04-03T19:50:02.943528: step 9104, loss 0.235972, acc 0.9375\n",
      "2017-04-03T19:50:03.143399: step 9105, loss 0.124326, acc 0.96875\n",
      "2017-04-03T19:50:03.344508: step 9106, loss 0.287057, acc 0.890625\n",
      "2017-04-03T19:50:03.545963: step 9107, loss 0.171505, acc 0.9375\n",
      "2017-04-03T19:50:03.749659: step 9108, loss 0.289658, acc 0.859375\n",
      "2017-04-03T19:50:03.952197: step 9109, loss 0.384745, acc 0.84375\n",
      "2017-04-03T19:50:04.157695: step 9110, loss 0.14183, acc 0.984375\n",
      "2017-04-03T19:50:04.406358: step 9111, loss 0.276535, acc 0.890625\n",
      "2017-04-03T19:50:04.606907: step 9112, loss 0.268511, acc 0.890625\n",
      "2017-04-03T19:50:04.812717: step 9113, loss 0.283253, acc 0.890625\n",
      "2017-04-03T19:50:05.016525: step 9114, loss 0.372344, acc 0.890625\n",
      "2017-04-03T19:50:05.221972: step 9115, loss 0.20271, acc 0.9375\n",
      "2017-04-03T19:50:05.425315: step 9116, loss 0.328196, acc 0.9375\n",
      "2017-04-03T19:50:05.631184: step 9117, loss 0.160076, acc 0.953125\n",
      "2017-04-03T19:50:05.833765: step 9118, loss 0.184773, acc 0.9375\n",
      "2017-04-03T19:50:06.083167: step 9119, loss 0.420763, acc 0.875\n",
      "2017-04-03T19:50:06.282463: step 9120, loss 0.211436, acc 0.953125\n",
      "2017-04-03T19:50:06.497056: step 9121, loss 0.258354, acc 0.890625\n",
      "2017-04-03T19:50:06.702247: step 9122, loss 0.222008, acc 0.90625\n",
      "2017-04-03T19:50:06.908265: step 9123, loss 0.206478, acc 0.9375\n",
      "2017-04-03T19:50:07.124233: step 9124, loss 0.219515, acc 0.96875\n",
      "2017-04-03T19:50:07.327645: step 9125, loss 0.27982, acc 0.921875\n",
      "2017-04-03T19:50:07.532984: step 9126, loss 0.369659, acc 0.921875\n",
      "2017-04-03T19:50:07.735090: step 9127, loss 0.16147, acc 0.953125\n",
      "2017-04-03T19:50:07.950721: step 9128, loss 0.362905, acc 0.875\n",
      "2017-04-03T19:50:08.157359: step 9129, loss 0.185325, acc 0.921875\n",
      "2017-04-03T19:50:08.363693: step 9130, loss 0.443319, acc 0.921875\n",
      "2017-04-03T19:50:08.568580: step 9131, loss 0.275007, acc 0.921875\n",
      "2017-04-03T19:50:08.780907: step 9132, loss 0.259997, acc 0.90625\n",
      "2017-04-03T19:50:08.986640: step 9133, loss 0.22985, acc 0.90625\n",
      "2017-04-03T19:50:09.197308: step 9134, loss 0.387543, acc 0.890625\n",
      "2017-04-03T19:50:09.395575: step 9135, loss 0.170258, acc 0.953125\n",
      "2017-04-03T19:50:09.595542: step 9136, loss 0.176516, acc 0.96875\n",
      "2017-04-03T19:50:09.799384: step 9137, loss 0.369044, acc 0.84375\n",
      "2017-04-03T19:50:10.001349: step 9138, loss 0.207021, acc 0.96875\n",
      "2017-04-03T19:50:10.244986: step 9139, loss 0.41137, acc 0.890625\n",
      "2017-04-03T19:50:10.488783: step 9140, loss 0.343032, acc 0.859375\n",
      "2017-04-03T19:50:10.694561: step 9141, loss 0.167785, acc 0.96875\n",
      "2017-04-03T19:50:10.894601: step 9142, loss 0.212216, acc 0.9375\n",
      "2017-04-03T19:50:11.101902: step 9143, loss 0.16047, acc 0.96875\n",
      "2017-04-03T19:50:11.305494: step 9144, loss 0.378412, acc 0.890625\n",
      "2017-04-03T19:50:11.507489: step 9145, loss 0.219137, acc 0.921875\n",
      "2017-04-03T19:50:11.707897: step 9146, loss 0.27396, acc 0.890625\n",
      "2017-04-03T19:50:11.910412: step 9147, loss 0.360779, acc 0.875\n",
      "2017-04-03T19:50:12.114056: step 9148, loss 0.240681, acc 0.921875\n",
      "2017-04-03T19:50:12.319261: step 9149, loss 0.345375, acc 0.875\n",
      "2017-04-03T19:50:12.522071: step 9150, loss 0.203157, acc 0.921875\n",
      "2017-04-03T19:50:12.765704: step 9151, loss 0.318258, acc 0.890625\n",
      "2017-04-03T19:50:12.967164: step 9152, loss 0.243031, acc 0.890625\n",
      "2017-04-03T19:50:13.173890: step 9153, loss 0.199666, acc 0.96875\n",
      "2017-04-03T19:50:13.376380: step 9154, loss 0.315791, acc 0.890625\n",
      "2017-04-03T19:50:13.581393: step 9155, loss 0.118362, acc 0.984375\n",
      "2017-04-03T19:50:13.798546: step 9156, loss 0.239736, acc 0.921875\n",
      "2017-04-03T19:50:14.001297: step 9157, loss 0.209997, acc 0.9375\n",
      "2017-04-03T19:50:14.205016: step 9158, loss 0.38077, acc 0.859375\n",
      "2017-04-03T19:50:14.411068: step 9159, loss 0.337019, acc 0.9375\n",
      "2017-04-03T19:50:14.660058: step 9160, loss 0.268628, acc 0.90625\n",
      "2017-04-03T19:50:14.866505: step 9161, loss 0.174022, acc 0.921875\n",
      "2017-04-03T19:50:15.117931: step 9162, loss 0.332026, acc 0.875\n",
      "2017-04-03T19:50:15.329401: step 9163, loss 0.212797, acc 0.921875\n",
      "2017-04-03T19:50:15.527845: step 9164, loss 0.239009, acc 0.90625\n",
      "2017-04-03T19:50:15.730883: step 9165, loss 0.137907, acc 0.984375\n",
      "2017-04-03T19:50:15.936609: step 9166, loss 0.179852, acc 0.90625\n",
      "2017-04-03T19:50:16.139641: step 9167, loss 0.168741, acc 0.96875\n",
      "2017-04-03T19:50:16.341826: step 9168, loss 0.16612, acc 0.9375\n",
      "2017-04-03T19:50:16.551835: step 9169, loss 0.352296, acc 0.890625\n",
      "2017-04-03T19:50:16.756439: step 9170, loss 0.180523, acc 0.953125\n",
      "2017-04-03T19:50:16.955206: step 9171, loss 0.321789, acc 0.921875\n",
      "2017-04-03T19:50:17.203159: step 9172, loss 0.195106, acc 0.9375\n",
      "2017-04-03T19:50:17.405051: step 9173, loss 0.242559, acc 0.921875\n",
      "2017-04-03T19:50:17.604903: step 9174, loss 0.154098, acc 0.96875\n",
      "2017-04-03T19:50:17.807678: step 9175, loss 0.26637, acc 0.921875\n",
      "2017-04-03T19:50:18.004800: step 9176, loss 0.173856, acc 0.953125\n",
      "2017-04-03T19:50:18.205348: step 9177, loss 0.267204, acc 0.90625\n",
      "2017-04-03T19:50:18.411873: step 9178, loss 0.17367, acc 0.9375\n",
      "2017-04-03T19:50:18.615534: step 9179, loss 0.238651, acc 0.90625\n",
      "2017-04-03T19:50:18.822983: step 9180, loss 0.394161, acc 0.828125\n",
      "2017-04-03T19:50:19.023526: step 9181, loss 0.278528, acc 0.921875\n",
      "2017-04-03T19:50:19.225839: step 9182, loss 0.13062, acc 0.984375\n",
      "2017-04-03T19:50:19.427673: step 9183, loss 0.26449, acc 0.90625\n",
      "2017-04-03T19:50:19.671894: step 9184, loss 0.141027, acc 0.96875\n",
      "2017-04-03T19:50:19.873424: step 9185, loss 0.435487, acc 0.890625\n",
      "2017-04-03T19:50:20.086012: step 9186, loss 0.197552, acc 0.921875\n",
      "2017-04-03T19:50:20.287005: step 9187, loss 0.430662, acc 0.859375\n",
      "2017-04-03T19:50:20.492099: step 9188, loss 0.152412, acc 0.953125\n",
      "2017-04-03T19:50:20.691868: step 9189, loss 0.223073, acc 0.9375\n",
      "2017-04-03T19:50:20.891058: step 9190, loss 0.20401, acc 0.953125\n",
      "2017-04-03T19:50:21.092865: step 9191, loss 0.304462, acc 0.875\n",
      "2017-04-03T19:50:21.295047: step 9192, loss 0.212793, acc 0.9375\n",
      "2017-04-03T19:50:21.493501: step 9193, loss 0.466967, acc 0.84375\n",
      "2017-04-03T19:50:21.700196: step 9194, loss 0.276194, acc 0.890625\n",
      "2017-04-03T19:50:21.901456: step 9195, loss 0.201875, acc 0.953125\n",
      "2017-04-03T19:50:22.124702: step 9196, loss 0.18249, acc 0.96875\n",
      "2017-04-03T19:50:22.330739: step 9197, loss 0.372309, acc 0.875\n",
      "2017-04-03T19:50:22.533621: step 9198, loss 0.199012, acc 0.96875\n",
      "2017-04-03T19:50:22.740532: step 9199, loss 0.417551, acc 0.84375\n",
      "2017-04-03T19:50:22.955465: step 9200, loss 0.21093, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:50:25.112814: step 9200, loss 3.96939, acc 0.301\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-9200\n",
      "\n",
      "2017-04-03T19:50:25.451345: step 9201, loss 0.361994, acc 0.875\n",
      "2017-04-03T19:50:25.655207: step 9202, loss 0.230443, acc 0.90625\n",
      "2017-04-03T19:50:25.899374: step 9203, loss 0.149347, acc 0.9375\n",
      "2017-04-03T19:50:26.148958: step 9204, loss 0.278865, acc 0.90625\n",
      "2017-04-03T19:50:26.357151: step 9205, loss 0.439159, acc 0.90625\n",
      "2017-04-03T19:50:26.558177: step 9206, loss 0.243245, acc 0.953125\n",
      "2017-04-03T19:50:26.763042: step 9207, loss 0.168127, acc 0.9375\n",
      "2017-04-03T19:50:26.965102: step 9208, loss 0.293372, acc 0.921875\n",
      "2017-04-03T19:50:27.211088: step 9209, loss 0.182134, acc 0.953125\n",
      "2017-04-03T19:50:27.415466: step 9210, loss 0.20103, acc 0.921875\n",
      "2017-04-03T19:50:27.619756: step 9211, loss 0.341526, acc 0.859375\n",
      "2017-04-03T19:50:27.824970: step 9212, loss 0.63944, acc 0.828125\n",
      "2017-04-03T19:50:28.029278: step 9213, loss 0.206825, acc 0.953125\n",
      "2017-04-03T19:50:28.233027: step 9214, loss 0.296266, acc 0.921875\n",
      "2017-04-03T19:50:28.438576: step 9215, loss 0.425094, acc 0.875\n",
      "2017-04-03T19:50:28.638175: step 9216, loss 0.170207, acc 0.953125\n",
      "2017-04-03T19:50:28.838685: step 9217, loss 0.327685, acc 0.890625\n",
      "2017-04-03T19:50:29.042563: step 9218, loss 0.200638, acc 0.9375\n",
      "2017-04-03T19:50:29.241423: step 9219, loss 0.237479, acc 0.953125\n",
      "2017-04-03T19:50:29.443996: step 9220, loss 0.216619, acc 0.921875\n",
      "2017-04-03T19:50:29.656387: step 9221, loss 0.201383, acc 0.9375\n",
      "2017-04-03T19:50:29.864766: step 9222, loss 0.241463, acc 0.90625\n",
      "2017-04-03T19:50:30.121318: step 9223, loss 0.35526, acc 0.859375\n",
      "2017-04-03T19:50:30.324218: step 9224, loss 0.149779, acc 0.96875\n",
      "2017-04-03T19:50:30.531489: step 9225, loss 0.230873, acc 0.9375\n",
      "2017-04-03T19:50:30.749028: step 9226, loss 0.222435, acc 0.890625\n",
      "2017-04-03T19:50:30.957003: step 9227, loss 0.261939, acc 0.890625\n",
      "2017-04-03T19:50:31.157274: step 9228, loss 0.191279, acc 0.9375\n",
      "2017-04-03T19:50:31.359181: step 9229, loss 0.500623, acc 0.828125\n",
      "2017-04-03T19:50:31.561798: step 9230, loss 0.197933, acc 0.921875\n",
      "2017-04-03T19:50:31.765187: step 9231, loss 0.146889, acc 0.953125\n",
      "2017-04-03T19:50:31.964822: step 9232, loss 0.319563, acc 0.875\n",
      "2017-04-03T19:50:32.179355: step 9233, loss 0.40729, acc 0.84375\n",
      "2017-04-03T19:50:32.380477: step 9234, loss 0.196577, acc 0.953125\n",
      "2017-04-03T19:50:32.598048: step 9235, loss 0.221312, acc 0.890625\n",
      "2017-04-03T19:50:32.808206: step 9236, loss 0.254003, acc 0.9375\n",
      "2017-04-03T19:50:33.020887: step 9237, loss 0.511351, acc 0.8125\n",
      "2017-04-03T19:50:33.222445: step 9238, loss 0.165743, acc 0.9375\n",
      "2017-04-03T19:50:33.425570: step 9239, loss 0.272308, acc 0.90625\n",
      "2017-04-03T19:50:33.629453: step 9240, loss 0.235456, acc 0.9375\n",
      "2017-04-03T19:50:33.834920: step 9241, loss 0.19898, acc 0.953125\n",
      "2017-04-03T19:50:34.038068: step 9242, loss 0.314052, acc 0.875\n",
      "2017-04-03T19:50:34.238361: step 9243, loss 0.391551, acc 0.828125\n",
      "2017-04-03T19:50:34.438960: step 9244, loss 0.53662, acc 0.828125\n",
      "2017-04-03T19:50:34.643288: step 9245, loss 0.283394, acc 0.921875\n",
      "2017-04-03T19:50:34.851339: step 9246, loss 0.228984, acc 0.90625\n",
      "2017-04-03T19:50:35.056253: step 9247, loss 0.19965, acc 0.9375\n",
      "2017-04-03T19:50:35.259367: step 9248, loss 0.401991, acc 0.828125\n",
      "2017-04-03T19:50:35.462803: step 9249, loss 0.307046, acc 0.90625\n",
      "2017-04-03T19:50:35.681041: step 9250, loss 0.215636, acc 0.921875\n",
      "2017-04-03T19:50:35.889170: step 9251, loss 0.323513, acc 0.921875\n",
      "2017-04-03T19:50:36.100514: step 9252, loss 0.192085, acc 0.96875\n",
      "2017-04-03T19:50:36.304716: step 9253, loss 0.225195, acc 0.9375\n",
      "2017-04-03T19:50:36.503429: step 9254, loss 0.159945, acc 0.96875\n",
      "2017-04-03T19:50:36.751480: step 9255, loss 0.288474, acc 0.90625\n",
      "2017-04-03T19:50:36.957447: step 9256, loss 0.279734, acc 0.84375\n",
      "2017-04-03T19:50:37.158930: step 9257, loss 0.275992, acc 0.921875\n",
      "2017-04-03T19:50:37.358223: step 9258, loss 0.389958, acc 0.90625\n",
      "2017-04-03T19:50:37.566094: step 9259, loss 0.248632, acc 0.9375\n",
      "2017-04-03T19:50:37.768138: step 9260, loss 0.331514, acc 0.875\n",
      "2017-04-03T19:50:38.016526: step 9261, loss 0.325422, acc 0.890625\n",
      "2017-04-03T19:50:38.221729: step 9262, loss 0.394999, acc 0.84375\n",
      "2017-04-03T19:50:38.429472: step 9263, loss 0.449052, acc 0.890625\n",
      "2017-04-03T19:50:38.631791: step 9264, loss 0.300089, acc 0.890625\n",
      "2017-04-03T19:50:38.835195: step 9265, loss 0.422995, acc 0.875\n",
      "2017-04-03T19:50:39.036144: step 9266, loss 0.268148, acc 0.921875\n",
      "2017-04-03T19:50:39.272914: step 9267, loss 0.263187, acc 0.921875\n",
      "2017-04-03T19:50:39.480162: step 9268, loss 0.2334, acc 0.890625\n",
      "2017-04-03T19:50:39.681445: step 9269, loss 0.245892, acc 0.875\n",
      "2017-04-03T19:50:39.876259: step 9270, loss 0.267379, acc 0.890625\n",
      "2017-04-03T19:50:40.074595: step 9271, loss 0.13363, acc 0.96875\n",
      "2017-04-03T19:50:40.269429: step 9272, loss 0.29232, acc 0.890625\n",
      "2017-04-03T19:50:40.473079: step 9273, loss 0.321256, acc 0.9375\n",
      "2017-04-03T19:50:40.676357: step 9274, loss 0.192859, acc 0.9375\n",
      "2017-04-03T19:50:40.880638: step 9275, loss 0.236386, acc 0.921875\n",
      "2017-04-03T19:50:41.083031: step 9276, loss 0.203098, acc 0.921875\n",
      "2017-04-03T19:50:41.282787: step 9277, loss 0.257324, acc 0.90625\n",
      "2017-04-03T19:50:41.493036: step 9278, loss 0.312579, acc 0.890625\n",
      "2017-04-03T19:50:41.736122: step 9279, loss 0.482481, acc 0.765625\n",
      "2017-04-03T19:50:41.939626: step 9280, loss 0.26281, acc 0.890625\n",
      "2017-04-03T19:50:42.143021: step 9281, loss 0.414976, acc 0.828125\n",
      "2017-04-03T19:50:42.386288: step 9282, loss 0.329126, acc 0.828125\n",
      "2017-04-03T19:50:42.588589: step 9283, loss 0.293138, acc 0.921875\n",
      "2017-04-03T19:50:42.795711: step 9284, loss 0.219453, acc 0.9375\n",
      "2017-04-03T19:50:42.994809: step 9285, loss 0.526278, acc 0.796875\n",
      "2017-04-03T19:50:43.240991: step 9286, loss 0.25797, acc 0.921875\n",
      "2017-04-03T19:50:43.484965: step 9287, loss 0.292616, acc 0.890625\n",
      "2017-04-03T19:50:43.688506: step 9288, loss 0.228273, acc 0.9375\n",
      "2017-04-03T19:50:43.930312: step 9289, loss 0.244793, acc 0.90625\n",
      "2017-04-03T19:50:44.134849: step 9290, loss 0.38914, acc 0.875\n",
      "2017-04-03T19:50:44.333715: step 9291, loss 0.386199, acc 0.828125\n",
      "2017-04-03T19:50:44.575699: step 9292, loss 0.29316, acc 0.84375\n",
      "2017-04-03T19:50:44.777395: step 9293, loss 0.205746, acc 0.9375\n",
      "2017-04-03T19:50:45.018340: step 9294, loss 0.242303, acc 0.921875\n",
      "2017-04-03T19:50:45.226201: step 9295, loss 0.252834, acc 0.9375\n",
      "2017-04-03T19:50:45.443945: step 9296, loss 0.322381, acc 0.875\n",
      "2017-04-03T19:50:45.645239: step 9297, loss 0.161668, acc 0.96875\n",
      "2017-04-03T19:50:45.851670: step 9298, loss 0.22354, acc 0.90625\n",
      "2017-04-03T19:50:46.052384: step 9299, loss 0.242194, acc 0.90625\n",
      "2017-04-03T19:50:46.260692: step 9300, loss 0.159641, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:50:48.380523: step 9300, loss 3.9513, acc 0.3005\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-9300\n",
      "\n",
      "2017-04-03T19:50:48.708512: step 9301, loss 0.249077, acc 0.9375\n",
      "2017-04-03T19:50:48.919966: step 9302, loss 0.312912, acc 0.921875\n",
      "2017-04-03T19:50:49.130711: step 9303, loss 0.293189, acc 0.90625\n",
      "2017-04-03T19:50:49.330942: step 9304, loss 0.255233, acc 0.921875\n",
      "2017-04-03T19:50:49.534898: step 9305, loss 0.306054, acc 0.875\n",
      "2017-04-03T19:50:49.739475: step 9306, loss 0.126928, acc 0.984375\n",
      "2017-04-03T19:50:49.940755: step 9307, loss 0.260345, acc 0.90625\n",
      "2017-04-03T19:50:50.142720: step 9308, loss 0.360369, acc 0.875\n",
      "2017-04-03T19:50:50.347383: step 9309, loss 0.302791, acc 0.90625\n",
      "2017-04-03T19:50:50.550872: step 9310, loss 0.373225, acc 0.90625\n",
      "2017-04-03T19:50:50.757067: step 9311, loss 0.183761, acc 0.9375\n",
      "2017-04-03T19:50:50.976740: step 9312, loss 0.173001, acc 0.96875\n",
      "2017-04-03T19:50:51.186160: step 9313, loss 0.199183, acc 0.9375\n",
      "2017-04-03T19:50:51.385024: step 9314, loss 0.189942, acc 0.9375\n",
      "2017-04-03T19:50:51.592153: step 9315, loss 0.224319, acc 0.9375\n",
      "2017-04-03T19:50:51.795384: step 9316, loss 0.234733, acc 0.9375\n",
      "2017-04-03T19:50:51.997205: step 9317, loss 0.150638, acc 0.953125\n",
      "2017-04-03T19:50:52.239181: step 9318, loss 0.296229, acc 0.90625\n",
      "2017-04-03T19:50:52.441875: step 9319, loss 0.378035, acc 0.953125\n",
      "2017-04-03T19:50:52.640954: step 9320, loss 0.244583, acc 0.9375\n",
      "2017-04-03T19:50:52.848472: step 9321, loss 0.381657, acc 0.890625\n",
      "2017-04-03T19:50:53.047544: step 9322, loss 0.23822, acc 0.9375\n",
      "2017-04-03T19:50:53.250363: step 9323, loss 0.327992, acc 0.859375\n",
      "2017-04-03T19:50:53.445963: step 9324, loss 0.484607, acc 0.859375\n",
      "2017-04-03T19:50:53.647540: step 9325, loss 0.206694, acc 0.9375\n",
      "2017-04-03T19:50:53.851474: step 9326, loss 0.170899, acc 0.96875\n",
      "2017-04-03T19:50:54.051136: step 9327, loss 0.225788, acc 0.90625\n",
      "2017-04-03T19:50:54.297491: step 9328, loss 0.164887, acc 0.953125\n",
      "2017-04-03T19:50:54.509154: step 9329, loss 0.417353, acc 0.828125\n",
      "2017-04-03T19:50:54.709224: step 9330, loss 0.331081, acc 0.84375\n",
      "2017-04-03T19:50:54.908866: step 9331, loss 0.415612, acc 0.84375\n",
      "2017-04-03T19:50:55.107786: step 9332, loss 0.203056, acc 0.96875\n",
      "2017-04-03T19:50:55.311040: step 9333, loss 0.173274, acc 0.96875\n",
      "2017-04-03T19:50:55.516885: step 9334, loss 0.224896, acc 0.9375\n",
      "2017-04-03T19:50:55.759400: step 9335, loss 0.462485, acc 0.859375\n",
      "2017-04-03T19:50:55.962431: step 9336, loss 0.252718, acc 0.9375\n",
      "2017-04-03T19:50:56.161415: step 9337, loss 0.24821, acc 0.90625\n",
      "2017-04-03T19:50:56.363123: step 9338, loss 0.26093, acc 0.90625\n",
      "2017-04-03T19:50:56.562380: step 9339, loss 0.388631, acc 0.859375\n",
      "2017-04-03T19:50:56.767623: step 9340, loss 0.32733, acc 0.90625\n",
      "2017-04-03T19:50:56.970932: step 9341, loss 0.368916, acc 0.90625\n",
      "2017-04-03T19:50:57.173052: step 9342, loss 0.259894, acc 0.96875\n",
      "2017-04-03T19:50:57.371066: step 9343, loss 0.265177, acc 0.953125\n",
      "2017-04-03T19:50:57.616925: step 9344, loss 0.233823, acc 0.921875\n",
      "2017-04-03T19:50:57.831073: step 9345, loss 0.300042, acc 0.890625\n",
      "2017-04-03T19:50:58.041655: step 9346, loss 0.394759, acc 0.875\n",
      "2017-04-03T19:50:58.239197: step 9347, loss 0.360227, acc 0.890625\n",
      "2017-04-03T19:50:58.442369: step 9348, loss 0.239174, acc 0.9375\n",
      "2017-04-03T19:50:58.644013: step 9349, loss 0.270322, acc 0.921875\n",
      "2017-04-03T19:50:58.846315: step 9350, loss 0.333318, acc 0.890625\n",
      "2017-04-03T19:50:59.047377: step 9351, loss 0.224543, acc 0.953125\n",
      "2017-04-03T19:50:59.250514: step 9352, loss 0.328566, acc 0.890625\n",
      "2017-04-03T19:50:59.451044: step 9353, loss 0.209986, acc 0.921875\n",
      "2017-04-03T19:50:59.665583: step 9354, loss 0.295934, acc 0.90625\n",
      "2017-04-03T19:50:59.865208: step 9355, loss 0.21606, acc 0.921875\n",
      "2017-04-03T19:51:00.069015: step 9356, loss 0.185878, acc 0.9375\n",
      "2017-04-03T19:51:00.272829: step 9357, loss 0.280574, acc 0.9375\n",
      "2017-04-03T19:51:00.472925: step 9358, loss 0.23003, acc 0.921875\n",
      "2017-04-03T19:51:00.672376: step 9359, loss 0.258201, acc 0.90625\n",
      "2017-04-03T19:51:00.876562: step 9360, loss 0.227373, acc 0.921875\n",
      "2017-04-03T19:51:01.079974: step 9361, loss 0.12341, acc 0.96875\n",
      "2017-04-03T19:51:01.287305: step 9362, loss 0.348414, acc 0.890625\n",
      "2017-04-03T19:51:01.490219: step 9363, loss 0.280699, acc 0.875\n",
      "2017-04-03T19:51:01.689221: step 9364, loss 0.359997, acc 0.90625\n",
      "2017-04-03T19:51:01.932618: step 9365, loss 0.196372, acc 0.921875\n",
      "2017-04-03T19:51:02.149117: step 9366, loss 0.38291, acc 0.859375\n",
      "2017-04-03T19:51:02.369300: step 9367, loss 0.248161, acc 0.9375\n",
      "2017-04-03T19:51:02.582080: step 9368, loss 0.192003, acc 0.953125\n",
      "2017-04-03T19:51:02.777956: step 9369, loss 0.201483, acc 0.953125\n",
      "2017-04-03T19:51:02.980216: step 9370, loss 0.150354, acc 0.9375\n",
      "2017-04-03T19:51:03.182695: step 9371, loss 0.407633, acc 0.9375\n",
      "2017-04-03T19:51:03.386839: step 9372, loss 0.226242, acc 0.921875\n",
      "2017-04-03T19:51:03.587364: step 9373, loss 0.249936, acc 0.921875\n",
      "2017-04-03T19:51:03.796956: step 9374, loss 0.210223, acc 0.9375\n",
      "2017-04-03T19:51:03.994721: step 9375, loss 0.242961, acc 0.921875\n",
      "2017-04-03T19:51:04.199240: step 9376, loss 0.229744, acc 0.953125\n",
      "2017-04-03T19:51:04.403158: step 9377, loss 0.346018, acc 0.890625\n",
      "2017-04-03T19:51:04.607394: step 9378, loss 0.356629, acc 0.9375\n",
      "2017-04-03T19:51:04.807393: step 9379, loss 0.26571, acc 0.921875\n",
      "2017-04-03T19:51:05.007796: step 9380, loss 0.183822, acc 0.953125\n",
      "2017-04-03T19:51:05.212801: step 9381, loss 0.233507, acc 0.953125\n",
      "2017-04-03T19:51:05.416510: step 9382, loss 0.213385, acc 0.921875\n",
      "2017-04-03T19:51:05.616819: step 9383, loss 0.402861, acc 0.90625\n",
      "2017-04-03T19:51:05.817934: step 9384, loss 0.485487, acc 0.828125\n",
      "2017-04-03T19:51:06.031188: step 9385, loss 0.184702, acc 0.96875\n",
      "2017-04-03T19:51:06.229437: step 9386, loss 0.254592, acc 0.875\n",
      "2017-04-03T19:51:06.430569: step 9387, loss 0.313311, acc 0.9375\n",
      "2017-04-03T19:51:06.633387: step 9388, loss 0.18076, acc 0.953125\n",
      "2017-04-03T19:51:06.836659: step 9389, loss 0.152688, acc 0.96875\n",
      "2017-04-03T19:51:07.044209: step 9390, loss 0.247448, acc 0.90625\n",
      "2017-04-03T19:51:07.246938: step 9391, loss 0.150623, acc 0.953125\n",
      "2017-04-03T19:51:07.447959: step 9392, loss 0.211222, acc 0.9375\n",
      "2017-04-03T19:51:07.647801: step 9393, loss 0.329467, acc 0.90625\n",
      "2017-04-03T19:51:07.890831: step 9394, loss 0.176952, acc 0.9375\n",
      "2017-04-03T19:51:08.095845: step 9395, loss 0.214727, acc 0.9375\n",
      "2017-04-03T19:51:08.302714: step 9396, loss 0.275252, acc 0.9375\n",
      "2017-04-03T19:51:08.502964: step 9397, loss 0.469099, acc 0.828125\n",
      "2017-04-03T19:51:08.701314: step 9398, loss 0.270872, acc 0.921875\n",
      "2017-04-03T19:51:08.902559: step 9399, loss 0.350296, acc 0.890625\n",
      "2017-04-03T19:51:09.112667: step 9400, loss 0.324266, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:51:11.259086: step 9400, loss 4.00341, acc 0.3055\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-9400\n",
      "\n",
      "2017-04-03T19:51:11.596304: step 9401, loss 0.330333, acc 0.875\n",
      "2017-04-03T19:51:11.802012: step 9402, loss 0.287426, acc 0.875\n",
      "2017-04-03T19:51:12.003226: step 9403, loss 0.27881, acc 0.890625\n",
      "2017-04-03T19:51:12.209891: step 9404, loss 0.127473, acc 0.984375\n",
      "2017-04-03T19:51:12.411952: step 9405, loss 0.204606, acc 0.9375\n",
      "2017-04-03T19:51:12.611586: step 9406, loss 0.342904, acc 0.890625\n",
      "2017-04-03T19:51:12.816668: step 9407, loss 0.298927, acc 0.859375\n",
      "2017-04-03T19:51:13.015629: step 9408, loss 0.255248, acc 0.921875\n",
      "2017-04-03T19:51:13.215559: step 9409, loss 0.296731, acc 0.890625\n",
      "2017-04-03T19:51:13.420238: step 9410, loss 0.421006, acc 0.859375\n",
      "2017-04-03T19:51:13.635134: step 9411, loss 0.237356, acc 0.90625\n",
      "2017-04-03T19:51:13.843812: step 9412, loss 0.356669, acc 0.859375\n",
      "2017-04-03T19:51:14.061761: step 9413, loss 0.303805, acc 0.90625\n",
      "2017-04-03T19:51:14.268787: step 9414, loss 0.173054, acc 0.953125\n",
      "2017-04-03T19:51:14.511495: step 9415, loss 0.270469, acc 0.9375\n",
      "2017-04-03T19:51:14.718286: step 9416, loss 0.184808, acc 0.953125\n",
      "2017-04-03T19:51:14.934259: step 9417, loss 0.230234, acc 0.921875\n",
      "2017-04-03T19:51:15.140859: step 9418, loss 0.323739, acc 0.921875\n",
      "2017-04-03T19:51:15.343893: step 9419, loss 0.427313, acc 0.84375\n",
      "2017-04-03T19:51:15.542922: step 9420, loss 0.258628, acc 0.921875\n",
      "2017-04-03T19:51:15.745657: step 9421, loss 0.244384, acc 0.921875\n",
      "2017-04-03T19:51:15.954538: step 9422, loss 0.429042, acc 0.859375\n",
      "2017-04-03T19:51:16.155961: step 9423, loss 0.334805, acc 0.9375\n",
      "2017-04-03T19:51:16.356186: step 9424, loss 0.230639, acc 0.953125\n",
      "2017-04-03T19:51:16.560671: step 9425, loss 0.242816, acc 0.890625\n",
      "2017-04-03T19:51:16.764242: step 9426, loss 0.434709, acc 0.828125\n",
      "2017-04-03T19:51:16.964380: step 9427, loss 0.24515, acc 0.875\n",
      "2017-04-03T19:51:17.173963: step 9428, loss 0.367786, acc 0.859375\n",
      "2017-04-03T19:51:17.378385: step 9429, loss 0.276756, acc 0.890625\n",
      "2017-04-03T19:51:17.579211: step 9430, loss 0.201109, acc 0.9375\n",
      "2017-04-03T19:51:17.783785: step 9431, loss 0.322077, acc 0.890625\n",
      "2017-04-03T19:51:17.983223: step 9432, loss 0.386846, acc 0.890625\n",
      "2017-04-03T19:51:18.183033: step 9433, loss 0.473743, acc 0.84375\n",
      "2017-04-03T19:51:18.384782: step 9434, loss 0.142583, acc 0.953125\n",
      "2017-04-03T19:51:18.593964: step 9435, loss 0.596576, acc 0.8125\n",
      "2017-04-03T19:51:18.793917: step 9436, loss 0.408896, acc 0.890625\n",
      "2017-04-03T19:51:18.995670: step 9437, loss 0.146935, acc 0.953125\n",
      "2017-04-03T19:51:19.195472: step 9438, loss 0.30805, acc 0.890625\n",
      "2017-04-03T19:51:19.442677: step 9439, loss 0.452362, acc 0.890625\n",
      "2017-04-03T19:51:19.686202: step 9440, loss 0.461702, acc 0.8125\n",
      "2017-04-03T19:51:19.890117: step 9441, loss 0.476789, acc 0.84375\n",
      "2017-04-03T19:51:20.092330: step 9442, loss 0.214291, acc 0.90625\n",
      "2017-04-03T19:51:20.297358: step 9443, loss 0.28109, acc 0.859375\n",
      "2017-04-03T19:51:20.501037: step 9444, loss 0.227449, acc 0.953125\n",
      "2017-04-03T19:51:20.707677: step 9445, loss 0.38165, acc 0.828125\n",
      "2017-04-03T19:51:20.908534: step 9446, loss 0.201371, acc 0.9375\n",
      "2017-04-03T19:51:21.114989: step 9447, loss 0.177276, acc 0.9375\n",
      "2017-04-03T19:51:21.312052: step 9448, loss 0.358736, acc 0.90625\n",
      "2017-04-03T19:51:21.510428: step 9449, loss 0.321393, acc 0.875\n",
      "2017-04-03T19:51:21.706810: step 9450, loss 0.377379, acc 0.875\n",
      "2017-04-03T19:51:21.928635: step 9451, loss 0.227545, acc 0.921875\n",
      "2017-04-03T19:51:22.129718: step 9452, loss 0.131973, acc 0.984375\n",
      "2017-04-03T19:51:22.341536: step 9453, loss 0.26391, acc 0.953125\n",
      "2017-04-03T19:51:22.592203: step 9454, loss 0.352615, acc 0.890625\n",
      "2017-04-03T19:51:22.794727: step 9455, loss 0.299634, acc 0.859375\n",
      "2017-04-03T19:51:22.998260: step 9456, loss 0.334342, acc 0.828125\n",
      "2017-04-03T19:51:23.201152: step 9457, loss 0.270748, acc 0.921875\n",
      "2017-04-03T19:51:23.402909: step 9458, loss 0.177135, acc 0.921875\n",
      "2017-04-03T19:51:23.604438: step 9459, loss 0.483457, acc 0.875\n",
      "2017-04-03T19:51:23.809508: step 9460, loss 0.329365, acc 0.90625\n",
      "2017-04-03T19:51:24.010900: step 9461, loss 0.318846, acc 0.921875\n",
      "2017-04-03T19:51:24.217204: step 9462, loss 0.348367, acc 0.890625\n",
      "2017-04-03T19:51:24.421065: step 9463, loss 0.41485, acc 0.828125\n",
      "2017-04-03T19:51:24.623699: step 9464, loss 0.295572, acc 0.90625\n",
      "2017-04-03T19:51:24.825248: step 9465, loss 0.14523, acc 0.96875\n",
      "2017-04-03T19:51:25.037038: step 9466, loss 0.312009, acc 0.890625\n",
      "2017-04-03T19:51:25.245750: step 9467, loss 0.283506, acc 0.90625\n",
      "2017-04-03T19:51:25.490565: step 9468, loss 0.239106, acc 0.921875\n",
      "2017-04-03T19:51:25.696725: step 9469, loss 0.308516, acc 0.890625\n",
      "2017-04-03T19:51:25.938861: step 9470, loss 0.40597, acc 0.84375\n",
      "2017-04-03T19:51:26.151182: step 9471, loss 0.452779, acc 0.875\n",
      "2017-04-03T19:51:26.364253: step 9472, loss 0.264605, acc 0.921875\n",
      "2017-04-03T19:51:26.566178: step 9473, loss 0.347492, acc 0.875\n",
      "2017-04-03T19:51:26.772856: step 9474, loss 0.42956, acc 0.84375\n",
      "2017-04-03T19:51:26.978094: step 9475, loss 0.247996, acc 0.90625\n",
      "2017-04-03T19:51:27.188822: step 9476, loss 0.125799, acc 0.953125\n",
      "2017-04-03T19:51:27.393663: step 9477, loss 0.363181, acc 0.890625\n",
      "2017-04-03T19:51:27.635508: step 9478, loss 0.445421, acc 0.890625\n",
      "2017-04-03T19:51:27.839454: step 9479, loss 0.376834, acc 0.84375\n",
      "2017-04-03T19:51:28.041293: step 9480, loss 0.244783, acc 0.96875\n",
      "2017-04-03T19:51:28.247030: step 9481, loss 0.407222, acc 0.875\n",
      "2017-04-03T19:51:28.449908: step 9482, loss 0.396698, acc 0.875\n",
      "2017-04-03T19:51:28.653074: step 9483, loss 0.229639, acc 0.90625\n",
      "2017-04-03T19:51:28.868384: step 9484, loss 0.293431, acc 0.890625\n",
      "2017-04-03T19:51:29.073626: step 9485, loss 0.293662, acc 0.921875\n",
      "2017-04-03T19:51:29.277677: step 9486, loss 0.29685, acc 0.890625\n",
      "2017-04-03T19:51:29.475381: step 9487, loss 0.555792, acc 0.859375\n",
      "2017-04-03T19:51:29.677525: step 9488, loss 0.186942, acc 0.953125\n",
      "2017-04-03T19:51:29.881324: step 9489, loss 0.247529, acc 0.9375\n",
      "2017-04-03T19:51:30.085075: step 9490, loss 0.282708, acc 0.9375\n",
      "2017-04-03T19:51:30.288891: step 9491, loss 0.213878, acc 0.921875\n",
      "2017-04-03T19:51:30.492192: step 9492, loss 0.43361, acc 0.890625\n",
      "2017-04-03T19:51:30.715837: step 9493, loss 0.173498, acc 0.953125\n",
      "2017-04-03T19:51:30.932595: step 9494, loss 0.197469, acc 0.921875\n",
      "2017-04-03T19:51:31.140781: step 9495, loss 0.140205, acc 0.9375\n",
      "2017-04-03T19:51:31.347221: step 9496, loss 0.293322, acc 0.890625\n",
      "2017-04-03T19:51:31.558308: step 9497, loss 0.379347, acc 0.84375\n",
      "2017-04-03T19:51:31.760255: step 9498, loss 0.241343, acc 0.9375\n",
      "2017-04-03T19:51:31.966797: step 9499, loss 0.199846, acc 0.921875\n",
      "2017-04-03T19:51:32.171569: step 9500, loss 0.230478, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:51:34.308553: step 9500, loss 3.99895, acc 0.30675\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-9500\n",
      "\n",
      "2017-04-03T19:51:34.637681: step 9501, loss 0.260648, acc 0.921875\n",
      "2017-04-03T19:51:34.843310: step 9502, loss 0.431925, acc 0.859375\n",
      "2017-04-03T19:51:35.053942: step 9503, loss 0.196573, acc 0.9375\n",
      "2017-04-03T19:51:35.258087: step 9504, loss 0.266807, acc 0.9375\n",
      "2017-04-03T19:51:35.466493: step 9505, loss 0.41905, acc 0.890625\n",
      "2017-04-03T19:51:35.672693: step 9506, loss 0.224677, acc 0.953125\n",
      "2017-04-03T19:51:35.882119: step 9507, loss 0.330812, acc 0.90625\n",
      "2017-04-03T19:51:36.128915: step 9508, loss 0.369844, acc 0.890625\n",
      "2017-04-03T19:51:36.344738: step 9509, loss 0.428145, acc 0.828125\n",
      "2017-04-03T19:51:36.556353: step 9510, loss 0.302655, acc 0.859375\n",
      "2017-04-03T19:51:36.761259: step 9511, loss 0.45324, acc 0.828125\n",
      "2017-04-03T19:51:36.965889: step 9512, loss 0.164664, acc 0.96875\n",
      "2017-04-03T19:51:37.168402: step 9513, loss 0.253364, acc 0.90625\n",
      "2017-04-03T19:51:37.369356: step 9514, loss 0.303509, acc 0.875\n",
      "2017-04-03T19:51:37.569400: step 9515, loss 0.126696, acc 0.96875\n",
      "2017-04-03T19:51:37.774774: step 9516, loss 0.484555, acc 0.796875\n",
      "2017-04-03T19:51:38.022745: step 9517, loss 0.273167, acc 0.921875\n",
      "2017-04-03T19:51:38.233182: step 9518, loss 0.286142, acc 0.90625\n",
      "2017-04-03T19:51:38.430062: step 9519, loss 0.180324, acc 0.953125\n",
      "2017-04-03T19:51:38.640441: step 9520, loss 0.176166, acc 0.96875\n",
      "2017-04-03T19:51:38.890009: step 9521, loss 0.297107, acc 0.921875\n",
      "2017-04-03T19:51:39.098277: step 9522, loss 0.219318, acc 0.9375\n",
      "2017-04-03T19:51:39.303191: step 9523, loss 0.288729, acc 0.875\n",
      "2017-04-03T19:51:39.511059: step 9524, loss 0.37932, acc 0.859375\n",
      "2017-04-03T19:51:39.714290: step 9525, loss 0.169985, acc 0.96875\n",
      "2017-04-03T19:51:39.956929: step 9526, loss 0.155089, acc 0.96875\n",
      "2017-04-03T19:51:40.167759: step 9527, loss 0.20455, acc 0.953125\n",
      "2017-04-03T19:51:40.372689: step 9528, loss 0.247115, acc 0.90625\n",
      "2017-04-03T19:51:40.579177: step 9529, loss 0.550975, acc 0.828125\n",
      "2017-04-03T19:51:40.783143: step 9530, loss 0.318019, acc 0.90625\n",
      "2017-04-03T19:51:40.992005: step 9531, loss 0.43402, acc 0.84375\n",
      "2017-04-03T19:51:41.193999: step 9532, loss 0.317222, acc 0.890625\n",
      "2017-04-03T19:51:41.437730: step 9533, loss 0.120817, acc 0.984375\n",
      "2017-04-03T19:51:41.689272: step 9534, loss 0.1205, acc 0.96875\n",
      "2017-04-03T19:51:41.893634: step 9535, loss 0.283044, acc 0.921875\n",
      "2017-04-03T19:51:42.095897: step 9536, loss 0.406944, acc 0.890625\n",
      "2017-04-03T19:51:42.316580: step 9537, loss 0.303796, acc 0.90625\n",
      "2017-04-03T19:51:42.522099: step 9538, loss 0.362888, acc 0.890625\n",
      "2017-04-03T19:51:42.727933: step 9539, loss 0.367153, acc 0.90625\n",
      "2017-04-03T19:51:42.931368: step 9540, loss 0.426903, acc 0.84375\n",
      "2017-04-03T19:51:43.143581: step 9541, loss 0.375529, acc 0.921875\n",
      "2017-04-03T19:51:43.359191: step 9542, loss 0.213111, acc 0.90625\n",
      "2017-04-03T19:51:43.562772: step 9543, loss 0.281319, acc 0.875\n",
      "2017-04-03T19:51:43.764287: step 9544, loss 0.535729, acc 0.84375\n",
      "2017-04-03T19:51:43.964593: step 9545, loss 0.354965, acc 0.859375\n",
      "2017-04-03T19:51:44.167620: step 9546, loss 0.31048, acc 0.921875\n",
      "2017-04-03T19:51:44.370589: step 9547, loss 0.26203, acc 0.90625\n",
      "2017-04-03T19:51:44.573669: step 9548, loss 0.315915, acc 0.90625\n",
      "2017-04-03T19:51:44.780094: step 9549, loss 0.279062, acc 0.875\n",
      "2017-04-03T19:51:44.981656: step 9550, loss 0.20911, acc 0.921875\n",
      "2017-04-03T19:51:45.184483: step 9551, loss 0.173077, acc 0.9375\n",
      "2017-04-03T19:51:45.389651: step 9552, loss 0.294413, acc 0.875\n",
      "2017-04-03T19:51:45.588921: step 9553, loss 0.296141, acc 0.875\n",
      "2017-04-03T19:51:45.793246: step 9554, loss 0.381895, acc 0.9375\n",
      "2017-04-03T19:51:46.009200: step 9555, loss 0.230521, acc 0.90625\n",
      "2017-04-03T19:51:46.226369: step 9556, loss 0.27894, acc 0.921875\n",
      "2017-04-03T19:51:46.441325: step 9557, loss 0.185004, acc 0.921875\n",
      "2017-04-03T19:51:46.646037: step 9558, loss 0.241628, acc 0.90625\n",
      "2017-04-03T19:51:46.855714: step 9559, loss 0.452928, acc 0.859375\n",
      "2017-04-03T19:51:47.059317: step 9560, loss 0.33235, acc 0.921875\n",
      "2017-04-03T19:51:47.265578: step 9561, loss 0.182594, acc 0.90625\n",
      "2017-04-03T19:51:47.470368: step 9562, loss 0.241259, acc 0.9375\n",
      "2017-04-03T19:51:47.677217: step 9563, loss 0.514063, acc 0.921875\n",
      "2017-04-03T19:51:47.926042: step 9564, loss 0.292708, acc 0.90625\n",
      "2017-04-03T19:51:48.137924: step 9565, loss 0.191689, acc 0.90625\n",
      "2017-04-03T19:51:48.387230: step 9566, loss 0.293196, acc 0.921875\n",
      "2017-04-03T19:51:48.632808: step 9567, loss 0.324909, acc 0.890625\n",
      "2017-04-03T19:51:48.842514: step 9568, loss 0.644208, acc 0.84375\n",
      "2017-04-03T19:51:49.045877: step 9569, loss 0.201722, acc 0.921875\n",
      "2017-04-03T19:51:49.300381: step 9570, loss 0.333097, acc 0.875\n",
      "2017-04-03T19:51:49.449071: step 9571, loss 0.264295, acc 0.9375\n",
      "2017-04-03T19:51:49.661182: step 9572, loss 0.268207, acc 0.90625\n",
      "2017-04-03T19:51:49.866281: step 9573, loss 0.189647, acc 0.953125\n",
      "2017-04-03T19:51:50.066887: step 9574, loss 0.297738, acc 0.890625\n",
      "2017-04-03T19:51:50.296981: step 9575, loss 0.162273, acc 0.953125\n",
      "2017-04-03T19:51:50.511879: step 9576, loss 0.2713, acc 0.90625\n",
      "2017-04-03T19:51:50.759995: step 9577, loss 0.300709, acc 0.921875\n",
      "2017-04-03T19:51:50.963326: step 9578, loss 0.10634, acc 0.96875\n",
      "2017-04-03T19:51:51.168967: step 9579, loss 0.097267, acc 0.96875\n",
      "2017-04-03T19:51:51.378163: step 9580, loss 0.112169, acc 0.96875\n",
      "2017-04-03T19:51:51.586004: step 9581, loss 0.128744, acc 0.953125\n",
      "2017-04-03T19:51:51.789713: step 9582, loss 0.281321, acc 0.890625\n",
      "2017-04-03T19:51:51.999284: step 9583, loss 0.155502, acc 0.953125\n",
      "2017-04-03T19:51:52.208852: step 9584, loss 0.318673, acc 0.890625\n",
      "2017-04-03T19:51:52.453000: step 9585, loss 0.237251, acc 0.9375\n",
      "2017-04-03T19:51:52.698646: step 9586, loss 0.248776, acc 0.9375\n",
      "2017-04-03T19:51:52.907995: step 9587, loss 0.2504, acc 0.953125\n",
      "2017-04-03T19:51:53.112602: step 9588, loss 0.291106, acc 0.90625\n",
      "2017-04-03T19:51:53.320703: step 9589, loss 0.186002, acc 0.953125\n",
      "2017-04-03T19:51:53.527665: step 9590, loss 0.167524, acc 0.9375\n",
      "2017-04-03T19:51:53.734641: step 9591, loss 0.196823, acc 0.921875\n",
      "2017-04-03T19:51:53.939883: step 9592, loss 0.198781, acc 0.921875\n",
      "2017-04-03T19:51:54.147851: step 9593, loss 0.243823, acc 0.921875\n",
      "2017-04-03T19:51:54.352868: step 9594, loss 0.161766, acc 0.953125\n",
      "2017-04-03T19:51:54.604897: step 9595, loss 0.110358, acc 0.96875\n",
      "2017-04-03T19:51:54.814952: step 9596, loss 0.0983522, acc 0.96875\n",
      "2017-04-03T19:51:55.028442: step 9597, loss 0.260553, acc 0.90625\n",
      "2017-04-03T19:51:55.232728: step 9598, loss 0.256426, acc 0.921875\n",
      "2017-04-03T19:51:55.436200: step 9599, loss 0.25149, acc 0.90625\n",
      "2017-04-03T19:51:55.640254: step 9600, loss 0.222312, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:51:57.706185: step 9600, loss 4.03562, acc 0.295\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-9600\n",
      "\n",
      "2017-04-03T19:51:58.084273: step 9601, loss 0.251053, acc 0.9375\n",
      "2017-04-03T19:51:58.289354: step 9602, loss 0.200006, acc 0.96875\n",
      "2017-04-03T19:51:58.496454: step 9603, loss 0.201589, acc 0.9375\n",
      "2017-04-03T19:51:58.700588: step 9604, loss 0.320669, acc 0.890625\n",
      "2017-04-03T19:51:58.903850: step 9605, loss 0.155456, acc 0.96875\n",
      "2017-04-03T19:51:59.104298: step 9606, loss 0.231862, acc 0.9375\n",
      "2017-04-03T19:51:59.348187: step 9607, loss 0.265811, acc 0.9375\n",
      "2017-04-03T19:51:59.556499: step 9608, loss 0.117121, acc 0.984375\n",
      "2017-04-03T19:51:59.764823: step 9609, loss 0.179368, acc 0.953125\n",
      "2017-04-03T19:51:59.970856: step 9610, loss 0.235032, acc 0.921875\n",
      "2017-04-03T19:52:00.177342: step 9611, loss 0.161916, acc 0.96875\n",
      "2017-04-03T19:52:00.384731: step 9612, loss 0.243421, acc 0.921875\n",
      "2017-04-03T19:52:00.594963: step 9613, loss 0.236583, acc 0.921875\n",
      "2017-04-03T19:52:00.803090: step 9614, loss 0.230971, acc 0.921875\n",
      "2017-04-03T19:52:01.004571: step 9615, loss 0.194224, acc 0.953125\n",
      "2017-04-03T19:52:01.209608: step 9616, loss 0.247268, acc 0.875\n",
      "2017-04-03T19:52:01.412261: step 9617, loss 0.179432, acc 0.90625\n",
      "2017-04-03T19:52:01.616776: step 9618, loss 0.167113, acc 0.953125\n",
      "2017-04-03T19:52:01.817848: step 9619, loss 0.213057, acc 0.9375\n",
      "2017-04-03T19:52:02.020988: step 9620, loss 0.237969, acc 0.90625\n",
      "2017-04-03T19:52:02.220152: step 9621, loss 0.158975, acc 0.984375\n",
      "2017-04-03T19:52:02.427115: step 9622, loss 0.188498, acc 0.9375\n",
      "2017-04-03T19:52:02.681194: step 9623, loss 0.112222, acc 0.984375\n",
      "2017-04-03T19:52:02.883562: step 9624, loss 0.262796, acc 0.90625\n",
      "2017-04-03T19:52:03.088104: step 9625, loss 0.210412, acc 0.9375\n",
      "2017-04-03T19:52:03.289518: step 9626, loss 0.372047, acc 0.921875\n",
      "2017-04-03T19:52:03.535255: step 9627, loss 0.221558, acc 0.9375\n",
      "2017-04-03T19:52:03.781502: step 9628, loss 0.184992, acc 0.9375\n",
      "2017-04-03T19:52:04.035350: step 9629, loss 0.114964, acc 0.984375\n",
      "2017-04-03T19:52:04.240074: step 9630, loss 0.152861, acc 0.96875\n",
      "2017-04-03T19:52:04.449663: step 9631, loss 0.700329, acc 0.84375\n",
      "2017-04-03T19:52:04.647638: step 9632, loss 0.173555, acc 0.921875\n",
      "2017-04-03T19:52:04.847888: step 9633, loss 0.226237, acc 0.9375\n",
      "2017-04-03T19:52:05.053921: step 9634, loss 0.209055, acc 0.953125\n",
      "2017-04-03T19:52:05.258736: step 9635, loss 0.231771, acc 0.9375\n",
      "2017-04-03T19:52:05.461426: step 9636, loss 0.110389, acc 0.96875\n",
      "2017-04-03T19:52:05.665443: step 9637, loss 0.262298, acc 0.859375\n",
      "2017-04-03T19:52:05.873327: step 9638, loss 0.157218, acc 0.984375\n",
      "2017-04-03T19:52:06.077161: step 9639, loss 0.260784, acc 0.921875\n",
      "2017-04-03T19:52:06.325060: step 9640, loss 0.207471, acc 0.921875\n",
      "2017-04-03T19:52:06.546812: step 9641, loss 0.189196, acc 0.921875\n",
      "2017-04-03T19:52:06.747849: step 9642, loss 0.317543, acc 0.90625\n",
      "2017-04-03T19:52:06.953297: step 9643, loss 0.207186, acc 0.9375\n",
      "2017-04-03T19:52:07.155410: step 9644, loss 0.175548, acc 0.921875\n",
      "2017-04-03T19:52:07.371235: step 9645, loss 0.152956, acc 0.953125\n",
      "2017-04-03T19:52:07.576940: step 9646, loss 0.242595, acc 0.9375\n",
      "2017-04-03T19:52:07.827456: step 9647, loss 0.151171, acc 0.953125\n",
      "2017-04-03T19:52:08.032632: step 9648, loss 0.284836, acc 0.890625\n",
      "2017-04-03T19:52:08.236149: step 9649, loss 0.179057, acc 0.96875\n",
      "2017-04-03T19:52:08.474647: step 9650, loss 0.29955, acc 0.90625\n",
      "2017-04-03T19:52:08.676632: step 9651, loss 0.258361, acc 0.921875\n",
      "2017-04-03T19:52:08.891015: step 9652, loss 0.281738, acc 0.875\n",
      "2017-04-03T19:52:09.093895: step 9653, loss 0.146632, acc 0.953125\n",
      "2017-04-03T19:52:09.301097: step 9654, loss 0.205591, acc 0.953125\n",
      "2017-04-03T19:52:09.507635: step 9655, loss 0.212058, acc 0.9375\n",
      "2017-04-03T19:52:09.713543: step 9656, loss 0.205344, acc 0.9375\n",
      "2017-04-03T19:52:09.950945: step 9657, loss 0.241828, acc 0.9375\n",
      "2017-04-03T19:52:10.154800: step 9658, loss 0.25049, acc 0.890625\n",
      "2017-04-03T19:52:10.362739: step 9659, loss 0.284751, acc 0.90625\n",
      "2017-04-03T19:52:10.566041: step 9660, loss 0.120019, acc 0.96875\n",
      "2017-04-03T19:52:10.775537: step 9661, loss 0.185354, acc 0.90625\n",
      "2017-04-03T19:52:10.978734: step 9662, loss 0.304681, acc 0.859375\n",
      "2017-04-03T19:52:11.186283: step 9663, loss 0.168244, acc 0.9375\n",
      "2017-04-03T19:52:11.385887: step 9664, loss 0.224124, acc 0.90625\n",
      "2017-04-03T19:52:11.585286: step 9665, loss 0.155758, acc 0.9375\n",
      "2017-04-03T19:52:11.789337: step 9666, loss 0.234236, acc 0.921875\n",
      "2017-04-03T19:52:11.992089: step 9667, loss 0.149973, acc 0.9375\n",
      "2017-04-03T19:52:12.194560: step 9668, loss 0.203191, acc 0.90625\n",
      "2017-04-03T19:52:12.399739: step 9669, loss 0.264587, acc 0.921875\n",
      "2017-04-03T19:52:12.649927: step 9670, loss 0.253095, acc 0.9375\n",
      "2017-04-03T19:52:12.850521: step 9671, loss 0.205608, acc 0.9375\n",
      "2017-04-03T19:52:13.050419: step 9672, loss 0.218839, acc 0.9375\n",
      "2017-04-03T19:52:13.297408: step 9673, loss 0.103693, acc 0.984375\n",
      "2017-04-03T19:52:13.499723: step 9674, loss 0.152935, acc 0.953125\n",
      "2017-04-03T19:52:13.708862: step 9675, loss 0.0765212, acc 0.984375\n",
      "2017-04-03T19:52:13.910372: step 9676, loss 0.374914, acc 0.859375\n",
      "2017-04-03T19:52:14.114363: step 9677, loss 0.198408, acc 0.953125\n",
      "2017-04-03T19:52:14.321503: step 9678, loss 0.223841, acc 0.9375\n",
      "2017-04-03T19:52:14.520606: step 9679, loss 0.196514, acc 0.953125\n",
      "2017-04-03T19:52:14.725403: step 9680, loss 0.241729, acc 0.921875\n",
      "2017-04-03T19:52:14.970162: step 9681, loss 0.220551, acc 0.890625\n",
      "2017-04-03T19:52:15.170266: step 9682, loss 0.29255, acc 0.875\n",
      "2017-04-03T19:52:15.376782: step 9683, loss 0.260198, acc 0.953125\n",
      "2017-04-03T19:52:15.579688: step 9684, loss 0.250534, acc 0.921875\n",
      "2017-04-03T19:52:15.781231: step 9685, loss 0.215716, acc 0.921875\n",
      "2017-04-03T19:52:15.990231: step 9686, loss 0.20717, acc 0.921875\n",
      "2017-04-03T19:52:16.198003: step 9687, loss 0.27494, acc 0.890625\n",
      "2017-04-03T19:52:16.443549: step 9688, loss 0.241998, acc 0.9375\n",
      "2017-04-03T19:52:16.647554: step 9689, loss 0.202273, acc 0.9375\n",
      "2017-04-03T19:52:16.845510: step 9690, loss 0.176488, acc 0.9375\n",
      "2017-04-03T19:52:17.044245: step 9691, loss 0.320198, acc 0.890625\n",
      "2017-04-03T19:52:17.250804: step 9692, loss 0.163833, acc 0.96875\n",
      "2017-04-03T19:52:17.452947: step 9693, loss 0.277862, acc 0.921875\n",
      "2017-04-03T19:52:17.655902: step 9694, loss 0.182317, acc 0.9375\n",
      "2017-04-03T19:52:17.860836: step 9695, loss 0.241708, acc 0.90625\n",
      "2017-04-03T19:52:18.064872: step 9696, loss 0.289367, acc 0.875\n",
      "2017-04-03T19:52:18.265928: step 9697, loss 0.341916, acc 0.9375\n",
      "2017-04-03T19:52:18.464178: step 9698, loss 0.223272, acc 0.96875\n",
      "2017-04-03T19:52:18.672007: step 9699, loss 0.246576, acc 0.9375\n",
      "2017-04-03T19:52:18.875326: step 9700, loss 0.178974, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:52:20.910218: step 9700, loss 4.15084, acc 0.29975\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-9700\n",
      "\n",
      "2017-04-03T19:52:21.235907: step 9701, loss 0.334101, acc 0.9375\n",
      "2017-04-03T19:52:21.448719: step 9702, loss 0.153392, acc 0.953125\n",
      "2017-04-03T19:52:21.661052: step 9703, loss 0.116182, acc 0.96875\n",
      "2017-04-03T19:52:21.862185: step 9704, loss 0.12527, acc 0.96875\n",
      "2017-04-03T19:52:22.064235: step 9705, loss 0.284772, acc 0.859375\n",
      "2017-04-03T19:52:22.265237: step 9706, loss 0.269814, acc 0.953125\n",
      "2017-04-03T19:52:22.472052: step 9707, loss 0.171568, acc 0.9375\n",
      "2017-04-03T19:52:22.719407: step 9708, loss 0.273216, acc 0.921875\n",
      "2017-04-03T19:52:22.937415: step 9709, loss 0.353911, acc 0.890625\n",
      "2017-04-03T19:52:23.139282: step 9710, loss 0.157625, acc 0.9375\n",
      "2017-04-03T19:52:23.342554: step 9711, loss 0.284252, acc 0.90625\n",
      "2017-04-03T19:52:23.547259: step 9712, loss 0.229726, acc 0.90625\n",
      "2017-04-03T19:52:23.749903: step 9713, loss 0.157083, acc 0.984375\n",
      "2017-04-03T19:52:23.995678: step 9714, loss 0.198681, acc 0.9375\n",
      "2017-04-03T19:52:24.202437: step 9715, loss 0.171524, acc 0.953125\n",
      "2017-04-03T19:52:24.406484: step 9716, loss 0.258405, acc 0.90625\n",
      "2017-04-03T19:52:24.605226: step 9717, loss 0.414054, acc 0.859375\n",
      "2017-04-03T19:52:24.813064: step 9718, loss 0.231312, acc 0.90625\n",
      "2017-04-03T19:52:25.010751: step 9719, loss 0.234401, acc 0.9375\n",
      "2017-04-03T19:52:25.212484: step 9720, loss 0.326458, acc 0.90625\n",
      "2017-04-03T19:52:25.415514: step 9721, loss 0.182856, acc 0.9375\n",
      "2017-04-03T19:52:25.655412: step 9722, loss 0.211826, acc 0.921875\n",
      "2017-04-03T19:52:25.902599: step 9723, loss 0.239024, acc 0.9375\n",
      "2017-04-03T19:52:26.101569: step 9724, loss 0.103738, acc 0.984375\n",
      "2017-04-03T19:52:26.346293: step 9725, loss 0.126859, acc 0.953125\n",
      "2017-04-03T19:52:26.597879: step 9726, loss 0.0783497, acc 1\n",
      "2017-04-03T19:52:26.847467: step 9727, loss 0.160063, acc 0.921875\n",
      "2017-04-03T19:52:27.054149: step 9728, loss 0.129084, acc 0.953125\n",
      "2017-04-03T19:52:27.256042: step 9729, loss 0.224695, acc 0.921875\n",
      "2017-04-03T19:52:27.457530: step 9730, loss 0.258385, acc 0.890625\n",
      "2017-04-03T19:52:27.666875: step 9731, loss 0.132695, acc 0.96875\n",
      "2017-04-03T19:52:27.868441: step 9732, loss 0.291457, acc 0.9375\n",
      "2017-04-03T19:52:28.068395: step 9733, loss 0.400905, acc 0.890625\n",
      "2017-04-03T19:52:28.273392: step 9734, loss 0.187408, acc 0.921875\n",
      "2017-04-03T19:52:28.473480: step 9735, loss 0.118402, acc 0.984375\n",
      "2017-04-03T19:52:28.676779: step 9736, loss 0.199304, acc 0.9375\n",
      "2017-04-03T19:52:28.875240: step 9737, loss 0.164811, acc 0.96875\n",
      "2017-04-03T19:52:29.074725: step 9738, loss 0.39694, acc 0.84375\n",
      "2017-04-03T19:52:29.285573: step 9739, loss 0.286147, acc 0.890625\n",
      "2017-04-03T19:52:29.492719: step 9740, loss 0.392533, acc 0.890625\n",
      "2017-04-03T19:52:29.697121: step 9741, loss 0.233224, acc 0.90625\n",
      "2017-04-03T19:52:29.913755: step 9742, loss 0.184071, acc 0.90625\n",
      "2017-04-03T19:52:30.123096: step 9743, loss 0.397135, acc 0.890625\n",
      "2017-04-03T19:52:30.344518: step 9744, loss 0.330085, acc 0.875\n",
      "2017-04-03T19:52:30.545604: step 9745, loss 0.122421, acc 0.96875\n",
      "2017-04-03T19:52:30.749547: step 9746, loss 0.310356, acc 0.875\n",
      "2017-04-03T19:52:30.955466: step 9747, loss 0.347516, acc 0.875\n",
      "2017-04-03T19:52:31.212745: step 9748, loss 0.22576, acc 0.953125\n",
      "2017-04-03T19:52:31.411929: step 9749, loss 0.322004, acc 0.890625\n",
      "2017-04-03T19:52:31.613665: step 9750, loss 0.15816, acc 0.9375\n",
      "2017-04-03T19:52:31.820979: step 9751, loss 0.0847556, acc 1\n",
      "2017-04-03T19:52:32.027443: step 9752, loss 0.24327, acc 0.9375\n",
      "2017-04-03T19:52:32.236630: step 9753, loss 0.20858, acc 0.9375\n",
      "2017-04-03T19:52:32.437324: step 9754, loss 0.33792, acc 0.859375\n",
      "2017-04-03T19:52:32.646567: step 9755, loss 0.288819, acc 0.921875\n",
      "2017-04-03T19:52:32.847809: step 9756, loss 0.288311, acc 0.890625\n",
      "2017-04-03T19:52:33.057114: step 9757, loss 0.19139, acc 0.9375\n",
      "2017-04-03T19:52:33.259078: step 9758, loss 0.267016, acc 0.9375\n",
      "2017-04-03T19:52:33.471367: step 9759, loss 0.207583, acc 0.90625\n",
      "2017-04-03T19:52:33.671613: step 9760, loss 0.325298, acc 0.875\n",
      "2017-04-03T19:52:33.876180: step 9761, loss 0.189489, acc 0.921875\n",
      "2017-04-03T19:52:34.078504: step 9762, loss 0.222637, acc 0.953125\n",
      "2017-04-03T19:52:34.282217: step 9763, loss 0.350361, acc 0.9375\n",
      "2017-04-03T19:52:34.488788: step 9764, loss 0.198022, acc 0.9375\n",
      "2017-04-03T19:52:34.741652: step 9765, loss 0.318218, acc 0.90625\n",
      "2017-04-03T19:52:34.944206: step 9766, loss 0.277961, acc 0.921875\n",
      "2017-04-03T19:52:35.146054: step 9767, loss 0.162585, acc 0.96875\n",
      "2017-04-03T19:52:35.350628: step 9768, loss 0.70638, acc 0.8125\n",
      "2017-04-03T19:52:35.562256: step 9769, loss 0.531477, acc 0.828125\n",
      "2017-04-03T19:52:35.761233: step 9770, loss 0.201965, acc 0.921875\n",
      "2017-04-03T19:52:35.963897: step 9771, loss 0.288213, acc 0.90625\n",
      "2017-04-03T19:52:36.215611: step 9772, loss 0.216715, acc 0.921875\n",
      "2017-04-03T19:52:36.419400: step 9773, loss 0.20586, acc 0.9375\n",
      "2017-04-03T19:52:36.623467: step 9774, loss 0.200752, acc 0.90625\n",
      "2017-04-03T19:52:36.824745: step 9775, loss 0.286516, acc 0.890625\n",
      "2017-04-03T19:52:37.028568: step 9776, loss 0.201524, acc 0.9375\n",
      "2017-04-03T19:52:37.253674: step 9777, loss 0.280636, acc 0.875\n",
      "2017-04-03T19:52:37.474338: step 9778, loss 0.314871, acc 0.921875\n",
      "2017-04-03T19:52:37.673525: step 9779, loss 0.341038, acc 0.890625\n",
      "2017-04-03T19:52:37.878936: step 9780, loss 0.266886, acc 0.921875\n",
      "2017-04-03T19:52:38.080671: step 9781, loss 0.194426, acc 0.96875\n",
      "2017-04-03T19:52:38.299761: step 9782, loss 0.199559, acc 0.9375\n",
      "2017-04-03T19:52:38.501562: step 9783, loss 0.147873, acc 0.96875\n",
      "2017-04-03T19:52:38.700348: step 9784, loss 0.28564, acc 0.890625\n",
      "2017-04-03T19:52:38.919747: step 9785, loss 0.45489, acc 0.828125\n",
      "2017-04-03T19:52:39.160535: step 9786, loss 0.198392, acc 0.96875\n",
      "2017-04-03T19:52:39.366074: step 9787, loss 0.142563, acc 0.953125\n",
      "2017-04-03T19:52:39.570145: step 9788, loss 0.224007, acc 0.90625\n",
      "2017-04-03T19:52:39.772409: step 9789, loss 0.184906, acc 0.90625\n",
      "2017-04-03T19:52:40.019403: step 9790, loss 0.204826, acc 0.90625\n",
      "2017-04-03T19:52:40.223701: step 9791, loss 0.360621, acc 0.890625\n",
      "2017-04-03T19:52:40.426926: step 9792, loss 0.195622, acc 0.921875\n",
      "2017-04-03T19:52:40.630665: step 9793, loss 0.264625, acc 0.9375\n",
      "2017-04-03T19:52:40.833771: step 9794, loss 0.413072, acc 0.828125\n",
      "2017-04-03T19:52:41.044322: step 9795, loss 0.316228, acc 0.890625\n",
      "2017-04-03T19:52:41.244415: step 9796, loss 0.213409, acc 0.921875\n",
      "2017-04-03T19:52:41.444723: step 9797, loss 0.16185, acc 0.96875\n",
      "2017-04-03T19:52:41.657655: step 9798, loss 0.273296, acc 0.921875\n",
      "2017-04-03T19:52:41.879125: step 9799, loss 0.219433, acc 0.921875\n",
      "2017-04-03T19:52:42.080464: step 9800, loss 0.306963, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:52:44.180314: step 9800, loss 4.15063, acc 0.296\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-9800\n",
      "\n",
      "2017-04-03T19:52:44.512861: step 9801, loss 0.060833, acc 0.984375\n",
      "2017-04-03T19:52:44.729415: step 9802, loss 0.266871, acc 0.90625\n",
      "2017-04-03T19:52:44.934155: step 9803, loss 0.423899, acc 0.859375\n",
      "2017-04-03T19:52:45.177062: step 9804, loss 0.202396, acc 0.953125\n",
      "2017-04-03T19:52:45.393062: step 9805, loss 0.284673, acc 0.890625\n",
      "2017-04-03T19:52:45.593230: step 9806, loss 0.157798, acc 0.953125\n",
      "2017-04-03T19:52:45.793112: step 9807, loss 0.236395, acc 0.921875\n",
      "2017-04-03T19:52:45.996905: step 9808, loss 0.1592, acc 0.96875\n",
      "2017-04-03T19:52:46.199062: step 9809, loss 0.168471, acc 0.90625\n",
      "2017-04-03T19:52:46.396285: step 9810, loss 0.215159, acc 0.953125\n",
      "2017-04-03T19:52:46.600114: step 9811, loss 0.10539, acc 0.953125\n",
      "2017-04-03T19:52:46.803966: step 9812, loss 0.265455, acc 0.90625\n",
      "2017-04-03T19:52:47.051136: step 9813, loss 0.336754, acc 0.859375\n",
      "2017-04-03T19:52:47.252094: step 9814, loss 0.233992, acc 0.9375\n",
      "2017-04-03T19:52:47.454461: step 9815, loss 0.142764, acc 0.953125\n",
      "2017-04-03T19:52:47.658527: step 9816, loss 0.172616, acc 0.96875\n",
      "2017-04-03T19:52:47.858273: step 9817, loss 0.243345, acc 0.9375\n",
      "2017-04-03T19:52:48.061897: step 9818, loss 0.200469, acc 0.9375\n",
      "2017-04-03T19:52:48.267682: step 9819, loss 0.222225, acc 0.921875\n",
      "2017-04-03T19:52:48.469218: step 9820, loss 0.263645, acc 0.890625\n",
      "2017-04-03T19:52:48.669087: step 9821, loss 0.0745205, acc 1\n",
      "2017-04-03T19:52:48.873477: step 9822, loss 0.123074, acc 0.953125\n",
      "2017-04-03T19:52:49.074790: step 9823, loss 0.240824, acc 0.90625\n",
      "2017-04-03T19:52:49.278912: step 9824, loss 0.412676, acc 0.875\n",
      "2017-04-03T19:52:49.483555: step 9825, loss 0.166103, acc 0.9375\n",
      "2017-04-03T19:52:49.688701: step 9826, loss 0.267144, acc 0.90625\n",
      "2017-04-03T19:52:49.895924: step 9827, loss 0.229966, acc 0.921875\n",
      "2017-04-03T19:52:50.099278: step 9828, loss 0.380848, acc 0.875\n",
      "2017-04-03T19:52:50.299774: step 9829, loss 0.382809, acc 0.9375\n",
      "2017-04-03T19:52:50.510294: step 9830, loss 0.335436, acc 0.890625\n",
      "2017-04-03T19:52:50.709353: step 9831, loss 0.168233, acc 0.921875\n",
      "2017-04-03T19:52:50.909171: step 9832, loss 0.308762, acc 0.859375\n",
      "2017-04-03T19:52:51.111788: step 9833, loss 0.264116, acc 0.90625\n",
      "2017-04-03T19:52:51.353142: step 9834, loss 0.205258, acc 0.921875\n",
      "2017-04-03T19:52:51.556757: step 9835, loss 0.279631, acc 0.90625\n",
      "2017-04-03T19:52:51.758418: step 9836, loss 0.297189, acc 0.921875\n",
      "2017-04-03T19:52:51.957524: step 9837, loss 0.215797, acc 0.9375\n",
      "2017-04-03T19:52:52.170338: step 9838, loss 0.194918, acc 0.953125\n",
      "2017-04-03T19:52:52.372036: step 9839, loss 0.314069, acc 0.90625\n",
      "2017-04-03T19:52:52.571341: step 9840, loss 0.304001, acc 0.90625\n",
      "2017-04-03T19:52:52.768459: step 9841, loss 0.261853, acc 0.921875\n",
      "2017-04-03T19:52:53.006198: step 9842, loss 0.175987, acc 0.984375\n",
      "2017-04-03T19:52:53.260456: step 9843, loss 0.364127, acc 0.90625\n",
      "2017-04-03T19:52:53.463407: step 9844, loss 0.29773, acc 0.90625\n",
      "2017-04-03T19:52:53.664424: step 9845, loss 0.205272, acc 0.90625\n",
      "2017-04-03T19:52:53.874303: step 9846, loss 0.181085, acc 0.953125\n",
      "2017-04-03T19:52:54.076422: step 9847, loss 0.32688, acc 0.890625\n",
      "2017-04-03T19:52:54.275669: step 9848, loss 0.170488, acc 0.953125\n",
      "2017-04-03T19:52:54.478331: step 9849, loss 0.242802, acc 0.90625\n",
      "2017-04-03T19:52:54.677561: step 9850, loss 0.193837, acc 0.9375\n",
      "2017-04-03T19:52:54.878249: step 9851, loss 0.258343, acc 0.90625\n",
      "2017-04-03T19:52:55.092659: step 9852, loss 0.373622, acc 0.921875\n",
      "2017-04-03T19:52:55.314032: step 9853, loss 0.284382, acc 0.921875\n",
      "2017-04-03T19:52:55.516085: step 9854, loss 0.17601, acc 0.921875\n",
      "2017-04-03T19:52:55.721346: step 9855, loss 0.119378, acc 0.96875\n",
      "2017-04-03T19:52:55.949638: step 9856, loss 0.188214, acc 0.953125\n",
      "2017-04-03T19:52:56.161604: step 9857, loss 0.265854, acc 0.921875\n",
      "2017-04-03T19:52:56.363486: step 9858, loss 0.149046, acc 0.96875\n",
      "2017-04-03T19:52:56.568328: step 9859, loss 0.214529, acc 0.9375\n",
      "2017-04-03T19:52:56.773841: step 9860, loss 0.274438, acc 0.90625\n",
      "2017-04-03T19:52:56.978939: step 9861, loss 0.253137, acc 0.90625\n",
      "2017-04-03T19:52:57.184272: step 9862, loss 0.18705, acc 0.96875\n",
      "2017-04-03T19:52:57.391308: step 9863, loss 0.259999, acc 0.90625\n",
      "2017-04-03T19:52:57.592389: step 9864, loss 0.219536, acc 0.921875\n",
      "2017-04-03T19:52:57.792209: step 9865, loss 0.270192, acc 0.90625\n",
      "2017-04-03T19:52:57.994244: step 9866, loss 0.104956, acc 0.984375\n",
      "2017-04-03T19:52:58.201549: step 9867, loss 0.141565, acc 0.953125\n",
      "2017-04-03T19:52:58.404413: step 9868, loss 0.129534, acc 0.96875\n",
      "2017-04-03T19:52:58.603964: step 9869, loss 0.250852, acc 0.90625\n",
      "2017-04-03T19:52:58.802176: step 9870, loss 0.379176, acc 0.859375\n",
      "2017-04-03T19:52:59.009762: step 9871, loss 0.212823, acc 0.890625\n",
      "2017-04-03T19:52:59.214325: step 9872, loss 0.264266, acc 0.890625\n",
      "2017-04-03T19:52:59.418723: step 9873, loss 0.272216, acc 0.953125\n",
      "2017-04-03T19:52:59.617492: step 9874, loss 0.290771, acc 0.921875\n",
      "2017-04-03T19:52:59.830032: step 9875, loss 0.192889, acc 0.9375\n",
      "2017-04-03T19:53:00.030588: step 9876, loss 0.157654, acc 0.96875\n",
      "2017-04-03T19:53:00.242331: step 9877, loss 0.41112, acc 0.875\n",
      "2017-04-03T19:53:00.444275: step 9878, loss 0.239008, acc 0.90625\n",
      "2017-04-03T19:53:00.646367: step 9879, loss 0.218002, acc 0.90625\n",
      "2017-04-03T19:53:00.847560: step 9880, loss 0.188478, acc 0.921875\n",
      "2017-04-03T19:53:01.051816: step 9881, loss 0.302695, acc 0.890625\n",
      "2017-04-03T19:53:01.254754: step 9882, loss 0.253022, acc 0.90625\n",
      "2017-04-03T19:53:01.457954: step 9883, loss 0.326964, acc 0.921875\n",
      "2017-04-03T19:53:01.661075: step 9884, loss 0.149116, acc 0.984375\n",
      "2017-04-03T19:53:01.870949: step 9885, loss 0.173749, acc 0.953125\n",
      "2017-04-03T19:53:02.079233: step 9886, loss 0.284925, acc 0.859375\n",
      "2017-04-03T19:53:02.279516: step 9887, loss 0.252485, acc 0.875\n",
      "2017-04-03T19:53:02.485933: step 9888, loss 0.19093, acc 0.90625\n",
      "2017-04-03T19:53:02.687982: step 9889, loss 0.37095, acc 0.890625\n",
      "2017-04-03T19:53:02.891415: step 9890, loss 0.371051, acc 0.890625\n",
      "2017-04-03T19:53:03.092805: step 9891, loss 0.121887, acc 1\n",
      "2017-04-03T19:53:03.297578: step 9892, loss 0.250534, acc 0.9375\n",
      "2017-04-03T19:53:03.550786: step 9893, loss 0.422314, acc 0.953125\n",
      "2017-04-03T19:53:03.756724: step 9894, loss 0.117394, acc 0.984375\n",
      "2017-04-03T19:53:03.964843: step 9895, loss 0.28876, acc 0.859375\n",
      "2017-04-03T19:53:04.165633: step 9896, loss 0.381273, acc 0.84375\n",
      "2017-04-03T19:53:04.411420: step 9897, loss 0.351468, acc 0.875\n",
      "2017-04-03T19:53:04.617634: step 9898, loss 0.17186, acc 0.953125\n",
      "2017-04-03T19:53:04.853664: step 9899, loss 0.226673, acc 0.9375\n",
      "2017-04-03T19:53:05.053938: step 9900, loss 0.325765, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:53:07.124596: step 9900, loss 4.22415, acc 0.297\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-9900\n",
      "\n",
      "2017-04-03T19:53:07.451444: step 9901, loss 0.269357, acc 0.890625\n",
      "2017-04-03T19:53:07.654386: step 9902, loss 0.454417, acc 0.90625\n",
      "2017-04-03T19:53:07.858638: step 9903, loss 0.181364, acc 0.9375\n",
      "2017-04-03T19:53:08.066184: step 9904, loss 0.363678, acc 0.890625\n",
      "2017-04-03T19:53:08.275048: step 9905, loss 0.141006, acc 0.96875\n",
      "2017-04-03T19:53:08.473773: step 9906, loss 0.215393, acc 0.953125\n",
      "2017-04-03T19:53:08.672134: step 9907, loss 0.258152, acc 0.9375\n",
      "2017-04-03T19:53:08.876277: step 9908, loss 0.206042, acc 0.9375\n",
      "2017-04-03T19:53:09.077926: step 9909, loss 0.107381, acc 0.96875\n",
      "2017-04-03T19:53:09.285221: step 9910, loss 0.166182, acc 0.953125\n",
      "2017-04-03T19:53:09.484543: step 9911, loss 0.212171, acc 0.921875\n",
      "2017-04-03T19:53:09.688025: step 9912, loss 0.153726, acc 0.953125\n",
      "2017-04-03T19:53:09.890633: step 9913, loss 0.135674, acc 0.9375\n",
      "2017-04-03T19:53:10.092701: step 9914, loss 0.269921, acc 0.90625\n",
      "2017-04-03T19:53:10.296104: step 9915, loss 0.314303, acc 0.890625\n",
      "2017-04-03T19:53:10.500334: step 9916, loss 0.212093, acc 0.921875\n",
      "2017-04-03T19:53:10.704592: step 9917, loss 0.325722, acc 0.890625\n",
      "2017-04-03T19:53:10.920180: step 9918, loss 0.194864, acc 0.921875\n",
      "2017-04-03T19:53:11.128010: step 9919, loss 0.397974, acc 0.875\n",
      "2017-04-03T19:53:11.325714: step 9920, loss 0.279072, acc 0.890625\n",
      "2017-04-03T19:53:11.536866: step 9921, loss 0.294033, acc 0.90625\n",
      "2017-04-03T19:53:11.743463: step 9922, loss 0.285291, acc 0.9375\n",
      "2017-04-03T19:53:11.944867: step 9923, loss 0.252359, acc 0.890625\n",
      "2017-04-03T19:53:12.190865: step 9924, loss 0.209395, acc 0.90625\n",
      "2017-04-03T19:53:12.399135: step 9925, loss 0.223536, acc 0.921875\n",
      "2017-04-03T19:53:12.603646: step 9926, loss 0.240267, acc 0.90625\n",
      "2017-04-03T19:53:12.813498: step 9927, loss 0.0955323, acc 0.984375\n",
      "2017-04-03T19:53:13.017449: step 9928, loss 0.245928, acc 0.9375\n",
      "2017-04-03T19:53:13.261856: step 9929, loss 0.277425, acc 0.90625\n",
      "2017-04-03T19:53:13.464603: step 9930, loss 0.275243, acc 0.875\n",
      "2017-04-03T19:53:13.663582: step 9931, loss 0.238696, acc 0.90625\n",
      "2017-04-03T19:53:13.910114: step 9932, loss 0.296482, acc 0.875\n",
      "2017-04-03T19:53:14.114137: step 9933, loss 0.234837, acc 0.9375\n",
      "2017-04-03T19:53:14.318156: step 9934, loss 0.198056, acc 0.90625\n",
      "2017-04-03T19:53:14.567916: step 9935, loss 0.264713, acc 0.890625\n",
      "2017-04-03T19:53:14.772952: step 9936, loss 0.180553, acc 0.953125\n",
      "2017-04-03T19:53:14.976007: step 9937, loss 0.177475, acc 0.9375\n",
      "2017-04-03T19:53:15.184940: step 9938, loss 0.224075, acc 0.90625\n",
      "2017-04-03T19:53:15.389119: step 9939, loss 0.262612, acc 0.921875\n",
      "2017-04-03T19:53:15.587357: step 9940, loss 0.257399, acc 0.90625\n",
      "2017-04-03T19:53:15.792348: step 9941, loss 0.149478, acc 0.984375\n",
      "2017-04-03T19:53:15.990060: step 9942, loss 0.415877, acc 0.84375\n",
      "2017-04-03T19:53:16.188370: step 9943, loss 0.413741, acc 0.875\n",
      "2017-04-03T19:53:16.386167: step 9944, loss 0.186794, acc 0.9375\n",
      "2017-04-03T19:53:16.589595: step 9945, loss 0.214651, acc 0.90625\n",
      "2017-04-03T19:53:16.793222: step 9946, loss 0.308698, acc 0.859375\n",
      "2017-04-03T19:53:16.992390: step 9947, loss 0.242656, acc 0.90625\n",
      "2017-04-03T19:53:17.186884: step 9948, loss 0.21434, acc 0.921875\n",
      "2017-04-03T19:53:17.389714: step 9949, loss 0.174168, acc 0.953125\n",
      "2017-04-03T19:53:17.592116: step 9950, loss 0.363842, acc 0.859375\n",
      "2017-04-03T19:53:17.838573: step 9951, loss 0.244448, acc 0.9375\n",
      "2017-04-03T19:53:18.042766: step 9952, loss 0.222771, acc 0.9375\n",
      "2017-04-03T19:53:18.241023: step 9953, loss 0.304655, acc 0.9375\n",
      "2017-04-03T19:53:18.444213: step 9954, loss 0.349146, acc 0.890625\n",
      "2017-04-03T19:53:18.645404: step 9955, loss 0.178872, acc 0.921875\n",
      "2017-04-03T19:53:18.859140: step 9956, loss 0.241795, acc 0.90625\n",
      "2017-04-03T19:53:19.073740: step 9957, loss 0.166592, acc 0.9375\n",
      "2017-04-03T19:53:19.315074: step 9958, loss 0.2429, acc 0.90625\n",
      "2017-04-03T19:53:19.566415: step 9959, loss 0.329852, acc 0.90625\n",
      "2017-04-03T19:53:19.770488: step 9960, loss 0.207538, acc 0.9375\n",
      "2017-04-03T19:53:19.968685: step 9961, loss 0.1552, acc 0.984375\n",
      "2017-04-03T19:53:20.169846: step 9962, loss 0.137828, acc 0.953125\n",
      "2017-04-03T19:53:20.376841: step 9963, loss 0.221772, acc 0.90625\n",
      "2017-04-03T19:53:20.586754: step 9964, loss 0.186247, acc 0.96875\n",
      "2017-04-03T19:53:20.837489: step 9965, loss 0.312487, acc 0.875\n",
      "2017-04-03T19:53:21.078959: step 9966, loss 0.232391, acc 0.921875\n",
      "2017-04-03T19:53:21.289767: step 9967, loss 0.394059, acc 0.84375\n",
      "2017-04-03T19:53:21.491704: step 9968, loss 0.325682, acc 0.90625\n",
      "2017-04-03T19:53:21.689283: step 9969, loss 0.289771, acc 0.90625\n",
      "2017-04-03T19:53:21.889131: step 9970, loss 0.328688, acc 0.90625\n",
      "2017-04-03T19:53:22.088154: step 9971, loss 0.206298, acc 0.9375\n",
      "2017-04-03T19:53:22.335192: step 9972, loss 0.184745, acc 0.953125\n",
      "2017-04-03T19:53:22.550900: step 9973, loss 0.208345, acc 0.921875\n",
      "2017-04-03T19:53:22.757552: step 9974, loss 0.229482, acc 0.90625\n",
      "2017-04-03T19:53:22.965853: step 9975, loss 0.276556, acc 0.921875\n",
      "2017-04-03T19:53:23.170974: step 9976, loss 0.159582, acc 0.953125\n",
      "2017-04-03T19:53:23.371434: step 9977, loss 0.208527, acc 0.9375\n",
      "2017-04-03T19:53:23.571228: step 9978, loss 0.38078, acc 0.828125\n",
      "2017-04-03T19:53:23.776423: step 9979, loss 0.474207, acc 0.875\n",
      "2017-04-03T19:53:23.983427: step 9980, loss 0.260076, acc 0.875\n",
      "2017-04-03T19:53:24.232258: step 9981, loss 0.261142, acc 0.875\n",
      "2017-04-03T19:53:24.484326: step 9982, loss 0.363305, acc 0.890625\n",
      "2017-04-03T19:53:24.688226: step 9983, loss 0.417016, acc 0.859375\n",
      "2017-04-03T19:53:24.892300: step 9984, loss 0.257107, acc 0.9375\n",
      "2017-04-03T19:53:25.139888: step 9985, loss 0.205708, acc 0.90625\n",
      "2017-04-03T19:53:25.344919: step 9986, loss 0.219167, acc 0.90625\n",
      "2017-04-03T19:53:25.543206: step 9987, loss 0.276905, acc 0.890625\n",
      "2017-04-03T19:53:25.744039: step 9988, loss 0.17428, acc 0.921875\n",
      "2017-04-03T19:53:25.949512: step 9989, loss 0.231256, acc 0.921875\n",
      "2017-04-03T19:53:26.164359: step 9990, loss 0.333249, acc 0.890625\n",
      "2017-04-03T19:53:26.372906: step 9991, loss 0.23215, acc 0.921875\n",
      "2017-04-03T19:53:26.577944: step 9992, loss 0.24722, acc 0.921875\n",
      "2017-04-03T19:53:26.785120: step 9993, loss 0.214066, acc 0.90625\n",
      "2017-04-03T19:53:26.986348: step 9994, loss 0.365591, acc 0.859375\n",
      "2017-04-03T19:53:27.192354: step 9995, loss 0.294146, acc 0.890625\n",
      "2017-04-03T19:53:27.397802: step 9996, loss 0.305346, acc 0.890625\n",
      "2017-04-03T19:53:27.599430: step 9997, loss 0.312173, acc 0.90625\n",
      "2017-04-03T19:53:27.805934: step 9998, loss 0.111124, acc 0.984375\n",
      "2017-04-03T19:53:28.007184: step 9999, loss 0.270313, acc 0.90625\n",
      "2017-04-03T19:53:28.214681: step 10000, loss 0.33812, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:53:30.362095: step 10000, loss 4.23469, acc 0.30475\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-10000\n",
      "\n",
      "2017-04-03T19:53:30.692726: step 10001, loss 0.306192, acc 0.875\n",
      "2017-04-03T19:53:30.898170: step 10002, loss 0.115826, acc 0.96875\n",
      "2017-04-03T19:53:31.107671: step 10003, loss 0.257561, acc 0.890625\n",
      "2017-04-03T19:53:31.313353: step 10004, loss 0.307533, acc 0.875\n",
      "2017-04-03T19:53:31.517210: step 10005, loss 0.153937, acc 0.96875\n",
      "2017-04-03T19:53:31.725861: step 10006, loss 0.331893, acc 0.9375\n",
      "2017-04-03T19:53:31.924568: step 10007, loss 0.221357, acc 0.921875\n",
      "2017-04-03T19:53:32.126768: step 10008, loss 0.35034, acc 0.875\n",
      "2017-04-03T19:53:32.329084: step 10009, loss 0.0965001, acc 0.984375\n",
      "2017-04-03T19:53:32.528676: step 10010, loss 0.269621, acc 0.90625\n",
      "2017-04-03T19:53:32.742269: step 10011, loss 0.25747, acc 0.90625\n",
      "2017-04-03T19:53:32.951245: step 10012, loss 0.207202, acc 0.9375\n",
      "2017-04-03T19:53:33.153156: step 10013, loss 0.180638, acc 0.9375\n",
      "2017-04-03T19:53:33.361907: step 10014, loss 0.250178, acc 0.953125\n",
      "2017-04-03T19:53:33.570846: step 10015, loss 0.347912, acc 0.90625\n",
      "2017-04-03T19:53:33.776216: step 10016, loss 0.125023, acc 0.96875\n",
      "2017-04-03T19:53:33.979881: step 10017, loss 0.280366, acc 0.9375\n",
      "2017-04-03T19:53:34.188694: step 10018, loss 0.426059, acc 0.84375\n",
      "2017-04-03T19:53:34.393998: step 10019, loss 0.146273, acc 0.953125\n",
      "2017-04-03T19:53:34.605611: step 10020, loss 0.369204, acc 0.890625\n",
      "2017-04-03T19:53:34.808572: step 10021, loss 0.391996, acc 0.875\n",
      "2017-04-03T19:53:35.008022: step 10022, loss 0.268912, acc 0.890625\n",
      "2017-04-03T19:53:35.253490: step 10023, loss 0.169282, acc 0.953125\n",
      "2017-04-03T19:53:35.456658: step 10024, loss 0.195046, acc 0.96875\n",
      "2017-04-03T19:53:35.682308: step 10025, loss 0.572841, acc 0.859375\n",
      "2017-04-03T19:53:35.890173: step 10026, loss 0.248772, acc 0.890625\n",
      "2017-04-03T19:53:36.136171: step 10027, loss 0.203365, acc 0.90625\n",
      "2017-04-03T19:53:36.344311: step 10028, loss 0.1972, acc 0.921875\n",
      "2017-04-03T19:53:36.543755: step 10029, loss 0.262224, acc 0.921875\n",
      "2017-04-03T19:53:36.744453: step 10030, loss 0.115278, acc 0.953125\n",
      "2017-04-03T19:53:36.946964: step 10031, loss 0.115779, acc 0.9375\n",
      "2017-04-03T19:53:37.152285: step 10032, loss 0.22583, acc 0.90625\n",
      "2017-04-03T19:53:37.353037: step 10033, loss 0.176458, acc 0.921875\n",
      "2017-04-03T19:53:37.553884: step 10034, loss 0.218663, acc 0.953125\n",
      "2017-04-03T19:53:37.758545: step 10035, loss 0.370203, acc 0.921875\n",
      "2017-04-03T19:53:37.960582: step 10036, loss 0.354106, acc 0.90625\n",
      "2017-04-03T19:53:38.165532: step 10037, loss 0.262046, acc 0.875\n",
      "2017-04-03T19:53:38.368435: step 10038, loss 0.233906, acc 0.921875\n",
      "2017-04-03T19:53:38.586696: step 10039, loss 0.414057, acc 0.859375\n",
      "2017-04-03T19:53:38.809287: step 10040, loss 0.214093, acc 0.90625\n",
      "2017-04-03T19:53:39.012955: step 10041, loss 0.167432, acc 0.96875\n",
      "2017-04-03T19:53:39.221305: step 10042, loss 0.199974, acc 0.921875\n",
      "2017-04-03T19:53:39.434721: step 10043, loss 0.20193, acc 0.921875\n",
      "2017-04-03T19:53:39.653786: step 10044, loss 0.195002, acc 0.9375\n",
      "2017-04-03T19:53:39.856122: step 10045, loss 0.50109, acc 0.90625\n",
      "2017-04-03T19:53:40.064530: step 10046, loss 0.23496, acc 0.90625\n",
      "2017-04-03T19:53:40.273521: step 10047, loss 0.267035, acc 0.921875\n",
      "2017-04-03T19:53:40.474395: step 10048, loss 0.175733, acc 0.9375\n",
      "2017-04-03T19:53:40.681822: step 10049, loss 0.349744, acc 0.890625\n",
      "2017-04-03T19:53:40.893344: step 10050, loss 0.226181, acc 0.953125\n",
      "2017-04-03T19:53:41.103363: step 10051, loss 0.157295, acc 0.953125\n",
      "2017-04-03T19:53:41.305748: step 10052, loss 0.266039, acc 0.90625\n",
      "2017-04-03T19:53:41.515776: step 10053, loss 0.287813, acc 0.90625\n",
      "2017-04-03T19:53:41.749126: step 10054, loss 0.308492, acc 0.84375\n",
      "2017-04-03T19:53:41.953176: step 10055, loss 0.270398, acc 0.921875\n",
      "2017-04-03T19:53:42.150262: step 10056, loss 0.307898, acc 0.921875\n",
      "2017-04-03T19:53:42.347370: step 10057, loss 0.290504, acc 0.890625\n",
      "2017-04-03T19:53:42.555559: step 10058, loss 0.219467, acc 0.890625\n",
      "2017-04-03T19:53:42.756010: step 10059, loss 0.2435, acc 0.875\n",
      "2017-04-03T19:53:42.963328: step 10060, loss 0.241451, acc 0.953125\n",
      "2017-04-03T19:53:43.167082: step 10061, loss 0.271172, acc 0.90625\n",
      "2017-04-03T19:53:43.374950: step 10062, loss 0.224065, acc 0.921875\n",
      "2017-04-03T19:53:43.576473: step 10063, loss 0.307551, acc 0.890625\n",
      "2017-04-03T19:53:43.779250: step 10064, loss 0.306566, acc 0.890625\n",
      "2017-04-03T19:53:43.981997: step 10065, loss 0.218099, acc 0.953125\n",
      "2017-04-03T19:53:44.185982: step 10066, loss 0.440074, acc 0.890625\n",
      "2017-04-03T19:53:44.388374: step 10067, loss 0.226245, acc 0.96875\n",
      "2017-04-03T19:53:44.596710: step 10068, loss 0.194102, acc 0.90625\n",
      "2017-04-03T19:53:44.802605: step 10069, loss 0.258215, acc 0.921875\n",
      "2017-04-03T19:53:45.003468: step 10070, loss 0.165173, acc 0.9375\n",
      "2017-04-03T19:53:45.206407: step 10071, loss 0.17903, acc 0.953125\n",
      "2017-04-03T19:53:45.407463: step 10072, loss 0.153618, acc 0.96875\n",
      "2017-04-03T19:53:45.610181: step 10073, loss 0.295682, acc 0.90625\n",
      "2017-04-03T19:53:45.809070: step 10074, loss 0.172641, acc 0.953125\n",
      "2017-04-03T19:53:46.012810: step 10075, loss 0.261876, acc 0.921875\n",
      "2017-04-03T19:53:46.221266: step 10076, loss 0.26128, acc 0.921875\n",
      "2017-04-03T19:53:46.425871: step 10077, loss 0.270443, acc 0.90625\n",
      "2017-04-03T19:53:46.672853: step 10078, loss 0.170527, acc 0.96875\n",
      "2017-04-03T19:53:46.880326: step 10079, loss 0.215719, acc 0.953125\n",
      "2017-04-03T19:53:47.087226: step 10080, loss 0.259457, acc 0.890625\n",
      "2017-04-03T19:53:47.292454: step 10081, loss 0.219163, acc 0.921875\n",
      "2017-04-03T19:53:47.496282: step 10082, loss 0.328106, acc 0.921875\n",
      "2017-04-03T19:53:47.707153: step 10083, loss 0.462823, acc 0.875\n",
      "2017-04-03T19:53:47.925668: step 10084, loss 0.272066, acc 0.9375\n",
      "2017-04-03T19:53:48.132514: step 10085, loss 0.26643, acc 0.890625\n",
      "2017-04-03T19:53:48.357032: step 10086, loss 0.322379, acc 0.859375\n",
      "2017-04-03T19:53:48.576075: step 10087, loss 0.227406, acc 0.90625\n",
      "2017-04-03T19:53:48.836108: step 10088, loss 0.285892, acc 0.90625\n",
      "2017-04-03T19:53:49.040991: step 10089, loss 0.221809, acc 0.90625\n",
      "2017-04-03T19:53:49.247198: step 10090, loss 0.218308, acc 0.953125\n",
      "2017-04-03T19:53:49.449940: step 10091, loss 0.182298, acc 0.921875\n",
      "2017-04-03T19:53:49.651756: step 10092, loss 0.254896, acc 0.9375\n",
      "2017-04-03T19:53:49.861922: step 10093, loss 0.268245, acc 0.921875\n",
      "2017-04-03T19:53:50.079835: step 10094, loss 0.242817, acc 0.90625\n",
      "2017-04-03T19:53:50.292820: step 10095, loss 0.314479, acc 0.890625\n",
      "2017-04-03T19:53:50.505686: step 10096, loss 0.242698, acc 0.921875\n",
      "2017-04-03T19:53:50.710670: step 10097, loss 0.435458, acc 0.859375\n",
      "2017-04-03T19:53:50.920330: step 10098, loss 0.240049, acc 0.890625\n",
      "2017-04-03T19:53:51.131053: step 10099, loss 0.234553, acc 0.953125\n",
      "2017-04-03T19:53:51.334026: step 10100, loss 0.237847, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:53:53.445046: step 10100, loss 4.27143, acc 0.301\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-10100\n",
      "\n",
      "2017-04-03T19:53:53.774522: step 10101, loss 0.245002, acc 0.875\n",
      "2017-04-03T19:53:54.026984: step 10102, loss 0.194866, acc 0.90625\n",
      "2017-04-03T19:53:54.229780: step 10103, loss 0.208499, acc 0.953125\n",
      "2017-04-03T19:53:54.475316: step 10104, loss 0.245051, acc 0.875\n",
      "2017-04-03T19:53:54.683239: step 10105, loss 0.364964, acc 0.859375\n",
      "2017-04-03T19:53:54.906265: step 10106, loss 0.381803, acc 0.921875\n",
      "2017-04-03T19:53:55.119232: step 10107, loss 0.340926, acc 0.875\n",
      "2017-04-03T19:53:55.322898: step 10108, loss 0.267709, acc 0.96875\n",
      "2017-04-03T19:53:55.526638: step 10109, loss 0.223635, acc 0.90625\n",
      "2017-04-03T19:53:55.727634: step 10110, loss 0.133815, acc 0.96875\n",
      "2017-04-03T19:53:55.933923: step 10111, loss 0.21235, acc 0.90625\n",
      "2017-04-03T19:53:56.144812: step 10112, loss 0.387191, acc 0.875\n",
      "2017-04-03T19:53:56.349102: step 10113, loss 0.148807, acc 0.953125\n",
      "2017-04-03T19:53:56.556885: step 10114, loss 0.161679, acc 0.9375\n",
      "2017-04-03T19:53:56.762102: step 10115, loss 0.152375, acc 0.9375\n",
      "2017-04-03T19:53:56.971772: step 10116, loss 0.250555, acc 0.9375\n",
      "2017-04-03T19:53:57.172748: step 10117, loss 0.358131, acc 0.90625\n",
      "2017-04-03T19:53:57.384049: step 10118, loss 0.107807, acc 0.984375\n",
      "2017-04-03T19:53:57.587993: step 10119, loss 0.201076, acc 0.921875\n",
      "2017-04-03T19:53:57.794634: step 10120, loss 0.186346, acc 0.9375\n",
      "2017-04-03T19:53:57.996621: step 10121, loss 0.159154, acc 0.953125\n",
      "2017-04-03T19:53:58.209619: step 10122, loss 0.180152, acc 0.953125\n",
      "2017-04-03T19:53:58.424859: step 10123, loss 0.243642, acc 0.90625\n",
      "2017-04-03T19:53:58.651294: step 10124, loss 0.157026, acc 0.9375\n",
      "2017-04-03T19:53:58.864592: step 10125, loss 0.297502, acc 0.90625\n",
      "2017-04-03T19:53:59.072898: step 10126, loss 0.330293, acc 0.90625\n",
      "2017-04-03T19:53:59.278506: step 10127, loss 0.312676, acc 0.9375\n",
      "2017-04-03T19:53:59.481643: step 10128, loss 0.27008, acc 0.90625\n",
      "2017-04-03T19:53:59.685210: step 10129, loss 0.386629, acc 0.890625\n",
      "2017-04-03T19:53:59.887792: step 10130, loss 0.291325, acc 0.90625\n",
      "2017-04-03T19:54:00.097315: step 10131, loss 0.313308, acc 0.875\n",
      "2017-04-03T19:54:00.301686: step 10132, loss 0.290129, acc 0.921875\n",
      "2017-04-03T19:54:00.507212: step 10133, loss 0.260673, acc 0.890625\n",
      "2017-04-03T19:54:00.654788: step 10134, loss 0.128205, acc 1\n",
      "2017-04-03T19:54:00.863873: step 10135, loss 0.1001, acc 0.984375\n",
      "2017-04-03T19:54:01.069254: step 10136, loss 0.252635, acc 0.90625\n",
      "2017-04-03T19:54:01.281794: step 10137, loss 0.128556, acc 0.96875\n",
      "2017-04-03T19:54:01.493488: step 10138, loss 0.10794, acc 0.984375\n",
      "2017-04-03T19:54:01.696593: step 10139, loss 0.29202, acc 0.921875\n",
      "2017-04-03T19:54:01.918523: step 10140, loss 0.175982, acc 0.953125\n",
      "2017-04-03T19:54:02.130536: step 10141, loss 0.198081, acc 0.953125\n",
      "2017-04-03T19:54:02.347599: step 10142, loss 0.178148, acc 0.953125\n",
      "2017-04-03T19:54:02.549053: step 10143, loss 0.353653, acc 0.921875\n",
      "2017-04-03T19:54:02.756177: step 10144, loss 0.203105, acc 0.953125\n",
      "2017-04-03T19:54:02.958369: step 10145, loss 0.265863, acc 0.90625\n",
      "2017-04-03T19:54:03.159794: step 10146, loss 0.0848114, acc 0.984375\n",
      "2017-04-03T19:54:03.373868: step 10147, loss 0.0893973, acc 0.984375\n",
      "2017-04-03T19:54:03.574226: step 10148, loss 0.271091, acc 0.890625\n",
      "2017-04-03T19:54:03.819841: step 10149, loss 0.185611, acc 0.953125\n",
      "2017-04-03T19:54:04.030005: step 10150, loss 0.142677, acc 0.96875\n",
      "2017-04-03T19:54:04.245399: step 10151, loss 0.345699, acc 0.875\n",
      "2017-04-03T19:54:04.451236: step 10152, loss 0.311537, acc 0.875\n",
      "2017-04-03T19:54:04.654995: step 10153, loss 0.193983, acc 0.90625\n",
      "2017-04-03T19:54:04.861990: step 10154, loss 0.162873, acc 0.96875\n",
      "2017-04-03T19:54:05.065352: step 10155, loss 0.211801, acc 0.921875\n",
      "2017-04-03T19:54:05.265949: step 10156, loss 0.247841, acc 0.9375\n",
      "2017-04-03T19:54:05.472752: step 10157, loss 0.332356, acc 0.875\n",
      "2017-04-03T19:54:05.680079: step 10158, loss 0.17034, acc 0.953125\n",
      "2017-04-03T19:54:05.885499: step 10159, loss 0.0601148, acc 0.984375\n",
      "2017-04-03T19:54:06.088087: step 10160, loss 0.135971, acc 0.984375\n",
      "2017-04-03T19:54:06.296991: step 10161, loss 0.287174, acc 0.984375\n",
      "2017-04-03T19:54:06.499795: step 10162, loss 0.2148, acc 0.9375\n",
      "2017-04-03T19:54:06.712346: step 10163, loss 0.256498, acc 0.9375\n",
      "2017-04-03T19:54:06.961996: step 10164, loss 0.207082, acc 0.953125\n",
      "2017-04-03T19:54:07.166808: step 10165, loss 0.354804, acc 0.890625\n",
      "2017-04-03T19:54:07.370857: step 10166, loss 0.192725, acc 0.90625\n",
      "2017-04-03T19:54:07.574477: step 10167, loss 0.152125, acc 0.9375\n",
      "2017-04-03T19:54:07.779502: step 10168, loss 0.373695, acc 0.90625\n",
      "2017-04-03T19:54:07.979787: step 10169, loss 0.101163, acc 0.96875\n",
      "2017-04-03T19:54:08.197521: step 10170, loss 0.168326, acc 0.96875\n",
      "2017-04-03T19:54:08.416749: step 10171, loss 0.174629, acc 0.9375\n",
      "2017-04-03T19:54:08.624676: step 10172, loss 0.163944, acc 0.953125\n",
      "2017-04-03T19:54:08.827911: step 10173, loss 0.167734, acc 0.953125\n",
      "2017-04-03T19:54:09.033540: step 10174, loss 0.135652, acc 0.984375\n",
      "2017-04-03T19:54:09.240084: step 10175, loss 0.129208, acc 0.9375\n",
      "2017-04-03T19:54:09.442027: step 10176, loss 0.165441, acc 0.9375\n",
      "2017-04-03T19:54:09.650628: step 10177, loss 0.144105, acc 0.953125\n",
      "2017-04-03T19:54:09.892264: step 10178, loss 0.245234, acc 0.953125\n",
      "2017-04-03T19:54:10.102304: step 10179, loss 0.296446, acc 0.875\n",
      "2017-04-03T19:54:10.310486: step 10180, loss 0.188993, acc 0.90625\n",
      "2017-04-03T19:54:10.513399: step 10181, loss 0.275879, acc 0.875\n",
      "2017-04-03T19:54:10.725510: step 10182, loss 0.209069, acc 0.90625\n",
      "2017-04-03T19:54:10.932097: step 10183, loss 0.227102, acc 0.9375\n",
      "2017-04-03T19:54:11.149725: step 10184, loss 0.276998, acc 0.890625\n",
      "2017-04-03T19:54:11.352367: step 10185, loss 0.0906796, acc 0.984375\n",
      "2017-04-03T19:54:11.556903: step 10186, loss 0.17514, acc 0.9375\n",
      "2017-04-03T19:54:11.756380: step 10187, loss 0.23817, acc 0.90625\n",
      "2017-04-03T19:54:11.961159: step 10188, loss 0.271996, acc 0.90625\n",
      "2017-04-03T19:54:12.169924: step 10189, loss 0.183724, acc 0.953125\n",
      "2017-04-03T19:54:12.415642: step 10190, loss 0.164042, acc 0.9375\n",
      "2017-04-03T19:54:12.620063: step 10191, loss 0.287077, acc 0.90625\n",
      "2017-04-03T19:54:12.826310: step 10192, loss 0.262129, acc 0.890625\n",
      "2017-04-03T19:54:13.026649: step 10193, loss 0.0621745, acc 1\n",
      "2017-04-03T19:54:13.233608: step 10194, loss 0.302013, acc 0.90625\n",
      "2017-04-03T19:54:13.484801: step 10195, loss 0.224956, acc 0.9375\n",
      "2017-04-03T19:54:13.695052: step 10196, loss 0.365288, acc 0.890625\n",
      "2017-04-03T19:54:13.901098: step 10197, loss 0.152072, acc 0.953125\n",
      "2017-04-03T19:54:14.101862: step 10198, loss 0.139586, acc 0.953125\n",
      "2017-04-03T19:54:14.310932: step 10199, loss 0.200117, acc 0.953125\n",
      "2017-04-03T19:54:14.513021: step 10200, loss 0.149892, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:54:16.640671: step 10200, loss 4.29382, acc 0.30125\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-10200\n",
      "\n",
      "2017-04-03T19:54:17.014366: step 10201, loss 0.254922, acc 0.9375\n",
      "2017-04-03T19:54:17.218053: step 10202, loss 0.22535, acc 0.90625\n",
      "2017-04-03T19:54:17.413306: step 10203, loss 0.175044, acc 0.953125\n",
      "2017-04-03T19:54:17.628753: step 10204, loss 0.143809, acc 0.953125\n",
      "2017-04-03T19:54:17.832508: step 10205, loss 0.167465, acc 0.96875\n",
      "2017-04-03T19:54:18.038183: step 10206, loss 0.257661, acc 0.90625\n",
      "2017-04-03T19:54:18.284134: step 10207, loss 0.419024, acc 0.890625\n",
      "2017-04-03T19:54:18.488990: step 10208, loss 0.136631, acc 0.953125\n",
      "2017-04-03T19:54:18.700097: step 10209, loss 0.340372, acc 0.921875\n",
      "2017-04-03T19:54:18.906762: step 10210, loss 0.267765, acc 0.921875\n",
      "2017-04-03T19:54:19.118256: step 10211, loss 0.192058, acc 0.953125\n",
      "2017-04-03T19:54:19.321918: step 10212, loss 0.140183, acc 0.953125\n",
      "2017-04-03T19:54:19.568224: step 10213, loss 0.249042, acc 0.90625\n",
      "2017-04-03T19:54:19.806508: step 10214, loss 0.106422, acc 0.984375\n",
      "2017-04-03T19:54:20.013451: step 10215, loss 0.157944, acc 0.953125\n",
      "2017-04-03T19:54:20.216130: step 10216, loss 0.386994, acc 0.90625\n",
      "2017-04-03T19:54:20.421061: step 10217, loss 0.19657, acc 0.921875\n",
      "2017-04-03T19:54:20.625914: step 10218, loss 0.114078, acc 0.984375\n",
      "2017-04-03T19:54:20.825858: step 10219, loss 0.27776, acc 0.90625\n",
      "2017-04-03T19:54:21.039054: step 10220, loss 0.192497, acc 0.921875\n",
      "2017-04-03T19:54:21.243229: step 10221, loss 0.247456, acc 0.90625\n",
      "2017-04-03T19:54:21.446525: step 10222, loss 0.144557, acc 0.953125\n",
      "2017-04-03T19:54:21.646596: step 10223, loss 0.202842, acc 0.9375\n",
      "2017-04-03T19:54:21.850390: step 10224, loss 0.166528, acc 0.921875\n",
      "2017-04-03T19:54:22.058283: step 10225, loss 0.110538, acc 0.984375\n",
      "2017-04-03T19:54:22.260051: step 10226, loss 0.244341, acc 0.921875\n",
      "2017-04-03T19:54:22.462169: step 10227, loss 0.227793, acc 0.9375\n",
      "2017-04-03T19:54:22.667560: step 10228, loss 0.13408, acc 0.953125\n",
      "2017-04-03T19:54:22.872472: step 10229, loss 0.211045, acc 0.9375\n",
      "2017-04-03T19:54:23.080989: step 10230, loss 0.269596, acc 0.90625\n",
      "2017-04-03T19:54:23.289465: step 10231, loss 0.139202, acc 0.9375\n",
      "2017-04-03T19:54:23.494367: step 10232, loss 0.219461, acc 0.9375\n",
      "2017-04-03T19:54:23.702924: step 10233, loss 0.239065, acc 0.9375\n",
      "2017-04-03T19:54:23.902271: step 10234, loss 0.325826, acc 0.921875\n",
      "2017-04-03T19:54:24.111019: step 10235, loss 0.286162, acc 0.890625\n",
      "2017-04-03T19:54:24.357065: step 10236, loss 0.292365, acc 0.90625\n",
      "2017-04-03T19:54:24.568190: step 10237, loss 0.20796, acc 0.9375\n",
      "2017-04-03T19:54:24.772505: step 10238, loss 0.240417, acc 0.90625\n",
      "2017-04-03T19:54:24.977522: step 10239, loss 0.26417, acc 0.90625\n",
      "2017-04-03T19:54:25.226188: step 10240, loss 0.224062, acc 0.921875\n",
      "2017-04-03T19:54:25.449717: step 10241, loss 0.210501, acc 0.9375\n",
      "2017-04-03T19:54:25.699142: step 10242, loss 0.16742, acc 0.921875\n",
      "2017-04-03T19:54:25.897773: step 10243, loss 0.250335, acc 0.890625\n",
      "2017-04-03T19:54:26.098852: step 10244, loss 0.138067, acc 0.96875\n",
      "2017-04-03T19:54:26.344453: step 10245, loss 0.103833, acc 0.96875\n",
      "2017-04-03T19:54:26.544086: step 10246, loss 0.126214, acc 0.96875\n",
      "2017-04-03T19:54:26.745237: step 10247, loss 0.220525, acc 0.9375\n",
      "2017-04-03T19:54:26.948963: step 10248, loss 0.13826, acc 0.96875\n",
      "2017-04-03T19:54:27.152791: step 10249, loss 0.216203, acc 0.921875\n",
      "2017-04-03T19:54:27.354655: step 10250, loss 0.152305, acc 0.953125\n",
      "2017-04-03T19:54:27.565897: step 10251, loss 0.230891, acc 0.90625\n",
      "2017-04-03T19:54:27.766107: step 10252, loss 0.152675, acc 0.953125\n",
      "2017-04-03T19:54:27.970614: step 10253, loss 0.0940407, acc 0.96875\n",
      "2017-04-03T19:54:28.175187: step 10254, loss 0.165199, acc 0.9375\n",
      "2017-04-03T19:54:28.377020: step 10255, loss 0.353937, acc 0.890625\n",
      "2017-04-03T19:54:28.617393: step 10256, loss 0.179701, acc 0.953125\n",
      "2017-04-03T19:54:28.824466: step 10257, loss 0.223337, acc 0.9375\n",
      "2017-04-03T19:54:29.024183: step 10258, loss 0.214253, acc 0.953125\n",
      "2017-04-03T19:54:29.266583: step 10259, loss 0.20692, acc 0.921875\n",
      "2017-04-03T19:54:29.473279: step 10260, loss 0.216698, acc 0.921875\n",
      "2017-04-03T19:54:29.685037: step 10261, loss 0.113236, acc 0.96875\n",
      "2017-04-03T19:54:29.900664: step 10262, loss 0.186233, acc 0.921875\n",
      "2017-04-03T19:54:30.106786: step 10263, loss 0.192261, acc 0.9375\n",
      "2017-04-03T19:54:30.317084: step 10264, loss 0.129593, acc 0.953125\n",
      "2017-04-03T19:54:30.544573: step 10265, loss 0.15963, acc 0.9375\n",
      "2017-04-03T19:54:30.772678: step 10266, loss 0.191078, acc 0.96875\n",
      "2017-04-03T19:54:30.990023: step 10267, loss 0.191487, acc 0.96875\n",
      "2017-04-03T19:54:31.190962: step 10268, loss 0.284239, acc 0.84375\n",
      "2017-04-03T19:54:31.391382: step 10269, loss 0.180674, acc 0.9375\n",
      "2017-04-03T19:54:31.592633: step 10270, loss 0.255572, acc 0.921875\n",
      "2017-04-03T19:54:31.796842: step 10271, loss 0.417801, acc 0.90625\n",
      "2017-04-03T19:54:31.998967: step 10272, loss 0.318617, acc 0.875\n",
      "2017-04-03T19:54:32.242158: step 10273, loss 0.13556, acc 0.953125\n",
      "2017-04-03T19:54:32.448289: step 10274, loss 0.302965, acc 0.90625\n",
      "2017-04-03T19:54:32.688496: step 10275, loss 0.225704, acc 0.921875\n",
      "2017-04-03T19:54:32.935340: step 10276, loss 0.239962, acc 0.890625\n",
      "2017-04-03T19:54:33.138736: step 10277, loss 0.158805, acc 0.953125\n",
      "2017-04-03T19:54:33.337431: step 10278, loss 0.186823, acc 0.921875\n",
      "2017-04-03T19:54:33.541700: step 10279, loss 0.13368, acc 0.96875\n",
      "2017-04-03T19:54:33.748166: step 10280, loss 0.165914, acc 0.9375\n",
      "2017-04-03T19:54:33.951983: step 10281, loss 0.207069, acc 0.9375\n",
      "2017-04-03T19:54:34.213667: step 10282, loss 0.18388, acc 0.953125\n",
      "2017-04-03T19:54:34.411616: step 10283, loss 0.281741, acc 0.859375\n",
      "2017-04-03T19:54:34.611146: step 10284, loss 0.222497, acc 0.953125\n",
      "2017-04-03T19:54:34.851301: step 10285, loss 0.115043, acc 0.96875\n",
      "2017-04-03T19:54:35.063211: step 10286, loss 0.0991788, acc 0.953125\n",
      "2017-04-03T19:54:35.276344: step 10287, loss 0.142243, acc 0.953125\n",
      "2017-04-03T19:54:35.472134: step 10288, loss 0.18976, acc 0.90625\n",
      "2017-04-03T19:54:35.676024: step 10289, loss 0.286909, acc 0.921875\n",
      "2017-04-03T19:54:35.876048: step 10290, loss 0.167015, acc 0.953125\n",
      "2017-04-03T19:54:36.129987: step 10291, loss 0.245013, acc 0.90625\n",
      "2017-04-03T19:54:36.331118: step 10292, loss 0.238519, acc 0.921875\n",
      "2017-04-03T19:54:36.532701: step 10293, loss 0.415495, acc 0.859375\n",
      "2017-04-03T19:54:36.758952: step 10294, loss 0.222408, acc 0.953125\n",
      "2017-04-03T19:54:36.970780: step 10295, loss 0.0731941, acc 0.984375\n",
      "2017-04-03T19:54:37.177248: step 10296, loss 0.09277, acc 0.96875\n",
      "2017-04-03T19:54:37.377208: step 10297, loss 0.17132, acc 0.90625\n",
      "2017-04-03T19:54:37.577750: step 10298, loss 0.0929419, acc 0.984375\n",
      "2017-04-03T19:54:37.779117: step 10299, loss 0.231962, acc 0.90625\n",
      "2017-04-03T19:54:37.984379: step 10300, loss 0.174745, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:54:40.176056: step 10300, loss 4.34507, acc 0.309\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-10300\n",
      "\n",
      "2017-04-03T19:54:40.551601: step 10301, loss 0.341852, acc 0.890625\n",
      "2017-04-03T19:54:40.754856: step 10302, loss 0.249592, acc 0.921875\n",
      "2017-04-03T19:54:40.960379: step 10303, loss 0.220433, acc 0.9375\n",
      "2017-04-03T19:54:41.206613: step 10304, loss 0.323814, acc 0.875\n",
      "2017-04-03T19:54:41.409248: step 10305, loss 0.218838, acc 0.953125\n",
      "2017-04-03T19:54:41.614111: step 10306, loss 0.208205, acc 0.9375\n",
      "2017-04-03T19:54:41.855064: step 10307, loss 0.137393, acc 0.984375\n",
      "2017-04-03T19:54:42.058498: step 10308, loss 0.386239, acc 0.921875\n",
      "2017-04-03T19:54:42.267760: step 10309, loss 0.225069, acc 0.921875\n",
      "2017-04-03T19:54:42.473377: step 10310, loss 0.413971, acc 0.890625\n",
      "2017-04-03T19:54:42.721423: step 10311, loss 0.204806, acc 0.953125\n",
      "2017-04-03T19:54:42.921168: step 10312, loss 0.473521, acc 0.84375\n",
      "2017-04-03T19:54:43.120501: step 10313, loss 0.190837, acc 0.96875\n",
      "2017-04-03T19:54:43.317956: step 10314, loss 0.127684, acc 0.96875\n",
      "2017-04-03T19:54:43.525379: step 10315, loss 0.24377, acc 0.9375\n",
      "2017-04-03T19:54:43.736093: step 10316, loss 0.274737, acc 0.90625\n",
      "2017-04-03T19:54:43.944380: step 10317, loss 0.180927, acc 0.9375\n",
      "2017-04-03T19:54:44.151647: step 10318, loss 0.118943, acc 0.9375\n",
      "2017-04-03T19:54:44.352614: step 10319, loss 0.303526, acc 0.921875\n",
      "2017-04-03T19:54:44.599621: step 10320, loss 0.134932, acc 0.953125\n",
      "2017-04-03T19:54:44.800065: step 10321, loss 0.210582, acc 0.921875\n",
      "2017-04-03T19:54:45.003413: step 10322, loss 0.18296, acc 0.96875\n",
      "2017-04-03T19:54:45.214182: step 10323, loss 0.26289, acc 0.890625\n",
      "2017-04-03T19:54:45.460742: step 10324, loss 0.190271, acc 0.96875\n",
      "2017-04-03T19:54:45.662437: step 10325, loss 0.182909, acc 0.9375\n",
      "2017-04-03T19:54:45.904489: step 10326, loss 0.179263, acc 0.9375\n",
      "2017-04-03T19:54:46.107243: step 10327, loss 0.190607, acc 0.953125\n",
      "2017-04-03T19:54:46.346991: step 10328, loss 0.201366, acc 0.921875\n",
      "2017-04-03T19:54:46.552319: step 10329, loss 0.238806, acc 0.953125\n",
      "2017-04-03T19:54:46.775307: step 10330, loss 0.188738, acc 0.96875\n",
      "2017-04-03T19:54:46.976287: step 10331, loss 0.259381, acc 0.921875\n",
      "2017-04-03T19:54:47.188742: step 10332, loss 0.31071, acc 0.875\n",
      "2017-04-03T19:54:47.390062: step 10333, loss 0.411623, acc 0.859375\n",
      "2017-04-03T19:54:47.592134: step 10334, loss 0.197191, acc 0.9375\n",
      "2017-04-03T19:54:47.793743: step 10335, loss 0.187771, acc 0.921875\n",
      "2017-04-03T19:54:47.997395: step 10336, loss 0.357917, acc 0.859375\n",
      "2017-04-03T19:54:48.201776: step 10337, loss 0.195752, acc 0.921875\n",
      "2017-04-03T19:54:48.402351: step 10338, loss 0.218971, acc 0.984375\n",
      "2017-04-03T19:54:48.607478: step 10339, loss 0.187303, acc 0.9375\n",
      "2017-04-03T19:54:48.809722: step 10340, loss 0.218905, acc 0.9375\n",
      "2017-04-03T19:54:49.010295: step 10341, loss 0.154255, acc 0.953125\n",
      "2017-04-03T19:54:49.211953: step 10342, loss 0.327008, acc 0.90625\n",
      "2017-04-03T19:54:49.418163: step 10343, loss 0.303551, acc 0.859375\n",
      "2017-04-03T19:54:49.621193: step 10344, loss 0.212104, acc 0.9375\n",
      "2017-04-03T19:54:49.824130: step 10345, loss 0.236046, acc 0.90625\n",
      "2017-04-03T19:54:50.023971: step 10346, loss 0.134206, acc 0.96875\n",
      "2017-04-03T19:54:50.231525: step 10347, loss 0.190636, acc 0.90625\n",
      "2017-04-03T19:54:50.432968: step 10348, loss 0.121457, acc 0.96875\n",
      "2017-04-03T19:54:50.637065: step 10349, loss 0.276391, acc 0.859375\n",
      "2017-04-03T19:54:50.842577: step 10350, loss 0.246055, acc 0.96875\n",
      "2017-04-03T19:54:51.050037: step 10351, loss 0.331991, acc 0.90625\n",
      "2017-04-03T19:54:51.253787: step 10352, loss 0.0972469, acc 0.953125\n",
      "2017-04-03T19:54:51.456442: step 10353, loss 0.45726, acc 0.953125\n",
      "2017-04-03T19:54:51.653036: step 10354, loss 0.221038, acc 0.921875\n",
      "2017-04-03T19:54:51.861243: step 10355, loss 0.196478, acc 0.953125\n",
      "2017-04-03T19:54:52.070331: step 10356, loss 0.305961, acc 0.921875\n",
      "2017-04-03T19:54:52.271816: step 10357, loss 0.407509, acc 0.890625\n",
      "2017-04-03T19:54:52.472482: step 10358, loss 0.181357, acc 0.9375\n",
      "2017-04-03T19:54:52.671620: step 10359, loss 0.25362, acc 0.875\n",
      "2017-04-03T19:54:52.881966: step 10360, loss 0.225409, acc 0.953125\n",
      "2017-04-03T19:54:53.081421: step 10361, loss 0.23818, acc 0.90625\n",
      "2017-04-03T19:54:53.296183: step 10362, loss 0.298172, acc 0.921875\n",
      "2017-04-03T19:54:53.495206: step 10363, loss 0.27448, acc 0.921875\n",
      "2017-04-03T19:54:53.738079: step 10364, loss 0.264102, acc 0.921875\n",
      "2017-04-03T19:54:53.940152: step 10365, loss 0.161766, acc 0.921875\n",
      "2017-04-03T19:54:54.145147: step 10366, loss 0.260172, acc 0.890625\n",
      "2017-04-03T19:54:54.349837: step 10367, loss 0.167073, acc 0.953125\n",
      "2017-04-03T19:54:54.548101: step 10368, loss 0.385451, acc 0.875\n",
      "2017-04-03T19:54:54.762813: step 10369, loss 0.221502, acc 0.890625\n",
      "2017-04-03T19:54:54.961688: step 10370, loss 0.397632, acc 0.890625\n",
      "2017-04-03T19:54:55.163901: step 10371, loss 0.237187, acc 0.90625\n",
      "2017-04-03T19:54:55.364568: step 10372, loss 0.169895, acc 0.96875\n",
      "2017-04-03T19:54:55.567132: step 10373, loss 0.195881, acc 0.96875\n",
      "2017-04-03T19:54:55.769291: step 10374, loss 0.176678, acc 0.953125\n",
      "2017-04-03T19:54:55.968452: step 10375, loss 0.349204, acc 0.859375\n",
      "2017-04-03T19:54:56.169213: step 10376, loss 0.343106, acc 0.921875\n",
      "2017-04-03T19:54:56.370872: step 10377, loss 0.283829, acc 0.890625\n",
      "2017-04-03T19:54:56.574354: step 10378, loss 0.152225, acc 0.953125\n",
      "2017-04-03T19:54:56.775831: step 10379, loss 0.266368, acc 0.90625\n",
      "2017-04-03T19:54:56.972782: step 10380, loss 0.124001, acc 0.953125\n",
      "2017-04-03T19:54:57.174034: step 10381, loss 0.199126, acc 0.890625\n",
      "2017-04-03T19:54:57.377793: step 10382, loss 0.288847, acc 0.9375\n",
      "2017-04-03T19:54:57.582897: step 10383, loss 0.142557, acc 0.984375\n",
      "2017-04-03T19:54:57.783856: step 10384, loss 0.244348, acc 0.9375\n",
      "2017-04-03T19:54:57.983348: step 10385, loss 0.245362, acc 0.921875\n",
      "2017-04-03T19:54:58.184816: step 10386, loss 0.136717, acc 0.953125\n",
      "2017-04-03T19:54:58.385502: step 10387, loss 0.105408, acc 0.96875\n",
      "2017-04-03T19:54:58.589439: step 10388, loss 0.243259, acc 0.90625\n",
      "2017-04-03T19:54:58.791859: step 10389, loss 0.2326, acc 0.9375\n",
      "2017-04-03T19:54:58.995840: step 10390, loss 0.294096, acc 0.953125\n",
      "2017-04-03T19:54:59.195525: step 10391, loss 0.373254, acc 0.90625\n",
      "2017-04-03T19:54:59.395605: step 10392, loss 0.311279, acc 0.90625\n",
      "2017-04-03T19:54:59.600198: step 10393, loss 0.117788, acc 0.984375\n",
      "2017-04-03T19:54:59.803000: step 10394, loss 0.270269, acc 0.921875\n",
      "2017-04-03T19:55:00.007275: step 10395, loss 0.26105, acc 0.875\n",
      "2017-04-03T19:55:00.211043: step 10396, loss 0.125795, acc 0.984375\n",
      "2017-04-03T19:55:00.463411: step 10397, loss 0.35519, acc 0.859375\n",
      "2017-04-03T19:55:00.676394: step 10398, loss 0.416009, acc 0.890625\n",
      "2017-04-03T19:55:00.891712: step 10399, loss 0.194671, acc 0.921875\n",
      "2017-04-03T19:55:01.091986: step 10400, loss 0.185446, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:55:03.189563: step 10400, loss 4.36649, acc 0.29975\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-10400\n",
      "\n",
      "2017-04-03T19:55:03.527488: step 10401, loss 0.207226, acc 0.90625\n",
      "2017-04-03T19:55:03.730163: step 10402, loss 0.193045, acc 0.953125\n",
      "2017-04-03T19:55:03.932273: step 10403, loss 0.21117, acc 0.921875\n",
      "2017-04-03T19:55:04.132612: step 10404, loss 0.425939, acc 0.921875\n",
      "2017-04-03T19:55:04.331756: step 10405, loss 0.101917, acc 0.953125\n",
      "2017-04-03T19:55:04.581643: step 10406, loss 0.185245, acc 0.90625\n",
      "2017-04-03T19:55:04.786212: step 10407, loss 0.124106, acc 0.96875\n",
      "2017-04-03T19:55:04.989932: step 10408, loss 0.185262, acc 0.96875\n",
      "2017-04-03T19:55:05.192117: step 10409, loss 0.169841, acc 0.953125\n",
      "2017-04-03T19:55:05.396995: step 10410, loss 0.141351, acc 0.953125\n",
      "2017-04-03T19:55:05.599196: step 10411, loss 0.279421, acc 0.953125\n",
      "2017-04-03T19:55:05.810966: step 10412, loss 0.104708, acc 0.984375\n",
      "2017-04-03T19:55:06.019795: step 10413, loss 0.185713, acc 0.9375\n",
      "2017-04-03T19:55:06.222961: step 10414, loss 0.27453, acc 0.9375\n",
      "2017-04-03T19:55:06.421508: step 10415, loss 0.34583, acc 0.90625\n",
      "2017-04-03T19:55:06.622739: step 10416, loss 0.230832, acc 0.890625\n",
      "2017-04-03T19:55:06.823236: step 10417, loss 0.255722, acc 0.953125\n",
      "2017-04-03T19:55:07.023220: step 10418, loss 0.190302, acc 0.953125\n",
      "2017-04-03T19:55:07.222073: step 10419, loss 0.317378, acc 0.921875\n",
      "2017-04-03T19:55:07.423677: step 10420, loss 0.262956, acc 0.875\n",
      "2017-04-03T19:55:07.624107: step 10421, loss 0.149316, acc 0.953125\n",
      "2017-04-03T19:55:07.846763: step 10422, loss 0.260502, acc 0.890625\n",
      "2017-04-03T19:55:08.051035: step 10423, loss 0.538054, acc 0.859375\n",
      "2017-04-03T19:55:08.251010: step 10424, loss 0.17291, acc 0.953125\n",
      "2017-04-03T19:55:08.452695: step 10425, loss 0.229078, acc 0.9375\n",
      "2017-04-03T19:55:08.652008: step 10426, loss 0.0970413, acc 1\n",
      "2017-04-03T19:55:08.856204: step 10427, loss 0.289584, acc 0.921875\n",
      "2017-04-03T19:55:09.055144: step 10428, loss 0.278387, acc 0.9375\n",
      "2017-04-03T19:55:09.259697: step 10429, loss 0.251145, acc 0.9375\n",
      "2017-04-03T19:55:09.458268: step 10430, loss 0.0945616, acc 0.96875\n",
      "2017-04-03T19:55:09.660909: step 10431, loss 0.271341, acc 0.90625\n",
      "2017-04-03T19:55:09.864206: step 10432, loss 0.187195, acc 0.96875\n",
      "2017-04-03T19:55:10.068153: step 10433, loss 0.273017, acc 0.90625\n",
      "2017-04-03T19:55:10.272743: step 10434, loss 0.314186, acc 0.921875\n",
      "2017-04-03T19:55:10.474559: step 10435, loss 0.169296, acc 0.953125\n",
      "2017-04-03T19:55:10.673913: step 10436, loss 0.188038, acc 0.921875\n",
      "2017-04-03T19:55:10.881008: step 10437, loss 0.171933, acc 0.953125\n",
      "2017-04-03T19:55:11.088172: step 10438, loss 0.24917, acc 0.890625\n",
      "2017-04-03T19:55:11.297461: step 10439, loss 0.167506, acc 0.96875\n",
      "2017-04-03T19:55:11.508725: step 10440, loss 0.248668, acc 0.921875\n",
      "2017-04-03T19:55:11.713621: step 10441, loss 0.249478, acc 0.921875\n",
      "2017-04-03T19:55:11.915232: step 10442, loss 0.223327, acc 0.890625\n",
      "2017-04-03T19:55:12.117421: step 10443, loss 0.153535, acc 0.9375\n",
      "2017-04-03T19:55:12.319394: step 10444, loss 0.199925, acc 0.9375\n",
      "2017-04-03T19:55:12.518676: step 10445, loss 0.428018, acc 0.84375\n",
      "2017-04-03T19:55:12.746367: step 10446, loss 0.170551, acc 0.953125\n",
      "2017-04-03T19:55:12.958147: step 10447, loss 0.258884, acc 0.90625\n",
      "2017-04-03T19:55:13.159208: step 10448, loss 0.223327, acc 0.921875\n",
      "2017-04-03T19:55:13.367658: step 10449, loss 0.163866, acc 0.953125\n",
      "2017-04-03T19:55:13.569132: step 10450, loss 0.271647, acc 0.890625\n",
      "2017-04-03T19:55:13.769764: step 10451, loss 0.154481, acc 0.9375\n",
      "2017-04-03T19:55:13.970817: step 10452, loss 0.217089, acc 0.90625\n",
      "2017-04-03T19:55:14.175606: step 10453, loss 0.364647, acc 0.859375\n",
      "2017-04-03T19:55:14.375294: step 10454, loss 0.253072, acc 0.90625\n",
      "2017-04-03T19:55:14.581633: step 10455, loss 0.310076, acc 0.890625\n",
      "2017-04-03T19:55:14.793949: step 10456, loss 0.146155, acc 0.984375\n",
      "2017-04-03T19:55:14.996373: step 10457, loss 0.233057, acc 0.921875\n",
      "2017-04-03T19:55:15.199515: step 10458, loss 0.37605, acc 0.890625\n",
      "2017-04-03T19:55:15.405652: step 10459, loss 0.242354, acc 0.953125\n",
      "2017-04-03T19:55:15.618552: step 10460, loss 0.271575, acc 0.890625\n",
      "2017-04-03T19:55:15.817058: step 10461, loss 0.252468, acc 0.921875\n",
      "2017-04-03T19:55:16.026092: step 10462, loss 0.237747, acc 0.96875\n",
      "2017-04-03T19:55:16.232324: step 10463, loss 0.444968, acc 0.921875\n",
      "2017-04-03T19:55:16.481834: step 10464, loss 0.321891, acc 0.921875\n",
      "2017-04-03T19:55:16.685252: step 10465, loss 0.373038, acc 0.84375\n",
      "2017-04-03T19:55:16.887336: step 10466, loss 0.1789, acc 0.96875\n",
      "2017-04-03T19:55:17.093842: step 10467, loss 0.229525, acc 0.90625\n",
      "2017-04-03T19:55:17.294121: step 10468, loss 0.255905, acc 0.921875\n",
      "2017-04-03T19:55:17.495557: step 10469, loss 0.316452, acc 0.90625\n",
      "2017-04-03T19:55:17.698631: step 10470, loss 0.141589, acc 0.953125\n",
      "2017-04-03T19:55:17.906981: step 10471, loss 0.149868, acc 0.953125\n",
      "2017-04-03T19:55:18.109477: step 10472, loss 0.177592, acc 0.9375\n",
      "2017-04-03T19:55:18.309140: step 10473, loss 0.295921, acc 0.921875\n",
      "2017-04-03T19:55:18.501971: step 10474, loss 0.170678, acc 0.90625\n",
      "2017-04-03T19:55:18.701975: step 10475, loss 0.189775, acc 0.953125\n",
      "2017-04-03T19:55:18.904914: step 10476, loss 0.340868, acc 0.90625\n",
      "2017-04-03T19:55:19.149173: step 10477, loss 0.225808, acc 0.921875\n",
      "2017-04-03T19:55:19.353727: step 10478, loss 0.268503, acc 0.921875\n",
      "2017-04-03T19:55:19.561519: step 10479, loss 0.170272, acc 0.9375\n",
      "2017-04-03T19:55:19.767061: step 10480, loss 0.229935, acc 0.90625\n",
      "2017-04-03T19:55:20.011074: step 10481, loss 0.180382, acc 0.9375\n",
      "2017-04-03T19:55:20.220066: step 10482, loss 0.227066, acc 0.953125\n",
      "2017-04-03T19:55:20.427739: step 10483, loss 0.330022, acc 0.875\n",
      "2017-04-03T19:55:20.629654: step 10484, loss 0.132851, acc 0.953125\n",
      "2017-04-03T19:55:20.837961: step 10485, loss 0.168658, acc 0.9375\n",
      "2017-04-03T19:55:21.040581: step 10486, loss 0.299442, acc 0.90625\n",
      "2017-04-03T19:55:21.248424: step 10487, loss 0.324044, acc 0.890625\n",
      "2017-04-03T19:55:21.459711: step 10488, loss 0.302911, acc 0.90625\n",
      "2017-04-03T19:55:21.659969: step 10489, loss 0.297132, acc 0.890625\n",
      "2017-04-03T19:55:21.863467: step 10490, loss 0.173857, acc 0.953125\n",
      "2017-04-03T19:55:22.064505: step 10491, loss 0.0837529, acc 0.953125\n",
      "2017-04-03T19:55:22.271528: step 10492, loss 0.27237, acc 0.890625\n",
      "2017-04-03T19:55:22.473812: step 10493, loss 0.285376, acc 0.90625\n",
      "2017-04-03T19:55:22.671313: step 10494, loss 0.218837, acc 0.90625\n",
      "2017-04-03T19:55:22.878206: step 10495, loss 0.200923, acc 0.953125\n",
      "2017-04-03T19:55:23.084979: step 10496, loss 0.104456, acc 0.96875\n",
      "2017-04-03T19:55:23.285690: step 10497, loss 0.380065, acc 0.890625\n",
      "2017-04-03T19:55:23.491321: step 10498, loss 0.29813, acc 0.921875\n",
      "2017-04-03T19:55:23.695493: step 10499, loss 0.329339, acc 0.890625\n",
      "2017-04-03T19:55:23.898830: step 10500, loss 0.0653149, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:55:26.040637: step 10500, loss 4.35568, acc 0.29\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-10500\n",
      "\n",
      "2017-04-03T19:55:26.412511: step 10501, loss 0.156278, acc 0.9375\n",
      "2017-04-03T19:55:26.619192: step 10502, loss 0.256629, acc 0.921875\n",
      "2017-04-03T19:55:26.857207: step 10503, loss 0.273952, acc 0.890625\n",
      "2017-04-03T19:55:27.085573: step 10504, loss 0.28413, acc 0.96875\n",
      "2017-04-03T19:55:27.292548: step 10505, loss 0.351045, acc 0.875\n",
      "2017-04-03T19:55:27.492724: step 10506, loss 0.230097, acc 0.90625\n",
      "2017-04-03T19:55:27.694310: step 10507, loss 0.201409, acc 0.921875\n",
      "2017-04-03T19:55:27.900125: step 10508, loss 0.327258, acc 0.890625\n",
      "2017-04-03T19:55:28.100864: step 10509, loss 0.247156, acc 0.90625\n",
      "2017-04-03T19:55:28.303131: step 10510, loss 0.184526, acc 0.9375\n",
      "2017-04-03T19:55:28.502213: step 10511, loss 0.401654, acc 0.828125\n",
      "2017-04-03T19:55:28.742630: step 10512, loss 0.209311, acc 0.9375\n",
      "2017-04-03T19:55:28.944925: step 10513, loss 0.194422, acc 0.96875\n",
      "2017-04-03T19:55:29.148198: step 10514, loss 0.20119, acc 0.953125\n",
      "2017-04-03T19:55:29.354542: step 10515, loss 0.389093, acc 0.84375\n",
      "2017-04-03T19:55:29.557620: step 10516, loss 0.338239, acc 0.875\n",
      "2017-04-03T19:55:29.763801: step 10517, loss 0.0907106, acc 0.984375\n",
      "2017-04-03T19:55:29.969141: step 10518, loss 0.186226, acc 0.953125\n",
      "2017-04-03T19:55:30.169516: step 10519, loss 0.159876, acc 0.953125\n",
      "2017-04-03T19:55:30.412379: step 10520, loss 0.0659323, acc 0.96875\n",
      "2017-04-03T19:55:30.617835: step 10521, loss 0.15459, acc 0.953125\n",
      "2017-04-03T19:55:30.827198: step 10522, loss 0.217428, acc 0.9375\n",
      "2017-04-03T19:55:31.037682: step 10523, loss 0.126655, acc 0.9375\n",
      "2017-04-03T19:55:31.237996: step 10524, loss 0.192392, acc 0.953125\n",
      "2017-04-03T19:55:31.448001: step 10525, loss 0.120093, acc 0.953125\n",
      "2017-04-03T19:55:31.652733: step 10526, loss 0.303085, acc 0.875\n",
      "2017-04-03T19:55:31.859607: step 10527, loss 0.267448, acc 0.9375\n",
      "2017-04-03T19:55:32.062288: step 10528, loss 0.25386, acc 0.890625\n",
      "2017-04-03T19:55:32.265206: step 10529, loss 0.236597, acc 0.90625\n",
      "2017-04-03T19:55:32.467863: step 10530, loss 0.133707, acc 0.953125\n",
      "2017-04-03T19:55:32.675330: step 10531, loss 0.220688, acc 0.9375\n",
      "2017-04-03T19:55:32.883365: step 10532, loss 0.168284, acc 0.953125\n",
      "2017-04-03T19:55:33.125285: step 10533, loss 0.224204, acc 0.921875\n",
      "2017-04-03T19:55:33.337197: step 10534, loss 0.263807, acc 0.90625\n",
      "2017-04-03T19:55:33.563278: step 10535, loss 0.347232, acc 0.875\n",
      "2017-04-03T19:55:33.785409: step 10536, loss 0.259108, acc 0.9375\n",
      "2017-04-03T19:55:33.989650: step 10537, loss 0.290345, acc 0.921875\n",
      "2017-04-03T19:55:34.190547: step 10538, loss 0.262735, acc 0.9375\n",
      "2017-04-03T19:55:34.397369: step 10539, loss 0.181132, acc 0.9375\n",
      "2017-04-03T19:55:34.599304: step 10540, loss 0.270704, acc 0.921875\n",
      "2017-04-03T19:55:34.801356: step 10541, loss 0.200014, acc 0.9375\n",
      "2017-04-03T19:55:34.998867: step 10542, loss 0.243703, acc 0.921875\n",
      "2017-04-03T19:55:35.198874: step 10543, loss 0.167924, acc 0.953125\n",
      "2017-04-03T19:55:35.404618: step 10544, loss 0.192831, acc 0.9375\n",
      "2017-04-03T19:55:35.649221: step 10545, loss 0.133152, acc 0.96875\n",
      "2017-04-03T19:55:35.853157: step 10546, loss 0.312766, acc 0.875\n",
      "2017-04-03T19:55:36.075689: step 10547, loss 0.176312, acc 0.953125\n",
      "2017-04-03T19:55:36.281855: step 10548, loss 0.139922, acc 0.9375\n",
      "2017-04-03T19:55:36.484048: step 10549, loss 0.239253, acc 0.921875\n",
      "2017-04-03T19:55:36.689784: step 10550, loss 0.236088, acc 0.90625\n",
      "2017-04-03T19:55:36.896444: step 10551, loss 0.129574, acc 0.953125\n",
      "2017-04-03T19:55:37.098648: step 10552, loss 0.27477, acc 0.890625\n",
      "2017-04-03T19:55:37.297554: step 10553, loss 0.247836, acc 0.90625\n",
      "2017-04-03T19:55:37.500411: step 10554, loss 0.214435, acc 0.9375\n",
      "2017-04-03T19:55:37.711393: step 10555, loss 0.185426, acc 0.953125\n",
      "2017-04-03T19:55:37.914893: step 10556, loss 0.153245, acc 0.9375\n",
      "2017-04-03T19:55:38.161793: step 10557, loss 0.158996, acc 0.953125\n",
      "2017-04-03T19:55:38.371488: step 10558, loss 0.318317, acc 0.9375\n",
      "2017-04-03T19:55:38.573991: step 10559, loss 0.157376, acc 0.953125\n",
      "2017-04-03T19:55:38.778471: step 10560, loss 0.344982, acc 0.921875\n",
      "2017-04-03T19:55:38.982713: step 10561, loss 0.182546, acc 0.9375\n",
      "2017-04-03T19:55:39.187617: step 10562, loss 0.132602, acc 0.953125\n",
      "2017-04-03T19:55:39.431351: step 10563, loss 0.162459, acc 0.921875\n",
      "2017-04-03T19:55:39.640715: step 10564, loss 0.214598, acc 0.9375\n",
      "2017-04-03T19:55:39.846225: step 10565, loss 0.248846, acc 0.953125\n",
      "2017-04-03T19:55:40.092296: step 10566, loss 0.226724, acc 0.90625\n",
      "2017-04-03T19:55:40.300247: step 10567, loss 0.201301, acc 0.921875\n",
      "2017-04-03T19:55:40.501903: step 10568, loss 0.199971, acc 0.921875\n",
      "2017-04-03T19:55:40.706107: step 10569, loss 0.259455, acc 0.9375\n",
      "2017-04-03T19:55:40.908985: step 10570, loss 0.169077, acc 0.9375\n",
      "2017-04-03T19:55:41.160805: step 10571, loss 0.227143, acc 0.953125\n",
      "2017-04-03T19:55:41.374043: step 10572, loss 0.240602, acc 0.90625\n",
      "2017-04-03T19:55:41.574939: step 10573, loss 0.137313, acc 0.96875\n",
      "2017-04-03T19:55:41.775267: step 10574, loss 0.22436, acc 0.890625\n",
      "2017-04-03T19:55:41.976248: step 10575, loss 0.163286, acc 0.953125\n",
      "2017-04-03T19:55:42.178735: step 10576, loss 0.324419, acc 0.90625\n",
      "2017-04-03T19:55:42.381886: step 10577, loss 0.175421, acc 0.953125\n",
      "2017-04-03T19:55:42.583640: step 10578, loss 0.283769, acc 0.890625\n",
      "2017-04-03T19:55:42.796230: step 10579, loss 0.333311, acc 0.875\n",
      "2017-04-03T19:55:43.015836: step 10580, loss 0.108, acc 0.96875\n",
      "2017-04-03T19:55:43.245176: step 10581, loss 0.173241, acc 0.921875\n",
      "2017-04-03T19:55:43.451034: step 10582, loss 0.196642, acc 0.921875\n",
      "2017-04-03T19:55:43.660302: step 10583, loss 0.159786, acc 0.96875\n",
      "2017-04-03T19:55:43.886808: step 10584, loss 0.154763, acc 0.953125\n",
      "2017-04-03T19:55:44.104452: step 10585, loss 0.118954, acc 0.953125\n",
      "2017-04-03T19:55:44.321775: step 10586, loss 0.326694, acc 0.875\n",
      "2017-04-03T19:55:44.543009: step 10587, loss 0.233457, acc 0.953125\n",
      "2017-04-03T19:55:44.749079: step 10588, loss 0.128359, acc 0.953125\n",
      "2017-04-03T19:55:44.952266: step 10589, loss 0.254147, acc 0.921875\n",
      "2017-04-03T19:55:45.161079: step 10590, loss 0.149195, acc 0.96875\n",
      "2017-04-03T19:55:45.367100: step 10591, loss 0.35369, acc 0.8125\n",
      "2017-04-03T19:55:45.571163: step 10592, loss 0.276339, acc 0.875\n",
      "2017-04-03T19:55:45.817030: step 10593, loss 0.273992, acc 0.9375\n",
      "2017-04-03T19:55:46.022647: step 10594, loss 0.197567, acc 0.953125\n",
      "2017-04-03T19:55:46.223260: step 10595, loss 0.229936, acc 0.90625\n",
      "2017-04-03T19:55:46.428744: step 10596, loss 0.231534, acc 0.90625\n",
      "2017-04-03T19:55:46.629680: step 10597, loss 0.146203, acc 0.9375\n",
      "2017-04-03T19:55:46.842159: step 10598, loss 0.14147, acc 0.984375\n",
      "2017-04-03T19:55:47.045831: step 10599, loss 0.449203, acc 0.875\n",
      "2017-04-03T19:55:47.246511: step 10600, loss 0.327256, acc 0.875\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:55:49.406904: step 10600, loss 4.42978, acc 0.2955\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-10600\n",
      "\n",
      "2017-04-03T19:55:49.757343: step 10601, loss 0.310605, acc 0.890625\n",
      "2017-04-03T19:55:49.966344: step 10602, loss 0.169505, acc 0.90625\n",
      "2017-04-03T19:55:50.168884: step 10603, loss 0.182955, acc 0.921875\n",
      "2017-04-03T19:55:50.374762: step 10604, loss 0.190869, acc 0.921875\n",
      "2017-04-03T19:55:50.577795: step 10605, loss 0.326212, acc 0.890625\n",
      "2017-04-03T19:55:50.781027: step 10606, loss 0.290159, acc 0.921875\n",
      "2017-04-03T19:55:50.978034: step 10607, loss 0.208758, acc 0.9375\n",
      "2017-04-03T19:55:51.183484: step 10608, loss 0.218731, acc 0.921875\n",
      "2017-04-03T19:55:51.389940: step 10609, loss 0.311558, acc 0.9375\n",
      "2017-04-03T19:55:51.596362: step 10610, loss 0.202679, acc 0.96875\n",
      "2017-04-03T19:55:51.803863: step 10611, loss 0.17677, acc 0.90625\n",
      "2017-04-03T19:55:52.005150: step 10612, loss 0.27449, acc 0.921875\n",
      "2017-04-03T19:55:52.209183: step 10613, loss 0.249724, acc 0.921875\n",
      "2017-04-03T19:55:52.453658: step 10614, loss 0.209239, acc 0.90625\n",
      "2017-04-03T19:55:52.701673: step 10615, loss 0.177621, acc 0.953125\n",
      "2017-04-03T19:55:52.909546: step 10616, loss 0.144413, acc 0.953125\n",
      "2017-04-03T19:55:53.114594: step 10617, loss 0.305705, acc 0.875\n",
      "2017-04-03T19:55:53.334040: step 10618, loss 0.352235, acc 0.890625\n",
      "2017-04-03T19:55:53.545242: step 10619, loss 0.485339, acc 0.84375\n",
      "2017-04-03T19:55:53.756046: step 10620, loss 0.193778, acc 0.953125\n",
      "2017-04-03T19:55:53.965766: step 10621, loss 0.18994, acc 0.953125\n",
      "2017-04-03T19:55:54.209582: step 10622, loss 0.212363, acc 0.921875\n",
      "2017-04-03T19:55:54.414402: step 10623, loss 0.360868, acc 0.84375\n",
      "2017-04-03T19:55:54.619279: step 10624, loss 0.208494, acc 0.953125\n",
      "2017-04-03T19:55:54.823811: step 10625, loss 0.164046, acc 0.953125\n",
      "2017-04-03T19:55:55.029006: step 10626, loss 0.0990675, acc 0.96875\n",
      "2017-04-03T19:55:55.283193: step 10627, loss 0.264667, acc 0.875\n",
      "2017-04-03T19:55:55.484086: step 10628, loss 0.302605, acc 0.90625\n",
      "2017-04-03T19:55:55.681883: step 10629, loss 0.138708, acc 0.96875\n",
      "2017-04-03T19:55:55.889465: step 10630, loss 0.257431, acc 0.90625\n",
      "2017-04-03T19:55:56.106640: step 10631, loss 0.18906, acc 0.921875\n",
      "2017-04-03T19:55:56.310062: step 10632, loss 0.142166, acc 0.9375\n",
      "2017-04-03T19:55:56.525539: step 10633, loss 0.170481, acc 0.90625\n",
      "2017-04-03T19:55:56.725133: step 10634, loss 0.170606, acc 0.953125\n",
      "2017-04-03T19:55:56.924053: step 10635, loss 0.468117, acc 0.859375\n",
      "2017-04-03T19:55:57.126548: step 10636, loss 0.39839, acc 0.875\n",
      "2017-04-03T19:55:57.326930: step 10637, loss 0.187055, acc 0.953125\n",
      "2017-04-03T19:55:57.530762: step 10638, loss 0.195588, acc 0.9375\n",
      "2017-04-03T19:55:57.734223: step 10639, loss 0.256565, acc 0.9375\n",
      "2017-04-03T19:55:57.938284: step 10640, loss 0.38906, acc 0.8125\n",
      "2017-04-03T19:55:58.146575: step 10641, loss 0.229148, acc 0.90625\n",
      "2017-04-03T19:55:58.350210: step 10642, loss 0.163598, acc 0.9375\n",
      "2017-04-03T19:55:58.554534: step 10643, loss 0.208645, acc 0.921875\n",
      "2017-04-03T19:55:58.756282: step 10644, loss 0.215902, acc 0.953125\n",
      "2017-04-03T19:55:58.968403: step 10645, loss 0.151418, acc 0.953125\n",
      "2017-04-03T19:55:59.189438: step 10646, loss 0.241587, acc 0.921875\n",
      "2017-04-03T19:55:59.404312: step 10647, loss 0.154723, acc 0.96875\n",
      "2017-04-03T19:55:59.613644: step 10648, loss 0.191841, acc 0.9375\n",
      "2017-04-03T19:55:59.815119: step 10649, loss 0.259164, acc 0.875\n",
      "2017-04-03T19:56:00.042107: step 10650, loss 0.322629, acc 0.921875\n",
      "2017-04-03T19:56:00.261044: step 10651, loss 0.126504, acc 0.96875\n",
      "2017-04-03T19:56:00.476547: step 10652, loss 0.330976, acc 0.890625\n",
      "2017-04-03T19:56:00.683556: step 10653, loss 0.222331, acc 0.921875\n",
      "2017-04-03T19:56:00.896582: step 10654, loss 0.271417, acc 0.890625\n",
      "2017-04-03T19:56:01.105883: step 10655, loss 0.187598, acc 0.96875\n",
      "2017-04-03T19:56:01.307706: step 10656, loss 0.25415, acc 0.921875\n",
      "2017-04-03T19:56:01.510690: step 10657, loss 0.21911, acc 0.9375\n",
      "2017-04-03T19:56:01.752507: step 10658, loss 0.22883, acc 0.9375\n",
      "2017-04-03T19:56:01.968864: step 10659, loss 0.288185, acc 0.90625\n",
      "2017-04-03T19:56:02.194683: step 10660, loss 0.211167, acc 0.9375\n",
      "2017-04-03T19:56:02.440196: step 10661, loss 0.300488, acc 0.84375\n",
      "2017-04-03T19:56:02.643055: step 10662, loss 0.251483, acc 0.921875\n",
      "2017-04-03T19:56:02.847269: step 10663, loss 0.104848, acc 0.96875\n",
      "2017-04-03T19:56:03.048891: step 10664, loss 0.192203, acc 0.9375\n",
      "2017-04-03T19:56:03.295335: step 10665, loss 0.309095, acc 0.921875\n",
      "2017-04-03T19:56:03.501425: step 10666, loss 0.276128, acc 0.921875\n",
      "2017-04-03T19:56:03.708119: step 10667, loss 0.237559, acc 0.953125\n",
      "2017-04-03T19:56:03.911546: step 10668, loss 0.546679, acc 0.90625\n",
      "2017-04-03T19:56:04.118414: step 10669, loss 0.270844, acc 0.875\n",
      "2017-04-03T19:56:04.328068: step 10670, loss 0.218821, acc 0.90625\n",
      "2017-04-03T19:56:04.532321: step 10671, loss 0.200257, acc 0.984375\n",
      "2017-04-03T19:56:04.738911: step 10672, loss 0.0941652, acc 0.953125\n",
      "2017-04-03T19:56:04.942333: step 10673, loss 0.221645, acc 0.90625\n",
      "2017-04-03T19:56:05.145413: step 10674, loss 0.216364, acc 0.90625\n",
      "2017-04-03T19:56:05.355701: step 10675, loss 0.372532, acc 0.875\n",
      "2017-04-03T19:56:05.564773: step 10676, loss 0.164045, acc 0.953125\n",
      "2017-04-03T19:56:05.770963: step 10677, loss 0.24828, acc 0.9375\n",
      "2017-04-03T19:56:05.973351: step 10678, loss 0.314639, acc 0.90625\n",
      "2017-04-03T19:56:06.179101: step 10679, loss 0.334888, acc 0.9375\n",
      "2017-04-03T19:56:06.429086: step 10680, loss 0.309275, acc 0.921875\n",
      "2017-04-03T19:56:06.637129: step 10681, loss 0.177429, acc 0.9375\n",
      "2017-04-03T19:56:06.842209: step 10682, loss 0.281216, acc 0.90625\n",
      "2017-04-03T19:56:07.045765: step 10683, loss 0.417035, acc 0.875\n",
      "2017-04-03T19:56:07.253952: step 10684, loss 0.164687, acc 0.96875\n",
      "2017-04-03T19:56:07.452595: step 10685, loss 0.183392, acc 0.9375\n",
      "2017-04-03T19:56:07.660810: step 10686, loss 0.279425, acc 0.90625\n",
      "2017-04-03T19:56:07.883297: step 10687, loss 0.211241, acc 0.921875\n",
      "2017-04-03T19:56:08.088427: step 10688, loss 0.31291, acc 0.90625\n",
      "2017-04-03T19:56:08.308939: step 10689, loss 0.224386, acc 0.96875\n",
      "2017-04-03T19:56:08.528561: step 10690, loss 0.123631, acc 0.984375\n",
      "2017-04-03T19:56:08.736194: step 10691, loss 0.446192, acc 0.84375\n",
      "2017-04-03T19:56:08.939545: step 10692, loss 0.326339, acc 0.84375\n",
      "2017-04-03T19:56:09.147879: step 10693, loss 0.244695, acc 0.90625\n",
      "2017-04-03T19:56:09.349711: step 10694, loss 0.211102, acc 0.953125\n",
      "2017-04-03T19:56:09.561956: step 10695, loss 0.354323, acc 0.90625\n",
      "2017-04-03T19:56:09.774513: step 10696, loss 0.391703, acc 0.890625\n",
      "2017-04-03T19:56:09.919249: step 10697, loss 0.3521, acc 0.875\n",
      "2017-04-03T19:56:10.134759: step 10698, loss 0.125079, acc 0.96875\n",
      "2017-04-03T19:56:10.338753: step 10699, loss 0.128248, acc 0.96875\n",
      "2017-04-03T19:56:10.547374: step 10700, loss 0.155761, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:56:12.675807: step 10700, loss 4.45892, acc 0.289\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-10700\n",
      "\n",
      "2017-04-03T19:56:13.018272: step 10701, loss 0.206993, acc 0.921875\n",
      "2017-04-03T19:56:13.236005: step 10702, loss 0.0804245, acc 0.984375\n",
      "2017-04-03T19:56:13.444502: step 10703, loss 0.162879, acc 0.9375\n",
      "2017-04-03T19:56:13.651037: step 10704, loss 0.272025, acc 0.953125\n",
      "2017-04-03T19:56:13.891545: step 10705, loss 0.135335, acc 0.921875\n",
      "2017-04-03T19:56:14.099299: step 10706, loss 0.100428, acc 0.96875\n",
      "2017-04-03T19:56:14.301804: step 10707, loss 0.244683, acc 0.9375\n",
      "2017-04-03T19:56:14.510577: step 10708, loss 0.147945, acc 0.90625\n",
      "2017-04-03T19:56:14.714617: step 10709, loss 0.188242, acc 0.9375\n",
      "2017-04-03T19:56:14.915300: step 10710, loss 0.252775, acc 0.90625\n",
      "2017-04-03T19:56:15.162279: step 10711, loss 0.165265, acc 0.953125\n",
      "2017-04-03T19:56:15.368793: step 10712, loss 0.28979, acc 0.875\n",
      "2017-04-03T19:56:15.623647: step 10713, loss 0.199504, acc 0.921875\n",
      "2017-04-03T19:56:15.829645: step 10714, loss 0.176256, acc 0.96875\n",
      "2017-04-03T19:56:16.070027: step 10715, loss 0.138984, acc 0.953125\n",
      "2017-04-03T19:56:16.269875: step 10716, loss 0.189835, acc 0.96875\n",
      "2017-04-03T19:56:16.474973: step 10717, loss 0.247148, acc 0.953125\n",
      "2017-04-03T19:56:16.676808: step 10718, loss 0.158422, acc 0.953125\n",
      "2017-04-03T19:56:16.881001: step 10719, loss 0.120822, acc 0.953125\n",
      "2017-04-03T19:56:17.090653: step 10720, loss 0.165155, acc 0.96875\n",
      "2017-04-03T19:56:17.311367: step 10721, loss 0.0914063, acc 0.984375\n",
      "2017-04-03T19:56:17.522863: step 10722, loss 0.107112, acc 0.96875\n",
      "2017-04-03T19:56:17.725939: step 10723, loss 0.207342, acc 0.953125\n",
      "2017-04-03T19:56:17.944638: step 10724, loss 0.114112, acc 0.953125\n",
      "2017-04-03T19:56:18.154314: step 10725, loss 0.287763, acc 0.890625\n",
      "2017-04-03T19:56:18.357387: step 10726, loss 0.239373, acc 0.90625\n",
      "2017-04-03T19:56:18.599312: step 10727, loss 0.250402, acc 0.90625\n",
      "2017-04-03T19:56:18.810226: step 10728, loss 0.16735, acc 0.9375\n",
      "2017-04-03T19:56:19.020609: step 10729, loss 0.0857273, acc 0.984375\n",
      "2017-04-03T19:56:19.242239: step 10730, loss 0.258861, acc 0.90625\n",
      "2017-04-03T19:56:19.454191: step 10731, loss 0.189337, acc 0.953125\n",
      "2017-04-03T19:56:19.664192: step 10732, loss 0.269236, acc 0.953125\n",
      "2017-04-03T19:56:19.876794: step 10733, loss 0.220348, acc 0.953125\n",
      "2017-04-03T19:56:20.079754: step 10734, loss 0.186864, acc 0.96875\n",
      "2017-04-03T19:56:20.282581: step 10735, loss 0.086775, acc 0.96875\n",
      "2017-04-03T19:56:20.494262: step 10736, loss 0.136302, acc 0.9375\n",
      "2017-04-03T19:56:20.704808: step 10737, loss 0.180869, acc 0.9375\n",
      "2017-04-03T19:56:20.910846: step 10738, loss 0.267939, acc 0.90625\n",
      "2017-04-03T19:56:21.122799: step 10739, loss 0.0839036, acc 0.984375\n",
      "2017-04-03T19:56:21.329036: step 10740, loss 0.120481, acc 0.984375\n",
      "2017-04-03T19:56:21.531866: step 10741, loss 0.179514, acc 0.9375\n",
      "2017-04-03T19:56:21.740725: step 10742, loss 0.208459, acc 0.953125\n",
      "2017-04-03T19:56:21.942882: step 10743, loss 0.26982, acc 0.9375\n",
      "2017-04-03T19:56:22.147703: step 10744, loss 0.175261, acc 0.921875\n",
      "2017-04-03T19:56:22.351971: step 10745, loss 0.176545, acc 0.953125\n",
      "2017-04-03T19:56:22.553377: step 10746, loss 0.220974, acc 0.953125\n",
      "2017-04-03T19:56:22.759014: step 10747, loss 0.222876, acc 0.90625\n",
      "2017-04-03T19:56:22.960974: step 10748, loss 0.123682, acc 1\n",
      "2017-04-03T19:56:23.167504: step 10749, loss 0.153827, acc 0.9375\n",
      "2017-04-03T19:56:23.372595: step 10750, loss 0.154379, acc 0.921875\n",
      "2017-04-03T19:56:23.577888: step 10751, loss 0.172493, acc 0.953125\n",
      "2017-04-03T19:56:23.780886: step 10752, loss 0.214994, acc 0.921875\n",
      "2017-04-03T19:56:23.985961: step 10753, loss 0.142677, acc 0.953125\n",
      "2017-04-03T19:56:24.191028: step 10754, loss 0.153253, acc 0.953125\n",
      "2017-04-03T19:56:24.435927: step 10755, loss 0.101311, acc 0.96875\n",
      "2017-04-03T19:56:24.635240: step 10756, loss 0.17513, acc 0.9375\n",
      "2017-04-03T19:56:24.839638: step 10757, loss 0.309832, acc 0.9375\n",
      "2017-04-03T19:56:25.043481: step 10758, loss 0.199141, acc 0.9375\n",
      "2017-04-03T19:56:25.245192: step 10759, loss 0.197818, acc 0.921875\n",
      "2017-04-03T19:56:25.451153: step 10760, loss 0.233876, acc 0.90625\n",
      "2017-04-03T19:56:25.653576: step 10761, loss 0.138656, acc 0.953125\n",
      "2017-04-03T19:56:25.860881: step 10762, loss 0.142073, acc 0.953125\n",
      "2017-04-03T19:56:26.064253: step 10763, loss 0.169628, acc 0.953125\n",
      "2017-04-03T19:56:26.273629: step 10764, loss 0.108232, acc 0.984375\n",
      "2017-04-03T19:56:26.489895: step 10765, loss 0.198684, acc 0.9375\n",
      "2017-04-03T19:56:26.694172: step 10766, loss 0.122846, acc 0.96875\n",
      "2017-04-03T19:56:26.895809: step 10767, loss 0.378358, acc 0.90625\n",
      "2017-04-03T19:56:27.095889: step 10768, loss 0.258693, acc 0.90625\n",
      "2017-04-03T19:56:27.299541: step 10769, loss 0.157359, acc 0.96875\n",
      "2017-04-03T19:56:27.506917: step 10770, loss 0.174578, acc 0.9375\n",
      "2017-04-03T19:56:27.709929: step 10771, loss 0.324449, acc 0.84375\n",
      "2017-04-03T19:56:27.914090: step 10772, loss 0.206608, acc 0.921875\n",
      "2017-04-03T19:56:28.118253: step 10773, loss 0.161752, acc 0.96875\n",
      "2017-04-03T19:56:28.323983: step 10774, loss 0.137542, acc 0.96875\n",
      "2017-04-03T19:56:28.524058: step 10775, loss 0.153888, acc 0.953125\n",
      "2017-04-03T19:56:28.727271: step 10776, loss 0.246309, acc 0.953125\n",
      "2017-04-03T19:56:28.933336: step 10777, loss 0.0890622, acc 0.96875\n",
      "2017-04-03T19:56:29.137638: step 10778, loss 0.233316, acc 0.96875\n",
      "2017-04-03T19:56:29.340207: step 10779, loss 0.205231, acc 0.953125\n",
      "2017-04-03T19:56:29.542688: step 10780, loss 0.180714, acc 0.96875\n",
      "2017-04-03T19:56:29.793183: step 10781, loss 0.205661, acc 0.921875\n",
      "2017-04-03T19:56:30.000926: step 10782, loss 0.157692, acc 0.9375\n",
      "2017-04-03T19:56:30.199530: step 10783, loss 0.151191, acc 0.953125\n",
      "2017-04-03T19:56:30.404134: step 10784, loss 0.131242, acc 0.9375\n",
      "2017-04-03T19:56:30.605277: step 10785, loss 0.093319, acc 0.953125\n",
      "2017-04-03T19:56:30.806711: step 10786, loss 0.218018, acc 0.90625\n",
      "2017-04-03T19:56:31.009626: step 10787, loss 0.217926, acc 0.953125\n",
      "2017-04-03T19:56:31.217987: step 10788, loss 0.155204, acc 0.9375\n",
      "2017-04-03T19:56:31.423883: step 10789, loss 0.293521, acc 0.953125\n",
      "2017-04-03T19:56:31.626054: step 10790, loss 0.129358, acc 0.984375\n",
      "2017-04-03T19:56:31.838522: step 10791, loss 0.186478, acc 0.9375\n",
      "2017-04-03T19:56:32.057080: step 10792, loss 0.242093, acc 0.921875\n",
      "2017-04-03T19:56:32.278275: step 10793, loss 0.156714, acc 0.953125\n",
      "2017-04-03T19:56:32.491620: step 10794, loss 0.25711, acc 0.90625\n",
      "2017-04-03T19:56:32.752202: step 10795, loss 0.111224, acc 0.984375\n",
      "2017-04-03T19:56:32.956744: step 10796, loss 0.103803, acc 0.96875\n",
      "2017-04-03T19:56:33.161224: step 10797, loss 0.203281, acc 0.90625\n",
      "2017-04-03T19:56:33.365022: step 10798, loss 0.104634, acc 0.984375\n",
      "2017-04-03T19:56:33.616402: step 10799, loss 0.238005, acc 0.90625\n",
      "2017-04-03T19:56:33.824161: step 10800, loss 0.206737, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:56:35.854021: step 10800, loss 4.50489, acc 0.296\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-10800\n",
      "\n",
      "2017-04-03T19:56:36.197920: step 10801, loss 0.218633, acc 0.953125\n",
      "2017-04-03T19:56:36.402273: step 10802, loss 0.25534, acc 0.90625\n",
      "2017-04-03T19:56:36.610768: step 10803, loss 0.227563, acc 0.921875\n",
      "2017-04-03T19:56:36.817285: step 10804, loss 0.221286, acc 0.921875\n",
      "2017-04-03T19:56:37.017449: step 10805, loss 0.263441, acc 0.953125\n",
      "2017-04-03T19:56:37.218793: step 10806, loss 0.217255, acc 0.953125\n",
      "2017-04-03T19:56:37.412927: step 10807, loss 0.220731, acc 0.921875\n",
      "2017-04-03T19:56:37.610935: step 10808, loss 0.231726, acc 0.953125\n",
      "2017-04-03T19:56:37.817792: step 10809, loss 0.134257, acc 0.9375\n",
      "2017-04-03T19:56:38.023912: step 10810, loss 0.130503, acc 0.921875\n",
      "2017-04-03T19:56:38.228751: step 10811, loss 0.430278, acc 0.890625\n",
      "2017-04-03T19:56:38.430065: step 10812, loss 0.263769, acc 0.921875\n",
      "2017-04-03T19:56:38.635875: step 10813, loss 0.122798, acc 0.953125\n",
      "2017-04-03T19:56:38.836944: step 10814, loss 0.0736847, acc 1\n",
      "2017-04-03T19:56:39.038457: step 10815, loss 0.368962, acc 0.90625\n",
      "2017-04-03T19:56:39.241223: step 10816, loss 0.236115, acc 0.9375\n",
      "2017-04-03T19:56:39.446838: step 10817, loss 0.235243, acc 0.90625\n",
      "2017-04-03T19:56:39.655399: step 10818, loss 0.198469, acc 0.953125\n",
      "2017-04-03T19:56:39.856085: step 10819, loss 0.211378, acc 0.921875\n",
      "2017-04-03T19:56:40.056853: step 10820, loss 0.163281, acc 0.921875\n",
      "2017-04-03T19:56:40.267634: step 10821, loss 0.260494, acc 0.875\n",
      "2017-04-03T19:56:40.483186: step 10822, loss 0.175396, acc 0.9375\n",
      "2017-04-03T19:56:40.686627: step 10823, loss 0.115597, acc 0.96875\n",
      "2017-04-03T19:56:40.887665: step 10824, loss 0.191589, acc 0.9375\n",
      "2017-04-03T19:56:41.087839: step 10825, loss 0.330529, acc 0.875\n",
      "2017-04-03T19:56:41.290351: step 10826, loss 0.359283, acc 0.875\n",
      "2017-04-03T19:56:41.501577: step 10827, loss 0.271788, acc 0.96875\n",
      "2017-04-03T19:56:41.705188: step 10828, loss 0.268914, acc 0.875\n",
      "2017-04-03T19:56:41.908402: step 10829, loss 0.134615, acc 0.953125\n",
      "2017-04-03T19:56:42.119361: step 10830, loss 0.175968, acc 0.953125\n",
      "2017-04-03T19:56:42.320663: step 10831, loss 0.137286, acc 0.984375\n",
      "2017-04-03T19:56:42.521615: step 10832, loss 0.202901, acc 0.9375\n",
      "2017-04-03T19:56:42.722170: step 10833, loss 0.168887, acc 0.96875\n",
      "2017-04-03T19:56:42.930522: step 10834, loss 0.356605, acc 0.921875\n",
      "2017-04-03T19:56:43.134516: step 10835, loss 0.125238, acc 0.921875\n",
      "2017-04-03T19:56:43.379552: step 10836, loss 0.105109, acc 0.96875\n",
      "2017-04-03T19:56:43.578935: step 10837, loss 0.167446, acc 0.953125\n",
      "2017-04-03T19:56:43.779432: step 10838, loss 0.195173, acc 0.953125\n",
      "2017-04-03T19:56:43.986719: step 10839, loss 0.282922, acc 0.921875\n",
      "2017-04-03T19:56:44.193374: step 10840, loss 0.325439, acc 0.875\n",
      "2017-04-03T19:56:44.395403: step 10841, loss 0.181662, acc 0.921875\n",
      "2017-04-03T19:56:44.598202: step 10842, loss 0.194941, acc 0.953125\n",
      "2017-04-03T19:56:44.806108: step 10843, loss 0.259911, acc 0.90625\n",
      "2017-04-03T19:56:45.011669: step 10844, loss 0.24988, acc 0.890625\n",
      "2017-04-03T19:56:45.214756: step 10845, loss 0.247887, acc 0.890625\n",
      "2017-04-03T19:56:45.419610: step 10846, loss 0.175867, acc 0.9375\n",
      "2017-04-03T19:56:45.626188: step 10847, loss 0.0834457, acc 0.984375\n",
      "2017-04-03T19:56:45.840855: step 10848, loss 0.230776, acc 0.921875\n",
      "2017-04-03T19:56:46.096620: step 10849, loss 0.131317, acc 0.96875\n",
      "2017-04-03T19:56:46.296173: step 10850, loss 0.168488, acc 0.953125\n",
      "2017-04-03T19:56:46.499543: step 10851, loss 0.104837, acc 0.96875\n",
      "2017-04-03T19:56:46.698882: step 10852, loss 0.123035, acc 0.9375\n",
      "2017-04-03T19:56:46.902048: step 10853, loss 0.29463, acc 0.90625\n",
      "2017-04-03T19:56:47.106331: step 10854, loss 0.118552, acc 0.953125\n",
      "2017-04-03T19:56:47.306755: step 10855, loss 0.237686, acc 0.921875\n",
      "2017-04-03T19:56:47.548265: step 10856, loss 0.155436, acc 0.953125\n",
      "2017-04-03T19:56:47.750036: step 10857, loss 0.166833, acc 0.9375\n",
      "2017-04-03T19:56:47.951788: step 10858, loss 0.146628, acc 0.96875\n",
      "2017-04-03T19:56:48.160026: step 10859, loss 0.27203, acc 0.90625\n",
      "2017-04-03T19:56:48.359421: step 10860, loss 0.233714, acc 0.90625\n",
      "2017-04-03T19:56:48.562703: step 10861, loss 0.0393699, acc 1\n",
      "2017-04-03T19:56:48.804471: step 10862, loss 0.266884, acc 0.875\n",
      "2017-04-03T19:56:49.010386: step 10863, loss 0.104686, acc 0.953125\n",
      "2017-04-03T19:56:49.209249: step 10864, loss 0.162973, acc 0.921875\n",
      "2017-04-03T19:56:49.412037: step 10865, loss 0.191619, acc 0.921875\n",
      "2017-04-03T19:56:49.648575: step 10866, loss 0.156245, acc 0.953125\n",
      "2017-04-03T19:56:49.850879: step 10867, loss 0.245855, acc 0.921875\n",
      "2017-04-03T19:56:50.094916: step 10868, loss 0.0782586, acc 0.984375\n",
      "2017-04-03T19:56:50.299500: step 10869, loss 0.102546, acc 0.96875\n",
      "2017-04-03T19:56:50.504251: step 10870, loss 0.224247, acc 0.9375\n",
      "2017-04-03T19:56:50.706075: step 10871, loss 0.165606, acc 0.9375\n",
      "2017-04-03T19:56:50.903747: step 10872, loss 0.174862, acc 0.9375\n",
      "2017-04-03T19:56:51.111736: step 10873, loss 0.137504, acc 0.96875\n",
      "2017-04-03T19:56:51.358081: step 10874, loss 0.121701, acc 0.953125\n",
      "2017-04-03T19:56:51.557381: step 10875, loss 0.145657, acc 0.9375\n",
      "2017-04-03T19:56:51.759475: step 10876, loss 0.231306, acc 0.921875\n",
      "2017-04-03T19:56:51.962892: step 10877, loss 0.202492, acc 0.90625\n",
      "2017-04-03T19:56:52.164303: step 10878, loss 0.193533, acc 0.921875\n",
      "2017-04-03T19:56:52.363963: step 10879, loss 0.164152, acc 0.921875\n",
      "2017-04-03T19:56:52.566623: step 10880, loss 0.132608, acc 0.96875\n",
      "2017-04-03T19:56:52.767591: step 10881, loss 0.17363, acc 0.9375\n",
      "2017-04-03T19:56:52.971358: step 10882, loss 0.165465, acc 0.953125\n",
      "2017-04-03T19:56:53.171777: step 10883, loss 0.206969, acc 0.921875\n",
      "2017-04-03T19:56:53.372460: step 10884, loss 0.185705, acc 0.953125\n",
      "2017-04-03T19:56:53.574693: step 10885, loss 0.224456, acc 0.9375\n",
      "2017-04-03T19:56:53.780232: step 10886, loss 0.127271, acc 0.953125\n",
      "2017-04-03T19:56:53.983585: step 10887, loss 0.115102, acc 0.96875\n",
      "2017-04-03T19:56:54.184903: step 10888, loss 0.0791169, acc 1\n",
      "2017-04-03T19:56:54.385803: step 10889, loss 0.187329, acc 0.953125\n",
      "2017-04-03T19:56:54.635389: step 10890, loss 0.117232, acc 0.96875\n",
      "2017-04-03T19:56:54.836390: step 10891, loss 0.147383, acc 0.96875\n",
      "2017-04-03T19:56:55.080341: step 10892, loss 0.186106, acc 0.90625\n",
      "2017-04-03T19:56:55.279336: step 10893, loss 0.114138, acc 0.96875\n",
      "2017-04-03T19:56:55.480973: step 10894, loss 0.120996, acc 0.984375\n",
      "2017-04-03T19:56:55.680969: step 10895, loss 0.160128, acc 0.953125\n",
      "2017-04-03T19:56:55.885275: step 10896, loss 0.0906718, acc 0.984375\n",
      "2017-04-03T19:56:56.092045: step 10897, loss 0.164706, acc 0.953125\n",
      "2017-04-03T19:56:56.293593: step 10898, loss 0.451613, acc 0.90625\n",
      "2017-04-03T19:56:56.497739: step 10899, loss 0.230253, acc 0.953125\n",
      "2017-04-03T19:56:56.697980: step 10900, loss 0.354864, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:56:58.732423: step 10900, loss 4.55106, acc 0.2985\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-10900\n",
      "\n",
      "2017-04-03T19:56:59.076015: step 10901, loss 0.25592, acc 0.890625\n",
      "2017-04-03T19:56:59.274409: step 10902, loss 0.22476, acc 0.9375\n",
      "2017-04-03T19:56:59.474582: step 10903, loss 0.331717, acc 0.921875\n",
      "2017-04-03T19:56:59.674632: step 10904, loss 0.160795, acc 0.984375\n",
      "2017-04-03T19:56:59.873908: step 10905, loss 0.139816, acc 0.96875\n",
      "2017-04-03T19:57:00.075812: step 10906, loss 0.244719, acc 0.921875\n",
      "2017-04-03T19:57:00.281522: step 10907, loss 0.151166, acc 0.953125\n",
      "2017-04-03T19:57:00.482538: step 10908, loss 0.0972252, acc 0.96875\n",
      "2017-04-03T19:57:00.726902: step 10909, loss 0.0555286, acc 1\n",
      "2017-04-03T19:57:00.943055: step 10910, loss 0.135011, acc 0.96875\n",
      "2017-04-03T19:57:01.149143: step 10911, loss 0.136831, acc 0.953125\n",
      "2017-04-03T19:57:01.350337: step 10912, loss 0.134202, acc 0.953125\n",
      "2017-04-03T19:57:01.551447: step 10913, loss 0.0871803, acc 0.953125\n",
      "2017-04-03T19:57:01.750350: step 10914, loss 0.303396, acc 0.890625\n",
      "2017-04-03T19:57:01.951217: step 10915, loss 0.181439, acc 0.9375\n",
      "2017-04-03T19:57:02.147530: step 10916, loss 0.213046, acc 0.9375\n",
      "2017-04-03T19:57:02.350723: step 10917, loss 0.137442, acc 0.953125\n",
      "2017-04-03T19:57:02.550655: step 10918, loss 0.15943, acc 0.96875\n",
      "2017-04-03T19:57:02.752890: step 10919, loss 0.140684, acc 0.953125\n",
      "2017-04-03T19:57:02.956003: step 10920, loss 0.132303, acc 0.96875\n",
      "2017-04-03T19:57:03.159658: step 10921, loss 0.218003, acc 0.921875\n",
      "2017-04-03T19:57:03.359069: step 10922, loss 0.172105, acc 0.953125\n",
      "2017-04-03T19:57:03.559114: step 10923, loss 0.123818, acc 0.984375\n",
      "2017-04-03T19:57:03.765537: step 10924, loss 0.253729, acc 0.96875\n",
      "2017-04-03T19:57:03.965144: step 10925, loss 0.23487, acc 0.90625\n",
      "2017-04-03T19:57:04.173444: step 10926, loss 0.132327, acc 0.96875\n",
      "2017-04-03T19:57:04.375195: step 10927, loss 0.249126, acc 0.921875\n",
      "2017-04-03T19:57:04.573822: step 10928, loss 0.181456, acc 0.9375\n",
      "2017-04-03T19:57:04.775823: step 10929, loss 0.18879, acc 0.921875\n",
      "2017-04-03T19:57:04.977093: step 10930, loss 0.326306, acc 0.921875\n",
      "2017-04-03T19:57:05.183878: step 10931, loss 0.139754, acc 0.984375\n",
      "2017-04-03T19:57:05.411323: step 10932, loss 0.26015, acc 0.90625\n",
      "2017-04-03T19:57:05.613921: step 10933, loss 0.267103, acc 0.9375\n",
      "2017-04-03T19:57:05.822981: step 10934, loss 0.242299, acc 0.921875\n",
      "2017-04-03T19:57:06.069781: step 10935, loss 0.252453, acc 0.890625\n",
      "2017-04-03T19:57:06.278305: step 10936, loss 0.166574, acc 0.953125\n",
      "2017-04-03T19:57:06.493915: step 10937, loss 0.143464, acc 0.953125\n",
      "2017-04-03T19:57:06.701804: step 10938, loss 0.242094, acc 0.9375\n",
      "2017-04-03T19:57:06.905200: step 10939, loss 0.186969, acc 0.90625\n",
      "2017-04-03T19:57:07.106483: step 10940, loss 0.239089, acc 0.921875\n",
      "2017-04-03T19:57:07.307654: step 10941, loss 0.124013, acc 0.953125\n",
      "2017-04-03T19:57:07.507940: step 10942, loss 0.177213, acc 0.9375\n",
      "2017-04-03T19:57:07.755034: step 10943, loss 0.202579, acc 0.921875\n",
      "2017-04-03T19:57:07.960209: step 10944, loss 0.138173, acc 0.953125\n",
      "2017-04-03T19:57:08.159248: step 10945, loss 0.131328, acc 0.9375\n",
      "2017-04-03T19:57:08.362075: step 10946, loss 0.231125, acc 0.875\n",
      "2017-04-03T19:57:08.561783: step 10947, loss 0.440071, acc 0.9375\n",
      "2017-04-03T19:57:08.764706: step 10948, loss 0.30665, acc 0.875\n",
      "2017-04-03T19:57:08.965336: step 10949, loss 0.221091, acc 0.9375\n",
      "2017-04-03T19:57:09.164686: step 10950, loss 0.218025, acc 0.90625\n",
      "2017-04-03T19:57:09.365021: step 10951, loss 0.176202, acc 0.953125\n",
      "2017-04-03T19:57:09.563742: step 10952, loss 0.228509, acc 0.90625\n",
      "2017-04-03T19:57:09.772050: step 10953, loss 0.139914, acc 0.953125\n",
      "2017-04-03T19:57:09.987927: step 10954, loss 0.116594, acc 0.953125\n",
      "2017-04-03T19:57:10.193780: step 10955, loss 0.277574, acc 0.921875\n",
      "2017-04-03T19:57:10.409889: step 10956, loss 0.108016, acc 0.96875\n",
      "2017-04-03T19:57:10.624285: step 10957, loss 0.169569, acc 0.9375\n",
      "2017-04-03T19:57:10.828574: step 10958, loss 0.367556, acc 0.90625\n",
      "2017-04-03T19:57:11.033656: step 10959, loss 0.130132, acc 0.96875\n",
      "2017-04-03T19:57:11.247277: step 10960, loss 0.265692, acc 0.921875\n",
      "2017-04-03T19:57:11.457423: step 10961, loss 0.288224, acc 0.9375\n",
      "2017-04-03T19:57:11.661214: step 10962, loss 0.137776, acc 0.9375\n",
      "2017-04-03T19:57:11.859742: step 10963, loss 0.186549, acc 0.921875\n",
      "2017-04-03T19:57:12.063873: step 10964, loss 0.395547, acc 0.890625\n",
      "2017-04-03T19:57:12.263465: step 10965, loss 0.166874, acc 0.9375\n",
      "2017-04-03T19:57:12.468412: step 10966, loss 0.464403, acc 0.875\n",
      "2017-04-03T19:57:12.670003: step 10967, loss 0.174942, acc 0.953125\n",
      "2017-04-03T19:57:12.876097: step 10968, loss 0.283881, acc 0.90625\n",
      "2017-04-03T19:57:13.083561: step 10969, loss 0.122887, acc 0.96875\n",
      "2017-04-03T19:57:13.299479: step 10970, loss 0.183884, acc 0.9375\n",
      "2017-04-03T19:57:13.499623: step 10971, loss 0.222675, acc 0.90625\n",
      "2017-04-03T19:57:13.706809: step 10972, loss 0.219838, acc 0.90625\n",
      "2017-04-03T19:57:13.924998: step 10973, loss 0.291897, acc 0.890625\n",
      "2017-04-03T19:57:14.144786: step 10974, loss 0.293295, acc 0.890625\n",
      "2017-04-03T19:57:14.362313: step 10975, loss 0.187442, acc 0.984375\n",
      "2017-04-03T19:57:14.565781: step 10976, loss 0.158798, acc 0.953125\n",
      "2017-04-03T19:57:14.765891: step 10977, loss 0.168546, acc 0.953125\n",
      "2017-04-03T19:57:14.969276: step 10978, loss 0.170691, acc 0.921875\n",
      "2017-04-03T19:57:15.177041: step 10979, loss 0.224713, acc 0.90625\n",
      "2017-04-03T19:57:15.383535: step 10980, loss 0.159806, acc 0.9375\n",
      "2017-04-03T19:57:15.587434: step 10981, loss 0.378049, acc 0.890625\n",
      "2017-04-03T19:57:15.788138: step 10982, loss 0.258205, acc 0.921875\n",
      "2017-04-03T19:57:15.991951: step 10983, loss 0.362093, acc 0.890625\n",
      "2017-04-03T19:57:16.199553: step 10984, loss 0.240366, acc 0.9375\n",
      "2017-04-03T19:57:16.398876: step 10985, loss 0.345915, acc 0.859375\n",
      "2017-04-03T19:57:16.605791: step 10986, loss 0.185307, acc 0.953125\n",
      "2017-04-03T19:57:16.806392: step 10987, loss 0.297969, acc 0.90625\n",
      "2017-04-03T19:57:17.008791: step 10988, loss 0.176077, acc 0.9375\n",
      "2017-04-03T19:57:17.209286: step 10989, loss 0.176845, acc 0.9375\n",
      "2017-04-03T19:57:17.412694: step 10990, loss 0.328933, acc 0.921875\n",
      "2017-04-03T19:57:17.613751: step 10991, loss 0.199483, acc 0.9375\n",
      "2017-04-03T19:57:17.814701: step 10992, loss 0.107954, acc 0.96875\n",
      "2017-04-03T19:57:18.021493: step 10993, loss 0.120495, acc 0.96875\n",
      "2017-04-03T19:57:18.221848: step 10994, loss 0.123372, acc 0.921875\n",
      "2017-04-03T19:57:18.445785: step 10995, loss 0.140501, acc 0.953125\n",
      "2017-04-03T19:57:18.650303: step 10996, loss 0.179032, acc 0.9375\n",
      "2017-04-03T19:57:18.851614: step 10997, loss 0.239692, acc 0.90625\n",
      "2017-04-03T19:57:19.054516: step 10998, loss 0.161609, acc 0.9375\n",
      "2017-04-03T19:57:19.255338: step 10999, loss 0.353893, acc 0.875\n",
      "2017-04-03T19:57:19.458557: step 11000, loss 0.25182, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:57:21.586692: step 11000, loss 4.65033, acc 0.3025\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-11000\n",
      "\n",
      "2017-04-03T19:57:21.915341: step 11001, loss 0.198645, acc 0.921875\n",
      "2017-04-03T19:57:22.157519: step 11002, loss 0.104286, acc 0.96875\n",
      "2017-04-03T19:57:22.371486: step 11003, loss 0.211939, acc 0.90625\n",
      "2017-04-03T19:57:22.587755: step 11004, loss 0.234195, acc 0.875\n",
      "2017-04-03T19:57:22.791529: step 11005, loss 0.218493, acc 0.9375\n",
      "2017-04-03T19:57:23.031312: step 11006, loss 0.23556, acc 0.921875\n",
      "2017-04-03T19:57:23.231812: step 11007, loss 0.280183, acc 0.9375\n",
      "2017-04-03T19:57:23.432950: step 11008, loss 0.0975011, acc 1\n",
      "2017-04-03T19:57:23.630144: step 11009, loss 0.0937839, acc 0.984375\n",
      "2017-04-03T19:57:23.830147: step 11010, loss 0.322168, acc 0.921875\n",
      "2017-04-03T19:57:24.039697: step 11011, loss 0.217551, acc 0.9375\n",
      "2017-04-03T19:57:24.253525: step 11012, loss 0.173965, acc 0.921875\n",
      "2017-04-03T19:57:24.456135: step 11013, loss 0.19624, acc 0.9375\n",
      "2017-04-03T19:57:24.656576: step 11014, loss 0.265291, acc 0.90625\n",
      "2017-04-03T19:57:24.861822: step 11015, loss 0.208969, acc 0.953125\n",
      "2017-04-03T19:57:25.066247: step 11016, loss 0.29238, acc 0.90625\n",
      "2017-04-03T19:57:25.261740: step 11017, loss 0.119755, acc 0.96875\n",
      "2017-04-03T19:57:25.506243: step 11018, loss 0.2679, acc 0.890625\n",
      "2017-04-03T19:57:25.750165: step 11019, loss 0.265258, acc 0.890625\n",
      "2017-04-03T19:57:25.989694: step 11020, loss 0.173794, acc 0.9375\n",
      "2017-04-03T19:57:26.192937: step 11021, loss 0.143837, acc 0.96875\n",
      "2017-04-03T19:57:26.405088: step 11022, loss 0.281539, acc 0.90625\n",
      "2017-04-03T19:57:26.607894: step 11023, loss 0.274589, acc 0.953125\n",
      "2017-04-03T19:57:26.809221: step 11024, loss 0.174007, acc 0.921875\n",
      "2017-04-03T19:57:27.013647: step 11025, loss 0.18422, acc 0.921875\n",
      "2017-04-03T19:57:27.214346: step 11026, loss 0.145924, acc 0.921875\n",
      "2017-04-03T19:57:27.417595: step 11027, loss 0.285128, acc 0.890625\n",
      "2017-04-03T19:57:27.619864: step 11028, loss 0.324244, acc 0.90625\n",
      "2017-04-03T19:57:27.825868: step 11029, loss 0.210105, acc 0.90625\n",
      "2017-04-03T19:57:28.028051: step 11030, loss 0.117827, acc 0.96875\n",
      "2017-04-03T19:57:28.234159: step 11031, loss 0.0827711, acc 0.984375\n",
      "2017-04-03T19:57:28.432997: step 11032, loss 0.209505, acc 0.890625\n",
      "2017-04-03T19:57:28.635187: step 11033, loss 0.197623, acc 0.953125\n",
      "2017-04-03T19:57:28.882405: step 11034, loss 0.292293, acc 0.921875\n",
      "2017-04-03T19:57:29.082553: step 11035, loss 0.140118, acc 0.921875\n",
      "2017-04-03T19:57:29.282993: step 11036, loss 0.371656, acc 0.921875\n",
      "2017-04-03T19:57:29.489048: step 11037, loss 0.154846, acc 0.9375\n",
      "2017-04-03T19:57:29.692818: step 11038, loss 0.259314, acc 0.921875\n",
      "2017-04-03T19:57:29.898588: step 11039, loss 0.220011, acc 0.921875\n",
      "2017-04-03T19:57:30.095741: step 11040, loss 0.230608, acc 0.90625\n",
      "2017-04-03T19:57:30.306863: step 11041, loss 0.249965, acc 0.9375\n",
      "2017-04-03T19:57:30.510708: step 11042, loss 0.272573, acc 0.9375\n",
      "2017-04-03T19:57:30.713799: step 11043, loss 0.114929, acc 0.96875\n",
      "2017-04-03T19:57:30.920607: step 11044, loss 0.171439, acc 0.953125\n",
      "2017-04-03T19:57:31.125860: step 11045, loss 0.163666, acc 0.953125\n",
      "2017-04-03T19:57:31.332026: step 11046, loss 0.116011, acc 0.953125\n",
      "2017-04-03T19:57:31.544526: step 11047, loss 0.150967, acc 0.953125\n",
      "2017-04-03T19:57:31.743433: step 11048, loss 0.140891, acc 0.953125\n",
      "2017-04-03T19:57:31.945623: step 11049, loss 0.261677, acc 0.921875\n",
      "2017-04-03T19:57:32.147613: step 11050, loss 0.086808, acc 0.984375\n",
      "2017-04-03T19:57:32.359241: step 11051, loss 0.244991, acc 0.90625\n",
      "2017-04-03T19:57:32.560909: step 11052, loss 0.18152, acc 0.921875\n",
      "2017-04-03T19:57:32.758222: step 11053, loss 0.181098, acc 0.96875\n",
      "2017-04-03T19:57:32.960238: step 11054, loss 0.140471, acc 0.984375\n",
      "2017-04-03T19:57:33.165526: step 11055, loss 0.271906, acc 0.90625\n",
      "2017-04-03T19:57:33.375093: step 11056, loss 0.348009, acc 0.890625\n",
      "2017-04-03T19:57:33.582642: step 11057, loss 0.223274, acc 0.9375\n",
      "2017-04-03T19:57:33.778727: step 11058, loss 0.274046, acc 0.921875\n",
      "2017-04-03T19:57:34.025457: step 11059, loss 0.253496, acc 0.9375\n",
      "2017-04-03T19:57:34.269346: step 11060, loss 0.214965, acc 0.90625\n",
      "2017-04-03T19:57:34.475413: step 11061, loss 0.313226, acc 0.90625\n",
      "2017-04-03T19:57:34.676297: step 11062, loss 0.144949, acc 0.96875\n",
      "2017-04-03T19:57:34.878880: step 11063, loss 0.0891446, acc 0.984375\n",
      "2017-04-03T19:57:35.079794: step 11064, loss 0.28916, acc 0.90625\n",
      "2017-04-03T19:57:35.294054: step 11065, loss 0.19747, acc 0.9375\n",
      "2017-04-03T19:57:35.504615: step 11066, loss 0.470775, acc 0.890625\n",
      "2017-04-03T19:57:35.706268: step 11067, loss 0.147803, acc 0.9375\n",
      "2017-04-03T19:57:35.904887: step 11068, loss 0.0991337, acc 0.921875\n",
      "2017-04-03T19:57:36.102176: step 11069, loss 0.207862, acc 0.953125\n",
      "2017-04-03T19:57:36.304329: step 11070, loss 0.247677, acc 0.921875\n",
      "2017-04-03T19:57:36.505774: step 11071, loss 0.164997, acc 0.9375\n",
      "2017-04-03T19:57:36.751074: step 11072, loss 0.434523, acc 0.84375\n",
      "2017-04-03T19:57:36.956453: step 11073, loss 0.276842, acc 0.890625\n",
      "2017-04-03T19:57:37.166392: step 11074, loss 0.30323, acc 0.90625\n",
      "2017-04-03T19:57:37.372386: step 11075, loss 0.205156, acc 0.90625\n",
      "2017-04-03T19:57:37.576309: step 11076, loss 0.104084, acc 1\n",
      "2017-04-03T19:57:37.787139: step 11077, loss 0.328076, acc 0.90625\n",
      "2017-04-03T19:57:37.994816: step 11078, loss 0.394547, acc 0.921875\n",
      "2017-04-03T19:57:38.201604: step 11079, loss 0.406258, acc 0.875\n",
      "2017-04-03T19:57:38.400533: step 11080, loss 0.450714, acc 0.890625\n",
      "2017-04-03T19:57:38.603595: step 11081, loss 0.134777, acc 0.953125\n",
      "2017-04-03T19:57:38.810114: step 11082, loss 0.207032, acc 0.953125\n",
      "2017-04-03T19:57:39.011725: step 11083, loss 0.202621, acc 0.921875\n",
      "2017-04-03T19:57:39.218747: step 11084, loss 0.15092, acc 0.953125\n",
      "2017-04-03T19:57:39.424313: step 11085, loss 0.136618, acc 0.9375\n",
      "2017-04-03T19:57:39.625099: step 11086, loss 0.487782, acc 0.9375\n",
      "2017-04-03T19:57:39.830870: step 11087, loss 0.295166, acc 0.90625\n",
      "2017-04-03T19:57:40.034433: step 11088, loss 0.21752, acc 0.9375\n",
      "2017-04-03T19:57:40.237896: step 11089, loss 0.153694, acc 0.9375\n",
      "2017-04-03T19:57:40.436964: step 11090, loss 0.0983895, acc 1\n",
      "2017-04-03T19:57:40.643721: step 11091, loss 0.286532, acc 0.9375\n",
      "2017-04-03T19:57:40.885650: step 11092, loss 0.291707, acc 0.921875\n",
      "2017-04-03T19:57:41.134997: step 11093, loss 0.279331, acc 0.921875\n",
      "2017-04-03T19:57:41.347833: step 11094, loss 0.119311, acc 0.96875\n",
      "2017-04-03T19:57:41.552106: step 11095, loss 0.132231, acc 0.9375\n",
      "2017-04-03T19:57:41.755452: step 11096, loss 0.0969815, acc 1\n",
      "2017-04-03T19:57:41.961855: step 11097, loss 0.331805, acc 0.875\n",
      "2017-04-03T19:57:42.167117: step 11098, loss 0.275624, acc 0.9375\n",
      "2017-04-03T19:57:42.366471: step 11099, loss 0.341933, acc 0.890625\n",
      "2017-04-03T19:57:42.565334: step 11100, loss 0.280183, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:57:44.602728: step 11100, loss 4.67665, acc 0.29125\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-11100\n",
      "\n",
      "2017-04-03T19:57:44.932540: step 11101, loss 0.458914, acc 0.875\n",
      "2017-04-03T19:57:45.132153: step 11102, loss 0.377707, acc 0.859375\n",
      "2017-04-03T19:57:45.337219: step 11103, loss 0.149684, acc 0.953125\n",
      "2017-04-03T19:57:45.540996: step 11104, loss 0.377688, acc 0.859375\n",
      "2017-04-03T19:57:45.743816: step 11105, loss 0.218008, acc 0.953125\n",
      "2017-04-03T19:57:45.949645: step 11106, loss 0.238782, acc 0.921875\n",
      "2017-04-03T19:57:46.150967: step 11107, loss 0.242307, acc 0.953125\n",
      "2017-04-03T19:57:46.360171: step 11108, loss 0.31056, acc 0.921875\n",
      "2017-04-03T19:57:46.565151: step 11109, loss 0.132147, acc 0.9375\n",
      "2017-04-03T19:57:46.769222: step 11110, loss 0.25375, acc 0.9375\n",
      "2017-04-03T19:57:46.984232: step 11111, loss 0.278026, acc 0.921875\n",
      "2017-04-03T19:57:47.192156: step 11112, loss 0.150164, acc 0.953125\n",
      "2017-04-03T19:57:47.400504: step 11113, loss 0.256741, acc 0.90625\n",
      "2017-04-03T19:57:47.602393: step 11114, loss 0.208911, acc 0.953125\n",
      "2017-04-03T19:57:47.804879: step 11115, loss 0.303216, acc 0.90625\n",
      "2017-04-03T19:57:48.008670: step 11116, loss 0.265487, acc 0.9375\n",
      "2017-04-03T19:57:48.211648: step 11117, loss 0.173166, acc 0.9375\n",
      "2017-04-03T19:57:48.411644: step 11118, loss 0.141006, acc 0.96875\n",
      "2017-04-03T19:57:48.616173: step 11119, loss 0.163021, acc 0.90625\n",
      "2017-04-03T19:57:48.817340: step 11120, loss 0.140799, acc 0.96875\n",
      "2017-04-03T19:57:49.023964: step 11121, loss 0.222585, acc 0.921875\n",
      "2017-04-03T19:57:49.228086: step 11122, loss 0.227427, acc 0.875\n",
      "2017-04-03T19:57:49.431639: step 11123, loss 0.222825, acc 0.921875\n",
      "2017-04-03T19:57:49.636773: step 11124, loss 0.162667, acc 0.96875\n",
      "2017-04-03T19:57:49.834616: step 11125, loss 0.092823, acc 0.984375\n",
      "2017-04-03T19:57:50.039050: step 11126, loss 0.126667, acc 0.953125\n",
      "2017-04-03T19:57:50.240343: step 11127, loss 0.36514, acc 0.890625\n",
      "2017-04-03T19:57:50.443075: step 11128, loss 0.196608, acc 0.90625\n",
      "2017-04-03T19:57:50.643710: step 11129, loss 0.18935, acc 0.9375\n",
      "2017-04-03T19:57:50.907615: step 11130, loss 0.146034, acc 0.953125\n",
      "2017-04-03T19:57:51.109423: step 11131, loss 0.211483, acc 0.953125\n",
      "2017-04-03T19:57:51.313533: step 11132, loss 0.140119, acc 0.953125\n",
      "2017-04-03T19:57:51.512225: step 11133, loss 0.293409, acc 0.890625\n",
      "2017-04-03T19:57:51.714005: step 11134, loss 0.174465, acc 0.96875\n",
      "2017-04-03T19:57:51.917281: step 11135, loss 0.212803, acc 0.921875\n",
      "2017-04-03T19:57:52.127368: step 11136, loss 0.191692, acc 0.9375\n",
      "2017-04-03T19:57:52.337065: step 11137, loss 0.364979, acc 0.90625\n",
      "2017-04-03T19:57:52.540585: step 11138, loss 0.143781, acc 0.984375\n",
      "2017-04-03T19:57:52.755232: step 11139, loss 0.0891783, acc 1\n",
      "2017-04-03T19:57:52.970885: step 11140, loss 0.457642, acc 0.90625\n",
      "2017-04-03T19:57:53.172617: step 11141, loss 0.208033, acc 0.9375\n",
      "2017-04-03T19:57:53.372909: step 11142, loss 0.191115, acc 0.90625\n",
      "2017-04-03T19:57:53.624938: step 11143, loss 0.160038, acc 0.96875\n",
      "2017-04-03T19:57:53.829458: step 11144, loss 0.188904, acc 0.9375\n",
      "2017-04-03T19:57:54.035262: step 11145, loss 0.240487, acc 0.921875\n",
      "2017-04-03T19:57:54.239826: step 11146, loss 0.191964, acc 0.921875\n",
      "2017-04-03T19:57:54.442031: step 11147, loss 0.0796881, acc 0.984375\n",
      "2017-04-03T19:57:54.647076: step 11148, loss 0.181511, acc 0.984375\n",
      "2017-04-03T19:57:54.856703: step 11149, loss 0.0966643, acc 0.96875\n",
      "2017-04-03T19:57:55.075718: step 11150, loss 0.207682, acc 0.9375\n",
      "2017-04-03T19:57:55.280401: step 11151, loss 0.204951, acc 0.953125\n",
      "2017-04-03T19:57:55.485387: step 11152, loss 0.126808, acc 0.96875\n",
      "2017-04-03T19:57:55.687555: step 11153, loss 0.180132, acc 0.921875\n",
      "2017-04-03T19:57:55.892067: step 11154, loss 0.222331, acc 0.921875\n",
      "2017-04-03T19:57:56.092442: step 11155, loss 0.289141, acc 0.90625\n",
      "2017-04-03T19:57:56.297537: step 11156, loss 0.178238, acc 0.9375\n",
      "2017-04-03T19:57:56.506546: step 11157, loss 0.238508, acc 0.921875\n",
      "2017-04-03T19:57:56.715387: step 11158, loss 0.26332, acc 0.875\n",
      "2017-04-03T19:57:56.916597: step 11159, loss 0.181258, acc 0.953125\n",
      "2017-04-03T19:57:57.130478: step 11160, loss 0.134175, acc 0.953125\n",
      "2017-04-03T19:57:57.340242: step 11161, loss 0.590424, acc 0.8125\n",
      "2017-04-03T19:57:57.590379: step 11162, loss 0.251387, acc 0.9375\n",
      "2017-04-03T19:57:57.794606: step 11163, loss 0.263359, acc 0.9375\n",
      "2017-04-03T19:57:58.008858: step 11164, loss 0.23527, acc 0.90625\n",
      "2017-04-03T19:57:58.217788: step 11165, loss 0.344748, acc 0.875\n",
      "2017-04-03T19:57:58.429896: step 11166, loss 0.100849, acc 0.984375\n",
      "2017-04-03T19:57:58.631047: step 11167, loss 0.111302, acc 0.953125\n",
      "2017-04-03T19:57:58.836185: step 11168, loss 0.2205, acc 0.9375\n",
      "2017-04-03T19:57:59.049172: step 11169, loss 0.263541, acc 0.90625\n",
      "2017-04-03T19:57:59.251792: step 11170, loss 0.0520167, acc 1\n",
      "2017-04-03T19:57:59.448613: step 11171, loss 0.273879, acc 0.890625\n",
      "2017-04-03T19:57:59.647062: step 11172, loss 0.189663, acc 0.921875\n",
      "2017-04-03T19:57:59.851983: step 11173, loss 0.382126, acc 0.875\n",
      "2017-04-03T19:58:00.062921: step 11174, loss 0.212745, acc 0.9375\n",
      "2017-04-03T19:58:00.264997: step 11175, loss 0.211848, acc 0.953125\n",
      "2017-04-03T19:58:00.468607: step 11176, loss 0.237783, acc 0.921875\n",
      "2017-04-03T19:58:00.683523: step 11177, loss 0.168958, acc 0.953125\n",
      "2017-04-03T19:58:00.884465: step 11178, loss 0.168464, acc 0.953125\n",
      "2017-04-03T19:58:01.084777: step 11179, loss 0.226849, acc 0.921875\n",
      "2017-04-03T19:58:01.295851: step 11180, loss 0.249867, acc 0.90625\n",
      "2017-04-03T19:58:01.502660: step 11181, loss 0.157297, acc 0.953125\n",
      "2017-04-03T19:58:01.707373: step 11182, loss 0.311117, acc 0.9375\n",
      "2017-04-03T19:58:01.909071: step 11183, loss 0.186924, acc 0.90625\n",
      "2017-04-03T19:58:02.159611: step 11184, loss 0.338249, acc 0.890625\n",
      "2017-04-03T19:58:02.366868: step 11185, loss 0.250679, acc 0.953125\n",
      "2017-04-03T19:58:02.564550: step 11186, loss 0.213923, acc 0.890625\n",
      "2017-04-03T19:58:02.766872: step 11187, loss 0.268762, acc 0.921875\n",
      "2017-04-03T19:58:02.973713: step 11188, loss 0.299221, acc 0.890625\n",
      "2017-04-03T19:58:03.181046: step 11189, loss 0.309711, acc 0.90625\n",
      "2017-04-03T19:58:03.385626: step 11190, loss 0.331682, acc 0.859375\n",
      "2017-04-03T19:58:03.587728: step 11191, loss 0.161157, acc 0.953125\n",
      "2017-04-03T19:58:03.795471: step 11192, loss 0.411577, acc 0.859375\n",
      "2017-04-03T19:58:04.000839: step 11193, loss 0.34758, acc 0.90625\n",
      "2017-04-03T19:58:04.243861: step 11194, loss 0.281211, acc 0.890625\n",
      "2017-04-03T19:58:04.462460: step 11195, loss 0.258862, acc 0.890625\n",
      "2017-04-03T19:58:04.680595: step 11196, loss 0.210856, acc 0.9375\n",
      "2017-04-03T19:58:04.884750: step 11197, loss 0.2129, acc 0.953125\n",
      "2017-04-03T19:58:05.129204: step 11198, loss 0.239393, acc 0.96875\n",
      "2017-04-03T19:58:05.336685: step 11199, loss 0.375516, acc 0.90625\n",
      "2017-04-03T19:58:05.538855: step 11200, loss 0.231229, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:58:07.625129: step 11200, loss 4.63278, acc 0.29225\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-11200\n",
      "\n",
      "2017-04-03T19:58:07.955435: step 11201, loss 0.19802, acc 0.921875\n",
      "2017-04-03T19:58:08.157278: step 11202, loss 0.168058, acc 0.9375\n",
      "2017-04-03T19:58:08.400372: step 11203, loss 0.208378, acc 0.921875\n",
      "2017-04-03T19:58:08.609125: step 11204, loss 0.130126, acc 0.953125\n",
      "2017-04-03T19:58:08.819084: step 11205, loss 0.0593627, acc 0.96875\n",
      "2017-04-03T19:58:09.027781: step 11206, loss 0.144593, acc 0.9375\n",
      "2017-04-03T19:58:09.236771: step 11207, loss 0.091655, acc 0.984375\n",
      "2017-04-03T19:58:09.488035: step 11208, loss 0.169991, acc 0.9375\n",
      "2017-04-03T19:58:09.733291: step 11209, loss 0.20289, acc 0.953125\n",
      "2017-04-03T19:58:09.935597: step 11210, loss 0.264571, acc 0.90625\n",
      "2017-04-03T19:58:10.136274: step 11211, loss 0.26858, acc 0.9375\n",
      "2017-04-03T19:58:10.337039: step 11212, loss 0.165849, acc 0.953125\n",
      "2017-04-03T19:58:10.585437: step 11213, loss 0.273411, acc 0.875\n",
      "2017-04-03T19:58:10.791705: step 11214, loss 0.288869, acc 0.90625\n",
      "2017-04-03T19:58:10.999867: step 11215, loss 0.294062, acc 0.890625\n",
      "2017-04-03T19:58:11.219597: step 11216, loss 0.254916, acc 0.921875\n",
      "2017-04-03T19:58:11.432554: step 11217, loss 0.17065, acc 0.9375\n",
      "2017-04-03T19:58:11.639941: step 11218, loss 0.161076, acc 0.953125\n",
      "2017-04-03T19:58:11.842040: step 11219, loss 0.195169, acc 0.953125\n",
      "2017-04-03T19:58:12.090159: step 11220, loss 0.205637, acc 0.9375\n",
      "2017-04-03T19:58:12.301318: step 11221, loss 0.326151, acc 0.90625\n",
      "2017-04-03T19:58:12.509945: step 11222, loss 0.120891, acc 0.953125\n",
      "2017-04-03T19:58:12.711847: step 11223, loss 0.146994, acc 0.96875\n",
      "2017-04-03T19:58:12.914799: step 11224, loss 0.216627, acc 0.921875\n",
      "2017-04-03T19:58:13.122325: step 11225, loss 0.177168, acc 0.90625\n",
      "2017-04-03T19:58:13.322929: step 11226, loss 0.335243, acc 0.890625\n",
      "2017-04-03T19:58:13.523238: step 11227, loss 0.185331, acc 0.90625\n",
      "2017-04-03T19:58:13.727964: step 11228, loss 0.154965, acc 0.96875\n",
      "2017-04-03T19:58:13.931241: step 11229, loss 0.19972, acc 0.96875\n",
      "2017-04-03T19:58:14.136421: step 11230, loss 0.249869, acc 0.921875\n",
      "2017-04-03T19:58:14.382506: step 11231, loss 0.241331, acc 0.921875\n",
      "2017-04-03T19:58:14.591481: step 11232, loss 0.1607, acc 0.96875\n",
      "2017-04-03T19:58:14.794857: step 11233, loss 0.121475, acc 0.953125\n",
      "2017-04-03T19:58:14.994854: step 11234, loss 0.152393, acc 0.953125\n",
      "2017-04-03T19:58:15.200393: step 11235, loss 0.221712, acc 0.90625\n",
      "2017-04-03T19:58:15.404004: step 11236, loss 0.317382, acc 0.921875\n",
      "2017-04-03T19:58:15.612663: step 11237, loss 0.150653, acc 0.921875\n",
      "2017-04-03T19:58:15.819309: step 11238, loss 0.440647, acc 0.890625\n",
      "2017-04-03T19:58:16.019499: step 11239, loss 0.0768031, acc 1\n",
      "2017-04-03T19:58:16.230700: step 11240, loss 0.204808, acc 0.90625\n",
      "2017-04-03T19:58:16.437725: step 11241, loss 0.222188, acc 0.90625\n",
      "2017-04-03T19:58:16.684028: step 11242, loss 0.406236, acc 0.953125\n",
      "2017-04-03T19:58:16.894427: step 11243, loss 0.208397, acc 0.921875\n",
      "2017-04-03T19:58:17.148047: step 11244, loss 0.12989, acc 0.984375\n",
      "2017-04-03T19:58:17.363950: step 11245, loss 0.292175, acc 0.90625\n",
      "2017-04-03T19:58:17.576983: step 11246, loss 0.225529, acc 0.921875\n",
      "2017-04-03T19:58:17.825111: step 11247, loss 0.266888, acc 0.875\n",
      "2017-04-03T19:58:18.032575: step 11248, loss 0.307571, acc 0.890625\n",
      "2017-04-03T19:58:18.243485: step 11249, loss 0.12319, acc 0.96875\n",
      "2017-04-03T19:58:18.448692: step 11250, loss 0.135502, acc 0.984375\n",
      "2017-04-03T19:58:18.653583: step 11251, loss 0.268984, acc 0.90625\n",
      "2017-04-03T19:58:18.854956: step 11252, loss 0.328029, acc 0.9375\n",
      "2017-04-03T19:58:19.104768: step 11253, loss 0.151246, acc 0.953125\n",
      "2017-04-03T19:58:19.309055: step 11254, loss 0.0519047, acc 0.984375\n",
      "2017-04-03T19:58:19.513767: step 11255, loss 0.431931, acc 0.84375\n",
      "2017-04-03T19:58:19.718297: step 11256, loss 0.184604, acc 0.921875\n",
      "2017-04-03T19:58:19.933042: step 11257, loss 0.277615, acc 0.90625\n",
      "2017-04-03T19:58:20.141171: step 11258, loss 0.36889, acc 0.921875\n",
      "2017-04-03T19:58:20.350794: step 11259, loss 0.164075, acc 0.953125\n",
      "2017-04-03T19:58:20.498313: step 11260, loss 0.171558, acc 0.875\n",
      "2017-04-03T19:58:20.707596: step 11261, loss 0.189499, acc 0.9375\n",
      "2017-04-03T19:58:20.908755: step 11262, loss 0.219376, acc 0.921875\n",
      "2017-04-03T19:58:21.108969: step 11263, loss 0.0999825, acc 0.96875\n",
      "2017-04-03T19:58:21.314220: step 11264, loss 0.0731864, acc 0.984375\n",
      "2017-04-03T19:58:21.520543: step 11265, loss 0.100126, acc 0.953125\n",
      "2017-04-03T19:58:21.738252: step 11266, loss 0.150551, acc 0.9375\n",
      "2017-04-03T19:58:21.957498: step 11267, loss 0.186791, acc 0.953125\n",
      "2017-04-03T19:58:22.217092: step 11268, loss 0.0961072, acc 0.96875\n",
      "2017-04-03T19:58:22.419788: step 11269, loss 0.137716, acc 0.96875\n",
      "2017-04-03T19:58:22.620215: step 11270, loss 0.320117, acc 0.875\n",
      "2017-04-03T19:58:22.826650: step 11271, loss 0.113326, acc 0.984375\n",
      "2017-04-03T19:58:23.031826: step 11272, loss 0.221075, acc 0.953125\n",
      "2017-04-03T19:58:23.233893: step 11273, loss 0.204126, acc 0.90625\n",
      "2017-04-03T19:58:23.435186: step 11274, loss 0.0884646, acc 0.96875\n",
      "2017-04-03T19:58:23.643716: step 11275, loss 0.188815, acc 0.9375\n",
      "2017-04-03T19:58:23.848126: step 11276, loss 0.153355, acc 0.953125\n",
      "2017-04-03T19:58:24.051688: step 11277, loss 0.246631, acc 0.9375\n",
      "2017-04-03T19:58:24.296914: step 11278, loss 0.114561, acc 0.96875\n",
      "2017-04-03T19:58:24.501940: step 11279, loss 0.158034, acc 0.921875\n",
      "2017-04-03T19:58:24.708860: step 11280, loss 0.195869, acc 0.9375\n",
      "2017-04-03T19:58:24.909797: step 11281, loss 0.242922, acc 0.921875\n",
      "2017-04-03T19:58:25.114650: step 11282, loss 0.137036, acc 0.953125\n",
      "2017-04-03T19:58:25.323057: step 11283, loss 0.191205, acc 0.953125\n",
      "2017-04-03T19:58:25.542434: step 11284, loss 0.164323, acc 0.9375\n",
      "2017-04-03T19:58:25.751322: step 11285, loss 0.24775, acc 0.90625\n",
      "2017-04-03T19:58:25.955793: step 11286, loss 0.17366, acc 0.953125\n",
      "2017-04-03T19:58:26.163796: step 11287, loss 0.116799, acc 0.953125\n",
      "2017-04-03T19:58:26.366536: step 11288, loss 0.209762, acc 0.9375\n",
      "2017-04-03T19:58:26.571035: step 11289, loss 0.162613, acc 0.953125\n",
      "2017-04-03T19:58:26.774523: step 11290, loss 0.185484, acc 0.921875\n",
      "2017-04-03T19:58:26.976263: step 11291, loss 0.232159, acc 0.921875\n",
      "2017-04-03T19:58:27.196297: step 11292, loss 0.216846, acc 0.953125\n",
      "2017-04-03T19:58:27.408744: step 11293, loss 0.165115, acc 0.921875\n",
      "2017-04-03T19:58:27.610111: step 11294, loss 0.0561372, acc 0.984375\n",
      "2017-04-03T19:58:27.814738: step 11295, loss 0.148305, acc 0.921875\n",
      "2017-04-03T19:58:28.018733: step 11296, loss 0.233781, acc 0.9375\n",
      "2017-04-03T19:58:28.221528: step 11297, loss 0.449547, acc 0.921875\n",
      "2017-04-03T19:58:28.425099: step 11298, loss 0.173412, acc 0.9375\n",
      "2017-04-03T19:58:28.632614: step 11299, loss 0.162837, acc 0.953125\n",
      "2017-04-03T19:58:28.882343: step 11300, loss 0.120325, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:58:30.963284: step 11300, loss 4.74995, acc 0.29375\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-11300\n",
      "\n",
      "2017-04-03T19:58:31.292082: step 11301, loss 0.112297, acc 0.96875\n",
      "2017-04-03T19:58:31.498809: step 11302, loss 0.174274, acc 0.953125\n",
      "2017-04-03T19:58:31.706961: step 11303, loss 0.121693, acc 0.96875\n",
      "2017-04-03T19:58:31.916490: step 11304, loss 0.178992, acc 0.921875\n",
      "2017-04-03T19:58:32.121227: step 11305, loss 0.187725, acc 0.890625\n",
      "2017-04-03T19:58:32.323051: step 11306, loss 0.213474, acc 0.921875\n",
      "2017-04-03T19:58:32.523116: step 11307, loss 0.0986164, acc 0.96875\n",
      "2017-04-03T19:58:32.729797: step 11308, loss 0.089079, acc 0.984375\n",
      "2017-04-03T19:58:32.929813: step 11309, loss 0.235175, acc 0.90625\n",
      "2017-04-03T19:58:33.132332: step 11310, loss 0.283129, acc 0.9375\n",
      "2017-04-03T19:58:33.335727: step 11311, loss 0.0957538, acc 0.984375\n",
      "2017-04-03T19:58:33.582453: step 11312, loss 0.154344, acc 0.953125\n",
      "2017-04-03T19:58:33.782507: step 11313, loss 0.164309, acc 0.921875\n",
      "2017-04-03T19:58:33.985221: step 11314, loss 0.212508, acc 0.90625\n",
      "2017-04-03T19:58:34.198094: step 11315, loss 0.183828, acc 0.9375\n",
      "2017-04-03T19:58:34.415485: step 11316, loss 0.137961, acc 0.953125\n",
      "2017-04-03T19:58:34.616648: step 11317, loss 0.114219, acc 0.96875\n",
      "2017-04-03T19:58:34.857501: step 11318, loss 0.218048, acc 0.921875\n",
      "2017-04-03T19:58:35.104730: step 11319, loss 0.159759, acc 0.953125\n",
      "2017-04-03T19:58:35.317587: step 11320, loss 0.133837, acc 0.953125\n",
      "2017-04-03T19:58:35.524166: step 11321, loss 0.255354, acc 0.890625\n",
      "2017-04-03T19:58:35.729472: step 11322, loss 0.218162, acc 0.921875\n",
      "2017-04-03T19:58:35.934101: step 11323, loss 0.113621, acc 0.96875\n",
      "2017-04-03T19:58:36.155594: step 11324, loss 0.16124, acc 0.96875\n",
      "2017-04-03T19:58:36.370399: step 11325, loss 0.148345, acc 0.953125\n",
      "2017-04-03T19:58:36.577676: step 11326, loss 0.335872, acc 0.84375\n",
      "2017-04-03T19:58:36.780440: step 11327, loss 0.107021, acc 0.953125\n",
      "2017-04-03T19:58:36.981848: step 11328, loss 0.10774, acc 0.984375\n",
      "2017-04-03T19:58:37.187068: step 11329, loss 0.104076, acc 0.953125\n",
      "2017-04-03T19:58:37.387585: step 11330, loss 0.233281, acc 0.921875\n",
      "2017-04-03T19:58:37.594743: step 11331, loss 0.19527, acc 0.9375\n",
      "2017-04-03T19:58:37.803828: step 11332, loss 0.233691, acc 0.9375\n",
      "2017-04-03T19:58:38.009034: step 11333, loss 0.147383, acc 0.96875\n",
      "2017-04-03T19:58:38.218149: step 11334, loss 0.132471, acc 0.984375\n",
      "2017-04-03T19:58:38.434378: step 11335, loss 0.0932598, acc 0.984375\n",
      "2017-04-03T19:58:38.642243: step 11336, loss 0.179042, acc 0.921875\n",
      "2017-04-03T19:58:38.845298: step 11337, loss 0.129131, acc 0.9375\n",
      "2017-04-03T19:58:39.054290: step 11338, loss 0.134925, acc 0.953125\n",
      "2017-04-03T19:58:39.256780: step 11339, loss 0.207019, acc 0.9375\n",
      "2017-04-03T19:58:39.499178: step 11340, loss 0.146303, acc 0.9375\n",
      "2017-04-03T19:58:39.701255: step 11341, loss 0.0663042, acc 0.984375\n",
      "2017-04-03T19:58:39.905943: step 11342, loss 0.117968, acc 0.953125\n",
      "2017-04-03T19:58:40.112884: step 11343, loss 0.105283, acc 1\n",
      "2017-04-03T19:58:40.314437: step 11344, loss 0.18525, acc 0.9375\n",
      "2017-04-03T19:58:40.517086: step 11345, loss 0.189592, acc 0.921875\n",
      "2017-04-03T19:58:40.718397: step 11346, loss 0.107179, acc 0.984375\n",
      "2017-04-03T19:58:40.922244: step 11347, loss 0.225644, acc 0.921875\n",
      "2017-04-03T19:58:41.123525: step 11348, loss 0.204846, acc 0.921875\n",
      "2017-04-03T19:58:41.331586: step 11349, loss 0.116969, acc 0.953125\n",
      "2017-04-03T19:58:41.542364: step 11350, loss 0.253646, acc 0.90625\n",
      "2017-04-03T19:58:41.744593: step 11351, loss 0.223104, acc 0.9375\n",
      "2017-04-03T19:58:41.951241: step 11352, loss 0.135099, acc 0.953125\n",
      "2017-04-03T19:58:42.152819: step 11353, loss 0.130026, acc 0.96875\n",
      "2017-04-03T19:58:42.363692: step 11354, loss 0.102193, acc 0.96875\n",
      "2017-04-03T19:58:42.565758: step 11355, loss 0.1716, acc 0.9375\n",
      "2017-04-03T19:58:42.770643: step 11356, loss 0.158821, acc 0.953125\n",
      "2017-04-03T19:58:42.976806: step 11357, loss 0.0851129, acc 0.984375\n",
      "2017-04-03T19:58:43.185899: step 11358, loss 0.0850408, acc 0.953125\n",
      "2017-04-03T19:58:43.388891: step 11359, loss 0.276491, acc 0.953125\n",
      "2017-04-03T19:58:43.590798: step 11360, loss 0.165872, acc 0.9375\n",
      "2017-04-03T19:58:43.799839: step 11361, loss 0.171611, acc 0.953125\n",
      "2017-04-03T19:58:44.008079: step 11362, loss 0.345732, acc 0.90625\n",
      "2017-04-03T19:58:44.213602: step 11363, loss 0.179737, acc 0.953125\n",
      "2017-04-03T19:58:44.417328: step 11364, loss 0.190581, acc 0.96875\n",
      "2017-04-03T19:58:44.628303: step 11365, loss 0.178632, acc 0.9375\n",
      "2017-04-03T19:58:44.832216: step 11366, loss 0.213451, acc 0.9375\n",
      "2017-04-03T19:58:45.032224: step 11367, loss 0.212126, acc 0.921875\n",
      "2017-04-03T19:58:45.236961: step 11368, loss 0.159311, acc 0.953125\n",
      "2017-04-03T19:58:45.443951: step 11369, loss 0.41741, acc 0.9375\n",
      "2017-04-03T19:58:45.646250: step 11370, loss 0.228589, acc 0.921875\n",
      "2017-04-03T19:58:45.864982: step 11371, loss 0.151677, acc 0.953125\n",
      "2017-04-03T19:58:46.085489: step 11372, loss 0.166127, acc 0.953125\n",
      "2017-04-03T19:58:46.306896: step 11373, loss 0.159286, acc 0.953125\n",
      "2017-04-03T19:58:46.550058: step 11374, loss 0.158107, acc 0.921875\n",
      "2017-04-03T19:58:46.761620: step 11375, loss 0.221106, acc 0.9375\n",
      "2017-04-03T19:58:46.963578: step 11376, loss 0.207935, acc 0.921875\n",
      "2017-04-03T19:58:47.164175: step 11377, loss 0.140901, acc 0.96875\n",
      "2017-04-03T19:58:47.380795: step 11378, loss 0.129822, acc 0.984375\n",
      "2017-04-03T19:58:47.595907: step 11379, loss 0.190947, acc 0.921875\n",
      "2017-04-03T19:58:47.792482: step 11380, loss 0.148536, acc 0.96875\n",
      "2017-04-03T19:58:48.034023: step 11381, loss 0.160619, acc 0.9375\n",
      "2017-04-03T19:58:48.235567: step 11382, loss 0.199123, acc 0.9375\n",
      "2017-04-03T19:58:48.434183: step 11383, loss 0.255625, acc 0.96875\n",
      "2017-04-03T19:58:48.676915: step 11384, loss 0.0561013, acc 1\n",
      "2017-04-03T19:58:48.878895: step 11385, loss 0.241981, acc 0.9375\n",
      "2017-04-03T19:58:49.082241: step 11386, loss 0.0468074, acc 1\n",
      "2017-04-03T19:58:49.284759: step 11387, loss 0.306482, acc 0.90625\n",
      "2017-04-03T19:58:49.485351: step 11388, loss 0.241236, acc 0.921875\n",
      "2017-04-03T19:58:49.694092: step 11389, loss 0.26223, acc 0.9375\n",
      "2017-04-03T19:58:49.898804: step 11390, loss 0.218242, acc 0.9375\n",
      "2017-04-03T19:58:50.109323: step 11391, loss 0.302493, acc 0.890625\n",
      "2017-04-03T19:58:50.306420: step 11392, loss 0.172583, acc 0.953125\n",
      "2017-04-03T19:58:50.513892: step 11393, loss 0.483155, acc 0.90625\n",
      "2017-04-03T19:58:50.714595: step 11394, loss 0.263204, acc 0.890625\n",
      "2017-04-03T19:58:50.923259: step 11395, loss 0.252713, acc 0.953125\n",
      "2017-04-03T19:58:51.126008: step 11396, loss 0.151175, acc 0.953125\n",
      "2017-04-03T19:58:51.324838: step 11397, loss 0.243687, acc 0.890625\n",
      "2017-04-03T19:58:51.529789: step 11398, loss 0.158979, acc 0.96875\n",
      "2017-04-03T19:58:51.729867: step 11399, loss 0.163297, acc 0.953125\n",
      "2017-04-03T19:58:51.933664: step 11400, loss 0.209324, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:58:54.077411: step 11400, loss 4.77539, acc 0.2855\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-11400\n",
      "\n",
      "2017-04-03T19:58:54.403105: step 11401, loss 0.164807, acc 0.953125\n",
      "2017-04-03T19:58:54.608015: step 11402, loss 0.19793, acc 0.921875\n",
      "2017-04-03T19:58:54.815457: step 11403, loss 0.172752, acc 0.953125\n",
      "2017-04-03T19:58:55.030846: step 11404, loss 0.237175, acc 0.9375\n",
      "2017-04-03T19:58:55.278303: step 11405, loss 0.162516, acc 0.9375\n",
      "2017-04-03T19:58:55.484359: step 11406, loss 0.338158, acc 0.875\n",
      "2017-04-03T19:58:55.687899: step 11407, loss 0.25836, acc 0.9375\n",
      "2017-04-03T19:58:55.893077: step 11408, loss 0.221125, acc 0.890625\n",
      "2017-04-03T19:58:56.098570: step 11409, loss 0.202414, acc 0.921875\n",
      "2017-04-03T19:58:56.301105: step 11410, loss 0.145326, acc 0.9375\n",
      "2017-04-03T19:58:56.504616: step 11411, loss 0.100362, acc 0.953125\n",
      "2017-04-03T19:58:56.738260: step 11412, loss 0.139025, acc 0.953125\n",
      "2017-04-03T19:58:56.940951: step 11413, loss 0.173505, acc 0.921875\n",
      "2017-04-03T19:58:57.142031: step 11414, loss 0.205009, acc 0.921875\n",
      "2017-04-03T19:58:57.343105: step 11415, loss 0.180414, acc 0.9375\n",
      "2017-04-03T19:58:57.549923: step 11416, loss 0.182973, acc 0.921875\n",
      "2017-04-03T19:58:57.754408: step 11417, loss 0.115498, acc 0.96875\n",
      "2017-04-03T19:58:57.989876: step 11418, loss 0.185596, acc 0.9375\n",
      "2017-04-03T19:58:58.189165: step 11419, loss 0.268885, acc 0.9375\n",
      "2017-04-03T19:58:58.393423: step 11420, loss 0.0620405, acc 1\n",
      "2017-04-03T19:58:58.595405: step 11421, loss 0.190837, acc 0.953125\n",
      "2017-04-03T19:58:58.786981: step 11422, loss 0.185644, acc 0.9375\n",
      "2017-04-03T19:58:58.986815: step 11423, loss 0.110914, acc 0.96875\n",
      "2017-04-03T19:58:59.192471: step 11424, loss 0.168596, acc 0.9375\n",
      "2017-04-03T19:58:59.404549: step 11425, loss 0.134661, acc 0.9375\n",
      "2017-04-03T19:58:59.619277: step 11426, loss 0.16518, acc 0.953125\n",
      "2017-04-03T19:58:59.818157: step 11427, loss 0.270112, acc 0.890625\n",
      "2017-04-03T19:59:00.019317: step 11428, loss 0.17298, acc 0.9375\n",
      "2017-04-03T19:59:00.223709: step 11429, loss 0.13916, acc 0.953125\n",
      "2017-04-03T19:59:00.425331: step 11430, loss 0.223775, acc 0.953125\n",
      "2017-04-03T19:59:00.626982: step 11431, loss 0.158985, acc 0.953125\n",
      "2017-04-03T19:59:00.827043: step 11432, loss 0.173833, acc 0.953125\n",
      "2017-04-03T19:59:01.029066: step 11433, loss 0.130045, acc 0.953125\n",
      "2017-04-03T19:59:01.231756: step 11434, loss 0.17275, acc 0.953125\n",
      "2017-04-03T19:59:01.436401: step 11435, loss 0.276764, acc 0.921875\n",
      "2017-04-03T19:59:01.636027: step 11436, loss 0.107386, acc 0.984375\n",
      "2017-04-03T19:59:01.841008: step 11437, loss 0.25372, acc 0.9375\n",
      "2017-04-03T19:59:02.044368: step 11438, loss 0.253719, acc 0.9375\n",
      "2017-04-03T19:59:02.250365: step 11439, loss 0.153246, acc 0.921875\n",
      "2017-04-03T19:59:02.453601: step 11440, loss 0.136981, acc 0.9375\n",
      "2017-04-03T19:59:02.658041: step 11441, loss 0.116955, acc 0.96875\n",
      "2017-04-03T19:59:02.859643: step 11442, loss 0.11296, acc 0.96875\n",
      "2017-04-03T19:59:03.062895: step 11443, loss 0.119048, acc 0.953125\n",
      "2017-04-03T19:59:03.267385: step 11444, loss 0.153342, acc 0.953125\n",
      "2017-04-03T19:59:03.467736: step 11445, loss 0.31382, acc 0.875\n",
      "2017-04-03T19:59:03.667555: step 11446, loss 0.199265, acc 0.96875\n",
      "2017-04-03T19:59:03.873438: step 11447, loss 0.0736629, acc 0.984375\n",
      "2017-04-03T19:59:04.074950: step 11448, loss 0.162899, acc 0.953125\n",
      "2017-04-03T19:59:04.272682: step 11449, loss 0.176378, acc 0.953125\n",
      "2017-04-03T19:59:04.474136: step 11450, loss 0.115124, acc 0.96875\n",
      "2017-04-03T19:59:04.674056: step 11451, loss 0.161533, acc 0.9375\n",
      "2017-04-03T19:59:04.883008: step 11452, loss 0.189284, acc 0.9375\n",
      "2017-04-03T19:59:05.087328: step 11453, loss 0.16377, acc 0.953125\n",
      "2017-04-03T19:59:05.289542: step 11454, loss 0.111057, acc 0.953125\n",
      "2017-04-03T19:59:05.494956: step 11455, loss 0.141008, acc 0.921875\n",
      "2017-04-03T19:59:05.695116: step 11456, loss 0.182672, acc 0.953125\n",
      "2017-04-03T19:59:05.899026: step 11457, loss 0.128268, acc 0.984375\n",
      "2017-04-03T19:59:06.097386: step 11458, loss 0.152056, acc 0.953125\n",
      "2017-04-03T19:59:06.298853: step 11459, loss 0.213419, acc 0.96875\n",
      "2017-04-03T19:59:06.503960: step 11460, loss 0.133499, acc 0.953125\n",
      "2017-04-03T19:59:06.709376: step 11461, loss 0.249286, acc 0.90625\n",
      "2017-04-03T19:59:06.908396: step 11462, loss 0.156573, acc 0.96875\n",
      "2017-04-03T19:59:07.121661: step 11463, loss 0.209295, acc 0.921875\n",
      "2017-04-03T19:59:07.338185: step 11464, loss 0.135064, acc 0.96875\n",
      "2017-04-03T19:59:07.540083: step 11465, loss 0.173788, acc 0.9375\n",
      "2017-04-03T19:59:07.747845: step 11466, loss 0.144413, acc 0.96875\n",
      "2017-04-03T19:59:07.952825: step 11467, loss 0.151806, acc 0.9375\n",
      "2017-04-03T19:59:08.155754: step 11468, loss 0.158099, acc 0.9375\n",
      "2017-04-03T19:59:08.354547: step 11469, loss 0.234273, acc 0.921875\n",
      "2017-04-03T19:59:08.600397: step 11470, loss 0.393067, acc 0.890625\n",
      "2017-04-03T19:59:08.798699: step 11471, loss 0.339475, acc 0.90625\n",
      "2017-04-03T19:59:09.002771: step 11472, loss 0.233345, acc 0.9375\n",
      "2017-04-03T19:59:09.199714: step 11473, loss 0.25548, acc 0.875\n",
      "2017-04-03T19:59:09.397220: step 11474, loss 0.14827, acc 0.953125\n",
      "2017-04-03T19:59:09.603912: step 11475, loss 0.179351, acc 0.953125\n",
      "2017-04-03T19:59:09.810393: step 11476, loss 0.260413, acc 0.921875\n",
      "2017-04-03T19:59:10.010433: step 11477, loss 0.320068, acc 0.90625\n",
      "2017-04-03T19:59:10.208580: step 11478, loss 0.163973, acc 0.953125\n",
      "2017-04-03T19:59:10.453060: step 11479, loss 0.101319, acc 0.96875\n",
      "2017-04-03T19:59:10.665664: step 11480, loss 0.133385, acc 0.984375\n",
      "2017-04-03T19:59:10.870665: step 11481, loss 0.435266, acc 0.890625\n",
      "2017-04-03T19:59:11.070525: step 11482, loss 0.11138, acc 0.953125\n",
      "2017-04-03T19:59:11.317975: step 11483, loss 0.0936164, acc 0.984375\n",
      "2017-04-03T19:59:11.574931: step 11484, loss 0.12898, acc 0.984375\n",
      "2017-04-03T19:59:11.794281: step 11485, loss 0.187984, acc 0.921875\n",
      "2017-04-03T19:59:11.994020: step 11486, loss 0.261317, acc 0.9375\n",
      "2017-04-03T19:59:12.197057: step 11487, loss 0.126511, acc 0.953125\n",
      "2017-04-03T19:59:12.399282: step 11488, loss 0.199913, acc 0.953125\n",
      "2017-04-03T19:59:12.599010: step 11489, loss 0.124293, acc 0.9375\n",
      "2017-04-03T19:59:12.802940: step 11490, loss 0.330557, acc 0.875\n",
      "2017-04-03T19:59:13.006270: step 11491, loss 0.0653763, acc 0.984375\n",
      "2017-04-03T19:59:13.215746: step 11492, loss 0.140184, acc 0.9375\n",
      "2017-04-03T19:59:13.418349: step 11493, loss 0.432206, acc 0.890625\n",
      "2017-04-03T19:59:13.618556: step 11494, loss 0.185151, acc 0.984375\n",
      "2017-04-03T19:59:13.817660: step 11495, loss 0.202934, acc 0.9375\n",
      "2017-04-03T19:59:14.014160: step 11496, loss 0.171699, acc 0.953125\n",
      "2017-04-03T19:59:14.222373: step 11497, loss 0.165569, acc 0.9375\n",
      "2017-04-03T19:59:14.427512: step 11498, loss 0.195831, acc 0.96875\n",
      "2017-04-03T19:59:14.629649: step 11499, loss 0.25319, acc 0.90625\n",
      "2017-04-03T19:59:14.833880: step 11500, loss 0.221157, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:59:16.898716: step 11500, loss 4.83638, acc 0.297\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-11500\n",
      "\n",
      "2017-04-03T19:59:17.271420: step 11501, loss 0.20644, acc 0.921875\n",
      "2017-04-03T19:59:17.478072: step 11502, loss 0.231875, acc 0.953125\n",
      "2017-04-03T19:59:17.684570: step 11503, loss 0.167679, acc 0.921875\n",
      "2017-04-03T19:59:17.888203: step 11504, loss 0.26769, acc 0.921875\n",
      "2017-04-03T19:59:18.089733: step 11505, loss 0.269863, acc 0.921875\n",
      "2017-04-03T19:59:18.296698: step 11506, loss 0.192278, acc 0.9375\n",
      "2017-04-03T19:59:18.499596: step 11507, loss 0.166132, acc 0.921875\n",
      "2017-04-03T19:59:18.698347: step 11508, loss 0.167477, acc 0.9375\n",
      "2017-04-03T19:59:18.901268: step 11509, loss 0.128269, acc 0.96875\n",
      "2017-04-03T19:59:19.102327: step 11510, loss 0.185861, acc 0.90625\n",
      "2017-04-03T19:59:19.302600: step 11511, loss 0.129504, acc 0.953125\n",
      "2017-04-03T19:59:19.506039: step 11512, loss 0.282519, acc 0.96875\n",
      "2017-04-03T19:59:19.708293: step 11513, loss 0.293307, acc 0.90625\n",
      "2017-04-03T19:59:19.916570: step 11514, loss 0.171093, acc 0.953125\n",
      "2017-04-03T19:59:20.119277: step 11515, loss 0.219541, acc 0.9375\n",
      "2017-04-03T19:59:20.359441: step 11516, loss 0.237517, acc 0.90625\n",
      "2017-04-03T19:59:20.559205: step 11517, loss 0.14762, acc 0.984375\n",
      "2017-04-03T19:59:20.762305: step 11518, loss 0.148013, acc 0.96875\n",
      "2017-04-03T19:59:21.006217: step 11519, loss 0.208627, acc 0.921875\n",
      "2017-04-03T19:59:21.255787: step 11520, loss 0.0998308, acc 1\n",
      "2017-04-03T19:59:21.516910: step 11521, loss 0.215675, acc 0.890625\n",
      "2017-04-03T19:59:21.716040: step 11522, loss 0.138191, acc 0.984375\n",
      "2017-04-03T19:59:21.914446: step 11523, loss 0.219698, acc 0.9375\n",
      "2017-04-03T19:59:22.119830: step 11524, loss 0.254821, acc 0.9375\n",
      "2017-04-03T19:59:22.320855: step 11525, loss 0.36262, acc 0.921875\n",
      "2017-04-03T19:59:22.517796: step 11526, loss 0.237289, acc 0.921875\n",
      "2017-04-03T19:59:22.721961: step 11527, loss 0.114455, acc 0.953125\n",
      "2017-04-03T19:59:22.927859: step 11528, loss 0.183539, acc 0.9375\n",
      "2017-04-03T19:59:23.143007: step 11529, loss 0.24144, acc 0.9375\n",
      "2017-04-03T19:59:23.347645: step 11530, loss 0.324411, acc 0.90625\n",
      "2017-04-03T19:59:23.553472: step 11531, loss 0.169557, acc 0.921875\n",
      "2017-04-03T19:59:23.801456: step 11532, loss 0.101132, acc 0.96875\n",
      "2017-04-03T19:59:24.002589: step 11533, loss 0.235703, acc 0.90625\n",
      "2017-04-03T19:59:24.205280: step 11534, loss 0.195311, acc 0.9375\n",
      "2017-04-03T19:59:24.423599: step 11535, loss 0.127926, acc 0.953125\n",
      "2017-04-03T19:59:24.628799: step 11536, loss 0.131815, acc 0.984375\n",
      "2017-04-03T19:59:24.837445: step 11537, loss 0.167513, acc 0.96875\n",
      "2017-04-03T19:59:25.038499: step 11538, loss 0.135154, acc 0.96875\n",
      "2017-04-03T19:59:25.242205: step 11539, loss 0.142998, acc 0.96875\n",
      "2017-04-03T19:59:25.447448: step 11540, loss 0.137512, acc 0.96875\n",
      "2017-04-03T19:59:25.650119: step 11541, loss 0.121212, acc 0.953125\n",
      "2017-04-03T19:59:25.850248: step 11542, loss 0.142368, acc 0.921875\n",
      "2017-04-03T19:59:26.060006: step 11543, loss 0.15391, acc 0.96875\n",
      "2017-04-03T19:59:26.256818: step 11544, loss 0.16301, acc 0.9375\n",
      "2017-04-03T19:59:26.455011: step 11545, loss 0.311007, acc 0.890625\n",
      "2017-04-03T19:59:26.655010: step 11546, loss 0.169636, acc 0.9375\n",
      "2017-04-03T19:59:26.858230: step 11547, loss 0.270852, acc 0.90625\n",
      "2017-04-03T19:59:27.098888: step 11548, loss 0.252224, acc 0.921875\n",
      "2017-04-03T19:59:27.313148: step 11549, loss 0.120224, acc 0.96875\n",
      "2017-04-03T19:59:27.520087: step 11550, loss 0.209892, acc 0.953125\n",
      "2017-04-03T19:59:27.719030: step 11551, loss 0.0934089, acc 0.96875\n",
      "2017-04-03T19:59:27.924077: step 11552, loss 0.174616, acc 0.953125\n",
      "2017-04-03T19:59:28.129734: step 11553, loss 0.0923332, acc 0.984375\n",
      "2017-04-03T19:59:28.331463: step 11554, loss 0.278243, acc 0.84375\n",
      "2017-04-03T19:59:28.532082: step 11555, loss 0.107563, acc 1\n",
      "2017-04-03T19:59:28.739349: step 11556, loss 0.104969, acc 0.96875\n",
      "2017-04-03T19:59:28.944521: step 11557, loss 0.298286, acc 0.890625\n",
      "2017-04-03T19:59:29.148319: step 11558, loss 0.202876, acc 0.9375\n",
      "2017-04-03T19:59:29.346183: step 11559, loss 0.195392, acc 0.9375\n",
      "2017-04-03T19:59:29.592395: step 11560, loss 0.191299, acc 0.953125\n",
      "2017-04-03T19:59:29.845044: step 11561, loss 0.175199, acc 0.953125\n",
      "2017-04-03T19:59:30.044405: step 11562, loss 0.231332, acc 0.890625\n",
      "2017-04-03T19:59:30.245652: step 11563, loss 0.0884189, acc 0.984375\n",
      "2017-04-03T19:59:30.448252: step 11564, loss 0.0933212, acc 0.984375\n",
      "2017-04-03T19:59:30.665027: step 11565, loss 0.151386, acc 0.96875\n",
      "2017-04-03T19:59:30.864939: step 11566, loss 0.202997, acc 0.953125\n",
      "2017-04-03T19:59:31.066059: step 11567, loss 0.0804148, acc 0.984375\n",
      "2017-04-03T19:59:31.263471: step 11568, loss 0.224305, acc 0.921875\n",
      "2017-04-03T19:59:31.463964: step 11569, loss 0.227511, acc 0.953125\n",
      "2017-04-03T19:59:31.670309: step 11570, loss 0.0757516, acc 0.984375\n",
      "2017-04-03T19:59:31.868623: step 11571, loss 0.355246, acc 0.875\n",
      "2017-04-03T19:59:32.074331: step 11572, loss 0.10293, acc 0.984375\n",
      "2017-04-03T19:59:32.280757: step 11573, loss 0.324425, acc 0.90625\n",
      "2017-04-03T19:59:32.487397: step 11574, loss 0.223223, acc 0.90625\n",
      "2017-04-03T19:59:32.681780: step 11575, loss 0.224001, acc 0.921875\n",
      "2017-04-03T19:59:32.892350: step 11576, loss 0.092343, acc 0.96875\n",
      "2017-04-03T19:59:33.094595: step 11577, loss 0.351053, acc 0.890625\n",
      "2017-04-03T19:59:33.301380: step 11578, loss 0.226117, acc 0.890625\n",
      "2017-04-03T19:59:33.507016: step 11579, loss 0.276902, acc 0.875\n",
      "2017-04-03T19:59:33.710176: step 11580, loss 0.104708, acc 0.96875\n",
      "2017-04-03T19:59:33.915446: step 11581, loss 0.144896, acc 0.96875\n",
      "2017-04-03T19:59:34.118652: step 11582, loss 0.129502, acc 0.984375\n",
      "2017-04-03T19:59:34.323788: step 11583, loss 0.160642, acc 0.953125\n",
      "2017-04-03T19:59:34.573371: step 11584, loss 0.261317, acc 0.90625\n",
      "2017-04-03T19:59:34.776265: step 11585, loss 0.169923, acc 0.953125\n",
      "2017-04-03T19:59:34.985205: step 11586, loss 0.220119, acc 0.921875\n",
      "2017-04-03T19:59:35.185683: step 11587, loss 0.191863, acc 0.9375\n",
      "2017-04-03T19:59:35.385940: step 11588, loss 0.251184, acc 0.953125\n",
      "2017-04-03T19:59:35.585319: step 11589, loss 0.257827, acc 0.890625\n",
      "2017-04-03T19:59:35.785778: step 11590, loss 0.141066, acc 0.953125\n",
      "2017-04-03T19:59:35.986906: step 11591, loss 0.205468, acc 0.921875\n",
      "2017-04-03T19:59:36.190064: step 11592, loss 0.278462, acc 0.875\n",
      "2017-04-03T19:59:36.389388: step 11593, loss 0.0735702, acc 0.96875\n",
      "2017-04-03T19:59:36.595064: step 11594, loss 0.162006, acc 0.9375\n",
      "2017-04-03T19:59:36.795714: step 11595, loss 0.155444, acc 0.9375\n",
      "2017-04-03T19:59:37.000743: step 11596, loss 0.246366, acc 0.921875\n",
      "2017-04-03T19:59:37.205756: step 11597, loss 0.158255, acc 0.9375\n",
      "2017-04-03T19:59:37.414114: step 11598, loss 0.218491, acc 0.953125\n",
      "2017-04-03T19:59:37.620398: step 11599, loss 0.064286, acc 0.984375\n",
      "2017-04-03T19:59:37.825354: step 11600, loss 0.257959, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T19:59:39.920801: step 11600, loss 4.86679, acc 0.29775\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-11600\n",
      "\n",
      "2017-04-03T19:59:40.247023: step 11601, loss 0.368821, acc 0.890625\n",
      "2017-04-03T19:59:40.448993: step 11602, loss 0.18414, acc 0.953125\n",
      "2017-04-03T19:59:40.647713: step 11603, loss 0.227754, acc 0.953125\n",
      "2017-04-03T19:59:40.846669: step 11604, loss 0.293829, acc 0.90625\n",
      "2017-04-03T19:59:41.101336: step 11605, loss 0.25883, acc 0.90625\n",
      "2017-04-03T19:59:41.306278: step 11606, loss 0.685231, acc 0.84375\n",
      "2017-04-03T19:59:41.552589: step 11607, loss 0.125604, acc 0.953125\n",
      "2017-04-03T19:59:41.752560: step 11608, loss 0.231962, acc 0.9375\n",
      "2017-04-03T19:59:41.957413: step 11609, loss 0.165658, acc 0.953125\n",
      "2017-04-03T19:59:42.209157: step 11610, loss 0.15664, acc 0.953125\n",
      "2017-04-03T19:59:42.416442: step 11611, loss 0.194278, acc 0.90625\n",
      "2017-04-03T19:59:42.617743: step 11612, loss 0.114999, acc 0.953125\n",
      "2017-04-03T19:59:42.818937: step 11613, loss 0.0941769, acc 0.96875\n",
      "2017-04-03T19:59:43.029870: step 11614, loss 0.162294, acc 0.953125\n",
      "2017-04-03T19:59:43.231168: step 11615, loss 0.348711, acc 0.90625\n",
      "2017-04-03T19:59:43.438403: step 11616, loss 0.214588, acc 0.90625\n",
      "2017-04-03T19:59:43.638513: step 11617, loss 0.205734, acc 0.9375\n",
      "2017-04-03T19:59:43.839460: step 11618, loss 0.252658, acc 0.875\n",
      "2017-04-03T19:59:44.044149: step 11619, loss 0.144038, acc 0.9375\n",
      "2017-04-03T19:59:44.259587: step 11620, loss 0.321697, acc 0.875\n",
      "2017-04-03T19:59:44.477911: step 11621, loss 0.242084, acc 0.90625\n",
      "2017-04-03T19:59:44.680655: step 11622, loss 0.176833, acc 0.953125\n",
      "2017-04-03T19:59:44.926366: step 11623, loss 0.149797, acc 0.953125\n",
      "2017-04-03T19:59:45.169268: step 11624, loss 0.183665, acc 0.9375\n",
      "2017-04-03T19:59:45.378203: step 11625, loss 0.125141, acc 0.96875\n",
      "2017-04-03T19:59:45.593459: step 11626, loss 0.16521, acc 0.953125\n",
      "2017-04-03T19:59:45.795816: step 11627, loss 0.246565, acc 0.90625\n",
      "2017-04-03T19:59:46.000916: step 11628, loss 0.275083, acc 0.890625\n",
      "2017-04-03T19:59:46.205358: step 11629, loss 0.197739, acc 0.90625\n",
      "2017-04-03T19:59:46.407834: step 11630, loss 0.153907, acc 0.9375\n",
      "2017-04-03T19:59:46.607335: step 11631, loss 0.203059, acc 0.9375\n",
      "2017-04-03T19:59:46.812863: step 11632, loss 0.223379, acc 0.9375\n",
      "2017-04-03T19:59:47.023520: step 11633, loss 0.114149, acc 0.96875\n",
      "2017-04-03T19:59:47.271449: step 11634, loss 0.150067, acc 0.953125\n",
      "2017-04-03T19:59:47.471902: step 11635, loss 0.298916, acc 0.9375\n",
      "2017-04-03T19:59:47.717016: step 11636, loss 0.101425, acc 0.96875\n",
      "2017-04-03T19:59:47.921044: step 11637, loss 0.102758, acc 0.96875\n",
      "2017-04-03T19:59:48.127538: step 11638, loss 0.250003, acc 0.90625\n",
      "2017-04-03T19:59:48.328966: step 11639, loss 0.137552, acc 0.9375\n",
      "2017-04-03T19:59:48.532801: step 11640, loss 0.112805, acc 0.953125\n",
      "2017-04-03T19:59:48.736819: step 11641, loss 0.195951, acc 0.953125\n",
      "2017-04-03T19:59:48.940481: step 11642, loss 0.188391, acc 0.90625\n",
      "2017-04-03T19:59:49.140718: step 11643, loss 0.071836, acc 0.984375\n",
      "2017-04-03T19:59:49.343708: step 11644, loss 0.196378, acc 0.9375\n",
      "2017-04-03T19:59:49.548424: step 11645, loss 0.209864, acc 0.9375\n",
      "2017-04-03T19:59:49.746003: step 11646, loss 0.132665, acc 0.953125\n",
      "2017-04-03T19:59:49.947853: step 11647, loss 0.168997, acc 0.96875\n",
      "2017-04-03T19:59:50.151784: step 11648, loss 0.453066, acc 0.9375\n",
      "2017-04-03T19:59:50.365195: step 11649, loss 0.12719, acc 0.953125\n",
      "2017-04-03T19:59:50.571719: step 11650, loss 0.164023, acc 0.921875\n",
      "2017-04-03T19:59:50.774045: step 11651, loss 0.204938, acc 0.9375\n",
      "2017-04-03T19:59:50.973612: step 11652, loss 0.274034, acc 0.921875\n",
      "2017-04-03T19:59:51.175881: step 11653, loss 0.107287, acc 0.984375\n",
      "2017-04-03T19:59:51.375242: step 11654, loss 0.113921, acc 0.96875\n",
      "2017-04-03T19:59:51.577669: step 11655, loss 0.215365, acc 0.921875\n",
      "2017-04-03T19:59:51.780236: step 11656, loss 0.117345, acc 0.984375\n",
      "2017-04-03T19:59:51.981477: step 11657, loss 0.0892068, acc 0.96875\n",
      "2017-04-03T19:59:52.189447: step 11658, loss 0.179296, acc 0.953125\n",
      "2017-04-03T19:59:52.387568: step 11659, loss 0.114927, acc 0.953125\n",
      "2017-04-03T19:59:52.590861: step 11660, loss 0.170476, acc 0.96875\n",
      "2017-04-03T19:59:52.800436: step 11661, loss 0.270444, acc 0.875\n",
      "2017-04-03T19:59:53.001756: step 11662, loss 0.126101, acc 0.96875\n",
      "2017-04-03T19:59:53.198379: step 11663, loss 0.141563, acc 0.9375\n",
      "2017-04-03T19:59:53.405886: step 11664, loss 0.229907, acc 0.921875\n",
      "2017-04-03T19:59:53.652432: step 11665, loss 0.299851, acc 0.875\n",
      "2017-04-03T19:59:53.864348: step 11666, loss 0.259964, acc 0.90625\n",
      "2017-04-03T19:59:54.064266: step 11667, loss 0.219557, acc 0.921875\n",
      "2017-04-03T19:59:54.265244: step 11668, loss 0.224224, acc 0.875\n",
      "2017-04-03T19:59:54.474009: step 11669, loss 0.157049, acc 0.953125\n",
      "2017-04-03T19:59:54.676875: step 11670, loss 0.0863016, acc 0.953125\n",
      "2017-04-03T19:59:54.879956: step 11671, loss 0.161765, acc 0.9375\n",
      "2017-04-03T19:59:55.080822: step 11672, loss 0.238755, acc 0.921875\n",
      "2017-04-03T19:59:55.283591: step 11673, loss 0.126899, acc 0.953125\n",
      "2017-04-03T19:59:55.488696: step 11674, loss 0.200963, acc 0.90625\n",
      "2017-04-03T19:59:55.688960: step 11675, loss 0.196169, acc 0.921875\n",
      "2017-04-03T19:59:55.890004: step 11676, loss 0.106111, acc 0.984375\n",
      "2017-04-03T19:59:56.130253: step 11677, loss 0.142853, acc 0.96875\n",
      "2017-04-03T19:59:56.339559: step 11678, loss 0.179407, acc 0.921875\n",
      "2017-04-03T19:59:56.555305: step 11679, loss 0.272899, acc 0.90625\n",
      "2017-04-03T19:59:56.754920: step 11680, loss 0.391843, acc 0.875\n",
      "2017-04-03T19:59:56.962606: step 11681, loss 0.0800914, acc 0.984375\n",
      "2017-04-03T19:59:57.168736: step 11682, loss 0.196581, acc 0.96875\n",
      "2017-04-03T19:59:57.372557: step 11683, loss 0.159284, acc 0.9375\n",
      "2017-04-03T19:59:57.584667: step 11684, loss 0.200471, acc 0.921875\n",
      "2017-04-03T19:59:57.785857: step 11685, loss 0.229471, acc 0.921875\n",
      "2017-04-03T19:59:57.994243: step 11686, loss 0.228433, acc 0.9375\n",
      "2017-04-03T19:59:58.208389: step 11687, loss 0.257195, acc 0.90625\n",
      "2017-04-03T19:59:58.414596: step 11688, loss 0.209147, acc 0.9375\n",
      "2017-04-03T19:59:58.624267: step 11689, loss 0.276981, acc 0.90625\n",
      "2017-04-03T19:59:58.844477: step 11690, loss 0.301248, acc 0.890625\n",
      "2017-04-03T19:59:59.063281: step 11691, loss 0.247723, acc 0.921875\n",
      "2017-04-03T19:59:59.281718: step 11692, loss 0.247653, acc 0.9375\n",
      "2017-04-03T19:59:59.499153: step 11693, loss 0.263188, acc 0.921875\n",
      "2017-04-03T19:59:59.756144: step 11694, loss 0.17712, acc 0.953125\n",
      "2017-04-03T19:59:59.962614: step 11695, loss 0.254049, acc 0.921875\n",
      "2017-04-03T20:00:00.166862: step 11696, loss 0.471482, acc 0.9375\n",
      "2017-04-03T20:00:00.366886: step 11697, loss 0.197411, acc 0.9375\n",
      "2017-04-03T20:00:00.567237: step 11698, loss 0.326106, acc 0.9375\n",
      "2017-04-03T20:00:00.777641: step 11699, loss 0.209909, acc 0.921875\n",
      "2017-04-03T20:00:00.985815: step 11700, loss 0.137573, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:00:03.040384: step 11700, loss 4.82743, acc 0.2935\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-11700\n",
      "\n",
      "2017-04-03T20:00:03.373613: step 11701, loss 0.24154, acc 0.921875\n",
      "2017-04-03T20:00:03.576346: step 11702, loss 0.236173, acc 0.953125\n",
      "2017-04-03T20:00:03.780194: step 11703, loss 0.133346, acc 0.9375\n",
      "2017-04-03T20:00:03.985088: step 11704, loss 0.112516, acc 0.9375\n",
      "2017-04-03T20:00:04.189237: step 11705, loss 0.116775, acc 0.96875\n",
      "2017-04-03T20:00:04.399008: step 11706, loss 0.272772, acc 0.921875\n",
      "2017-04-03T20:00:04.601775: step 11707, loss 0.325259, acc 0.875\n",
      "2017-04-03T20:00:04.846927: step 11708, loss 0.278122, acc 0.9375\n",
      "2017-04-03T20:00:05.049526: step 11709, loss 0.259071, acc 0.890625\n",
      "2017-04-03T20:00:05.250567: step 11710, loss 0.20261, acc 0.90625\n",
      "2017-04-03T20:00:05.451652: step 11711, loss 0.262751, acc 0.890625\n",
      "2017-04-03T20:00:05.657298: step 11712, loss 0.218159, acc 0.921875\n",
      "2017-04-03T20:00:05.864298: step 11713, loss 0.213851, acc 0.9375\n",
      "2017-04-03T20:00:06.070235: step 11714, loss 0.20016, acc 0.9375\n",
      "2017-04-03T20:00:06.285396: step 11715, loss 0.153286, acc 0.953125\n",
      "2017-04-03T20:00:06.502646: step 11716, loss 0.163188, acc 0.9375\n",
      "2017-04-03T20:00:06.713215: step 11717, loss 0.182209, acc 0.921875\n",
      "2017-04-03T20:00:06.917028: step 11718, loss 0.335741, acc 0.875\n",
      "2017-04-03T20:00:07.127380: step 11719, loss 0.145996, acc 0.953125\n",
      "2017-04-03T20:00:07.332432: step 11720, loss 0.247617, acc 0.953125\n",
      "2017-04-03T20:00:07.536537: step 11721, loss 0.22178, acc 0.921875\n",
      "2017-04-03T20:00:07.742892: step 11722, loss 0.182835, acc 0.9375\n",
      "2017-04-03T20:00:07.943624: step 11723, loss 0.145778, acc 0.953125\n",
      "2017-04-03T20:00:08.143798: step 11724, loss 0.414052, acc 0.921875\n",
      "2017-04-03T20:00:08.346525: step 11725, loss 0.221012, acc 0.890625\n",
      "2017-04-03T20:00:08.593408: step 11726, loss 0.271294, acc 0.921875\n",
      "2017-04-03T20:00:08.796200: step 11727, loss 0.198442, acc 0.953125\n",
      "2017-04-03T20:00:09.014864: step 11728, loss 0.222646, acc 0.90625\n",
      "2017-04-03T20:00:09.222842: step 11729, loss 0.224386, acc 0.96875\n",
      "2017-04-03T20:00:09.422763: step 11730, loss 0.187966, acc 0.9375\n",
      "2017-04-03T20:00:09.626970: step 11731, loss 0.241133, acc 0.9375\n",
      "2017-04-03T20:00:09.829424: step 11732, loss 0.272892, acc 0.921875\n",
      "2017-04-03T20:00:10.031321: step 11733, loss 0.200512, acc 0.890625\n",
      "2017-04-03T20:00:10.278482: step 11734, loss 0.317659, acc 0.921875\n",
      "2017-04-03T20:00:10.485571: step 11735, loss 0.0941514, acc 0.96875\n",
      "2017-04-03T20:00:10.693365: step 11736, loss 0.107749, acc 0.984375\n",
      "2017-04-03T20:00:10.893896: step 11737, loss 0.234336, acc 0.9375\n",
      "2017-04-03T20:00:11.099022: step 11738, loss 0.39671, acc 0.875\n",
      "2017-04-03T20:00:11.301863: step 11739, loss 0.175874, acc 0.921875\n",
      "2017-04-03T20:00:11.503492: step 11740, loss 0.0756744, acc 0.984375\n",
      "2017-04-03T20:00:11.749034: step 11741, loss 0.177285, acc 0.9375\n",
      "2017-04-03T20:00:11.958183: step 11742, loss 0.171911, acc 0.90625\n",
      "2017-04-03T20:00:12.167193: step 11743, loss 0.150329, acc 0.953125\n",
      "2017-04-03T20:00:12.388384: step 11744, loss 0.303751, acc 0.890625\n",
      "2017-04-03T20:00:12.591853: step 11745, loss 0.194608, acc 0.921875\n",
      "2017-04-03T20:00:12.795272: step 11746, loss 0.239943, acc 0.890625\n",
      "2017-04-03T20:00:13.004202: step 11747, loss 0.287487, acc 0.875\n",
      "2017-04-03T20:00:13.213747: step 11748, loss 0.261893, acc 0.921875\n",
      "2017-04-03T20:00:13.431872: step 11749, loss 0.263108, acc 0.921875\n",
      "2017-04-03T20:00:13.630678: step 11750, loss 0.244889, acc 0.953125\n",
      "2017-04-03T20:00:13.835291: step 11751, loss 0.0666046, acc 0.984375\n",
      "2017-04-03T20:00:14.039036: step 11752, loss 0.164932, acc 0.953125\n",
      "2017-04-03T20:00:14.281838: step 11753, loss 0.14164, acc 0.96875\n",
      "2017-04-03T20:00:14.485479: step 11754, loss 0.286641, acc 0.90625\n",
      "2017-04-03T20:00:14.687167: step 11755, loss 0.175927, acc 0.9375\n",
      "2017-04-03T20:00:14.893634: step 11756, loss 0.220157, acc 0.921875\n",
      "2017-04-03T20:00:15.095058: step 11757, loss 0.218623, acc 0.921875\n",
      "2017-04-03T20:00:15.296094: step 11758, loss 0.185643, acc 0.9375\n",
      "2017-04-03T20:00:15.496122: step 11759, loss 0.15076, acc 0.984375\n",
      "2017-04-03T20:00:15.697917: step 11760, loss 0.137715, acc 0.953125\n",
      "2017-04-03T20:00:15.899038: step 11761, loss 0.227398, acc 0.9375\n",
      "2017-04-03T20:00:16.108817: step 11762, loss 0.144324, acc 0.96875\n",
      "2017-04-03T20:00:16.311997: step 11763, loss 0.118612, acc 0.96875\n",
      "2017-04-03T20:00:16.515850: step 11764, loss 0.147394, acc 0.953125\n",
      "2017-04-03T20:00:16.720419: step 11765, loss 0.115491, acc 0.953125\n",
      "2017-04-03T20:00:16.923287: step 11766, loss 0.272916, acc 0.953125\n",
      "2017-04-03T20:00:17.129186: step 11767, loss 0.318772, acc 0.859375\n",
      "2017-04-03T20:00:17.333633: step 11768, loss 0.263053, acc 0.90625\n",
      "2017-04-03T20:00:17.541629: step 11769, loss 0.112437, acc 0.96875\n",
      "2017-04-03T20:00:17.741399: step 11770, loss 0.22737, acc 0.953125\n",
      "2017-04-03T20:00:17.948596: step 11771, loss 0.248782, acc 0.921875\n",
      "2017-04-03T20:00:18.150251: step 11772, loss 0.257491, acc 0.921875\n",
      "2017-04-03T20:00:18.352465: step 11773, loss 0.101297, acc 0.96875\n",
      "2017-04-03T20:00:18.555844: step 11774, loss 0.190045, acc 0.921875\n",
      "2017-04-03T20:00:18.757863: step 11775, loss 0.140236, acc 0.96875\n",
      "2017-04-03T20:00:18.961432: step 11776, loss 0.0551208, acc 1\n",
      "2017-04-03T20:00:19.164580: step 11777, loss 0.109381, acc 0.96875\n",
      "2017-04-03T20:00:19.369380: step 11778, loss 0.290187, acc 0.90625\n",
      "2017-04-03T20:00:19.573935: step 11779, loss 0.199085, acc 0.921875\n",
      "2017-04-03T20:00:19.813061: step 11780, loss 0.16426, acc 0.9375\n",
      "2017-04-03T20:00:20.017989: step 11781, loss 0.092673, acc 0.953125\n",
      "2017-04-03T20:00:20.220742: step 11782, loss 0.199382, acc 0.90625\n",
      "2017-04-03T20:00:20.420750: step 11783, loss 0.362135, acc 0.875\n",
      "2017-04-03T20:00:20.624182: step 11784, loss 0.368325, acc 0.9375\n",
      "2017-04-03T20:00:20.828641: step 11785, loss 0.29563, acc 0.90625\n",
      "2017-04-03T20:00:21.037688: step 11786, loss 0.13239, acc 0.921875\n",
      "2017-04-03T20:00:21.244881: step 11787, loss 0.112655, acc 0.984375\n",
      "2017-04-03T20:00:21.444207: step 11788, loss 0.277624, acc 0.921875\n",
      "2017-04-03T20:00:21.654619: step 11789, loss 0.267074, acc 0.9375\n",
      "2017-04-03T20:00:21.857936: step 11790, loss 0.230776, acc 0.90625\n",
      "2017-04-03T20:00:22.064942: step 11791, loss 0.163003, acc 0.953125\n",
      "2017-04-03T20:00:22.268958: step 11792, loss 0.153301, acc 0.9375\n",
      "2017-04-03T20:00:22.473435: step 11793, loss 0.452811, acc 0.875\n",
      "2017-04-03T20:00:22.673165: step 11794, loss 0.285454, acc 0.953125\n",
      "2017-04-03T20:00:22.874622: step 11795, loss 0.225232, acc 0.921875\n",
      "2017-04-03T20:00:23.081194: step 11796, loss 0.238505, acc 0.953125\n",
      "2017-04-03T20:00:23.286198: step 11797, loss 0.129501, acc 0.96875\n",
      "2017-04-03T20:00:23.492490: step 11798, loss 0.224865, acc 0.9375\n",
      "2017-04-03T20:00:23.742130: step 11799, loss 0.161873, acc 0.953125\n",
      "2017-04-03T20:00:23.970798: step 11800, loss 0.106057, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:00:26.088874: step 11800, loss 4.88771, acc 0.29125\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-11800\n",
      "\n",
      "2017-04-03T20:00:26.471289: step 11801, loss 0.135144, acc 0.953125\n",
      "2017-04-03T20:00:26.674116: step 11802, loss 0.0885202, acc 0.984375\n",
      "2017-04-03T20:00:26.876621: step 11803, loss 0.264395, acc 0.9375\n",
      "2017-04-03T20:00:27.126905: step 11804, loss 0.0521645, acc 1\n",
      "2017-04-03T20:00:27.333932: step 11805, loss 0.259429, acc 0.90625\n",
      "2017-04-03T20:00:27.537452: step 11806, loss 0.204398, acc 0.953125\n",
      "2017-04-03T20:00:27.796518: step 11807, loss 0.178407, acc 0.9375\n",
      "2017-04-03T20:00:28.042756: step 11808, loss 0.239533, acc 0.921875\n",
      "2017-04-03T20:00:28.248157: step 11809, loss 0.234356, acc 0.90625\n",
      "2017-04-03T20:00:28.450863: step 11810, loss 0.172705, acc 0.9375\n",
      "2017-04-03T20:00:28.657058: step 11811, loss 0.259097, acc 0.90625\n",
      "2017-04-03T20:00:28.866198: step 11812, loss 0.282422, acc 0.890625\n",
      "2017-04-03T20:00:29.073761: step 11813, loss 0.217585, acc 0.953125\n",
      "2017-04-03T20:00:29.287347: step 11814, loss 0.11493, acc 0.96875\n",
      "2017-04-03T20:00:29.488782: step 11815, loss 0.087015, acc 0.96875\n",
      "2017-04-03T20:00:29.696723: step 11816, loss 0.168081, acc 0.90625\n",
      "2017-04-03T20:00:29.904123: step 11817, loss 0.131561, acc 0.9375\n",
      "2017-04-03T20:00:30.111556: step 11818, loss 0.32038, acc 0.859375\n",
      "2017-04-03T20:00:30.317494: step 11819, loss 0.18427, acc 0.90625\n",
      "2017-04-03T20:00:30.525544: step 11820, loss 0.366802, acc 0.953125\n",
      "2017-04-03T20:00:30.724361: step 11821, loss 0.245457, acc 0.921875\n",
      "2017-04-03T20:00:30.930678: step 11822, loss 0.28908, acc 0.921875\n",
      "2017-04-03T20:00:31.081421: step 11823, loss 0.165014, acc 0.96875\n",
      "2017-04-03T20:00:31.286475: step 11824, loss 0.0654441, acc 0.984375\n",
      "2017-04-03T20:00:31.493152: step 11825, loss 0.0660778, acc 0.984375\n",
      "2017-04-03T20:00:31.745696: step 11826, loss 0.215833, acc 0.9375\n",
      "2017-04-03T20:00:31.952890: step 11827, loss 0.141315, acc 0.96875\n",
      "2017-04-03T20:00:32.153857: step 11828, loss 0.168956, acc 0.921875\n",
      "2017-04-03T20:00:32.355621: step 11829, loss 0.101883, acc 0.9375\n",
      "2017-04-03T20:00:32.555880: step 11830, loss 0.0874438, acc 0.96875\n",
      "2017-04-03T20:00:32.775385: step 11831, loss 0.226086, acc 0.9375\n",
      "2017-04-03T20:00:32.992150: step 11832, loss 0.0982914, acc 0.953125\n",
      "2017-04-03T20:00:33.204157: step 11833, loss 0.117133, acc 0.953125\n",
      "2017-04-03T20:00:33.411018: step 11834, loss 0.181166, acc 0.921875\n",
      "2017-04-03T20:00:33.615194: step 11835, loss 0.276269, acc 0.875\n",
      "2017-04-03T20:00:33.816221: step 11836, loss 0.0692194, acc 1\n",
      "2017-04-03T20:00:34.018243: step 11837, loss 0.0615977, acc 0.984375\n",
      "2017-04-03T20:00:34.221932: step 11838, loss 0.224859, acc 0.921875\n",
      "2017-04-03T20:00:34.430495: step 11839, loss 0.103611, acc 0.96875\n",
      "2017-04-03T20:00:34.629885: step 11840, loss 0.191696, acc 0.90625\n",
      "2017-04-03T20:00:34.832778: step 11841, loss 0.104023, acc 0.953125\n",
      "2017-04-03T20:00:35.036847: step 11842, loss 0.117546, acc 0.9375\n",
      "2017-04-03T20:00:35.246982: step 11843, loss 0.1125, acc 0.953125\n",
      "2017-04-03T20:00:35.452397: step 11844, loss 0.103442, acc 0.96875\n",
      "2017-04-03T20:00:35.659448: step 11845, loss 0.243031, acc 0.90625\n",
      "2017-04-03T20:00:35.873064: step 11846, loss 0.151091, acc 0.921875\n",
      "2017-04-03T20:00:36.074211: step 11847, loss 0.145062, acc 0.9375\n",
      "2017-04-03T20:00:36.285603: step 11848, loss 0.160226, acc 0.953125\n",
      "2017-04-03T20:00:36.488364: step 11849, loss 0.274859, acc 0.875\n",
      "2017-04-03T20:00:36.690639: step 11850, loss 0.0589379, acc 1\n",
      "2017-04-03T20:00:36.896634: step 11851, loss 0.0657329, acc 1\n",
      "2017-04-03T20:00:37.125120: step 11852, loss 0.163349, acc 0.96875\n",
      "2017-04-03T20:00:37.393618: step 11853, loss 0.258717, acc 0.9375\n",
      "2017-04-03T20:00:37.607144: step 11854, loss 0.311193, acc 0.921875\n",
      "2017-04-03T20:00:37.809847: step 11855, loss 0.20305, acc 0.9375\n",
      "2017-04-03T20:00:38.015923: step 11856, loss 0.140607, acc 0.953125\n",
      "2017-04-03T20:00:38.225449: step 11857, loss 0.226652, acc 0.921875\n",
      "2017-04-03T20:00:38.430499: step 11858, loss 0.173194, acc 0.921875\n",
      "2017-04-03T20:00:38.679560: step 11859, loss 0.156434, acc 0.96875\n",
      "2017-04-03T20:00:38.890087: step 11860, loss 0.121985, acc 0.96875\n",
      "2017-04-03T20:00:39.100151: step 11861, loss 0.164453, acc 0.921875\n",
      "2017-04-03T20:00:39.319298: step 11862, loss 0.0880302, acc 0.984375\n",
      "2017-04-03T20:00:39.522686: step 11863, loss 0.168949, acc 0.953125\n",
      "2017-04-03T20:00:39.726898: step 11864, loss 0.101707, acc 0.953125\n",
      "2017-04-03T20:00:39.942980: step 11865, loss 0.150983, acc 0.96875\n",
      "2017-04-03T20:00:40.153826: step 11866, loss 0.175377, acc 0.921875\n",
      "2017-04-03T20:00:40.354931: step 11867, loss 0.0695747, acc 1\n",
      "2017-04-03T20:00:40.596659: step 11868, loss 0.130236, acc 0.9375\n",
      "2017-04-03T20:00:40.803730: step 11869, loss 0.053582, acc 1\n",
      "2017-04-03T20:00:41.018530: step 11870, loss 0.342337, acc 0.921875\n",
      "2017-04-03T20:00:41.229708: step 11871, loss 0.172919, acc 0.984375\n",
      "2017-04-03T20:00:41.435939: step 11872, loss 0.227321, acc 0.953125\n",
      "2017-04-03T20:00:41.637568: step 11873, loss 0.188025, acc 0.9375\n",
      "2017-04-03T20:00:41.850228: step 11874, loss 0.245406, acc 0.921875\n",
      "2017-04-03T20:00:42.053412: step 11875, loss 0.0512313, acc 1\n",
      "2017-04-03T20:00:42.257216: step 11876, loss 0.0768323, acc 0.96875\n",
      "2017-04-03T20:00:42.468818: step 11877, loss 0.195466, acc 0.9375\n",
      "2017-04-03T20:00:42.686029: step 11878, loss 0.241609, acc 0.921875\n",
      "2017-04-03T20:00:42.930406: step 11879, loss 0.112263, acc 0.96875\n",
      "2017-04-03T20:00:43.141200: step 11880, loss 0.133767, acc 0.96875\n",
      "2017-04-03T20:00:43.340190: step 11881, loss 0.142876, acc 0.96875\n",
      "2017-04-03T20:00:43.544448: step 11882, loss 0.0792701, acc 1\n",
      "2017-04-03T20:00:43.746747: step 11883, loss 0.19923, acc 0.9375\n",
      "2017-04-03T20:00:43.982485: step 11884, loss 0.0571313, acc 0.984375\n",
      "2017-04-03T20:00:44.183587: step 11885, loss 0.20029, acc 0.921875\n",
      "2017-04-03T20:00:44.385666: step 11886, loss 0.101694, acc 0.96875\n",
      "2017-04-03T20:00:44.589527: step 11887, loss 0.034323, acc 1\n",
      "2017-04-03T20:00:44.787986: step 11888, loss 0.0502419, acc 0.984375\n",
      "2017-04-03T20:00:44.992974: step 11889, loss 0.118289, acc 0.953125\n",
      "2017-04-03T20:00:45.194358: step 11890, loss 0.207305, acc 0.96875\n",
      "2017-04-03T20:00:45.408635: step 11891, loss 0.105771, acc 0.96875\n",
      "2017-04-03T20:00:45.609897: step 11892, loss 0.189881, acc 0.9375\n",
      "2017-04-03T20:00:45.852852: step 11893, loss 0.0383924, acc 1\n",
      "2017-04-03T20:00:46.054106: step 11894, loss 0.106467, acc 0.96875\n",
      "2017-04-03T20:00:46.267193: step 11895, loss 0.238275, acc 0.890625\n",
      "2017-04-03T20:00:46.468330: step 11896, loss 0.159159, acc 0.9375\n",
      "2017-04-03T20:00:46.669135: step 11897, loss 0.163184, acc 0.921875\n",
      "2017-04-03T20:00:46.915167: step 11898, loss 0.205679, acc 0.921875\n",
      "2017-04-03T20:00:47.131983: step 11899, loss 0.183745, acc 0.9375\n",
      "2017-04-03T20:00:47.384859: step 11900, loss 0.188647, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:00:49.567209: step 11900, loss 4.92614, acc 0.291\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-11900\n",
      "\n",
      "2017-04-03T20:00:49.893728: step 11901, loss 0.158607, acc 0.96875\n",
      "2017-04-03T20:00:50.097374: step 11902, loss 0.226944, acc 0.921875\n",
      "2017-04-03T20:00:50.295937: step 11903, loss 0.208982, acc 0.9375\n",
      "2017-04-03T20:00:50.506745: step 11904, loss 0.131893, acc 0.9375\n",
      "2017-04-03T20:00:50.707799: step 11905, loss 0.103978, acc 0.96875\n",
      "2017-04-03T20:00:50.908619: step 11906, loss 0.165894, acc 0.953125\n",
      "2017-04-03T20:00:51.120350: step 11907, loss 0.231101, acc 0.921875\n",
      "2017-04-03T20:00:51.320088: step 11908, loss 0.156853, acc 0.953125\n",
      "2017-04-03T20:00:51.567068: step 11909, loss 0.118928, acc 0.9375\n",
      "2017-04-03T20:00:51.773734: step 11910, loss 0.122699, acc 0.96875\n",
      "2017-04-03T20:00:51.998332: step 11911, loss 0.209894, acc 0.953125\n",
      "2017-04-03T20:00:52.200071: step 11912, loss 0.262948, acc 0.921875\n",
      "2017-04-03T20:00:52.447663: step 11913, loss 0.36304, acc 0.875\n",
      "2017-04-03T20:00:52.655158: step 11914, loss 0.178738, acc 0.921875\n",
      "2017-04-03T20:00:52.869733: step 11915, loss 0.159156, acc 0.96875\n",
      "2017-04-03T20:00:53.071823: step 11916, loss 0.140868, acc 0.984375\n",
      "2017-04-03T20:00:53.276507: step 11917, loss 0.068584, acc 1\n",
      "2017-04-03T20:00:53.478271: step 11918, loss 0.111844, acc 0.96875\n",
      "2017-04-03T20:00:53.687040: step 11919, loss 0.21118, acc 0.921875\n",
      "2017-04-03T20:00:53.884133: step 11920, loss 0.240879, acc 0.890625\n",
      "2017-04-03T20:00:54.086973: step 11921, loss 0.170537, acc 0.9375\n",
      "2017-04-03T20:00:54.293148: step 11922, loss 0.157741, acc 0.953125\n",
      "2017-04-03T20:00:54.503943: step 11923, loss 0.248537, acc 0.875\n",
      "2017-04-03T20:00:54.719036: step 11924, loss 0.191909, acc 0.96875\n",
      "2017-04-03T20:00:54.938398: step 11925, loss 0.0657538, acc 0.96875\n",
      "2017-04-03T20:00:55.157725: step 11926, loss 0.126232, acc 0.953125\n",
      "2017-04-03T20:00:55.364077: step 11927, loss 0.152556, acc 0.96875\n",
      "2017-04-03T20:00:55.565714: step 11928, loss 0.28062, acc 0.921875\n",
      "2017-04-03T20:00:55.771174: step 11929, loss 0.213721, acc 0.9375\n",
      "2017-04-03T20:00:55.973350: step 11930, loss 0.191414, acc 0.953125\n",
      "2017-04-03T20:00:56.173471: step 11931, loss 0.143686, acc 0.96875\n",
      "2017-04-03T20:00:56.376877: step 11932, loss 0.14017, acc 0.96875\n",
      "2017-04-03T20:00:56.585546: step 11933, loss 0.109099, acc 0.953125\n",
      "2017-04-03T20:00:56.793395: step 11934, loss 0.179846, acc 0.9375\n",
      "2017-04-03T20:00:56.999632: step 11935, loss 0.279995, acc 0.921875\n",
      "2017-04-03T20:00:57.205174: step 11936, loss 0.205552, acc 0.90625\n",
      "2017-04-03T20:00:57.442081: step 11937, loss 0.0976056, acc 0.984375\n",
      "2017-04-03T20:00:57.659212: step 11938, loss 0.149243, acc 0.953125\n",
      "2017-04-03T20:00:57.879053: step 11939, loss 0.0827793, acc 0.984375\n",
      "2017-04-03T20:00:58.080644: step 11940, loss 0.156621, acc 0.953125\n",
      "2017-04-03T20:00:58.279597: step 11941, loss 0.0697027, acc 0.984375\n",
      "2017-04-03T20:00:58.479558: step 11942, loss 0.185265, acc 0.9375\n",
      "2017-04-03T20:00:58.686866: step 11943, loss 0.190854, acc 0.9375\n",
      "2017-04-03T20:00:58.888028: step 11944, loss 0.333061, acc 0.890625\n",
      "2017-04-03T20:00:59.092367: step 11945, loss 0.0981042, acc 0.953125\n",
      "2017-04-03T20:00:59.292284: step 11946, loss 0.203786, acc 0.9375\n",
      "2017-04-03T20:00:59.496234: step 11947, loss 0.298781, acc 0.859375\n",
      "2017-04-03T20:00:59.700582: step 11948, loss 0.137029, acc 0.9375\n",
      "2017-04-03T20:00:59.907609: step 11949, loss 0.269568, acc 0.890625\n",
      "2017-04-03T20:01:00.154107: step 11950, loss 0.276794, acc 0.921875\n",
      "2017-04-03T20:01:00.363302: step 11951, loss 0.176923, acc 0.921875\n",
      "2017-04-03T20:01:00.565834: step 11952, loss 0.0774687, acc 0.984375\n",
      "2017-04-03T20:01:00.772375: step 11953, loss 0.192137, acc 0.921875\n",
      "2017-04-03T20:01:00.975707: step 11954, loss 0.142787, acc 0.96875\n",
      "2017-04-03T20:01:01.176265: step 11955, loss 0.0795215, acc 1\n",
      "2017-04-03T20:01:01.378712: step 11956, loss 0.127032, acc 0.953125\n",
      "2017-04-03T20:01:01.578639: step 11957, loss 0.124522, acc 0.96875\n",
      "2017-04-03T20:01:01.779980: step 11958, loss 0.255294, acc 0.9375\n",
      "2017-04-03T20:01:01.983708: step 11959, loss 0.185832, acc 0.953125\n",
      "2017-04-03T20:01:02.187443: step 11960, loss 0.111305, acc 0.953125\n",
      "2017-04-03T20:01:02.395616: step 11961, loss 0.146894, acc 0.953125\n",
      "2017-04-03T20:01:02.595578: step 11962, loss 0.196578, acc 0.9375\n",
      "2017-04-03T20:01:02.801985: step 11963, loss 0.0740631, acc 0.984375\n",
      "2017-04-03T20:01:03.008390: step 11964, loss 0.15388, acc 0.96875\n",
      "2017-04-03T20:01:03.209352: step 11965, loss 0.27056, acc 0.875\n",
      "2017-04-03T20:01:03.430328: step 11966, loss 0.202813, acc 0.953125\n",
      "2017-04-03T20:01:03.671470: step 11967, loss 0.276412, acc 0.875\n",
      "2017-04-03T20:01:03.869646: step 11968, loss 0.0728779, acc 0.96875\n",
      "2017-04-03T20:01:04.074964: step 11969, loss 0.292403, acc 0.953125\n",
      "2017-04-03T20:01:04.317019: step 11970, loss 0.105395, acc 0.96875\n",
      "2017-04-03T20:01:04.521707: step 11971, loss 0.24816, acc 0.921875\n",
      "2017-04-03T20:01:04.734542: step 11972, loss 0.185795, acc 0.9375\n",
      "2017-04-03T20:01:04.933065: step 11973, loss 0.0988752, acc 0.96875\n",
      "2017-04-03T20:01:05.141759: step 11974, loss 0.17375, acc 0.9375\n",
      "2017-04-03T20:01:05.363062: step 11975, loss 0.16313, acc 0.9375\n",
      "2017-04-03T20:01:05.623230: step 11976, loss 0.122186, acc 0.96875\n",
      "2017-04-03T20:01:05.827584: step 11977, loss 0.0838207, acc 0.96875\n",
      "2017-04-03T20:01:06.047340: step 11978, loss 0.223496, acc 0.921875\n",
      "2017-04-03T20:01:06.269556: step 11979, loss 0.19508, acc 0.9375\n",
      "2017-04-03T20:01:06.486973: step 11980, loss 0.0673145, acc 0.984375\n",
      "2017-04-03T20:01:06.696939: step 11981, loss 0.244925, acc 0.9375\n",
      "2017-04-03T20:01:06.896520: step 11982, loss 0.0606643, acc 0.96875\n",
      "2017-04-03T20:01:07.137165: step 11983, loss 0.137441, acc 0.96875\n",
      "2017-04-03T20:01:07.341041: step 11984, loss 0.265432, acc 0.9375\n",
      "2017-04-03T20:01:07.541175: step 11985, loss 0.203237, acc 0.90625\n",
      "2017-04-03T20:01:07.782477: step 11986, loss 0.313516, acc 0.921875\n",
      "2017-04-03T20:01:07.989335: step 11987, loss 0.108078, acc 0.984375\n",
      "2017-04-03T20:01:08.194917: step 11988, loss 0.210059, acc 0.96875\n",
      "2017-04-03T20:01:08.393120: step 11989, loss 0.165289, acc 0.96875\n",
      "2017-04-03T20:01:08.592179: step 11990, loss 0.112481, acc 0.96875\n",
      "2017-04-03T20:01:08.797444: step 11991, loss 0.110675, acc 0.953125\n",
      "2017-04-03T20:01:09.000522: step 11992, loss 0.191286, acc 0.921875\n",
      "2017-04-03T20:01:09.203585: step 11993, loss 0.224764, acc 0.9375\n",
      "2017-04-03T20:01:09.412625: step 11994, loss 0.154179, acc 0.9375\n",
      "2017-04-03T20:01:09.611843: step 11995, loss 0.253377, acc 0.90625\n",
      "2017-04-03T20:01:09.812571: step 11996, loss 0.10063, acc 0.96875\n",
      "2017-04-03T20:01:10.016552: step 11997, loss 0.104239, acc 0.96875\n",
      "2017-04-03T20:01:10.225036: step 11998, loss 0.18625, acc 0.921875\n",
      "2017-04-03T20:01:10.431351: step 11999, loss 0.0960901, acc 0.984375\n",
      "2017-04-03T20:01:10.637674: step 12000, loss 0.10509, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:01:12.779228: step 12000, loss 4.99442, acc 0.29175\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-12000\n",
      "\n",
      "2017-04-03T20:01:13.106422: step 12001, loss 0.107569, acc 0.96875\n",
      "2017-04-03T20:01:13.311944: step 12002, loss 0.214525, acc 0.9375\n",
      "2017-04-03T20:01:13.510712: step 12003, loss 0.217404, acc 0.9375\n",
      "2017-04-03T20:01:13.713005: step 12004, loss 0.159699, acc 0.921875\n",
      "2017-04-03T20:01:13.912133: step 12005, loss 0.158792, acc 0.953125\n",
      "2017-04-03T20:01:14.113256: step 12006, loss 0.172405, acc 0.9375\n",
      "2017-04-03T20:01:14.310889: step 12007, loss 0.14795, acc 0.953125\n",
      "2017-04-03T20:01:14.513466: step 12008, loss 0.19451, acc 0.9375\n",
      "2017-04-03T20:01:14.715660: step 12009, loss 0.0990587, acc 0.96875\n",
      "2017-04-03T20:01:14.917375: step 12010, loss 0.224767, acc 0.90625\n",
      "2017-04-03T20:01:15.117485: step 12011, loss 0.147246, acc 0.953125\n",
      "2017-04-03T20:01:15.317809: step 12012, loss 0.125939, acc 0.984375\n",
      "2017-04-03T20:01:15.529567: step 12013, loss 0.133694, acc 0.953125\n",
      "2017-04-03T20:01:15.737705: step 12014, loss 0.131516, acc 0.9375\n",
      "2017-04-03T20:01:15.953635: step 12015, loss 0.210571, acc 0.9375\n",
      "2017-04-03T20:01:16.160529: step 12016, loss 0.16314, acc 0.9375\n",
      "2017-04-03T20:01:16.372617: step 12017, loss 0.185208, acc 0.9375\n",
      "2017-04-03T20:01:16.573684: step 12018, loss 0.196991, acc 0.9375\n",
      "2017-04-03T20:01:16.789732: step 12019, loss 0.098195, acc 0.96875\n",
      "2017-04-03T20:01:17.001693: step 12020, loss 0.271491, acc 0.921875\n",
      "2017-04-03T20:01:17.209254: step 12021, loss 0.200507, acc 0.9375\n",
      "2017-04-03T20:01:17.409071: step 12022, loss 0.196106, acc 0.921875\n",
      "2017-04-03T20:01:17.616349: step 12023, loss 0.300191, acc 0.921875\n",
      "2017-04-03T20:01:17.867068: step 12024, loss 0.136926, acc 0.96875\n",
      "2017-04-03T20:01:18.072851: step 12025, loss 0.13943, acc 0.96875\n",
      "2017-04-03T20:01:18.275442: step 12026, loss 0.113913, acc 0.953125\n",
      "2017-04-03T20:01:18.471819: step 12027, loss 0.1297, acc 0.953125\n",
      "2017-04-03T20:01:18.715903: step 12028, loss 0.0877838, acc 0.96875\n",
      "2017-04-03T20:01:18.915803: step 12029, loss 0.188492, acc 0.90625\n",
      "2017-04-03T20:01:19.121380: step 12030, loss 0.150624, acc 0.953125\n",
      "2017-04-03T20:01:19.326934: step 12031, loss 0.12565, acc 0.953125\n",
      "2017-04-03T20:01:19.532148: step 12032, loss 0.238907, acc 0.921875\n",
      "2017-04-03T20:01:19.737038: step 12033, loss 0.130682, acc 0.96875\n",
      "2017-04-03T20:01:19.939931: step 12034, loss 0.0508902, acc 1\n",
      "2017-04-03T20:01:20.140799: step 12035, loss 0.303725, acc 0.921875\n",
      "2017-04-03T20:01:20.347795: step 12036, loss 0.312936, acc 0.921875\n",
      "2017-04-03T20:01:20.552812: step 12037, loss 0.0997374, acc 0.984375\n",
      "2017-04-03T20:01:20.779098: step 12038, loss 0.157797, acc 0.9375\n",
      "2017-04-03T20:01:20.995951: step 12039, loss 0.381491, acc 0.921875\n",
      "2017-04-03T20:01:21.198553: step 12040, loss 0.0944368, acc 0.984375\n",
      "2017-04-03T20:01:21.399116: step 12041, loss 0.295442, acc 0.90625\n",
      "2017-04-03T20:01:21.607538: step 12042, loss 0.0986134, acc 0.96875\n",
      "2017-04-03T20:01:21.849991: step 12043, loss 0.225907, acc 0.890625\n",
      "2017-04-03T20:01:22.051356: step 12044, loss 0.205831, acc 0.9375\n",
      "2017-04-03T20:01:22.251900: step 12045, loss 0.150989, acc 0.953125\n",
      "2017-04-03T20:01:22.454387: step 12046, loss 0.1043, acc 0.984375\n",
      "2017-04-03T20:01:22.657438: step 12047, loss 0.111298, acc 0.96875\n",
      "2017-04-03T20:01:22.861748: step 12048, loss 0.187055, acc 0.953125\n",
      "2017-04-03T20:01:23.062106: step 12049, loss 0.265642, acc 0.90625\n",
      "2017-04-03T20:01:23.264720: step 12050, loss 0.424966, acc 0.875\n",
      "2017-04-03T20:01:23.466198: step 12051, loss 0.309181, acc 0.890625\n",
      "2017-04-03T20:01:23.665862: step 12052, loss 0.173439, acc 0.9375\n",
      "2017-04-03T20:01:23.866940: step 12053, loss 0.193016, acc 0.9375\n",
      "2017-04-03T20:01:24.070200: step 12054, loss 0.42343, acc 0.90625\n",
      "2017-04-03T20:01:24.270127: step 12055, loss 0.106741, acc 0.96875\n",
      "2017-04-03T20:01:24.511120: step 12056, loss 0.167321, acc 0.921875\n",
      "2017-04-03T20:01:24.707302: step 12057, loss 0.122104, acc 0.96875\n",
      "2017-04-03T20:01:24.918522: step 12058, loss 0.164777, acc 0.9375\n",
      "2017-04-03T20:01:25.125589: step 12059, loss 0.268724, acc 0.875\n",
      "2017-04-03T20:01:25.350654: step 12060, loss 0.137619, acc 0.953125\n",
      "2017-04-03T20:01:25.556853: step 12061, loss 0.219268, acc 0.921875\n",
      "2017-04-03T20:01:25.759431: step 12062, loss 0.0916181, acc 0.984375\n",
      "2017-04-03T20:01:25.957264: step 12063, loss 0.115118, acc 0.953125\n",
      "2017-04-03T20:01:26.154295: step 12064, loss 0.0921069, acc 0.984375\n",
      "2017-04-03T20:01:26.355561: step 12065, loss 0.186001, acc 0.921875\n",
      "2017-04-03T20:01:26.557690: step 12066, loss 0.196935, acc 0.90625\n",
      "2017-04-03T20:01:26.767052: step 12067, loss 0.0905352, acc 0.953125\n",
      "2017-04-03T20:01:26.965653: step 12068, loss 0.077645, acc 0.984375\n",
      "2017-04-03T20:01:27.166669: step 12069, loss 0.164517, acc 0.921875\n",
      "2017-04-03T20:01:27.373604: step 12070, loss 0.10785, acc 0.96875\n",
      "2017-04-03T20:01:27.578854: step 12071, loss 0.290502, acc 0.921875\n",
      "2017-04-03T20:01:27.788639: step 12072, loss 0.143982, acc 0.9375\n",
      "2017-04-03T20:01:27.988409: step 12073, loss 0.150414, acc 0.90625\n",
      "2017-04-03T20:01:28.190986: step 12074, loss 0.107452, acc 0.984375\n",
      "2017-04-03T20:01:28.398713: step 12075, loss 0.0581635, acc 1\n",
      "2017-04-03T20:01:28.600391: step 12076, loss 0.24188, acc 0.921875\n",
      "2017-04-03T20:01:28.799284: step 12077, loss 0.148668, acc 0.953125\n",
      "2017-04-03T20:01:29.003956: step 12078, loss 0.167856, acc 0.953125\n",
      "2017-04-03T20:01:29.207662: step 12079, loss 0.194925, acc 0.953125\n",
      "2017-04-03T20:01:29.409832: step 12080, loss 0.185548, acc 0.921875\n",
      "2017-04-03T20:01:29.611016: step 12081, loss 0.182208, acc 0.9375\n",
      "2017-04-03T20:01:29.819682: step 12082, loss 0.242877, acc 0.9375\n",
      "2017-04-03T20:01:30.021456: step 12083, loss 0.178708, acc 0.9375\n",
      "2017-04-03T20:01:30.231462: step 12084, loss 0.307248, acc 0.875\n",
      "2017-04-03T20:01:30.432664: step 12085, loss 0.11872, acc 0.984375\n",
      "2017-04-03T20:01:30.636497: step 12086, loss 0.369578, acc 0.84375\n",
      "2017-04-03T20:01:30.877951: step 12087, loss 0.246299, acc 0.90625\n",
      "2017-04-03T20:01:31.096537: step 12088, loss 0.171184, acc 0.96875\n",
      "2017-04-03T20:01:31.300375: step 12089, loss 0.0872748, acc 0.96875\n",
      "2017-04-03T20:01:31.501102: step 12090, loss 0.313567, acc 0.953125\n",
      "2017-04-03T20:01:31.703919: step 12091, loss 0.110116, acc 0.96875\n",
      "2017-04-03T20:01:31.905827: step 12092, loss 0.193901, acc 0.9375\n",
      "2017-04-03T20:01:32.113356: step 12093, loss 0.142996, acc 0.984375\n",
      "2017-04-03T20:01:32.313401: step 12094, loss 0.130721, acc 0.96875\n",
      "2017-04-03T20:01:32.516232: step 12095, loss 0.344682, acc 0.875\n",
      "2017-04-03T20:01:32.715459: step 12096, loss 0.275791, acc 0.90625\n",
      "2017-04-03T20:01:32.917703: step 12097, loss 0.182074, acc 0.953125\n",
      "2017-04-03T20:01:33.120543: step 12098, loss 0.281584, acc 0.96875\n",
      "2017-04-03T20:01:33.319902: step 12099, loss 0.214234, acc 0.921875\n",
      "2017-04-03T20:01:33.523510: step 12100, loss 0.157909, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:01:35.651304: step 12100, loss 5.05603, acc 0.28625\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-12100\n",
      "\n",
      "2017-04-03T20:01:35.992643: step 12101, loss 0.238886, acc 0.9375\n",
      "2017-04-03T20:01:36.193800: step 12102, loss 0.215326, acc 0.921875\n",
      "2017-04-03T20:01:36.398207: step 12103, loss 0.191457, acc 0.90625\n",
      "2017-04-03T20:01:36.600835: step 12104, loss 0.126719, acc 0.953125\n",
      "2017-04-03T20:01:36.808791: step 12105, loss 0.3916, acc 0.921875\n",
      "2017-04-03T20:01:37.006788: step 12106, loss 0.261472, acc 0.9375\n",
      "2017-04-03T20:01:37.212389: step 12107, loss 0.250907, acc 0.90625\n",
      "2017-04-03T20:01:37.423627: step 12108, loss 0.0802381, acc 1\n",
      "2017-04-03T20:01:37.625158: step 12109, loss 0.159804, acc 0.9375\n",
      "2017-04-03T20:01:37.827921: step 12110, loss 0.132985, acc 0.96875\n",
      "2017-04-03T20:01:38.042470: step 12111, loss 0.484825, acc 0.921875\n",
      "2017-04-03T20:01:38.249389: step 12112, loss 0.145779, acc 0.921875\n",
      "2017-04-03T20:01:38.452562: step 12113, loss 0.146055, acc 0.921875\n",
      "2017-04-03T20:01:38.691792: step 12114, loss 0.14218, acc 0.953125\n",
      "2017-04-03T20:01:38.893672: step 12115, loss 0.0937156, acc 0.984375\n",
      "2017-04-03T20:01:39.100026: step 12116, loss 0.104807, acc 0.953125\n",
      "2017-04-03T20:01:39.312072: step 12117, loss 0.230233, acc 0.953125\n",
      "2017-04-03T20:01:39.513686: step 12118, loss 0.231023, acc 0.953125\n",
      "2017-04-03T20:01:39.718146: step 12119, loss 0.130728, acc 0.96875\n",
      "2017-04-03T20:01:39.924512: step 12120, loss 0.394645, acc 0.921875\n",
      "2017-04-03T20:01:40.127743: step 12121, loss 0.143051, acc 0.953125\n",
      "2017-04-03T20:01:40.373710: step 12122, loss 0.141264, acc 0.96875\n",
      "2017-04-03T20:01:40.586650: step 12123, loss 0.102351, acc 0.96875\n",
      "2017-04-03T20:01:40.792944: step 12124, loss 0.47779, acc 0.875\n",
      "2017-04-03T20:01:40.991797: step 12125, loss 0.253967, acc 0.9375\n",
      "2017-04-03T20:01:41.195026: step 12126, loss 0.347654, acc 0.859375\n",
      "2017-04-03T20:01:41.400090: step 12127, loss 0.1032, acc 0.953125\n",
      "2017-04-03T20:01:41.603505: step 12128, loss 0.242216, acc 0.875\n",
      "2017-04-03T20:01:41.801968: step 12129, loss 0.20726, acc 0.921875\n",
      "2017-04-03T20:01:42.046243: step 12130, loss 0.162898, acc 0.96875\n",
      "2017-04-03T20:01:42.296549: step 12131, loss 0.247154, acc 0.9375\n",
      "2017-04-03T20:01:42.496112: step 12132, loss 0.400429, acc 0.90625\n",
      "2017-04-03T20:01:42.696620: step 12133, loss 0.219904, acc 0.921875\n",
      "2017-04-03T20:01:42.892054: step 12134, loss 0.245279, acc 0.9375\n",
      "2017-04-03T20:01:43.105667: step 12135, loss 0.0983891, acc 0.984375\n",
      "2017-04-03T20:01:43.325743: step 12136, loss 0.36911, acc 0.890625\n",
      "2017-04-03T20:01:43.530333: step 12137, loss 0.110267, acc 0.96875\n",
      "2017-04-03T20:01:43.772322: step 12138, loss 0.237575, acc 0.921875\n",
      "2017-04-03T20:01:43.972326: step 12139, loss 0.198423, acc 0.953125\n",
      "2017-04-03T20:01:44.178105: step 12140, loss 0.172131, acc 0.9375\n",
      "2017-04-03T20:01:44.382589: step 12141, loss 0.134204, acc 0.953125\n",
      "2017-04-03T20:01:44.583015: step 12142, loss 0.175101, acc 0.9375\n",
      "2017-04-03T20:01:44.785407: step 12143, loss 0.238505, acc 0.9375\n",
      "2017-04-03T20:01:44.993730: step 12144, loss 0.284244, acc 0.921875\n",
      "2017-04-03T20:01:45.189914: step 12145, loss 0.270254, acc 0.9375\n",
      "2017-04-03T20:01:45.396072: step 12146, loss 0.342326, acc 0.859375\n",
      "2017-04-03T20:01:45.643282: step 12147, loss 0.108561, acc 0.953125\n",
      "2017-04-03T20:01:45.888168: step 12148, loss 0.138361, acc 0.953125\n",
      "2017-04-03T20:01:46.095003: step 12149, loss 0.133158, acc 0.9375\n",
      "2017-04-03T20:01:46.298282: step 12150, loss 0.120883, acc 0.953125\n",
      "2017-04-03T20:01:46.500362: step 12151, loss 0.306223, acc 0.890625\n",
      "2017-04-03T20:01:46.702782: step 12152, loss 0.198638, acc 0.953125\n",
      "2017-04-03T20:01:46.908722: step 12153, loss 0.20965, acc 0.921875\n",
      "2017-04-03T20:01:47.106023: step 12154, loss 0.388425, acc 0.921875\n",
      "2017-04-03T20:01:47.315525: step 12155, loss 0.275232, acc 0.921875\n",
      "2017-04-03T20:01:47.560485: step 12156, loss 0.233437, acc 0.90625\n",
      "2017-04-03T20:01:47.769904: step 12157, loss 0.249547, acc 0.921875\n",
      "2017-04-03T20:01:47.969384: step 12158, loss 0.148268, acc 0.9375\n",
      "2017-04-03T20:01:48.182397: step 12159, loss 0.202578, acc 0.90625\n",
      "2017-04-03T20:01:48.400013: step 12160, loss 0.0756036, acc 0.953125\n",
      "2017-04-03T20:01:48.645231: step 12161, loss 0.257988, acc 0.90625\n",
      "2017-04-03T20:01:48.851437: step 12162, loss 0.108986, acc 0.984375\n",
      "2017-04-03T20:01:49.051719: step 12163, loss 0.306945, acc 0.875\n",
      "2017-04-03T20:01:49.252971: step 12164, loss 0.0988172, acc 0.96875\n",
      "2017-04-03T20:01:49.458288: step 12165, loss 0.1207, acc 0.953125\n",
      "2017-04-03T20:01:49.660591: step 12166, loss 0.335465, acc 0.875\n",
      "2017-04-03T20:01:49.868250: step 12167, loss 0.0486695, acc 1\n",
      "2017-04-03T20:01:50.067695: step 12168, loss 0.271992, acc 0.890625\n",
      "2017-04-03T20:01:50.278499: step 12169, loss 0.191229, acc 0.9375\n",
      "2017-04-03T20:01:50.528042: step 12170, loss 0.250138, acc 0.9375\n",
      "2017-04-03T20:01:50.742001: step 12171, loss 0.22191, acc 0.921875\n",
      "2017-04-03T20:01:50.946771: step 12172, loss 0.155899, acc 0.9375\n",
      "2017-04-03T20:01:51.150481: step 12173, loss 0.236696, acc 0.921875\n",
      "2017-04-03T20:01:51.354417: step 12174, loss 0.188018, acc 0.9375\n",
      "2017-04-03T20:01:51.556421: step 12175, loss 0.250126, acc 0.90625\n",
      "2017-04-03T20:01:51.758915: step 12176, loss 0.144261, acc 0.96875\n",
      "2017-04-03T20:01:51.959239: step 12177, loss 0.216757, acc 0.921875\n",
      "2017-04-03T20:01:52.165813: step 12178, loss 0.217148, acc 0.9375\n",
      "2017-04-03T20:01:52.367288: step 12179, loss 0.248554, acc 0.90625\n",
      "2017-04-03T20:01:52.607524: step 12180, loss 0.143311, acc 0.953125\n",
      "2017-04-03T20:01:52.810882: step 12181, loss 0.151381, acc 0.953125\n",
      "2017-04-03T20:01:53.011909: step 12182, loss 0.300148, acc 0.953125\n",
      "2017-04-03T20:01:53.213458: step 12183, loss 0.251879, acc 0.890625\n",
      "2017-04-03T20:01:53.413348: step 12184, loss 0.273584, acc 0.921875\n",
      "2017-04-03T20:01:53.615847: step 12185, loss 0.340797, acc 0.859375\n",
      "2017-04-03T20:01:53.822312: step 12186, loss 0.118021, acc 0.96875\n",
      "2017-04-03T20:01:54.022138: step 12187, loss 0.222918, acc 0.9375\n",
      "2017-04-03T20:01:54.222256: step 12188, loss 0.144669, acc 0.9375\n",
      "2017-04-03T20:01:54.428177: step 12189, loss 0.161514, acc 0.96875\n",
      "2017-04-03T20:01:54.630728: step 12190, loss 0.337447, acc 0.859375\n",
      "2017-04-03T20:01:54.831882: step 12191, loss 0.301392, acc 0.90625\n",
      "2017-04-03T20:01:55.034216: step 12192, loss 0.123744, acc 0.96875\n",
      "2017-04-03T20:01:55.234383: step 12193, loss 0.105489, acc 0.96875\n",
      "2017-04-03T20:01:55.445167: step 12194, loss 0.166504, acc 0.890625\n",
      "2017-04-03T20:01:55.650248: step 12195, loss 0.278144, acc 0.90625\n",
      "2017-04-03T20:01:55.856572: step 12196, loss 0.263433, acc 0.9375\n",
      "2017-04-03T20:01:56.066237: step 12197, loss 0.135903, acc 0.96875\n",
      "2017-04-03T20:01:56.263355: step 12198, loss 0.249068, acc 0.90625\n",
      "2017-04-03T20:01:56.489309: step 12199, loss 0.271058, acc 0.90625\n",
      "2017-04-03T20:01:56.692931: step 12200, loss 0.283107, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:01:58.756811: step 12200, loss 5.03379, acc 0.294\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-12200\n",
      "\n",
      "2017-04-03T20:01:59.126736: step 12201, loss 0.218969, acc 0.921875\n",
      "2017-04-03T20:01:59.326522: step 12202, loss 0.18074, acc 0.921875\n",
      "2017-04-03T20:01:59.528296: step 12203, loss 0.241089, acc 0.890625\n",
      "2017-04-03T20:01:59.733331: step 12204, loss 0.168829, acc 0.921875\n",
      "2017-04-03T20:01:59.933907: step 12205, loss 0.246395, acc 0.90625\n",
      "2017-04-03T20:02:00.133990: step 12206, loss 0.145818, acc 0.984375\n",
      "2017-04-03T20:02:00.340995: step 12207, loss 0.243855, acc 0.9375\n",
      "2017-04-03T20:02:00.543863: step 12208, loss 0.208992, acc 0.9375\n",
      "2017-04-03T20:02:00.759499: step 12209, loss 0.0982629, acc 0.96875\n",
      "2017-04-03T20:02:00.962204: step 12210, loss 0.165595, acc 0.9375\n",
      "2017-04-03T20:02:01.161229: step 12211, loss 0.228354, acc 0.9375\n",
      "2017-04-03T20:02:01.366384: step 12212, loss 0.319404, acc 0.953125\n",
      "2017-04-03T20:02:01.565918: step 12213, loss 0.187578, acc 0.921875\n",
      "2017-04-03T20:02:01.780647: step 12214, loss 0.248543, acc 0.953125\n",
      "2017-04-03T20:02:01.994877: step 12215, loss 0.163679, acc 0.9375\n",
      "2017-04-03T20:02:02.207006: step 12216, loss 0.119852, acc 0.96875\n",
      "2017-04-03T20:02:02.412060: step 12217, loss 0.244998, acc 0.953125\n",
      "2017-04-03T20:02:02.612427: step 12218, loss 0.241554, acc 0.921875\n",
      "2017-04-03T20:02:02.813071: step 12219, loss 0.133731, acc 0.96875\n",
      "2017-04-03T20:02:03.014724: step 12220, loss 0.193846, acc 0.921875\n",
      "2017-04-03T20:02:03.218840: step 12221, loss 0.115081, acc 0.953125\n",
      "2017-04-03T20:02:03.433402: step 12222, loss 0.20266, acc 0.953125\n",
      "2017-04-03T20:02:03.674360: step 12223, loss 0.112068, acc 0.9375\n",
      "2017-04-03T20:02:03.877635: step 12224, loss 0.299131, acc 0.921875\n",
      "2017-04-03T20:02:04.075444: step 12225, loss 0.467084, acc 0.890625\n",
      "2017-04-03T20:02:04.280199: step 12226, loss 0.185716, acc 0.921875\n",
      "2017-04-03T20:02:04.485772: step 12227, loss 0.168354, acc 0.953125\n",
      "2017-04-03T20:02:04.692543: step 12228, loss 0.229617, acc 0.953125\n",
      "2017-04-03T20:02:04.892125: step 12229, loss 0.0769933, acc 0.984375\n",
      "2017-04-03T20:02:05.100586: step 12230, loss 0.505533, acc 0.890625\n",
      "2017-04-03T20:02:05.303423: step 12231, loss 0.123225, acc 0.96875\n",
      "2017-04-03T20:02:05.505368: step 12232, loss 0.145167, acc 0.9375\n",
      "2017-04-03T20:02:05.709153: step 12233, loss 0.289577, acc 0.90625\n",
      "2017-04-03T20:02:05.910726: step 12234, loss 0.354225, acc 0.859375\n",
      "2017-04-03T20:02:06.110026: step 12235, loss 0.130666, acc 0.9375\n",
      "2017-04-03T20:02:06.318140: step 12236, loss 0.172947, acc 0.96875\n",
      "2017-04-03T20:02:06.523411: step 12237, loss 0.137721, acc 0.96875\n",
      "2017-04-03T20:02:06.721097: step 12238, loss 0.138627, acc 0.953125\n",
      "2017-04-03T20:02:06.924057: step 12239, loss 0.161453, acc 0.96875\n",
      "2017-04-03T20:02:07.123170: step 12240, loss 0.23811, acc 0.921875\n",
      "2017-04-03T20:02:07.325488: step 12241, loss 0.140282, acc 0.953125\n",
      "2017-04-03T20:02:07.531103: step 12242, loss 0.167776, acc 0.953125\n",
      "2017-04-03T20:02:07.734106: step 12243, loss 0.231669, acc 0.90625\n",
      "2017-04-03T20:02:07.937214: step 12244, loss 0.204415, acc 0.921875\n",
      "2017-04-03T20:02:08.138175: step 12245, loss 0.191925, acc 0.921875\n",
      "2017-04-03T20:02:08.338278: step 12246, loss 0.246259, acc 0.90625\n",
      "2017-04-03T20:02:08.547803: step 12247, loss 0.180697, acc 0.953125\n",
      "2017-04-03T20:02:08.754017: step 12248, loss 0.378654, acc 0.890625\n",
      "2017-04-03T20:02:08.955871: step 12249, loss 0.356396, acc 0.90625\n",
      "2017-04-03T20:02:09.184932: step 12250, loss 0.097561, acc 0.96875\n",
      "2017-04-03T20:02:09.390457: step 12251, loss 0.160784, acc 0.953125\n",
      "2017-04-03T20:02:09.594720: step 12252, loss 0.319399, acc 0.90625\n",
      "2017-04-03T20:02:09.794516: step 12253, loss 0.138846, acc 0.953125\n",
      "2017-04-03T20:02:10.043385: step 12254, loss 0.433898, acc 0.90625\n",
      "2017-04-03T20:02:10.254189: step 12255, loss 0.230501, acc 0.953125\n",
      "2017-04-03T20:02:10.455388: step 12256, loss 0.187397, acc 0.921875\n",
      "2017-04-03T20:02:10.656534: step 12257, loss 0.373078, acc 0.921875\n",
      "2017-04-03T20:02:10.859448: step 12258, loss 0.100551, acc 0.96875\n",
      "2017-04-03T20:02:11.102759: step 12259, loss 0.171262, acc 0.921875\n",
      "2017-04-03T20:02:11.315306: step 12260, loss 0.234265, acc 0.890625\n",
      "2017-04-03T20:02:11.516381: step 12261, loss 0.109599, acc 0.953125\n",
      "2017-04-03T20:02:11.719028: step 12262, loss 0.0713692, acc 0.984375\n",
      "2017-04-03T20:02:11.919037: step 12263, loss 0.244908, acc 0.921875\n",
      "2017-04-03T20:02:12.119143: step 12264, loss 0.122193, acc 0.96875\n",
      "2017-04-03T20:02:12.317682: step 12265, loss 0.398582, acc 0.921875\n",
      "2017-04-03T20:02:12.519855: step 12266, loss 0.23238, acc 0.90625\n",
      "2017-04-03T20:02:12.724447: step 12267, loss 0.200368, acc 0.921875\n",
      "2017-04-03T20:02:12.928551: step 12268, loss 0.169307, acc 0.953125\n",
      "2017-04-03T20:02:13.134593: step 12269, loss 0.10247, acc 0.953125\n",
      "2017-04-03T20:02:13.338452: step 12270, loss 0.122991, acc 0.984375\n",
      "2017-04-03T20:02:13.553368: step 12271, loss 0.177999, acc 0.96875\n",
      "2017-04-03T20:02:13.794036: step 12272, loss 0.131169, acc 0.953125\n",
      "2017-04-03T20:02:13.995168: step 12273, loss 0.103169, acc 0.984375\n",
      "2017-04-03T20:02:14.196747: step 12274, loss 0.724703, acc 0.890625\n",
      "2017-04-03T20:02:14.397952: step 12275, loss 0.261312, acc 0.90625\n",
      "2017-04-03T20:02:14.599619: step 12276, loss 0.182758, acc 0.9375\n",
      "2017-04-03T20:02:14.798843: step 12277, loss 0.101843, acc 0.984375\n",
      "2017-04-03T20:02:15.005226: step 12278, loss 0.220066, acc 0.9375\n",
      "2017-04-03T20:02:15.204669: step 12279, loss 0.269764, acc 0.921875\n",
      "2017-04-03T20:02:15.408896: step 12280, loss 0.299561, acc 0.921875\n",
      "2017-04-03T20:02:15.613285: step 12281, loss 0.125479, acc 0.96875\n",
      "2017-04-03T20:02:15.818391: step 12282, loss 0.153459, acc 0.921875\n",
      "2017-04-03T20:02:16.020367: step 12283, loss 0.24868, acc 0.875\n",
      "2017-04-03T20:02:16.223390: step 12284, loss 0.130507, acc 0.953125\n",
      "2017-04-03T20:02:16.432790: step 12285, loss 0.142247, acc 0.9375\n",
      "2017-04-03T20:02:16.676689: step 12286, loss 0.205766, acc 0.90625\n",
      "2017-04-03T20:02:16.927098: step 12287, loss 0.118535, acc 0.96875\n",
      "2017-04-03T20:02:17.130362: step 12288, loss 0.405691, acc 0.90625\n",
      "2017-04-03T20:02:17.371332: step 12289, loss 0.204272, acc 0.921875\n",
      "2017-04-03T20:02:17.573006: step 12290, loss 0.204418, acc 0.953125\n",
      "2017-04-03T20:02:17.777063: step 12291, loss 0.484454, acc 0.921875\n",
      "2017-04-03T20:02:17.978652: step 12292, loss 0.189042, acc 0.921875\n",
      "2017-04-03T20:02:18.179920: step 12293, loss 0.198299, acc 0.9375\n",
      "2017-04-03T20:02:18.383551: step 12294, loss 0.155208, acc 0.953125\n",
      "2017-04-03T20:02:18.588150: step 12295, loss 0.142732, acc 0.953125\n",
      "2017-04-03T20:02:18.792590: step 12296, loss 0.244384, acc 0.984375\n",
      "2017-04-03T20:02:19.001537: step 12297, loss 0.134203, acc 0.96875\n",
      "2017-04-03T20:02:19.204169: step 12298, loss 0.206967, acc 0.953125\n",
      "2017-04-03T20:02:19.413686: step 12299, loss 0.306221, acc 0.90625\n",
      "2017-04-03T20:02:19.619964: step 12300, loss 0.15567, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:02:21.731646: step 12300, loss 5.07222, acc 0.288\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-12300\n",
      "\n",
      "2017-04-03T20:02:22.111033: step 12301, loss 0.135547, acc 0.984375\n",
      "2017-04-03T20:02:22.312979: step 12302, loss 0.182486, acc 0.953125\n",
      "2017-04-03T20:02:22.522254: step 12303, loss 0.184405, acc 0.953125\n",
      "2017-04-03T20:02:22.729982: step 12304, loss 0.273121, acc 0.90625\n",
      "2017-04-03T20:02:22.930875: step 12305, loss 0.163768, acc 0.9375\n",
      "2017-04-03T20:02:23.134845: step 12306, loss 0.17077, acc 0.9375\n",
      "2017-04-03T20:02:23.333206: step 12307, loss 0.18466, acc 0.921875\n",
      "2017-04-03T20:02:23.538571: step 12308, loss 0.144168, acc 0.96875\n",
      "2017-04-03T20:02:23.745783: step 12309, loss 0.25854, acc 0.890625\n",
      "2017-04-03T20:02:23.946581: step 12310, loss 0.152886, acc 0.953125\n",
      "2017-04-03T20:02:24.145799: step 12311, loss 0.157116, acc 0.9375\n",
      "2017-04-03T20:02:24.357539: step 12312, loss 0.13447, acc 0.96875\n",
      "2017-04-03T20:02:24.558503: step 12313, loss 0.276159, acc 0.921875\n",
      "2017-04-03T20:02:24.766431: step 12314, loss 0.16498, acc 0.953125\n",
      "2017-04-03T20:02:24.973884: step 12315, loss 0.178408, acc 0.921875\n",
      "2017-04-03T20:02:25.177156: step 12316, loss 0.182303, acc 0.9375\n",
      "2017-04-03T20:02:25.378286: step 12317, loss 0.182332, acc 0.9375\n",
      "2017-04-03T20:02:25.591230: step 12318, loss 0.196319, acc 0.953125\n",
      "2017-04-03T20:02:25.804741: step 12319, loss 0.32321, acc 0.890625\n",
      "2017-04-03T20:02:26.016626: step 12320, loss 0.180431, acc 0.953125\n",
      "2017-04-03T20:02:26.232420: step 12321, loss 0.268397, acc 0.875\n",
      "2017-04-03T20:02:26.441185: step 12322, loss 0.233255, acc 0.9375\n",
      "2017-04-03T20:02:26.645145: step 12323, loss 0.123078, acc 0.96875\n",
      "2017-04-03T20:02:26.889693: step 12324, loss 0.222879, acc 0.90625\n",
      "2017-04-03T20:02:27.096843: step 12325, loss 0.215056, acc 0.921875\n",
      "2017-04-03T20:02:27.296574: step 12326, loss 0.250403, acc 0.921875\n",
      "2017-04-03T20:02:27.496143: step 12327, loss 0.235234, acc 0.9375\n",
      "2017-04-03T20:02:27.696496: step 12328, loss 0.27891, acc 0.90625\n",
      "2017-04-03T20:02:27.900804: step 12329, loss 0.117243, acc 0.984375\n",
      "2017-04-03T20:02:28.101453: step 12330, loss 0.150761, acc 0.96875\n",
      "2017-04-03T20:02:28.306795: step 12331, loss 0.236714, acc 0.90625\n",
      "2017-04-03T20:02:28.515764: step 12332, loss 0.233744, acc 0.9375\n",
      "2017-04-03T20:02:28.716667: step 12333, loss 0.294991, acc 0.875\n",
      "2017-04-03T20:02:28.917140: step 12334, loss 0.203746, acc 0.9375\n",
      "2017-04-03T20:02:29.120809: step 12335, loss 0.42834, acc 0.859375\n",
      "2017-04-03T20:02:29.331636: step 12336, loss 0.192236, acc 0.953125\n",
      "2017-04-03T20:02:29.540193: step 12337, loss 0.164252, acc 0.953125\n",
      "2017-04-03T20:02:29.748803: step 12338, loss 0.380527, acc 0.875\n",
      "2017-04-03T20:02:29.955515: step 12339, loss 0.0687544, acc 1\n",
      "2017-04-03T20:02:30.160258: step 12340, loss 0.272865, acc 0.90625\n",
      "2017-04-03T20:02:30.368099: step 12341, loss 0.118897, acc 0.953125\n",
      "2017-04-03T20:02:30.614753: step 12342, loss 0.114679, acc 0.953125\n",
      "2017-04-03T20:02:30.816605: step 12343, loss 0.276353, acc 0.890625\n",
      "2017-04-03T20:02:31.023525: step 12344, loss 0.129947, acc 0.953125\n",
      "2017-04-03T20:02:31.226835: step 12345, loss 0.143516, acc 0.953125\n",
      "2017-04-03T20:02:31.424044: step 12346, loss 0.224178, acc 0.90625\n",
      "2017-04-03T20:02:31.627858: step 12347, loss 0.302628, acc 0.921875\n",
      "2017-04-03T20:02:31.831960: step 12348, loss 0.382112, acc 0.90625\n",
      "2017-04-03T20:02:32.034282: step 12349, loss 0.184668, acc 0.921875\n",
      "2017-04-03T20:02:32.238196: step 12350, loss 0.178511, acc 0.953125\n",
      "2017-04-03T20:02:32.443736: step 12351, loss 0.133076, acc 0.96875\n",
      "2017-04-03T20:02:32.648423: step 12352, loss 0.0730447, acc 0.984375\n",
      "2017-04-03T20:02:32.855404: step 12353, loss 0.22239, acc 0.9375\n",
      "2017-04-03T20:02:33.057916: step 12354, loss 0.115228, acc 1\n",
      "2017-04-03T20:02:33.267599: step 12355, loss 0.0930337, acc 0.984375\n",
      "2017-04-03T20:02:33.471051: step 12356, loss 0.222493, acc 0.921875\n",
      "2017-04-03T20:02:33.714929: step 12357, loss 0.221519, acc 0.9375\n",
      "2017-04-03T20:02:33.926408: step 12358, loss 0.32929, acc 0.921875\n",
      "2017-04-03T20:02:34.128188: step 12359, loss 0.469566, acc 0.859375\n",
      "2017-04-03T20:02:34.329201: step 12360, loss 0.263501, acc 0.890625\n",
      "2017-04-03T20:02:34.530035: step 12361, loss 0.175869, acc 0.9375\n",
      "2017-04-03T20:02:34.774175: step 12362, loss 0.283611, acc 0.921875\n",
      "2017-04-03T20:02:34.976930: step 12363, loss 0.213803, acc 0.90625\n",
      "2017-04-03T20:02:35.187222: step 12364, loss 0.104082, acc 0.984375\n",
      "2017-04-03T20:02:35.400159: step 12365, loss 0.304705, acc 0.9375\n",
      "2017-04-03T20:02:35.610559: step 12366, loss 0.287491, acc 0.90625\n",
      "2017-04-03T20:02:35.821675: step 12367, loss 0.104726, acc 0.953125\n",
      "2017-04-03T20:02:36.024582: step 12368, loss 0.186719, acc 0.953125\n",
      "2017-04-03T20:02:36.227169: step 12369, loss 0.154705, acc 0.984375\n",
      "2017-04-03T20:02:36.444103: step 12370, loss 0.193933, acc 0.953125\n",
      "2017-04-03T20:02:36.659670: step 12371, loss 0.236901, acc 0.921875\n",
      "2017-04-03T20:02:36.863806: step 12372, loss 0.341003, acc 0.90625\n",
      "2017-04-03T20:02:37.080696: step 12373, loss 0.121953, acc 0.984375\n",
      "2017-04-03T20:02:37.297636: step 12374, loss 0.272405, acc 0.859375\n",
      "2017-04-03T20:02:37.503936: step 12375, loss 0.11019, acc 0.953125\n",
      "2017-04-03T20:02:37.706346: step 12376, loss 0.133914, acc 0.953125\n",
      "2017-04-03T20:02:37.910796: step 12377, loss 0.225162, acc 0.953125\n",
      "2017-04-03T20:02:38.118559: step 12378, loss 0.189462, acc 0.9375\n",
      "2017-04-03T20:02:38.322861: step 12379, loss 0.178028, acc 0.9375\n",
      "2017-04-03T20:02:38.527861: step 12380, loss 0.257858, acc 0.890625\n",
      "2017-04-03T20:02:38.770973: step 12381, loss 0.276301, acc 0.875\n",
      "2017-04-03T20:02:38.975809: step 12382, loss 0.439193, acc 0.90625\n",
      "2017-04-03T20:02:39.178043: step 12383, loss 0.211071, acc 0.921875\n",
      "2017-04-03T20:02:39.387489: step 12384, loss 0.130885, acc 0.96875\n",
      "2017-04-03T20:02:39.596328: step 12385, loss 0.292661, acc 0.875\n",
      "2017-04-03T20:02:39.745562: step 12386, loss 0.114678, acc 0.9375\n",
      "2017-04-03T20:02:39.953940: step 12387, loss 0.16957, acc 0.9375\n",
      "2017-04-03T20:02:40.195099: step 12388, loss 0.121133, acc 0.96875\n",
      "2017-04-03T20:02:40.403656: step 12389, loss 0.10339, acc 0.953125\n",
      "2017-04-03T20:02:40.603696: step 12390, loss 0.111918, acc 0.984375\n",
      "2017-04-03T20:02:40.810116: step 12391, loss 0.163134, acc 0.953125\n",
      "2017-04-03T20:02:41.055921: step 12392, loss 0.0988152, acc 0.984375\n",
      "2017-04-03T20:02:41.264916: step 12393, loss 0.233763, acc 0.921875\n",
      "2017-04-03T20:02:41.462194: step 12394, loss 0.367117, acc 0.9375\n",
      "2017-04-03T20:02:41.662500: step 12395, loss 0.123395, acc 0.953125\n",
      "2017-04-03T20:02:41.868370: step 12396, loss 0.0992891, acc 0.96875\n",
      "2017-04-03T20:02:42.090200: step 12397, loss 0.312713, acc 0.875\n",
      "2017-04-03T20:02:42.308236: step 12398, loss 0.113257, acc 0.953125\n",
      "2017-04-03T20:02:42.511876: step 12399, loss 0.22151, acc 0.9375\n",
      "2017-04-03T20:02:42.717011: step 12400, loss 0.214151, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:02:44.886966: step 12400, loss 5.08316, acc 0.294\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-12400\n",
      "\n",
      "2017-04-03T20:02:45.220952: step 12401, loss 0.164314, acc 0.921875\n",
      "2017-04-03T20:02:45.424061: step 12402, loss 0.110001, acc 0.96875\n",
      "2017-04-03T20:02:45.625015: step 12403, loss 0.203786, acc 0.921875\n",
      "2017-04-03T20:02:45.831075: step 12404, loss 0.133235, acc 0.9375\n",
      "2017-04-03T20:02:46.035576: step 12405, loss 0.233404, acc 0.921875\n",
      "2017-04-03T20:02:46.234448: step 12406, loss 0.0870115, acc 0.96875\n",
      "2017-04-03T20:02:46.479242: step 12407, loss 0.192153, acc 0.921875\n",
      "2017-04-03T20:02:46.686184: step 12408, loss 0.218942, acc 0.90625\n",
      "2017-04-03T20:02:46.887923: step 12409, loss 0.115853, acc 0.96875\n",
      "2017-04-03T20:02:47.133386: step 12410, loss 0.142606, acc 0.953125\n",
      "2017-04-03T20:02:47.334273: step 12411, loss 0.319864, acc 0.90625\n",
      "2017-04-03T20:02:47.533613: step 12412, loss 0.322311, acc 0.875\n",
      "2017-04-03T20:02:47.738112: step 12413, loss 0.101857, acc 0.96875\n",
      "2017-04-03T20:02:47.942147: step 12414, loss 0.113507, acc 0.953125\n",
      "2017-04-03T20:02:48.143087: step 12415, loss 0.129744, acc 0.96875\n",
      "2017-04-03T20:02:48.349380: step 12416, loss 0.241732, acc 0.90625\n",
      "2017-04-03T20:02:48.593527: step 12417, loss 0.165998, acc 0.9375\n",
      "2017-04-03T20:02:48.806137: step 12418, loss 0.0953072, acc 0.96875\n",
      "2017-04-03T20:02:49.007739: step 12419, loss 0.0800043, acc 0.984375\n",
      "2017-04-03T20:02:49.212245: step 12420, loss 0.33879, acc 0.859375\n",
      "2017-04-03T20:02:49.451249: step 12421, loss 0.151333, acc 0.9375\n",
      "2017-04-03T20:02:49.655116: step 12422, loss 0.26675, acc 0.90625\n",
      "2017-04-03T20:02:49.855478: step 12423, loss 0.0884829, acc 0.984375\n",
      "2017-04-03T20:02:50.061080: step 12424, loss 0.140689, acc 0.96875\n",
      "2017-04-03T20:02:50.290886: step 12425, loss 0.0352397, acc 1\n",
      "2017-04-03T20:02:50.505289: step 12426, loss 0.139354, acc 0.953125\n",
      "2017-04-03T20:02:50.716832: step 12427, loss 0.0825852, acc 0.984375\n",
      "2017-04-03T20:02:50.926011: step 12428, loss 0.124152, acc 0.953125\n",
      "2017-04-03T20:02:51.131340: step 12429, loss 0.160588, acc 0.953125\n",
      "2017-04-03T20:02:51.332678: step 12430, loss 0.154041, acc 0.953125\n",
      "2017-04-03T20:02:51.538118: step 12431, loss 0.100937, acc 0.96875\n",
      "2017-04-03T20:02:51.739100: step 12432, loss 0.18173, acc 0.96875\n",
      "2017-04-03T20:02:51.985687: step 12433, loss 0.106113, acc 0.96875\n",
      "2017-04-03T20:02:52.188829: step 12434, loss 0.116313, acc 0.96875\n",
      "2017-04-03T20:02:52.392378: step 12435, loss 0.114412, acc 0.953125\n",
      "2017-04-03T20:02:52.641412: step 12436, loss 0.196228, acc 0.9375\n",
      "2017-04-03T20:02:52.845396: step 12437, loss 0.0608786, acc 1\n",
      "2017-04-03T20:02:53.057385: step 12438, loss 0.0724137, acc 0.984375\n",
      "2017-04-03T20:02:53.260084: step 12439, loss 0.0653052, acc 1\n",
      "2017-04-03T20:02:53.461762: step 12440, loss 0.1354, acc 0.9375\n",
      "2017-04-03T20:02:53.665098: step 12441, loss 0.200884, acc 0.921875\n",
      "2017-04-03T20:02:53.873767: step 12442, loss 0.208067, acc 0.921875\n",
      "2017-04-03T20:02:54.074692: step 12443, loss 0.0593603, acc 0.984375\n",
      "2017-04-03T20:02:54.281046: step 12444, loss 0.17878, acc 0.9375\n",
      "2017-04-03T20:02:54.485273: step 12445, loss 0.122691, acc 0.984375\n",
      "2017-04-03T20:02:54.713602: step 12446, loss 0.164013, acc 0.984375\n",
      "2017-04-03T20:02:54.961329: step 12447, loss 0.216807, acc 0.9375\n",
      "2017-04-03T20:02:55.177546: step 12448, loss 0.18596, acc 0.9375\n",
      "2017-04-03T20:02:55.374453: step 12449, loss 0.120061, acc 0.96875\n",
      "2017-04-03T20:02:55.578776: step 12450, loss 0.291548, acc 0.890625\n",
      "2017-04-03T20:02:55.791053: step 12451, loss 0.136665, acc 0.921875\n",
      "2017-04-03T20:02:55.993076: step 12452, loss 0.162658, acc 0.984375\n",
      "2017-04-03T20:02:56.209408: step 12453, loss 0.121224, acc 0.984375\n",
      "2017-04-03T20:02:56.409834: step 12454, loss 0.188196, acc 0.9375\n",
      "2017-04-03T20:02:56.611710: step 12455, loss 0.195774, acc 0.921875\n",
      "2017-04-03T20:02:56.813477: step 12456, loss 0.110906, acc 0.96875\n",
      "2017-04-03T20:02:57.016595: step 12457, loss 0.198279, acc 0.921875\n",
      "2017-04-03T20:02:57.219821: step 12458, loss 0.125525, acc 0.953125\n",
      "2017-04-03T20:02:57.482396: step 12459, loss 0.164791, acc 0.953125\n",
      "2017-04-03T20:02:57.693186: step 12460, loss 0.0249296, acc 1\n",
      "2017-04-03T20:02:57.903502: step 12461, loss 0.0993899, acc 0.96875\n",
      "2017-04-03T20:02:58.117095: step 12462, loss 0.208867, acc 0.921875\n",
      "2017-04-03T20:02:58.336085: step 12463, loss 0.174237, acc 0.96875\n",
      "2017-04-03T20:02:58.552898: step 12464, loss 0.0493326, acc 0.984375\n",
      "2017-04-03T20:02:58.758433: step 12465, loss 0.162631, acc 0.953125\n",
      "2017-04-03T20:02:58.965774: step 12466, loss 0.199648, acc 0.9375\n",
      "2017-04-03T20:02:59.172904: step 12467, loss 0.166039, acc 0.953125\n",
      "2017-04-03T20:02:59.379681: step 12468, loss 0.0871287, acc 0.96875\n",
      "2017-04-03T20:02:59.585001: step 12469, loss 0.310068, acc 0.890625\n",
      "2017-04-03T20:02:59.788086: step 12470, loss 0.184533, acc 0.953125\n",
      "2017-04-03T20:02:59.993555: step 12471, loss 0.0784251, acc 0.96875\n",
      "2017-04-03T20:03:00.196532: step 12472, loss 0.0792349, acc 1\n",
      "2017-04-03T20:03:00.451261: step 12473, loss 0.0491535, acc 1\n",
      "2017-04-03T20:03:00.653545: step 12474, loss 0.139127, acc 0.953125\n",
      "2017-04-03T20:03:00.851200: step 12475, loss 0.176647, acc 0.953125\n",
      "2017-04-03T20:03:01.056717: step 12476, loss 0.113809, acc 0.96875\n",
      "2017-04-03T20:03:01.254687: step 12477, loss 0.185777, acc 0.921875\n",
      "2017-04-03T20:03:01.455905: step 12478, loss 0.179626, acc 0.96875\n",
      "2017-04-03T20:03:01.656966: step 12479, loss 0.156606, acc 0.953125\n",
      "2017-04-03T20:03:01.859397: step 12480, loss 0.125716, acc 0.953125\n",
      "2017-04-03T20:03:02.056490: step 12481, loss 0.0890146, acc 0.953125\n",
      "2017-04-03T20:03:02.261651: step 12482, loss 0.0830135, acc 0.984375\n",
      "2017-04-03T20:03:02.460630: step 12483, loss 0.4119, acc 0.84375\n",
      "2017-04-03T20:03:02.657548: step 12484, loss 0.120222, acc 0.953125\n",
      "2017-04-03T20:03:02.860947: step 12485, loss 0.255873, acc 0.890625\n",
      "2017-04-03T20:03:03.103951: step 12486, loss 0.145615, acc 0.9375\n",
      "2017-04-03T20:03:03.345191: step 12487, loss 0.250251, acc 0.9375\n",
      "2017-04-03T20:03:03.543430: step 12488, loss 0.170931, acc 0.9375\n",
      "2017-04-03T20:03:03.745836: step 12489, loss 0.344391, acc 0.875\n",
      "2017-04-03T20:03:03.946436: step 12490, loss 0.120794, acc 0.953125\n",
      "2017-04-03T20:03:04.152200: step 12491, loss 0.313059, acc 0.921875\n",
      "2017-04-03T20:03:04.354964: step 12492, loss 0.195124, acc 0.9375\n",
      "2017-04-03T20:03:04.609953: step 12493, loss 0.228603, acc 0.921875\n",
      "2017-04-03T20:03:04.856226: step 12494, loss 0.14163, acc 0.984375\n",
      "2017-04-03T20:03:05.063613: step 12495, loss 0.109309, acc 0.96875\n",
      "2017-04-03T20:03:05.283467: step 12496, loss 0.235155, acc 0.90625\n",
      "2017-04-03T20:03:05.495310: step 12497, loss 0.0811367, acc 0.984375\n",
      "2017-04-03T20:03:05.700100: step 12498, loss 0.201129, acc 0.96875\n",
      "2017-04-03T20:03:05.897904: step 12499, loss 0.149701, acc 0.96875\n",
      "2017-04-03T20:03:06.141745: step 12500, loss 0.126141, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:03:08.287534: step 12500, loss 5.19883, acc 0.30325\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-12500\n",
      "\n",
      "2017-04-03T20:03:08.621307: step 12501, loss 0.119407, acc 0.96875\n",
      "2017-04-03T20:03:08.860040: step 12502, loss 0.188218, acc 0.96875\n",
      "2017-04-03T20:03:09.069797: step 12503, loss 0.127787, acc 0.953125\n",
      "2017-04-03T20:03:09.280624: step 12504, loss 0.210994, acc 0.953125\n",
      "2017-04-03T20:03:09.484846: step 12505, loss 0.209233, acc 0.9375\n",
      "2017-04-03T20:03:09.686351: step 12506, loss 0.150488, acc 0.9375\n",
      "2017-04-03T20:03:09.886679: step 12507, loss 0.330977, acc 0.921875\n",
      "2017-04-03T20:03:10.095567: step 12508, loss 0.085507, acc 0.984375\n",
      "2017-04-03T20:03:10.302507: step 12509, loss 0.159522, acc 0.9375\n",
      "2017-04-03T20:03:10.547760: step 12510, loss 0.293965, acc 0.96875\n",
      "2017-04-03T20:03:10.754787: step 12511, loss 0.129259, acc 0.953125\n",
      "2017-04-03T20:03:10.956374: step 12512, loss 0.19956, acc 0.9375\n",
      "2017-04-03T20:03:11.158460: step 12513, loss 0.105722, acc 0.984375\n",
      "2017-04-03T20:03:11.360386: step 12514, loss 0.250735, acc 0.9375\n",
      "2017-04-03T20:03:11.560574: step 12515, loss 0.19033, acc 0.9375\n",
      "2017-04-03T20:03:11.780207: step 12516, loss 0.196606, acc 0.921875\n",
      "2017-04-03T20:03:11.993049: step 12517, loss 0.0825904, acc 0.984375\n",
      "2017-04-03T20:03:12.202247: step 12518, loss 0.154111, acc 0.953125\n",
      "2017-04-03T20:03:12.404497: step 12519, loss 0.0959194, acc 0.984375\n",
      "2017-04-03T20:03:12.607097: step 12520, loss 0.13894, acc 0.953125\n",
      "2017-04-03T20:03:12.807471: step 12521, loss 0.173665, acc 0.921875\n",
      "2017-04-03T20:03:13.043074: step 12522, loss 0.135086, acc 0.96875\n",
      "2017-04-03T20:03:13.253255: step 12523, loss 0.182338, acc 0.953125\n",
      "2017-04-03T20:03:13.469770: step 12524, loss 0.129117, acc 0.953125\n",
      "2017-04-03T20:03:13.676214: step 12525, loss 0.107416, acc 0.96875\n",
      "2017-04-03T20:03:13.880654: step 12526, loss 0.0950871, acc 0.984375\n",
      "2017-04-03T20:03:14.080735: step 12527, loss 0.198824, acc 0.921875\n",
      "2017-04-03T20:03:14.281736: step 12528, loss 0.155875, acc 0.96875\n",
      "2017-04-03T20:03:14.487819: step 12529, loss 0.365636, acc 0.953125\n",
      "2017-04-03T20:03:14.688031: step 12530, loss 0.156247, acc 0.953125\n",
      "2017-04-03T20:03:14.890262: step 12531, loss 0.239702, acc 0.9375\n",
      "2017-04-03T20:03:15.090312: step 12532, loss 0.067725, acc 0.96875\n",
      "2017-04-03T20:03:15.300658: step 12533, loss 0.124511, acc 0.96875\n",
      "2017-04-03T20:03:15.512580: step 12534, loss 0.119311, acc 0.953125\n",
      "2017-04-03T20:03:15.711970: step 12535, loss 0.161383, acc 0.953125\n",
      "2017-04-03T20:03:15.955417: step 12536, loss 0.0659792, acc 0.984375\n",
      "2017-04-03T20:03:16.157605: step 12537, loss 0.163662, acc 0.984375\n",
      "2017-04-03T20:03:16.363915: step 12538, loss 0.373606, acc 0.9375\n",
      "2017-04-03T20:03:16.568733: step 12539, loss 0.124054, acc 0.953125\n",
      "2017-04-03T20:03:16.778552: step 12540, loss 0.1155, acc 0.96875\n",
      "2017-04-03T20:03:16.978543: step 12541, loss 0.0539825, acc 0.984375\n",
      "2017-04-03T20:03:17.223789: step 12542, loss 0.132704, acc 0.953125\n",
      "2017-04-03T20:03:17.425616: step 12543, loss 0.280478, acc 0.9375\n",
      "2017-04-03T20:03:17.634469: step 12544, loss 0.0516463, acc 0.984375\n",
      "2017-04-03T20:03:17.846132: step 12545, loss 0.0997034, acc 0.96875\n",
      "2017-04-03T20:03:18.046534: step 12546, loss 0.163101, acc 0.953125\n",
      "2017-04-03T20:03:18.247660: step 12547, loss 0.149263, acc 0.953125\n",
      "2017-04-03T20:03:18.454431: step 12548, loss 0.24318, acc 0.921875\n",
      "2017-04-03T20:03:18.654293: step 12549, loss 0.184847, acc 0.90625\n",
      "2017-04-03T20:03:18.856162: step 12550, loss 0.202279, acc 0.9375\n",
      "2017-04-03T20:03:19.098864: step 12551, loss 0.245326, acc 0.921875\n",
      "2017-04-03T20:03:19.298536: step 12552, loss 0.0997675, acc 0.953125\n",
      "2017-04-03T20:03:19.499765: step 12553, loss 0.141591, acc 0.953125\n",
      "2017-04-03T20:03:19.715700: step 12554, loss 0.2513, acc 0.921875\n",
      "2017-04-03T20:03:19.917595: step 12555, loss 0.0818939, acc 0.984375\n",
      "2017-04-03T20:03:20.120579: step 12556, loss 0.261887, acc 0.9375\n",
      "2017-04-03T20:03:20.323709: step 12557, loss 0.121257, acc 0.984375\n",
      "2017-04-03T20:03:20.535304: step 12558, loss 0.152368, acc 0.9375\n",
      "2017-04-03T20:03:20.753742: step 12559, loss 0.0684877, acc 0.984375\n",
      "2017-04-03T20:03:20.988472: step 12560, loss 0.32987, acc 0.875\n",
      "2017-04-03T20:03:21.194633: step 12561, loss 0.119281, acc 0.953125\n",
      "2017-04-03T20:03:21.403827: step 12562, loss 0.352431, acc 0.90625\n",
      "2017-04-03T20:03:21.603858: step 12563, loss 0.072395, acc 0.984375\n",
      "2017-04-03T20:03:21.856251: step 12564, loss 0.195996, acc 0.921875\n",
      "2017-04-03T20:03:22.064506: step 12565, loss 0.200433, acc 0.9375\n",
      "2017-04-03T20:03:22.267171: step 12566, loss 0.152279, acc 0.953125\n",
      "2017-04-03T20:03:22.474051: step 12567, loss 0.152891, acc 0.953125\n",
      "2017-04-03T20:03:22.682952: step 12568, loss 0.227943, acc 0.9375\n",
      "2017-04-03T20:03:22.882856: step 12569, loss 0.105239, acc 0.953125\n",
      "2017-04-03T20:03:23.084088: step 12570, loss 0.106241, acc 0.953125\n",
      "2017-04-03T20:03:23.309831: step 12571, loss 0.153189, acc 0.90625\n",
      "2017-04-03T20:03:23.521137: step 12572, loss 0.106906, acc 0.96875\n",
      "2017-04-03T20:03:23.724845: step 12573, loss 0.205161, acc 0.953125\n",
      "2017-04-03T20:03:23.928254: step 12574, loss 0.343433, acc 0.953125\n",
      "2017-04-03T20:03:24.131706: step 12575, loss 0.111793, acc 0.953125\n",
      "2017-04-03T20:03:24.333980: step 12576, loss 0.117384, acc 0.953125\n",
      "2017-04-03T20:03:24.535238: step 12577, loss 0.267478, acc 0.953125\n",
      "2017-04-03T20:03:24.735593: step 12578, loss 0.197088, acc 0.953125\n",
      "2017-04-03T20:03:24.938984: step 12579, loss 0.0808983, acc 0.984375\n",
      "2017-04-03T20:03:25.153603: step 12580, loss 0.239079, acc 0.9375\n",
      "2017-04-03T20:03:25.357345: step 12581, loss 0.207044, acc 0.921875\n",
      "2017-04-03T20:03:25.559301: step 12582, loss 0.0784342, acc 0.96875\n",
      "2017-04-03T20:03:25.769236: step 12583, loss 0.169155, acc 0.921875\n",
      "2017-04-03T20:03:25.970156: step 12584, loss 0.160312, acc 0.953125\n",
      "2017-04-03T20:03:26.175089: step 12585, loss 0.202541, acc 0.96875\n",
      "2017-04-03T20:03:26.416689: step 12586, loss 0.116472, acc 0.984375\n",
      "2017-04-03T20:03:26.660464: step 12587, loss 0.199545, acc 0.921875\n",
      "2017-04-03T20:03:26.863940: step 12588, loss 0.281827, acc 0.90625\n",
      "2017-04-03T20:03:27.061639: step 12589, loss 0.0965037, acc 0.984375\n",
      "2017-04-03T20:03:27.266742: step 12590, loss 0.15411, acc 0.953125\n",
      "2017-04-03T20:03:27.516442: step 12591, loss 0.121933, acc 0.96875\n",
      "2017-04-03T20:03:27.721675: step 12592, loss 0.151977, acc 0.9375\n",
      "2017-04-03T20:03:27.922585: step 12593, loss 0.191058, acc 0.953125\n",
      "2017-04-03T20:03:28.137935: step 12594, loss 0.190569, acc 0.953125\n",
      "2017-04-03T20:03:28.355205: step 12595, loss 0.124257, acc 0.96875\n",
      "2017-04-03T20:03:28.600886: step 12596, loss 0.0706212, acc 0.984375\n",
      "2017-04-03T20:03:28.802037: step 12597, loss 0.194075, acc 0.9375\n",
      "2017-04-03T20:03:29.002896: step 12598, loss 0.207859, acc 0.9375\n",
      "2017-04-03T20:03:29.203503: step 12599, loss 0.0678809, acc 0.96875\n",
      "2017-04-03T20:03:29.404645: step 12600, loss 0.151066, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:03:31.521595: step 12600, loss 5.31459, acc 0.29775\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-12600\n",
      "\n",
      "2017-04-03T20:03:31.845929: step 12601, loss 0.22038, acc 0.90625\n",
      "2017-04-03T20:03:32.038228: step 12602, loss 0.136705, acc 0.96875\n",
      "2017-04-03T20:03:32.241103: step 12603, loss 0.227954, acc 0.953125\n",
      "2017-04-03T20:03:32.443587: step 12604, loss 0.156502, acc 0.96875\n",
      "2017-04-03T20:03:32.645760: step 12605, loss 0.255778, acc 0.921875\n",
      "2017-04-03T20:03:32.845421: step 12606, loss 0.140069, acc 0.984375\n",
      "2017-04-03T20:03:33.052009: step 12607, loss 0.229806, acc 0.890625\n",
      "2017-04-03T20:03:33.254291: step 12608, loss 0.0761344, acc 0.984375\n",
      "2017-04-03T20:03:33.457807: step 12609, loss 0.173225, acc 0.90625\n",
      "2017-04-03T20:03:33.659102: step 12610, loss 0.252713, acc 0.890625\n",
      "2017-04-03T20:03:33.908481: step 12611, loss 0.128804, acc 0.96875\n",
      "2017-04-03T20:03:34.111329: step 12612, loss 0.164217, acc 0.9375\n",
      "2017-04-03T20:03:34.314575: step 12613, loss 0.143428, acc 0.953125\n",
      "2017-04-03T20:03:34.528459: step 12614, loss 0.201366, acc 0.9375\n",
      "2017-04-03T20:03:34.733262: step 12615, loss 0.156785, acc 0.9375\n",
      "2017-04-03T20:03:34.934707: step 12616, loss 0.185732, acc 0.9375\n",
      "2017-04-03T20:03:35.133327: step 12617, loss 0.102498, acc 0.96875\n",
      "2017-04-03T20:03:35.335025: step 12618, loss 0.150968, acc 0.953125\n",
      "2017-04-03T20:03:35.537684: step 12619, loss 0.169022, acc 0.953125\n",
      "2017-04-03T20:03:35.738038: step 12620, loss 0.124775, acc 0.984375\n",
      "2017-04-03T20:03:35.939573: step 12621, loss 0.16373, acc 0.96875\n",
      "2017-04-03T20:03:36.137971: step 12622, loss 0.352214, acc 0.9375\n",
      "2017-04-03T20:03:36.337415: step 12623, loss 0.283975, acc 0.90625\n",
      "2017-04-03T20:03:36.538885: step 12624, loss 0.105347, acc 0.96875\n",
      "2017-04-03T20:03:36.742021: step 12625, loss 0.0855198, acc 1\n",
      "2017-04-03T20:03:36.946930: step 12626, loss 0.167728, acc 0.9375\n",
      "2017-04-03T20:03:37.150204: step 12627, loss 0.182734, acc 0.953125\n",
      "2017-04-03T20:03:37.360480: step 12628, loss 0.15605, acc 0.953125\n",
      "2017-04-03T20:03:37.579381: step 12629, loss 0.132595, acc 0.984375\n",
      "2017-04-03T20:03:37.793777: step 12630, loss 0.0858051, acc 0.984375\n",
      "2017-04-03T20:03:38.012739: step 12631, loss 0.189681, acc 0.921875\n",
      "2017-04-03T20:03:38.216475: step 12632, loss 0.289749, acc 0.9375\n",
      "2017-04-03T20:03:38.418742: step 12633, loss 0.251684, acc 0.890625\n",
      "2017-04-03T20:03:38.619896: step 12634, loss 0.275178, acc 0.921875\n",
      "2017-04-03T20:03:38.864307: step 12635, loss 0.149504, acc 0.9375\n",
      "2017-04-03T20:03:39.068207: step 12636, loss 0.190717, acc 0.953125\n",
      "2017-04-03T20:03:39.283374: step 12637, loss 0.237472, acc 0.921875\n",
      "2017-04-03T20:03:39.536425: step 12638, loss 0.101358, acc 0.96875\n",
      "2017-04-03T20:03:39.737730: step 12639, loss 0.199264, acc 0.9375\n",
      "2017-04-03T20:03:39.940826: step 12640, loss 0.132203, acc 0.96875\n",
      "2017-04-03T20:03:40.140270: step 12641, loss 0.182819, acc 0.90625\n",
      "2017-04-03T20:03:40.343016: step 12642, loss 0.134201, acc 0.953125\n",
      "2017-04-03T20:03:40.548102: step 12643, loss 0.14275, acc 0.921875\n",
      "2017-04-03T20:03:40.753119: step 12644, loss 0.186792, acc 0.921875\n",
      "2017-04-03T20:03:40.956555: step 12645, loss 0.293269, acc 0.890625\n",
      "2017-04-03T20:03:41.158576: step 12646, loss 0.193575, acc 0.953125\n",
      "2017-04-03T20:03:41.399335: step 12647, loss 0.147761, acc 0.953125\n",
      "2017-04-03T20:03:41.601910: step 12648, loss 0.159399, acc 0.96875\n",
      "2017-04-03T20:03:41.806274: step 12649, loss 0.0579186, acc 0.984375\n",
      "2017-04-03T20:03:42.014807: step 12650, loss 0.0982291, acc 0.96875\n",
      "2017-04-03T20:03:42.218156: step 12651, loss 0.157442, acc 0.9375\n",
      "2017-04-03T20:03:42.422026: step 12652, loss 0.128324, acc 0.921875\n",
      "2017-04-03T20:03:42.665838: step 12653, loss 0.0935715, acc 0.984375\n",
      "2017-04-03T20:03:42.865513: step 12654, loss 0.204258, acc 0.921875\n",
      "2017-04-03T20:03:43.069296: step 12655, loss 0.159043, acc 0.96875\n",
      "2017-04-03T20:03:43.270389: step 12656, loss 0.0841822, acc 0.953125\n",
      "2017-04-03T20:03:43.469000: step 12657, loss 0.220298, acc 0.953125\n",
      "2017-04-03T20:03:43.678362: step 12658, loss 0.173251, acc 0.953125\n",
      "2017-04-03T20:03:43.882914: step 12659, loss 0.0845318, acc 0.984375\n",
      "2017-04-03T20:03:44.083444: step 12660, loss 0.212, acc 0.90625\n",
      "2017-04-03T20:03:44.274165: step 12661, loss 0.147445, acc 0.96875\n",
      "2017-04-03T20:03:44.477970: step 12662, loss 0.128579, acc 0.96875\n",
      "2017-04-03T20:03:44.679666: step 12663, loss 0.110401, acc 0.96875\n",
      "2017-04-03T20:03:44.878926: step 12664, loss 0.108235, acc 0.96875\n",
      "2017-04-03T20:03:45.078340: step 12665, loss 0.0783109, acc 1\n",
      "2017-04-03T20:03:45.292148: step 12666, loss 0.254476, acc 0.96875\n",
      "2017-04-03T20:03:45.497776: step 12667, loss 0.310438, acc 0.890625\n",
      "2017-04-03T20:03:45.696625: step 12668, loss 0.0719704, acc 1\n",
      "2017-04-03T20:03:45.898467: step 12669, loss 0.151726, acc 0.96875\n",
      "2017-04-03T20:03:46.100269: step 12670, loss 0.254547, acc 0.953125\n",
      "2017-04-03T20:03:46.302491: step 12671, loss 0.232021, acc 0.921875\n",
      "2017-04-03T20:03:46.504357: step 12672, loss 0.223208, acc 0.921875\n",
      "2017-04-03T20:03:46.717015: step 12673, loss 0.0861453, acc 0.984375\n",
      "2017-04-03T20:03:46.991484: step 12674, loss 0.11239, acc 0.953125\n",
      "2017-04-03T20:03:47.191184: step 12675, loss 0.213783, acc 0.9375\n",
      "2017-04-03T20:03:47.394007: step 12676, loss 0.29207, acc 0.890625\n",
      "2017-04-03T20:03:47.599438: step 12677, loss 0.204301, acc 0.921875\n",
      "2017-04-03T20:03:47.802358: step 12678, loss 0.122583, acc 0.96875\n",
      "2017-04-03T20:03:48.018072: step 12679, loss 0.192576, acc 0.9375\n",
      "2017-04-03T20:03:48.216715: step 12680, loss 0.138123, acc 0.953125\n",
      "2017-04-03T20:03:48.418468: step 12681, loss 0.125659, acc 0.984375\n",
      "2017-04-03T20:03:48.658801: step 12682, loss 0.149642, acc 0.953125\n",
      "2017-04-03T20:03:48.863486: step 12683, loss 0.233491, acc 0.9375\n",
      "2017-04-03T20:03:49.091524: step 12684, loss 0.159049, acc 0.953125\n",
      "2017-04-03T20:03:49.309966: step 12685, loss 0.106662, acc 0.96875\n",
      "2017-04-03T20:03:49.508440: step 12686, loss 0.164481, acc 0.9375\n",
      "2017-04-03T20:03:49.708305: step 12687, loss 0.091738, acc 0.96875\n",
      "2017-04-03T20:03:49.910555: step 12688, loss 0.184766, acc 0.9375\n",
      "2017-04-03T20:03:50.158646: step 12689, loss 0.206395, acc 0.96875\n",
      "2017-04-03T20:03:50.362281: step 12690, loss 0.261015, acc 0.9375\n",
      "2017-04-03T20:03:50.561182: step 12691, loss 0.300084, acc 0.890625\n",
      "2017-04-03T20:03:50.764753: step 12692, loss 0.0804196, acc 0.984375\n",
      "2017-04-03T20:03:50.966000: step 12693, loss 0.141194, acc 0.96875\n",
      "2017-04-03T20:03:51.169040: step 12694, loss 0.247132, acc 0.890625\n",
      "2017-04-03T20:03:51.368343: step 12695, loss 0.246269, acc 0.90625\n",
      "2017-04-03T20:03:51.613318: step 12696, loss 0.191417, acc 0.953125\n",
      "2017-04-03T20:03:51.818308: step 12697, loss 0.146795, acc 0.9375\n",
      "2017-04-03T20:03:52.066768: step 12698, loss 0.249649, acc 0.9375\n",
      "2017-04-03T20:03:52.270998: step 12699, loss 0.275682, acc 0.921875\n",
      "2017-04-03T20:03:52.513075: step 12700, loss 0.160439, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:03:54.723365: step 12700, loss 5.20625, acc 0.29575\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-12700\n",
      "\n",
      "2017-04-03T20:03:55.052883: step 12701, loss 0.23724, acc 0.953125\n",
      "2017-04-03T20:03:55.253278: step 12702, loss 0.13311, acc 0.953125\n",
      "2017-04-03T20:03:55.450745: step 12703, loss 0.389786, acc 0.953125\n",
      "2017-04-03T20:03:55.656910: step 12704, loss 0.163626, acc 0.9375\n",
      "2017-04-03T20:03:55.855870: step 12705, loss 0.318797, acc 0.859375\n",
      "2017-04-03T20:03:56.064295: step 12706, loss 0.106963, acc 0.96875\n",
      "2017-04-03T20:03:56.270533: step 12707, loss 0.0893047, acc 0.96875\n",
      "2017-04-03T20:03:56.473258: step 12708, loss 0.29469, acc 0.890625\n",
      "2017-04-03T20:03:56.674447: step 12709, loss 0.106299, acc 0.96875\n",
      "2017-04-03T20:03:56.876081: step 12710, loss 0.179404, acc 0.9375\n",
      "2017-04-03T20:03:57.076536: step 12711, loss 0.271736, acc 0.96875\n",
      "2017-04-03T20:03:57.277559: step 12712, loss 0.250438, acc 0.890625\n",
      "2017-04-03T20:03:57.482559: step 12713, loss 0.201562, acc 0.953125\n",
      "2017-04-03T20:03:57.685736: step 12714, loss 0.0628979, acc 0.984375\n",
      "2017-04-03T20:03:57.884427: step 12715, loss 0.168367, acc 0.96875\n",
      "2017-04-03T20:03:58.093015: step 12716, loss 0.193, acc 0.9375\n",
      "2017-04-03T20:03:58.292414: step 12717, loss 0.136463, acc 0.96875\n",
      "2017-04-03T20:03:58.495055: step 12718, loss 0.181752, acc 0.9375\n",
      "2017-04-03T20:03:58.698126: step 12719, loss 0.116751, acc 0.96875\n",
      "2017-04-03T20:03:58.900640: step 12720, loss 0.132955, acc 0.96875\n",
      "2017-04-03T20:03:59.099144: step 12721, loss 0.142291, acc 0.9375\n",
      "2017-04-03T20:03:59.302048: step 12722, loss 0.243687, acc 0.953125\n",
      "2017-04-03T20:03:59.549699: step 12723, loss 0.156439, acc 0.953125\n",
      "2017-04-03T20:03:59.750841: step 12724, loss 0.447009, acc 0.921875\n",
      "2017-04-03T20:03:59.966196: step 12725, loss 0.160237, acc 0.953125\n",
      "2017-04-03T20:04:00.206728: step 12726, loss 0.176499, acc 0.96875\n",
      "2017-04-03T20:04:00.427776: step 12727, loss 0.287472, acc 0.921875\n",
      "2017-04-03T20:04:00.637365: step 12728, loss 0.225728, acc 0.890625\n",
      "2017-04-03T20:04:00.835787: step 12729, loss 0.0702068, acc 0.984375\n",
      "2017-04-03T20:04:01.040625: step 12730, loss 0.244321, acc 0.90625\n",
      "2017-04-03T20:04:01.238891: step 12731, loss 0.148167, acc 0.9375\n",
      "2017-04-03T20:04:01.441975: step 12732, loss 0.103507, acc 0.953125\n",
      "2017-04-03T20:04:01.649696: step 12733, loss 0.0996257, acc 0.953125\n",
      "2017-04-03T20:04:01.854536: step 12734, loss 0.146441, acc 0.953125\n",
      "2017-04-03T20:04:02.096223: step 12735, loss 0.224812, acc 0.890625\n",
      "2017-04-03T20:04:02.297014: step 12736, loss 0.27206, acc 0.90625\n",
      "2017-04-03T20:04:02.507356: step 12737, loss 0.132269, acc 0.953125\n",
      "2017-04-03T20:04:02.710755: step 12738, loss 0.171862, acc 0.921875\n",
      "2017-04-03T20:04:02.910733: step 12739, loss 0.38576, acc 0.890625\n",
      "2017-04-03T20:04:03.113599: step 12740, loss 0.0980621, acc 0.96875\n",
      "2017-04-03T20:04:03.316913: step 12741, loss 0.105174, acc 0.953125\n",
      "2017-04-03T20:04:03.517359: step 12742, loss 0.204663, acc 0.9375\n",
      "2017-04-03T20:04:03.715624: step 12743, loss 0.298822, acc 0.96875\n",
      "2017-04-03T20:04:03.917922: step 12744, loss 0.294539, acc 0.890625\n",
      "2017-04-03T20:04:04.118908: step 12745, loss 0.13736, acc 0.953125\n",
      "2017-04-03T20:04:04.323982: step 12746, loss 0.0811078, acc 1\n",
      "2017-04-03T20:04:04.525684: step 12747, loss 0.054269, acc 1\n",
      "2017-04-03T20:04:04.728281: step 12748, loss 0.188432, acc 0.953125\n",
      "2017-04-03T20:04:04.932235: step 12749, loss 0.096865, acc 1\n",
      "2017-04-03T20:04:05.178784: step 12750, loss 0.190887, acc 0.9375\n",
      "2017-04-03T20:04:05.380573: step 12751, loss 0.145428, acc 0.96875\n",
      "2017-04-03T20:04:05.583228: step 12752, loss 0.168562, acc 0.9375\n",
      "2017-04-03T20:04:05.785945: step 12753, loss 0.248119, acc 0.9375\n",
      "2017-04-03T20:04:05.989133: step 12754, loss 0.0790323, acc 0.96875\n",
      "2017-04-03T20:04:06.185913: step 12755, loss 0.178161, acc 0.9375\n",
      "2017-04-03T20:04:06.389521: step 12756, loss 0.165171, acc 0.921875\n",
      "2017-04-03T20:04:06.590478: step 12757, loss 0.13169, acc 0.96875\n",
      "2017-04-03T20:04:06.789336: step 12758, loss 0.342299, acc 0.921875\n",
      "2017-04-03T20:04:06.993783: step 12759, loss 0.247432, acc 0.9375\n",
      "2017-04-03T20:04:07.197222: step 12760, loss 0.159895, acc 0.9375\n",
      "2017-04-03T20:04:07.405224: step 12761, loss 0.0724008, acc 0.984375\n",
      "2017-04-03T20:04:07.607239: step 12762, loss 0.0895284, acc 0.96875\n",
      "2017-04-03T20:04:07.848162: step 12763, loss 0.108422, acc 0.953125\n",
      "2017-04-03T20:04:08.054208: step 12764, loss 0.130024, acc 0.953125\n",
      "2017-04-03T20:04:08.259714: step 12765, loss 0.177368, acc 0.953125\n",
      "2017-04-03T20:04:08.457481: step 12766, loss 0.274775, acc 0.875\n",
      "2017-04-03T20:04:08.701269: step 12767, loss 0.334823, acc 0.953125\n",
      "2017-04-03T20:04:08.907738: step 12768, loss 0.117985, acc 0.953125\n",
      "2017-04-03T20:04:09.110342: step 12769, loss 0.307324, acc 0.921875\n",
      "2017-04-03T20:04:09.313168: step 12770, loss 0.064506, acc 0.984375\n",
      "2017-04-03T20:04:09.527356: step 12771, loss 0.167847, acc 0.9375\n",
      "2017-04-03T20:04:09.769529: step 12772, loss 0.109215, acc 0.96875\n",
      "2017-04-03T20:04:09.972094: step 12773, loss 0.0720562, acc 0.984375\n",
      "2017-04-03T20:04:10.173316: step 12774, loss 0.203895, acc 0.953125\n",
      "2017-04-03T20:04:10.378398: step 12775, loss 0.113139, acc 0.96875\n",
      "2017-04-03T20:04:10.584953: step 12776, loss 0.0975457, acc 0.96875\n",
      "2017-04-03T20:04:10.788307: step 12777, loss 0.226938, acc 0.9375\n",
      "2017-04-03T20:04:10.999872: step 12778, loss 0.0738106, acc 0.96875\n",
      "2017-04-03T20:04:11.216183: step 12779, loss 0.106457, acc 0.953125\n",
      "2017-04-03T20:04:11.418647: step 12780, loss 0.189919, acc 0.90625\n",
      "2017-04-03T20:04:11.619581: step 12781, loss 0.168768, acc 0.953125\n",
      "2017-04-03T20:04:11.863062: step 12782, loss 0.144609, acc 0.953125\n",
      "2017-04-03T20:04:12.070527: step 12783, loss 0.156089, acc 0.96875\n",
      "2017-04-03T20:04:12.319893: step 12784, loss 0.32113, acc 0.875\n",
      "2017-04-03T20:04:12.527232: step 12785, loss 0.19605, acc 0.953125\n",
      "2017-04-03T20:04:12.725822: step 12786, loss 0.124798, acc 0.96875\n",
      "2017-04-03T20:04:12.933430: step 12787, loss 0.155196, acc 0.953125\n",
      "2017-04-03T20:04:13.140869: step 12788, loss 0.170492, acc 0.921875\n",
      "2017-04-03T20:04:13.389363: step 12789, loss 0.264903, acc 0.9375\n",
      "2017-04-03T20:04:13.643696: step 12790, loss 0.216348, acc 0.921875\n",
      "2017-04-03T20:04:13.845158: step 12791, loss 0.0637512, acc 0.984375\n",
      "2017-04-03T20:04:14.046704: step 12792, loss 0.184249, acc 0.921875\n",
      "2017-04-03T20:04:14.248498: step 12793, loss 0.0947799, acc 0.96875\n",
      "2017-04-03T20:04:14.451276: step 12794, loss 0.242765, acc 0.9375\n",
      "2017-04-03T20:04:14.653487: step 12795, loss 0.103655, acc 0.96875\n",
      "2017-04-03T20:04:14.857735: step 12796, loss 0.134284, acc 0.953125\n",
      "2017-04-03T20:04:15.077472: step 12797, loss 0.137803, acc 0.96875\n",
      "2017-04-03T20:04:15.288310: step 12798, loss 0.132083, acc 0.984375\n",
      "2017-04-03T20:04:15.493804: step 12799, loss 0.162779, acc 0.953125\n",
      "2017-04-03T20:04:15.734504: step 12800, loss 0.14425, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:04:17.836354: step 12800, loss 5.2306, acc 0.2905\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-12800\n",
      "\n",
      "2017-04-03T20:04:18.159693: step 12801, loss 0.184802, acc 0.9375\n",
      "2017-04-03T20:04:18.363262: step 12802, loss 0.254261, acc 0.890625\n",
      "2017-04-03T20:04:18.561988: step 12803, loss 0.154005, acc 0.921875\n",
      "2017-04-03T20:04:18.806731: step 12804, loss 0.18291, acc 0.96875\n",
      "2017-04-03T20:04:19.014322: step 12805, loss 0.185782, acc 0.9375\n",
      "2017-04-03T20:04:19.217063: step 12806, loss 0.261117, acc 0.90625\n",
      "2017-04-03T20:04:19.423530: step 12807, loss 0.189119, acc 0.953125\n",
      "2017-04-03T20:04:19.626054: step 12808, loss 0.163883, acc 0.953125\n",
      "2017-04-03T20:04:19.839366: step 12809, loss 0.0989318, acc 0.984375\n",
      "2017-04-03T20:04:20.041268: step 12810, loss 0.359844, acc 0.90625\n",
      "2017-04-03T20:04:20.243789: step 12811, loss 0.155155, acc 0.953125\n",
      "2017-04-03T20:04:20.449350: step 12812, loss 0.266079, acc 0.890625\n",
      "2017-04-03T20:04:20.694020: step 12813, loss 0.136009, acc 0.9375\n",
      "2017-04-03T20:04:20.895880: step 12814, loss 0.203124, acc 0.921875\n",
      "2017-04-03T20:04:21.113413: step 12815, loss 0.201249, acc 0.984375\n",
      "2017-04-03T20:04:21.317602: step 12816, loss 0.0917482, acc 0.984375\n",
      "2017-04-03T20:04:21.522079: step 12817, loss 0.294502, acc 0.9375\n",
      "2017-04-03T20:04:21.721787: step 12818, loss 0.230213, acc 0.9375\n",
      "2017-04-03T20:04:21.925899: step 12819, loss 0.170736, acc 0.953125\n",
      "2017-04-03T20:04:22.129751: step 12820, loss 0.133094, acc 0.9375\n",
      "2017-04-03T20:04:22.328261: step 12821, loss 0.284441, acc 0.890625\n",
      "2017-04-03T20:04:22.542988: step 12822, loss 0.0883287, acc 0.96875\n",
      "2017-04-03T20:04:22.789929: step 12823, loss 0.194456, acc 0.953125\n",
      "2017-04-03T20:04:23.004495: step 12824, loss 0.180298, acc 0.921875\n",
      "2017-04-03T20:04:23.212606: step 12825, loss 0.130585, acc 0.9375\n",
      "2017-04-03T20:04:23.429680: step 12826, loss 0.102583, acc 0.953125\n",
      "2017-04-03T20:04:23.636993: step 12827, loss 0.136537, acc 0.9375\n",
      "2017-04-03T20:04:23.840963: step 12828, loss 0.18022, acc 0.953125\n",
      "2017-04-03T20:04:24.038816: step 12829, loss 0.182211, acc 0.953125\n",
      "2017-04-03T20:04:24.243174: step 12830, loss 0.0900183, acc 0.984375\n",
      "2017-04-03T20:04:24.445884: step 12831, loss 0.301051, acc 0.90625\n",
      "2017-04-03T20:04:24.647190: step 12832, loss 0.0810427, acc 0.96875\n",
      "2017-04-03T20:04:24.847038: step 12833, loss 0.295526, acc 0.921875\n",
      "2017-04-03T20:04:25.050657: step 12834, loss 0.0851102, acc 0.984375\n",
      "2017-04-03T20:04:25.249226: step 12835, loss 0.192185, acc 0.96875\n",
      "2017-04-03T20:04:25.450842: step 12836, loss 0.239126, acc 0.921875\n",
      "2017-04-03T20:04:25.655443: step 12837, loss 0.143248, acc 0.984375\n",
      "2017-04-03T20:04:25.858144: step 12838, loss 0.169293, acc 0.953125\n",
      "2017-04-03T20:04:26.061674: step 12839, loss 0.294871, acc 0.921875\n",
      "2017-04-03T20:04:26.312124: step 12840, loss 0.141016, acc 0.953125\n",
      "2017-04-03T20:04:26.521909: step 12841, loss 0.261928, acc 0.90625\n",
      "2017-04-03T20:04:26.739887: step 12842, loss 0.0940674, acc 0.984375\n",
      "2017-04-03T20:04:26.948927: step 12843, loss 0.183685, acc 0.953125\n",
      "2017-04-03T20:04:27.160325: step 12844, loss 0.272646, acc 0.90625\n",
      "2017-04-03T20:04:27.367379: step 12845, loss 0.139654, acc 0.96875\n",
      "2017-04-03T20:04:27.570323: step 12846, loss 0.139574, acc 0.9375\n",
      "2017-04-03T20:04:27.775600: step 12847, loss 0.227186, acc 0.921875\n",
      "2017-04-03T20:04:27.978405: step 12848, loss 0.224023, acc 0.921875\n",
      "2017-04-03T20:04:28.182769: step 12849, loss 0.192737, acc 0.9375\n",
      "2017-04-03T20:04:28.386393: step 12850, loss 0.0996563, acc 0.96875\n",
      "2017-04-03T20:04:28.627293: step 12851, loss 0.113997, acc 0.953125\n",
      "2017-04-03T20:04:28.829094: step 12852, loss 0.183917, acc 0.921875\n",
      "2017-04-03T20:04:29.033297: step 12853, loss 0.12084, acc 0.96875\n",
      "2017-04-03T20:04:29.237175: step 12854, loss 0.163856, acc 0.9375\n",
      "2017-04-03T20:04:29.447846: step 12855, loss 0.202904, acc 0.9375\n",
      "2017-04-03T20:04:29.655101: step 12856, loss 0.216825, acc 0.90625\n",
      "2017-04-03T20:04:29.862079: step 12857, loss 0.0771856, acc 0.984375\n",
      "2017-04-03T20:04:30.065407: step 12858, loss 0.137312, acc 0.953125\n",
      "2017-04-03T20:04:30.277919: step 12859, loss 0.12214, acc 0.96875\n",
      "2017-04-03T20:04:30.491037: step 12860, loss 0.149382, acc 0.953125\n",
      "2017-04-03T20:04:30.705669: step 12861, loss 0.232943, acc 0.9375\n",
      "2017-04-03T20:04:30.909744: step 12862, loss 0.16826, acc 0.9375\n",
      "2017-04-03T20:04:31.112216: step 12863, loss 0.159552, acc 0.921875\n",
      "2017-04-03T20:04:31.339521: step 12864, loss 0.110117, acc 0.9375\n",
      "2017-04-03T20:04:31.543720: step 12865, loss 0.123369, acc 0.96875\n",
      "2017-04-03T20:04:31.746306: step 12866, loss 0.12393, acc 0.984375\n",
      "2017-04-03T20:04:31.962400: step 12867, loss 0.229865, acc 0.921875\n",
      "2017-04-03T20:04:32.181159: step 12868, loss 0.121441, acc 0.953125\n",
      "2017-04-03T20:04:32.401719: step 12869, loss 0.173507, acc 0.953125\n",
      "2017-04-03T20:04:32.613898: step 12870, loss 0.0852739, acc 0.96875\n",
      "2017-04-03T20:04:32.813360: step 12871, loss 0.166089, acc 0.953125\n",
      "2017-04-03T20:04:33.041486: step 12872, loss 0.3588, acc 0.859375\n",
      "2017-04-03T20:04:33.256155: step 12873, loss 0.181879, acc 0.953125\n",
      "2017-04-03T20:04:33.459128: step 12874, loss 0.132452, acc 0.953125\n",
      "2017-04-03T20:04:33.661592: step 12875, loss 0.201781, acc 0.921875\n",
      "2017-04-03T20:04:33.859547: step 12876, loss 0.359398, acc 0.921875\n",
      "2017-04-03T20:04:34.061195: step 12877, loss 0.137051, acc 0.953125\n",
      "2017-04-03T20:04:34.315462: step 12878, loss 0.205244, acc 0.921875\n",
      "2017-04-03T20:04:34.526879: step 12879, loss 0.157578, acc 0.90625\n",
      "2017-04-03T20:04:34.743335: step 12880, loss 0.212267, acc 0.9375\n",
      "2017-04-03T20:04:34.949739: step 12881, loss 0.151219, acc 0.96875\n",
      "2017-04-03T20:04:35.150348: step 12882, loss 0.330565, acc 0.90625\n",
      "2017-04-03T20:04:35.350166: step 12883, loss 0.13512, acc 0.953125\n",
      "2017-04-03T20:04:35.552417: step 12884, loss 0.138306, acc 0.9375\n",
      "2017-04-03T20:04:35.758995: step 12885, loss 0.218199, acc 0.9375\n",
      "2017-04-03T20:04:35.965346: step 12886, loss 0.1541, acc 0.921875\n",
      "2017-04-03T20:04:36.164604: step 12887, loss 0.128973, acc 0.9375\n",
      "2017-04-03T20:04:36.416384: step 12888, loss 0.230913, acc 0.9375\n",
      "2017-04-03T20:04:36.664608: step 12889, loss 0.270301, acc 0.9375\n",
      "2017-04-03T20:04:36.908070: step 12890, loss 0.0595929, acc 1\n",
      "2017-04-03T20:04:37.111370: step 12891, loss 0.113458, acc 0.96875\n",
      "2017-04-03T20:04:37.357332: step 12892, loss 0.197231, acc 0.921875\n",
      "2017-04-03T20:04:37.563017: step 12893, loss 0.224375, acc 0.921875\n",
      "2017-04-03T20:04:37.807235: step 12894, loss 0.219892, acc 0.90625\n",
      "2017-04-03T20:04:38.009470: step 12895, loss 0.198608, acc 0.921875\n",
      "2017-04-03T20:04:38.209111: step 12896, loss 0.111364, acc 0.953125\n",
      "2017-04-03T20:04:38.414798: step 12897, loss 0.163596, acc 0.9375\n",
      "2017-04-03T20:04:38.613796: step 12898, loss 0.266575, acc 0.953125\n",
      "2017-04-03T20:04:38.815221: step 12899, loss 0.153316, acc 0.9375\n",
      "2017-04-03T20:04:39.020752: step 12900, loss 0.186733, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:04:41.160792: step 12900, loss 5.269, acc 0.28975\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-12900\n",
      "\n",
      "2017-04-03T20:04:41.513696: step 12901, loss 0.23762, acc 0.921875\n",
      "2017-04-03T20:04:41.714489: step 12902, loss 0.147432, acc 0.9375\n",
      "2017-04-03T20:04:41.921184: step 12903, loss 0.208859, acc 0.9375\n",
      "2017-04-03T20:04:42.136991: step 12904, loss 0.287728, acc 0.90625\n",
      "2017-04-03T20:04:42.357182: step 12905, loss 0.101272, acc 0.96875\n",
      "2017-04-03T20:04:42.571867: step 12906, loss 0.171041, acc 0.9375\n",
      "2017-04-03T20:04:42.775468: step 12907, loss 0.187588, acc 0.921875\n",
      "2017-04-03T20:04:42.981189: step 12908, loss 0.182811, acc 0.953125\n",
      "2017-04-03T20:04:43.188687: step 12909, loss 0.344815, acc 0.9375\n",
      "2017-04-03T20:04:43.401142: step 12910, loss 0.215587, acc 0.953125\n",
      "2017-04-03T20:04:43.606741: step 12911, loss 0.129319, acc 0.96875\n",
      "2017-04-03T20:04:43.809166: step 12912, loss 0.285371, acc 0.9375\n",
      "2017-04-03T20:04:44.013762: step 12913, loss 0.425451, acc 0.9375\n",
      "2017-04-03T20:04:44.217051: step 12914, loss 0.280207, acc 0.890625\n",
      "2017-04-03T20:04:44.421829: step 12915, loss 0.12908, acc 0.953125\n",
      "2017-04-03T20:04:44.630209: step 12916, loss 0.247145, acc 0.921875\n",
      "2017-04-03T20:04:44.826183: step 12917, loss 0.216745, acc 0.9375\n",
      "2017-04-03T20:04:45.032789: step 12918, loss 0.156804, acc 0.921875\n",
      "2017-04-03T20:04:45.244166: step 12919, loss 0.167858, acc 0.9375\n",
      "2017-04-03T20:04:45.460781: step 12920, loss 0.0863568, acc 0.984375\n",
      "2017-04-03T20:04:45.713180: step 12921, loss 0.220202, acc 0.953125\n",
      "2017-04-03T20:04:45.927581: step 12922, loss 0.107273, acc 0.96875\n",
      "2017-04-03T20:04:46.174065: step 12923, loss 0.181839, acc 0.9375\n",
      "2017-04-03T20:04:46.373508: step 12924, loss 0.116983, acc 0.953125\n",
      "2017-04-03T20:04:46.622841: step 12925, loss 0.102293, acc 0.96875\n",
      "2017-04-03T20:04:46.827113: step 12926, loss 0.107952, acc 0.96875\n",
      "2017-04-03T20:04:47.030192: step 12927, loss 0.204068, acc 0.953125\n",
      "2017-04-03T20:04:47.236284: step 12928, loss 0.113918, acc 0.96875\n",
      "2017-04-03T20:04:47.482534: step 12929, loss 0.425798, acc 0.875\n",
      "2017-04-03T20:04:47.684533: step 12930, loss 0.127671, acc 0.984375\n",
      "2017-04-03T20:04:47.890005: step 12931, loss 0.180951, acc 0.9375\n",
      "2017-04-03T20:04:48.089780: step 12932, loss 0.226606, acc 0.953125\n",
      "2017-04-03T20:04:48.292415: step 12933, loss 0.24704, acc 0.890625\n",
      "2017-04-03T20:04:48.503287: step 12934, loss 0.325635, acc 0.90625\n",
      "2017-04-03T20:04:48.723235: step 12935, loss 0.252227, acc 0.90625\n",
      "2017-04-03T20:04:48.942955: step 12936, loss 0.0822285, acc 0.984375\n",
      "2017-04-03T20:04:49.161525: step 12937, loss 0.256004, acc 0.921875\n",
      "2017-04-03T20:04:49.378918: step 12938, loss 0.101666, acc 0.984375\n",
      "2017-04-03T20:04:49.587838: step 12939, loss 0.255927, acc 0.90625\n",
      "2017-04-03T20:04:49.790565: step 12940, loss 0.166852, acc 0.9375\n",
      "2017-04-03T20:04:49.991630: step 12941, loss 0.246908, acc 0.90625\n",
      "2017-04-03T20:04:50.195496: step 12942, loss 0.0495263, acc 1\n",
      "2017-04-03T20:04:50.448987: step 12943, loss 0.255192, acc 0.9375\n",
      "2017-04-03T20:04:50.652668: step 12944, loss 0.199805, acc 0.9375\n",
      "2017-04-03T20:04:50.850159: step 12945, loss 0.126202, acc 0.953125\n",
      "2017-04-03T20:04:51.058738: step 12946, loss 0.127898, acc 0.953125\n",
      "2017-04-03T20:04:51.262813: step 12947, loss 0.193015, acc 0.953125\n",
      "2017-04-03T20:04:51.468551: step 12948, loss 0.152946, acc 0.953125\n",
      "2017-04-03T20:04:51.616581: step 12949, loss 0.146619, acc 0.96875\n",
      "2017-04-03T20:04:51.821615: step 12950, loss 0.172205, acc 0.96875\n",
      "2017-04-03T20:04:52.023312: step 12951, loss 0.156581, acc 0.96875\n",
      "2017-04-03T20:04:52.234741: step 12952, loss 0.107296, acc 0.96875\n",
      "2017-04-03T20:04:52.451504: step 12953, loss 0.0990688, acc 0.984375\n",
      "2017-04-03T20:04:52.667207: step 12954, loss 0.0989627, acc 0.96875\n",
      "2017-04-03T20:04:52.869252: step 12955, loss 0.0958427, acc 0.96875\n",
      "2017-04-03T20:04:53.084152: step 12956, loss 0.150496, acc 0.96875\n",
      "2017-04-03T20:04:53.286117: step 12957, loss 0.0929092, acc 0.96875\n",
      "2017-04-03T20:04:53.530218: step 12958, loss 0.115104, acc 0.953125\n",
      "2017-04-03T20:04:53.736016: step 12959, loss 0.0785024, acc 0.984375\n",
      "2017-04-03T20:04:53.940387: step 12960, loss 0.182218, acc 0.953125\n",
      "2017-04-03T20:04:54.188273: step 12961, loss 0.15949, acc 0.953125\n",
      "2017-04-03T20:04:54.395408: step 12962, loss 0.128105, acc 0.9375\n",
      "2017-04-03T20:04:54.599073: step 12963, loss 0.0726774, acc 0.984375\n",
      "2017-04-03T20:04:54.840776: step 12964, loss 0.205293, acc 0.9375\n",
      "2017-04-03T20:04:55.061568: step 12965, loss 0.226095, acc 0.921875\n",
      "2017-04-03T20:04:55.271390: step 12966, loss 0.133177, acc 0.984375\n",
      "2017-04-03T20:04:55.479006: step 12967, loss 0.0807152, acc 0.984375\n",
      "2017-04-03T20:04:55.679302: step 12968, loss 0.0560224, acc 0.984375\n",
      "2017-04-03T20:04:55.881270: step 12969, loss 0.127561, acc 0.953125\n",
      "2017-04-03T20:04:56.082708: step 12970, loss 0.133397, acc 0.9375\n",
      "2017-04-03T20:04:56.285628: step 12971, loss 0.112842, acc 0.96875\n",
      "2017-04-03T20:04:56.489331: step 12972, loss 0.121032, acc 0.96875\n",
      "2017-04-03T20:04:56.690486: step 12973, loss 0.157014, acc 0.921875\n",
      "2017-04-03T20:04:56.929619: step 12974, loss 0.108747, acc 0.96875\n",
      "2017-04-03T20:04:57.135126: step 12975, loss 0.0785897, acc 0.984375\n",
      "2017-04-03T20:04:57.352990: step 12976, loss 0.0919841, acc 0.953125\n",
      "2017-04-03T20:04:57.563636: step 12977, loss 0.114067, acc 0.96875\n",
      "2017-04-03T20:04:57.774540: step 12978, loss 0.0750846, acc 1\n",
      "2017-04-03T20:04:57.980476: step 12979, loss 0.0730418, acc 0.984375\n",
      "2017-04-03T20:04:58.175628: step 12980, loss 0.184313, acc 0.953125\n",
      "2017-04-03T20:04:58.377611: step 12981, loss 0.0502157, acc 1\n",
      "2017-04-03T20:04:58.582812: step 12982, loss 0.118534, acc 0.96875\n",
      "2017-04-03T20:04:58.825031: step 12983, loss 0.183326, acc 0.9375\n",
      "2017-04-03T20:04:59.027291: step 12984, loss 0.206317, acc 0.9375\n",
      "2017-04-03T20:04:59.230923: step 12985, loss 0.206982, acc 0.9375\n",
      "2017-04-03T20:04:59.432547: step 12986, loss 0.0799395, acc 0.984375\n",
      "2017-04-03T20:04:59.637965: step 12987, loss 0.177183, acc 0.96875\n",
      "2017-04-03T20:04:59.887694: step 12988, loss 0.143011, acc 0.9375\n",
      "2017-04-03T20:05:00.091872: step 12989, loss 0.197848, acc 0.953125\n",
      "2017-04-03T20:05:00.296104: step 12990, loss 0.126962, acc 0.96875\n",
      "2017-04-03T20:05:00.497680: step 12991, loss 0.111381, acc 0.96875\n",
      "2017-04-03T20:05:00.701837: step 12992, loss 0.10752, acc 0.984375\n",
      "2017-04-03T20:05:00.923336: step 12993, loss 0.171792, acc 0.953125\n",
      "2017-04-03T20:05:01.139241: step 12994, loss 0.151596, acc 0.921875\n",
      "2017-04-03T20:05:01.340393: step 12995, loss 0.145286, acc 0.96875\n",
      "2017-04-03T20:05:01.541819: step 12996, loss 0.0476082, acc 1\n",
      "2017-04-03T20:05:01.743919: step 12997, loss 0.118046, acc 0.953125\n",
      "2017-04-03T20:05:01.948176: step 12998, loss 0.186739, acc 0.9375\n",
      "2017-04-03T20:05:02.150368: step 12999, loss 0.120409, acc 0.9375\n",
      "2017-04-03T20:05:02.351904: step 13000, loss 0.0357827, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:05:04.495109: step 13000, loss 5.36803, acc 0.29775\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-13000\n",
      "\n",
      "2017-04-03T20:05:04.835409: step 13001, loss 0.102178, acc 0.953125\n",
      "2017-04-03T20:05:05.039205: step 13002, loss 0.0954273, acc 0.9375\n",
      "2017-04-03T20:05:05.240812: step 13003, loss 0.0913001, acc 1\n",
      "2017-04-03T20:05:05.447808: step 13004, loss 0.11788, acc 0.953125\n",
      "2017-04-03T20:05:05.646071: step 13005, loss 0.085604, acc 0.984375\n",
      "2017-04-03T20:05:05.887572: step 13006, loss 0.283367, acc 0.875\n",
      "2017-04-03T20:05:06.101370: step 13007, loss 0.162722, acc 0.953125\n",
      "2017-04-03T20:05:06.311240: step 13008, loss 0.229581, acc 0.96875\n",
      "2017-04-03T20:05:06.512899: step 13009, loss 0.197036, acc 0.96875\n",
      "2017-04-03T20:05:06.719288: step 13010, loss 0.201486, acc 0.953125\n",
      "2017-04-03T20:05:06.920977: step 13011, loss 0.31696, acc 0.875\n",
      "2017-04-03T20:05:07.120931: step 13012, loss 0.120023, acc 0.96875\n",
      "2017-04-03T20:05:07.325833: step 13013, loss 0.0821333, acc 0.953125\n",
      "2017-04-03T20:05:07.531867: step 13014, loss 0.208581, acc 0.953125\n",
      "2017-04-03T20:05:07.733852: step 13015, loss 0.0807668, acc 0.984375\n",
      "2017-04-03T20:05:07.936814: step 13016, loss 0.069875, acc 0.984375\n",
      "2017-04-03T20:05:08.140374: step 13017, loss 0.208323, acc 0.90625\n",
      "2017-04-03T20:05:08.387659: step 13018, loss 0.182542, acc 0.953125\n",
      "2017-04-03T20:05:08.595573: step 13019, loss 0.120102, acc 0.953125\n",
      "2017-04-03T20:05:08.798902: step 13020, loss 0.12934, acc 0.953125\n",
      "2017-04-03T20:05:09.000214: step 13021, loss 0.34333, acc 0.90625\n",
      "2017-04-03T20:05:09.260674: step 13022, loss 0.255422, acc 0.9375\n",
      "2017-04-03T20:05:09.465984: step 13023, loss 0.108093, acc 0.96875\n",
      "2017-04-03T20:05:09.664153: step 13024, loss 0.272049, acc 0.90625\n",
      "2017-04-03T20:05:09.870827: step 13025, loss 0.0865757, acc 0.953125\n",
      "2017-04-03T20:05:10.076955: step 13026, loss 0.150635, acc 0.9375\n",
      "2017-04-03T20:05:10.324818: step 13027, loss 0.09074, acc 0.96875\n",
      "2017-04-03T20:05:10.530920: step 13028, loss 0.186778, acc 0.953125\n",
      "2017-04-03T20:05:10.732144: step 13029, loss 0.284978, acc 0.890625\n",
      "2017-04-03T20:05:10.960554: step 13030, loss 0.171517, acc 0.96875\n",
      "2017-04-03T20:05:11.186011: step 13031, loss 0.059048, acc 0.984375\n",
      "2017-04-03T20:05:11.382546: step 13032, loss 0.0556713, acc 1\n",
      "2017-04-03T20:05:11.586610: step 13033, loss 0.112611, acc 0.96875\n",
      "2017-04-03T20:05:11.788248: step 13034, loss 0.0620725, acc 0.984375\n",
      "2017-04-03T20:05:11.993371: step 13035, loss 0.0950225, acc 0.96875\n",
      "2017-04-03T20:05:12.244932: step 13036, loss 0.104695, acc 0.96875\n",
      "2017-04-03T20:05:12.447064: step 13037, loss 0.138332, acc 0.96875\n",
      "2017-04-03T20:05:12.647685: step 13038, loss 0.174535, acc 0.9375\n",
      "2017-04-03T20:05:12.854430: step 13039, loss 0.0770265, acc 0.96875\n",
      "2017-04-03T20:05:13.070991: step 13040, loss 0.0608698, acc 1\n",
      "2017-04-03T20:05:13.283473: step 13041, loss 0.0704192, acc 0.96875\n",
      "2017-04-03T20:05:13.499553: step 13042, loss 0.192248, acc 0.921875\n",
      "2017-04-03T20:05:13.704260: step 13043, loss 0.165045, acc 0.953125\n",
      "2017-04-03T20:05:13.909643: step 13044, loss 0.119131, acc 0.953125\n",
      "2017-04-03T20:05:14.112366: step 13045, loss 0.176197, acc 0.984375\n",
      "2017-04-03T20:05:14.317401: step 13046, loss 0.120857, acc 0.953125\n",
      "2017-04-03T20:05:14.517673: step 13047, loss 0.0926031, acc 0.96875\n",
      "2017-04-03T20:05:14.768188: step 13048, loss 0.230838, acc 0.9375\n",
      "2017-04-03T20:05:14.973153: step 13049, loss 0.125258, acc 0.921875\n",
      "2017-04-03T20:05:15.176480: step 13050, loss 0.114133, acc 0.96875\n",
      "2017-04-03T20:05:15.387832: step 13051, loss 0.19114, acc 0.953125\n",
      "2017-04-03T20:05:15.595805: step 13052, loss 0.184621, acc 0.9375\n",
      "2017-04-03T20:05:15.804084: step 13053, loss 0.134426, acc 0.953125\n",
      "2017-04-03T20:05:16.007813: step 13054, loss 0.153816, acc 0.953125\n",
      "2017-04-03T20:05:16.211394: step 13055, loss 0.106515, acc 0.953125\n",
      "2017-04-03T20:05:16.417118: step 13056, loss 0.106609, acc 0.953125\n",
      "2017-04-03T20:05:16.621042: step 13057, loss 0.10523, acc 0.96875\n",
      "2017-04-03T20:05:16.825450: step 13058, loss 0.128237, acc 0.953125\n",
      "2017-04-03T20:05:17.027140: step 13059, loss 0.0941312, acc 0.984375\n",
      "2017-04-03T20:05:17.229280: step 13060, loss 0.215541, acc 0.921875\n",
      "2017-04-03T20:05:17.434932: step 13061, loss 0.262082, acc 0.921875\n",
      "2017-04-03T20:05:17.637898: step 13062, loss 0.0716136, acc 0.984375\n",
      "2017-04-03T20:05:17.839688: step 13063, loss 0.232459, acc 0.890625\n",
      "2017-04-03T20:05:18.037539: step 13064, loss 0.0869019, acc 0.96875\n",
      "2017-04-03T20:05:18.235804: step 13065, loss 0.194496, acc 0.9375\n",
      "2017-04-03T20:05:18.434852: step 13066, loss 0.116046, acc 0.953125\n",
      "2017-04-03T20:05:18.644270: step 13067, loss 0.157901, acc 0.96875\n",
      "2017-04-03T20:05:18.845241: step 13068, loss 0.194717, acc 0.921875\n",
      "2017-04-03T20:05:19.051161: step 13069, loss 0.146271, acc 0.953125\n",
      "2017-04-03T20:05:19.251043: step 13070, loss 0.158634, acc 0.96875\n",
      "2017-04-03T20:05:19.450347: step 13071, loss 0.104558, acc 0.953125\n",
      "2017-04-03T20:05:19.650663: step 13072, loss 0.0577136, acc 1\n",
      "2017-04-03T20:05:19.851232: step 13073, loss 0.0975713, acc 0.96875\n",
      "2017-04-03T20:05:20.092412: step 13074, loss 0.229229, acc 0.90625\n",
      "2017-04-03T20:05:20.295202: step 13075, loss 0.139407, acc 0.96875\n",
      "2017-04-03T20:05:20.494793: step 13076, loss 0.0639992, acc 1\n",
      "2017-04-03T20:05:20.694605: step 13077, loss 0.0851021, acc 0.984375\n",
      "2017-04-03T20:05:20.903663: step 13078, loss 0.372983, acc 0.875\n",
      "2017-04-03T20:05:21.105837: step 13079, loss 0.107787, acc 0.96875\n",
      "2017-04-03T20:05:21.308026: step 13080, loss 0.135424, acc 0.96875\n",
      "2017-04-03T20:05:21.510369: step 13081, loss 0.137458, acc 0.953125\n",
      "2017-04-03T20:05:21.708300: step 13082, loss 0.118077, acc 0.953125\n",
      "2017-04-03T20:05:21.910716: step 13083, loss 0.206071, acc 0.9375\n",
      "2017-04-03T20:05:22.117520: step 13084, loss 0.142806, acc 0.953125\n",
      "2017-04-03T20:05:22.323383: step 13085, loss 0.0722289, acc 1\n",
      "2017-04-03T20:05:22.533569: step 13086, loss 0.169205, acc 0.96875\n",
      "2017-04-03T20:05:22.741043: step 13087, loss 0.153278, acc 0.9375\n",
      "2017-04-03T20:05:22.948274: step 13088, loss 0.134378, acc 0.9375\n",
      "2017-04-03T20:05:23.149453: step 13089, loss 0.121008, acc 0.953125\n",
      "2017-04-03T20:05:23.346816: step 13090, loss 0.123543, acc 0.953125\n",
      "2017-04-03T20:05:23.554622: step 13091, loss 0.191532, acc 0.921875\n",
      "2017-04-03T20:05:23.755253: step 13092, loss 0.15027, acc 0.96875\n",
      "2017-04-03T20:05:23.960498: step 13093, loss 0.133939, acc 0.9375\n",
      "2017-04-03T20:05:24.166442: step 13094, loss 0.173357, acc 0.96875\n",
      "2017-04-03T20:05:24.369967: step 13095, loss 0.308763, acc 0.953125\n",
      "2017-04-03T20:05:24.576718: step 13096, loss 0.14215, acc 0.953125\n",
      "2017-04-03T20:05:24.779053: step 13097, loss 0.123967, acc 0.953125\n",
      "2017-04-03T20:05:24.979040: step 13098, loss 0.261499, acc 0.890625\n",
      "2017-04-03T20:05:25.176758: step 13099, loss 0.122309, acc 0.9375\n",
      "2017-04-03T20:05:25.372784: step 13100, loss 0.189388, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:05:27.441229: step 13100, loss 5.4219, acc 0.2945\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-13100\n",
      "\n",
      "2017-04-03T20:05:27.769589: step 13101, loss 0.183445, acc 0.953125\n",
      "2017-04-03T20:05:28.020117: step 13102, loss 0.0383377, acc 1\n",
      "2017-04-03T20:05:28.218284: step 13103, loss 0.118235, acc 0.9375\n",
      "2017-04-03T20:05:28.410211: step 13104, loss 0.191693, acc 0.921875\n",
      "2017-04-03T20:05:28.611556: step 13105, loss 0.063977, acc 0.984375\n",
      "2017-04-03T20:05:28.857419: step 13106, loss 0.206594, acc 0.921875\n",
      "2017-04-03T20:05:29.064106: step 13107, loss 0.185003, acc 0.953125\n",
      "2017-04-03T20:05:29.264376: step 13108, loss 0.216939, acc 0.90625\n",
      "2017-04-03T20:05:29.475760: step 13109, loss 0.15194, acc 0.96875\n",
      "2017-04-03T20:05:29.678210: step 13110, loss 0.149837, acc 0.96875\n",
      "2017-04-03T20:05:29.878385: step 13111, loss 0.163217, acc 0.96875\n",
      "2017-04-03T20:05:30.085541: step 13112, loss 0.144658, acc 0.96875\n",
      "2017-04-03T20:05:30.294620: step 13113, loss 0.203455, acc 0.9375\n",
      "2017-04-03T20:05:30.498802: step 13114, loss 0.191382, acc 0.90625\n",
      "2017-04-03T20:05:30.750164: step 13115, loss 0.177999, acc 0.953125\n",
      "2017-04-03T20:05:30.950019: step 13116, loss 0.229354, acc 0.9375\n",
      "2017-04-03T20:05:31.168477: step 13117, loss 0.0705212, acc 0.984375\n",
      "2017-04-03T20:05:31.374890: step 13118, loss 0.0890338, acc 0.96875\n",
      "2017-04-03T20:05:31.576984: step 13119, loss 0.117141, acc 0.96875\n",
      "2017-04-03T20:05:31.775216: step 13120, loss 0.0709374, acc 0.96875\n",
      "2017-04-03T20:05:31.976483: step 13121, loss 0.0781757, acc 0.984375\n",
      "2017-04-03T20:05:32.179730: step 13122, loss 0.0716349, acc 1\n",
      "2017-04-03T20:05:32.386218: step 13123, loss 0.119611, acc 0.9375\n",
      "2017-04-03T20:05:32.589018: step 13124, loss 0.148561, acc 0.9375\n",
      "2017-04-03T20:05:32.788919: step 13125, loss 0.0543537, acc 1\n",
      "2017-04-03T20:05:32.985052: step 13126, loss 0.176532, acc 0.96875\n",
      "2017-04-03T20:05:33.194287: step 13127, loss 0.145204, acc 0.9375\n",
      "2017-04-03T20:05:33.403434: step 13128, loss 0.144104, acc 0.96875\n",
      "2017-04-03T20:05:33.611959: step 13129, loss 0.192102, acc 0.921875\n",
      "2017-04-03T20:05:33.821523: step 13130, loss 0.0896871, acc 0.96875\n",
      "2017-04-03T20:05:34.021682: step 13131, loss 0.119751, acc 0.96875\n",
      "2017-04-03T20:05:34.214583: step 13132, loss 0.0804582, acc 0.96875\n",
      "2017-04-03T20:05:34.457103: step 13133, loss 0.133477, acc 0.9375\n",
      "2017-04-03T20:05:34.665312: step 13134, loss 0.110261, acc 0.953125\n",
      "2017-04-03T20:05:34.863298: step 13135, loss 0.252497, acc 0.9375\n",
      "2017-04-03T20:05:35.100543: step 13136, loss 0.149527, acc 0.984375\n",
      "2017-04-03T20:05:35.347340: step 13137, loss 0.206384, acc 0.9375\n",
      "2017-04-03T20:05:35.548205: step 13138, loss 0.0404132, acc 1\n",
      "2017-04-03T20:05:35.749386: step 13139, loss 0.0874233, acc 0.96875\n",
      "2017-04-03T20:05:35.996572: step 13140, loss 0.126771, acc 0.96875\n",
      "2017-04-03T20:05:36.209090: step 13141, loss 0.138676, acc 0.953125\n",
      "2017-04-03T20:05:36.411868: step 13142, loss 0.138041, acc 0.953125\n",
      "2017-04-03T20:05:36.615773: step 13143, loss 0.0967488, acc 0.96875\n",
      "2017-04-03T20:05:36.819150: step 13144, loss 0.0871796, acc 0.96875\n",
      "2017-04-03T20:05:37.018448: step 13145, loss 0.0992614, acc 0.984375\n",
      "2017-04-03T20:05:37.221482: step 13146, loss 0.208168, acc 0.953125\n",
      "2017-04-03T20:05:37.421199: step 13147, loss 0.101685, acc 0.984375\n",
      "2017-04-03T20:05:37.631055: step 13148, loss 0.40866, acc 0.84375\n",
      "2017-04-03T20:05:37.831663: step 13149, loss 0.159339, acc 0.96875\n",
      "2017-04-03T20:05:38.028481: step 13150, loss 0.228535, acc 0.9375\n",
      "2017-04-03T20:05:38.231619: step 13151, loss 0.0781175, acc 0.96875\n",
      "2017-04-03T20:05:38.439839: step 13152, loss 0.137132, acc 0.96875\n",
      "2017-04-03T20:05:38.644347: step 13153, loss 0.196829, acc 0.953125\n",
      "2017-04-03T20:05:38.845391: step 13154, loss 0.157216, acc 0.953125\n",
      "2017-04-03T20:05:39.051072: step 13155, loss 0.225048, acc 0.96875\n",
      "2017-04-03T20:05:39.257111: step 13156, loss 0.106676, acc 0.953125\n",
      "2017-04-03T20:05:39.476722: step 13157, loss 0.111041, acc 0.96875\n",
      "2017-04-03T20:05:39.677947: step 13158, loss 0.15017, acc 0.953125\n",
      "2017-04-03T20:05:39.879024: step 13159, loss 0.158003, acc 0.96875\n",
      "2017-04-03T20:05:40.080352: step 13160, loss 0.0931826, acc 0.96875\n",
      "2017-04-03T20:05:40.287495: step 13161, loss 0.070401, acc 0.984375\n",
      "2017-04-03T20:05:40.503617: step 13162, loss 0.0838411, acc 0.984375\n",
      "2017-04-03T20:05:40.703416: step 13163, loss 0.16588, acc 0.953125\n",
      "2017-04-03T20:05:40.902139: step 13164, loss 0.174273, acc 0.953125\n",
      "2017-04-03T20:05:41.136919: step 13165, loss 0.0917412, acc 1\n",
      "2017-04-03T20:05:41.338968: step 13166, loss 0.0812577, acc 0.96875\n",
      "2017-04-03T20:05:41.586516: step 13167, loss 0.065237, acc 0.984375\n",
      "2017-04-03T20:05:41.795783: step 13168, loss 0.186667, acc 0.953125\n",
      "2017-04-03T20:05:42.013506: step 13169, loss 0.101641, acc 0.96875\n",
      "2017-04-03T20:05:42.261137: step 13170, loss 0.17, acc 0.921875\n",
      "2017-04-03T20:05:42.463452: step 13171, loss 0.148089, acc 0.984375\n",
      "2017-04-03T20:05:42.705690: step 13172, loss 0.206676, acc 0.953125\n",
      "2017-04-03T20:05:42.920695: step 13173, loss 0.0515879, acc 1\n",
      "2017-04-03T20:05:43.125399: step 13174, loss 0.0527581, acc 1\n",
      "2017-04-03T20:05:43.337519: step 13175, loss 0.206775, acc 0.953125\n",
      "2017-04-03T20:05:43.552806: step 13176, loss 0.0891093, acc 0.984375\n",
      "2017-04-03T20:05:43.753933: step 13177, loss 0.113071, acc 0.953125\n",
      "2017-04-03T20:05:43.958765: step 13178, loss 0.178999, acc 0.921875\n",
      "2017-04-03T20:05:44.162711: step 13179, loss 0.1456, acc 0.96875\n",
      "2017-04-03T20:05:44.374920: step 13180, loss 0.162205, acc 0.921875\n",
      "2017-04-03T20:05:44.590947: step 13181, loss 0.18779, acc 0.9375\n",
      "2017-04-03T20:05:44.808069: step 13182, loss 0.208906, acc 0.9375\n",
      "2017-04-03T20:05:45.024121: step 13183, loss 0.192588, acc 0.984375\n",
      "2017-04-03T20:05:45.228371: step 13184, loss 0.139858, acc 0.984375\n",
      "2017-04-03T20:05:45.427009: step 13185, loss 0.120312, acc 0.96875\n",
      "2017-04-03T20:05:45.631025: step 13186, loss 0.233022, acc 0.921875\n",
      "2017-04-03T20:05:45.876872: step 13187, loss 0.288541, acc 0.9375\n",
      "2017-04-03T20:05:46.076551: step 13188, loss 0.146482, acc 0.9375\n",
      "2017-04-03T20:05:46.277613: step 13189, loss 0.245744, acc 0.890625\n",
      "2017-04-03T20:05:46.481426: step 13190, loss 0.0848633, acc 0.984375\n",
      "2017-04-03T20:05:46.687811: step 13191, loss 0.205854, acc 0.953125\n",
      "2017-04-03T20:05:46.886794: step 13192, loss 0.140501, acc 0.96875\n",
      "2017-04-03T20:05:47.084535: step 13193, loss 0.229721, acc 0.9375\n",
      "2017-04-03T20:05:47.282412: step 13194, loss 0.181423, acc 0.921875\n",
      "2017-04-03T20:05:47.481760: step 13195, loss 0.241208, acc 0.921875\n",
      "2017-04-03T20:05:47.684956: step 13196, loss 0.130393, acc 0.953125\n",
      "2017-04-03T20:05:47.929613: step 13197, loss 0.193959, acc 0.921875\n",
      "2017-04-03T20:05:48.134633: step 13198, loss 0.166822, acc 0.9375\n",
      "2017-04-03T20:05:48.334016: step 13199, loss 0.165592, acc 0.96875\n",
      "2017-04-03T20:05:48.534176: step 13200, loss 0.212663, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:05:50.569684: step 13200, loss 5.49864, acc 0.292\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-13200\n",
      "\n",
      "2017-04-03T20:05:50.897847: step 13201, loss 0.172888, acc 0.9375\n",
      "2017-04-03T20:05:51.105797: step 13202, loss 0.116397, acc 0.953125\n",
      "2017-04-03T20:05:51.303554: step 13203, loss 0.212695, acc 0.90625\n",
      "2017-04-03T20:05:51.505289: step 13204, loss 0.290835, acc 0.890625\n",
      "2017-04-03T20:05:51.708307: step 13205, loss 0.146999, acc 0.96875\n",
      "2017-04-03T20:05:51.909454: step 13206, loss 0.263988, acc 0.90625\n",
      "2017-04-03T20:05:52.112379: step 13207, loss 0.156547, acc 0.96875\n",
      "2017-04-03T20:05:52.321434: step 13208, loss 0.235836, acc 0.890625\n",
      "2017-04-03T20:05:52.519335: step 13209, loss 0.22455, acc 0.921875\n",
      "2017-04-03T20:05:52.723805: step 13210, loss 0.136593, acc 0.953125\n",
      "2017-04-03T20:05:52.921304: step 13211, loss 0.0814753, acc 0.96875\n",
      "2017-04-03T20:05:53.121208: step 13212, loss 0.0808998, acc 1\n",
      "2017-04-03T20:05:53.318129: step 13213, loss 0.0876404, acc 0.984375\n",
      "2017-04-03T20:05:53.521137: step 13214, loss 0.168499, acc 0.9375\n",
      "2017-04-03T20:05:53.723645: step 13215, loss 0.166352, acc 0.953125\n",
      "2017-04-03T20:05:53.927818: step 13216, loss 0.0907038, acc 0.96875\n",
      "2017-04-03T20:05:54.135685: step 13217, loss 0.100366, acc 0.953125\n",
      "2017-04-03T20:05:54.339820: step 13218, loss 0.320647, acc 0.9375\n",
      "2017-04-03T20:05:54.546946: step 13219, loss 0.208211, acc 0.9375\n",
      "2017-04-03T20:05:54.745639: step 13220, loss 0.0781668, acc 0.96875\n",
      "2017-04-03T20:05:54.952012: step 13221, loss 0.187739, acc 0.953125\n",
      "2017-04-03T20:05:55.151035: step 13222, loss 0.0627093, acc 1\n",
      "2017-04-03T20:05:55.354342: step 13223, loss 0.154339, acc 0.96875\n",
      "2017-04-03T20:05:55.566772: step 13224, loss 0.200352, acc 0.921875\n",
      "2017-04-03T20:05:55.768038: step 13225, loss 0.200548, acc 0.921875\n",
      "2017-04-03T20:05:55.976107: step 13226, loss 0.120327, acc 0.96875\n",
      "2017-04-03T20:05:56.218249: step 13227, loss 0.268518, acc 0.875\n",
      "2017-04-03T20:05:56.422994: step 13228, loss 0.103588, acc 0.953125\n",
      "2017-04-03T20:05:56.625404: step 13229, loss 0.180227, acc 0.921875\n",
      "2017-04-03T20:05:56.835702: step 13230, loss 0.145943, acc 0.953125\n",
      "2017-04-03T20:05:57.085848: step 13231, loss 0.263093, acc 0.890625\n",
      "2017-04-03T20:05:57.296689: step 13232, loss 0.287903, acc 0.90625\n",
      "2017-04-03T20:05:57.496773: step 13233, loss 0.123556, acc 0.953125\n",
      "2017-04-03T20:05:57.703766: step 13234, loss 0.1322, acc 0.921875\n",
      "2017-04-03T20:05:57.905227: step 13235, loss 0.092011, acc 0.984375\n",
      "2017-04-03T20:05:58.105638: step 13236, loss 0.170156, acc 0.9375\n",
      "2017-04-03T20:05:58.351389: step 13237, loss 0.289896, acc 0.921875\n",
      "2017-04-03T20:05:58.554704: step 13238, loss 0.142791, acc 0.9375\n",
      "2017-04-03T20:05:58.761272: step 13239, loss 0.12153, acc 0.96875\n",
      "2017-04-03T20:05:58.974197: step 13240, loss 0.142711, acc 0.9375\n",
      "2017-04-03T20:05:59.186163: step 13241, loss 0.218433, acc 0.890625\n",
      "2017-04-03T20:05:59.409042: step 13242, loss 0.10975, acc 0.96875\n",
      "2017-04-03T20:05:59.614954: step 13243, loss 0.115688, acc 0.96875\n",
      "2017-04-03T20:05:59.809518: step 13244, loss 0.125746, acc 0.984375\n",
      "2017-04-03T20:06:00.009743: step 13245, loss 0.132647, acc 0.953125\n",
      "2017-04-03T20:06:00.210840: step 13246, loss 0.204043, acc 0.921875\n",
      "2017-04-03T20:06:00.407116: step 13247, loss 0.124839, acc 0.984375\n",
      "2017-04-03T20:06:00.613137: step 13248, loss 0.0969166, acc 0.984375\n",
      "2017-04-03T20:06:00.824716: step 13249, loss 0.122987, acc 0.953125\n",
      "2017-04-03T20:06:01.023577: step 13250, loss 0.167282, acc 0.9375\n",
      "2017-04-03T20:06:01.232914: step 13251, loss 0.167299, acc 0.921875\n",
      "2017-04-03T20:06:01.433007: step 13252, loss 0.104691, acc 0.984375\n",
      "2017-04-03T20:06:01.641665: step 13253, loss 0.345309, acc 0.9375\n",
      "2017-04-03T20:06:01.841068: step 13254, loss 0.0906623, acc 0.953125\n",
      "2017-04-03T20:06:02.048631: step 13255, loss 0.134762, acc 0.96875\n",
      "2017-04-03T20:06:02.258082: step 13256, loss 0.179314, acc 0.953125\n",
      "2017-04-03T20:06:02.457053: step 13257, loss 0.282321, acc 0.90625\n",
      "2017-04-03T20:06:02.673000: step 13258, loss 0.130012, acc 0.9375\n",
      "2017-04-03T20:06:02.873402: step 13259, loss 0.158857, acc 0.953125\n",
      "2017-04-03T20:06:03.078235: step 13260, loss 0.0618339, acc 0.984375\n",
      "2017-04-03T20:06:03.283914: step 13261, loss 0.150501, acc 0.953125\n",
      "2017-04-03T20:06:03.484861: step 13262, loss 0.420328, acc 0.921875\n",
      "2017-04-03T20:06:03.685860: step 13263, loss 0.157196, acc 0.953125\n",
      "2017-04-03T20:06:03.885651: step 13264, loss 0.16042, acc 0.953125\n",
      "2017-04-03T20:06:04.120061: step 13265, loss 0.202364, acc 0.921875\n",
      "2017-04-03T20:06:04.338406: step 13266, loss 0.0958202, acc 0.984375\n",
      "2017-04-03T20:06:04.541778: step 13267, loss 0.162215, acc 0.90625\n",
      "2017-04-03T20:06:04.740428: step 13268, loss 0.091697, acc 0.96875\n",
      "2017-04-03T20:06:04.939081: step 13269, loss 0.127467, acc 0.953125\n",
      "2017-04-03T20:06:05.139114: step 13270, loss 0.187475, acc 0.953125\n",
      "2017-04-03T20:06:05.381172: step 13271, loss 0.256289, acc 0.90625\n",
      "2017-04-03T20:06:05.586984: step 13272, loss 0.0976274, acc 0.96875\n",
      "2017-04-03T20:06:05.781006: step 13273, loss 0.15805, acc 0.9375\n",
      "2017-04-03T20:06:06.025017: step 13274, loss 0.249565, acc 0.90625\n",
      "2017-04-03T20:06:06.232316: step 13275, loss 0.124215, acc 0.96875\n",
      "2017-04-03T20:06:06.476048: step 13276, loss 0.180357, acc 0.921875\n",
      "2017-04-03T20:06:06.678874: step 13277, loss 0.0927811, acc 0.96875\n",
      "2017-04-03T20:06:06.879494: step 13278, loss 0.116257, acc 0.96875\n",
      "2017-04-03T20:06:07.079536: step 13279, loss 0.131215, acc 0.9375\n",
      "2017-04-03T20:06:07.286513: step 13280, loss 0.316961, acc 0.921875\n",
      "2017-04-03T20:06:07.485087: step 13281, loss 0.13382, acc 0.96875\n",
      "2017-04-03T20:06:07.693537: step 13282, loss 0.0264483, acc 1\n",
      "2017-04-03T20:06:07.898800: step 13283, loss 0.293903, acc 0.90625\n",
      "2017-04-03T20:06:08.097460: step 13284, loss 0.19455, acc 0.9375\n",
      "2017-04-03T20:06:08.299420: step 13285, loss 0.166785, acc 0.953125\n",
      "2017-04-03T20:06:08.498813: step 13286, loss 0.0727859, acc 0.984375\n",
      "2017-04-03T20:06:08.699435: step 13287, loss 0.0973173, acc 0.984375\n",
      "2017-04-03T20:06:08.909451: step 13288, loss 0.0846245, acc 1\n",
      "2017-04-03T20:06:09.117379: step 13289, loss 0.186696, acc 0.9375\n",
      "2017-04-03T20:06:09.317509: step 13290, loss 0.322699, acc 0.890625\n",
      "2017-04-03T20:06:09.521559: step 13291, loss 0.135054, acc 0.96875\n",
      "2017-04-03T20:06:09.724564: step 13292, loss 0.277897, acc 0.9375\n",
      "2017-04-03T20:06:09.923958: step 13293, loss 0.100719, acc 0.984375\n",
      "2017-04-03T20:06:10.127418: step 13294, loss 0.274236, acc 0.9375\n",
      "2017-04-03T20:06:10.328161: step 13295, loss 0.141817, acc 0.953125\n",
      "2017-04-03T20:06:10.529920: step 13296, loss 0.183075, acc 0.96875\n",
      "2017-04-03T20:06:10.733579: step 13297, loss 0.141368, acc 0.96875\n",
      "2017-04-03T20:06:10.940516: step 13298, loss 0.181388, acc 0.953125\n",
      "2017-04-03T20:06:11.138545: step 13299, loss 0.173668, acc 0.953125\n",
      "2017-04-03T20:06:11.382021: step 13300, loss 0.154104, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:06:13.522672: step 13300, loss 5.4475, acc 0.2895\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-13300\n",
      "\n",
      "2017-04-03T20:06:13.858501: step 13301, loss 0.166016, acc 0.9375\n",
      "2017-04-03T20:06:14.098018: step 13302, loss 0.184018, acc 0.921875\n",
      "2017-04-03T20:06:14.312532: step 13303, loss 0.619214, acc 0.890625\n",
      "2017-04-03T20:06:14.511475: step 13304, loss 0.14775, acc 0.9375\n",
      "2017-04-03T20:06:14.713301: step 13305, loss 0.0486752, acc 0.984375\n",
      "2017-04-03T20:06:14.933029: step 13306, loss 0.253756, acc 0.953125\n",
      "2017-04-03T20:06:15.134446: step 13307, loss 0.156157, acc 0.921875\n",
      "2017-04-03T20:06:15.331979: step 13308, loss 0.12923, acc 0.953125\n",
      "2017-04-03T20:06:15.537098: step 13309, loss 0.0916064, acc 1\n",
      "2017-04-03T20:06:15.739702: step 13310, loss 0.286971, acc 0.953125\n",
      "2017-04-03T20:06:15.943425: step 13311, loss 0.119405, acc 0.984375\n",
      "2017-04-03T20:06:16.149248: step 13312, loss 0.0788415, acc 0.984375\n",
      "2017-04-03T20:06:16.355754: step 13313, loss 0.101682, acc 0.96875\n",
      "2017-04-03T20:06:16.558796: step 13314, loss 0.217492, acc 0.9375\n",
      "2017-04-03T20:06:16.767671: step 13315, loss 0.140103, acc 0.9375\n",
      "2017-04-03T20:06:16.971062: step 13316, loss 0.11368, acc 0.953125\n",
      "2017-04-03T20:06:17.172464: step 13317, loss 0.181582, acc 0.96875\n",
      "2017-04-03T20:06:17.373984: step 13318, loss 0.152111, acc 0.953125\n",
      "2017-04-03T20:06:17.573964: step 13319, loss 0.158531, acc 0.953125\n",
      "2017-04-03T20:06:17.776084: step 13320, loss 0.0621126, acc 0.984375\n",
      "2017-04-03T20:06:17.977406: step 13321, loss 0.0741369, acc 0.984375\n",
      "2017-04-03T20:06:18.175650: step 13322, loss 0.134515, acc 0.9375\n",
      "2017-04-03T20:06:18.420797: step 13323, loss 0.126572, acc 0.953125\n",
      "2017-04-03T20:06:18.621029: step 13324, loss 0.182666, acc 0.953125\n",
      "2017-04-03T20:06:18.819343: step 13325, loss 0.151517, acc 0.984375\n",
      "2017-04-03T20:06:19.020388: step 13326, loss 0.136853, acc 0.9375\n",
      "2017-04-03T20:06:19.222913: step 13327, loss 0.209753, acc 0.90625\n",
      "2017-04-03T20:06:19.436970: step 13328, loss 0.256416, acc 0.921875\n",
      "2017-04-03T20:06:19.640803: step 13329, loss 0.184722, acc 0.953125\n",
      "2017-04-03T20:06:19.840872: step 13330, loss 0.0699779, acc 0.984375\n",
      "2017-04-03T20:06:20.045798: step 13331, loss 0.107262, acc 0.984375\n",
      "2017-04-03T20:06:20.240306: step 13332, loss 0.13796, acc 0.921875\n",
      "2017-04-03T20:06:20.444568: step 13333, loss 0.277941, acc 0.84375\n",
      "2017-04-03T20:06:20.641893: step 13334, loss 0.383534, acc 0.921875\n",
      "2017-04-03T20:06:20.865681: step 13335, loss 0.0896238, acc 0.953125\n",
      "2017-04-03T20:06:21.074329: step 13336, loss 0.226618, acc 0.9375\n",
      "2017-04-03T20:06:21.276081: step 13337, loss 0.0476902, acc 1\n",
      "2017-04-03T20:06:21.483381: step 13338, loss 0.149683, acc 0.96875\n",
      "2017-04-03T20:06:21.685811: step 13339, loss 0.112887, acc 0.96875\n",
      "2017-04-03T20:06:21.885368: step 13340, loss 0.211532, acc 0.921875\n",
      "2017-04-03T20:06:22.086976: step 13341, loss 0.140082, acc 0.953125\n",
      "2017-04-03T20:06:22.289770: step 13342, loss 0.186675, acc 0.96875\n",
      "2017-04-03T20:06:22.487932: step 13343, loss 0.178611, acc 0.953125\n",
      "2017-04-03T20:06:22.687753: step 13344, loss 0.129026, acc 0.953125\n",
      "2017-04-03T20:06:22.890441: step 13345, loss 0.125316, acc 0.9375\n",
      "2017-04-03T20:06:23.139550: step 13346, loss 0.313057, acc 0.90625\n",
      "2017-04-03T20:06:23.338391: step 13347, loss 0.142295, acc 0.9375\n",
      "2017-04-03T20:06:23.552348: step 13348, loss 0.29474, acc 0.9375\n",
      "2017-04-03T20:06:23.750139: step 13349, loss 0.103171, acc 0.96875\n",
      "2017-04-03T20:06:24.005373: step 13350, loss 0.265557, acc 0.90625\n",
      "2017-04-03T20:06:24.212406: step 13351, loss 0.32055, acc 0.921875\n",
      "2017-04-03T20:06:24.416522: step 13352, loss 0.279549, acc 0.953125\n",
      "2017-04-03T20:06:24.658326: step 13353, loss 0.247592, acc 0.921875\n",
      "2017-04-03T20:06:24.867159: step 13354, loss 0.194835, acc 0.96875\n",
      "2017-04-03T20:06:25.066750: step 13355, loss 0.25077, acc 0.9375\n",
      "2017-04-03T20:06:25.270311: step 13356, loss 0.143313, acc 0.9375\n",
      "2017-04-03T20:06:25.475800: step 13357, loss 0.0800949, acc 0.984375\n",
      "2017-04-03T20:06:25.683013: step 13358, loss 0.215625, acc 0.890625\n",
      "2017-04-03T20:06:25.928792: step 13359, loss 0.0921323, acc 0.96875\n",
      "2017-04-03T20:06:26.133173: step 13360, loss 0.188261, acc 0.953125\n",
      "2017-04-03T20:06:26.334651: step 13361, loss 0.269449, acc 0.890625\n",
      "2017-04-03T20:06:26.534786: step 13362, loss 0.119566, acc 0.96875\n",
      "2017-04-03T20:06:26.738672: step 13363, loss 0.327081, acc 0.875\n",
      "2017-04-03T20:06:26.988292: step 13364, loss 0.045086, acc 1\n",
      "2017-04-03T20:06:27.189508: step 13365, loss 0.275589, acc 0.921875\n",
      "2017-04-03T20:06:27.391983: step 13366, loss 0.087271, acc 0.96875\n",
      "2017-04-03T20:06:27.596987: step 13367, loss 0.11349, acc 0.96875\n",
      "2017-04-03T20:06:27.796012: step 13368, loss 0.105581, acc 0.96875\n",
      "2017-04-03T20:06:28.005849: step 13369, loss 0.288156, acc 0.921875\n",
      "2017-04-03T20:06:28.205922: step 13370, loss 0.145903, acc 0.953125\n",
      "2017-04-03T20:06:28.408976: step 13371, loss 0.165233, acc 0.953125\n",
      "2017-04-03T20:06:28.658628: step 13372, loss 0.0891859, acc 0.984375\n",
      "2017-04-03T20:06:28.859627: step 13373, loss 0.0869448, acc 0.984375\n",
      "2017-04-03T20:06:29.061474: step 13374, loss 0.0967691, acc 0.984375\n",
      "2017-04-03T20:06:29.264024: step 13375, loss 0.135047, acc 0.9375\n",
      "2017-04-03T20:06:29.473105: step 13376, loss 0.250232, acc 0.921875\n",
      "2017-04-03T20:06:29.672337: step 13377, loss 0.103872, acc 0.96875\n",
      "2017-04-03T20:06:29.879868: step 13378, loss 0.133398, acc 0.953125\n",
      "2017-04-03T20:06:30.129958: step 13379, loss 0.240732, acc 0.953125\n",
      "2017-04-03T20:06:30.328180: step 13380, loss 0.120165, acc 0.96875\n",
      "2017-04-03T20:06:30.532387: step 13381, loss 0.18398, acc 0.9375\n",
      "2017-04-03T20:06:30.734941: step 13382, loss 0.153581, acc 0.953125\n",
      "2017-04-03T20:06:30.937819: step 13383, loss 0.382159, acc 0.953125\n",
      "2017-04-03T20:06:31.136971: step 13384, loss 0.132724, acc 0.953125\n",
      "2017-04-03T20:06:31.336549: step 13385, loss 0.189212, acc 0.953125\n",
      "2017-04-03T20:06:31.541122: step 13386, loss 0.196081, acc 0.9375\n",
      "2017-04-03T20:06:31.743341: step 13387, loss 0.282581, acc 0.921875\n",
      "2017-04-03T20:06:31.950780: step 13388, loss 0.231902, acc 0.90625\n",
      "2017-04-03T20:06:32.159107: step 13389, loss 0.151755, acc 0.9375\n",
      "2017-04-03T20:06:32.359123: step 13390, loss 0.0819782, acc 0.984375\n",
      "2017-04-03T20:06:32.570720: step 13391, loss 0.155842, acc 0.953125\n",
      "2017-04-03T20:06:32.769142: step 13392, loss 0.0918767, acc 0.96875\n",
      "2017-04-03T20:06:32.974011: step 13393, loss 0.168312, acc 0.9375\n",
      "2017-04-03T20:06:33.176621: step 13394, loss 0.153878, acc 0.921875\n",
      "2017-04-03T20:06:33.379862: step 13395, loss 0.146275, acc 0.96875\n",
      "2017-04-03T20:06:33.623719: step 13396, loss 0.191652, acc 0.953125\n",
      "2017-04-03T20:06:33.830995: step 13397, loss 0.0765533, acc 0.96875\n",
      "2017-04-03T20:06:34.075132: step 13398, loss 0.141915, acc 0.96875\n",
      "2017-04-03T20:06:34.277868: step 13399, loss 0.214164, acc 0.921875\n",
      "2017-04-03T20:06:34.491045: step 13400, loss 0.256494, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:06:36.592365: step 13400, loss 5.53139, acc 0.295\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-13400\n",
      "\n",
      "2017-04-03T20:06:36.928541: step 13401, loss 0.365928, acc 0.9375\n",
      "2017-04-03T20:06:37.126689: step 13402, loss 0.194913, acc 0.953125\n",
      "2017-04-03T20:06:37.331872: step 13403, loss 0.289893, acc 0.875\n",
      "2017-04-03T20:06:37.535079: step 13404, loss 0.134403, acc 0.953125\n",
      "2017-04-03T20:06:37.733681: step 13405, loss 0.088614, acc 0.984375\n",
      "2017-04-03T20:06:37.947331: step 13406, loss 0.156582, acc 0.9375\n",
      "2017-04-03T20:06:38.152004: step 13407, loss 0.0408126, acc 1\n",
      "2017-04-03T20:06:38.395491: step 13408, loss 0.215686, acc 0.9375\n",
      "2017-04-03T20:06:38.593275: step 13409, loss 0.0858057, acc 0.984375\n",
      "2017-04-03T20:06:38.839360: step 13410, loss 0.181428, acc 0.953125\n",
      "2017-04-03T20:06:39.091276: step 13411, loss 0.423859, acc 0.875\n",
      "2017-04-03T20:06:39.297798: step 13412, loss 0.233846, acc 0.90625\n",
      "2017-04-03T20:06:39.502266: step 13413, loss 0.211476, acc 0.9375\n",
      "2017-04-03T20:06:39.713504: step 13414, loss 0.151973, acc 0.9375\n",
      "2017-04-03T20:06:39.929805: step 13415, loss 0.203331, acc 0.90625\n",
      "2017-04-03T20:06:40.142773: step 13416, loss 0.144281, acc 0.9375\n",
      "2017-04-03T20:06:40.345322: step 13417, loss 0.104698, acc 0.96875\n",
      "2017-04-03T20:06:40.566836: step 13418, loss 0.160869, acc 0.953125\n",
      "2017-04-03T20:06:40.785664: step 13419, loss 0.157214, acc 0.9375\n",
      "2017-04-03T20:06:41.004818: step 13420, loss 0.318355, acc 0.9375\n",
      "2017-04-03T20:06:41.210696: step 13421, loss 0.224569, acc 0.9375\n",
      "2017-04-03T20:06:41.412177: step 13422, loss 0.181428, acc 0.953125\n",
      "2017-04-03T20:06:41.652489: step 13423, loss 0.144353, acc 0.96875\n",
      "2017-04-03T20:06:41.861283: step 13424, loss 0.105857, acc 0.96875\n",
      "2017-04-03T20:06:42.073836: step 13425, loss 0.102838, acc 0.984375\n",
      "2017-04-03T20:06:42.280743: step 13426, loss 0.203277, acc 0.90625\n",
      "2017-04-03T20:06:42.524878: step 13427, loss 0.0874893, acc 0.96875\n",
      "2017-04-03T20:06:42.734108: step 13428, loss 0.156752, acc 0.953125\n",
      "2017-04-03T20:06:42.938194: step 13429, loss 0.272705, acc 0.875\n",
      "2017-04-03T20:06:43.142038: step 13430, loss 0.0962384, acc 0.984375\n",
      "2017-04-03T20:06:43.388222: step 13431, loss 0.115611, acc 0.984375\n",
      "2017-04-03T20:06:43.591354: step 13432, loss 0.18835, acc 0.9375\n",
      "2017-04-03T20:06:43.791414: step 13433, loss 0.0638102, acc 0.984375\n",
      "2017-04-03T20:06:43.990081: step 13434, loss 0.187396, acc 0.953125\n",
      "2017-04-03T20:06:44.200755: step 13435, loss 0.074283, acc 0.984375\n",
      "2017-04-03T20:06:44.399300: step 13436, loss 0.117731, acc 0.96875\n",
      "2017-04-03T20:06:44.599955: step 13437, loss 0.0970282, acc 0.984375\n",
      "2017-04-03T20:06:44.802538: step 13438, loss 0.179818, acc 0.9375\n",
      "2017-04-03T20:06:45.011724: step 13439, loss 0.152033, acc 0.9375\n",
      "2017-04-03T20:06:45.211153: step 13440, loss 0.217068, acc 0.90625\n",
      "2017-04-03T20:06:45.439270: step 13441, loss 0.116029, acc 0.953125\n",
      "2017-04-03T20:06:45.654881: step 13442, loss 0.201244, acc 0.921875\n",
      "2017-04-03T20:06:45.858813: step 13443, loss 0.197998, acc 0.9375\n",
      "2017-04-03T20:06:46.055389: step 13444, loss 0.120386, acc 0.953125\n",
      "2017-04-03T20:06:46.262068: step 13445, loss 0.194157, acc 0.9375\n",
      "2017-04-03T20:06:46.468678: step 13446, loss 0.130256, acc 0.953125\n",
      "2017-04-03T20:06:46.671002: step 13447, loss 0.158166, acc 0.953125\n",
      "2017-04-03T20:06:46.924626: step 13448, loss 0.243887, acc 0.90625\n",
      "2017-04-03T20:06:47.123044: step 13449, loss 0.184678, acc 0.921875\n",
      "2017-04-03T20:06:47.325032: step 13450, loss 0.193572, acc 0.921875\n",
      "2017-04-03T20:06:47.534440: step 13451, loss 0.27269, acc 0.90625\n",
      "2017-04-03T20:06:47.737358: step 13452, loss 0.202323, acc 0.9375\n",
      "2017-04-03T20:06:47.943481: step 13453, loss 0.375504, acc 0.890625\n",
      "2017-04-03T20:06:48.147455: step 13454, loss 0.26847, acc 0.9375\n",
      "2017-04-03T20:06:48.352320: step 13455, loss 0.184219, acc 0.921875\n",
      "2017-04-03T20:06:48.553351: step 13456, loss 0.135819, acc 0.984375\n",
      "2017-04-03T20:06:48.756237: step 13457, loss 0.125673, acc 0.9375\n",
      "2017-04-03T20:06:48.965123: step 13458, loss 0.16881, acc 0.9375\n",
      "2017-04-03T20:06:49.168839: step 13459, loss 0.0976578, acc 0.984375\n",
      "2017-04-03T20:06:49.385766: step 13460, loss 0.169616, acc 0.90625\n",
      "2017-04-03T20:06:49.585826: step 13461, loss 0.498532, acc 0.953125\n",
      "2017-04-03T20:06:49.790363: step 13462, loss 0.446547, acc 0.84375\n",
      "2017-04-03T20:06:49.992150: step 13463, loss 0.130997, acc 0.9375\n",
      "2017-04-03T20:06:50.197397: step 13464, loss 0.135276, acc 0.953125\n",
      "2017-04-03T20:06:50.396527: step 13465, loss 0.211478, acc 0.9375\n",
      "2017-04-03T20:06:50.601142: step 13466, loss 0.142261, acc 0.96875\n",
      "2017-04-03T20:06:50.808555: step 13467, loss 0.246841, acc 0.921875\n",
      "2017-04-03T20:06:51.014797: step 13468, loss 0.160829, acc 0.921875\n",
      "2017-04-03T20:06:51.216312: step 13469, loss 0.33855, acc 0.890625\n",
      "2017-04-03T20:06:51.421710: step 13470, loss 0.221333, acc 0.921875\n",
      "2017-04-03T20:06:51.624573: step 13471, loss 0.179815, acc 0.9375\n",
      "2017-04-03T20:06:51.826506: step 13472, loss 0.132574, acc 0.953125\n",
      "2017-04-03T20:06:52.075713: step 13473, loss 0.119006, acc 0.953125\n",
      "2017-04-03T20:06:52.320036: step 13474, loss 0.121467, acc 0.953125\n",
      "2017-04-03T20:06:52.533550: step 13475, loss 0.174609, acc 0.921875\n",
      "2017-04-03T20:06:52.736385: step 13476, loss 0.0741984, acc 0.984375\n",
      "2017-04-03T20:06:52.943262: step 13477, loss 0.415337, acc 0.90625\n",
      "2017-04-03T20:06:53.143728: step 13478, loss 0.273439, acc 0.90625\n",
      "2017-04-03T20:06:53.347547: step 13479, loss 0.0934314, acc 0.96875\n",
      "2017-04-03T20:06:53.549584: step 13480, loss 0.138811, acc 0.9375\n",
      "2017-04-03T20:06:53.753125: step 13481, loss 0.201846, acc 0.96875\n",
      "2017-04-03T20:06:53.955020: step 13482, loss 0.180518, acc 0.953125\n",
      "2017-04-03T20:06:54.167252: step 13483, loss 0.229959, acc 0.890625\n",
      "2017-04-03T20:06:54.374426: step 13484, loss 0.148531, acc 0.9375\n",
      "2017-04-03T20:06:54.573503: step 13485, loss 0.240187, acc 0.890625\n",
      "2017-04-03T20:06:54.826439: step 13486, loss 0.203265, acc 0.9375\n",
      "2017-04-03T20:06:55.044179: step 13487, loss 0.425617, acc 0.84375\n",
      "2017-04-03T20:06:55.247441: step 13488, loss 0.0843906, acc 0.984375\n",
      "2017-04-03T20:06:55.446504: step 13489, loss 0.251146, acc 0.921875\n",
      "2017-04-03T20:06:55.652965: step 13490, loss 0.0809803, acc 0.96875\n",
      "2017-04-03T20:06:55.852349: step 13491, loss 0.0969709, acc 0.984375\n",
      "2017-04-03T20:06:56.055988: step 13492, loss 0.282903, acc 0.921875\n",
      "2017-04-03T20:06:56.260039: step 13493, loss 0.197492, acc 0.921875\n",
      "2017-04-03T20:06:56.462453: step 13494, loss 0.0986671, acc 0.96875\n",
      "2017-04-03T20:06:56.665842: step 13495, loss 0.176099, acc 0.921875\n",
      "2017-04-03T20:06:56.875339: step 13496, loss 0.0936697, acc 0.984375\n",
      "2017-04-03T20:06:57.081895: step 13497, loss 0.163142, acc 0.921875\n",
      "2017-04-03T20:06:57.283646: step 13498, loss 0.161246, acc 0.921875\n",
      "2017-04-03T20:06:57.490416: step 13499, loss 0.184734, acc 0.953125\n",
      "2017-04-03T20:06:57.696418: step 13500, loss 0.130026, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:06:59.803332: step 13500, loss 5.49079, acc 0.29\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-13500\n",
      "\n",
      "2017-04-03T20:07:00.148550: step 13501, loss 0.16804, acc 0.9375\n",
      "2017-04-03T20:07:00.391891: step 13502, loss 0.209839, acc 0.953125\n",
      "2017-04-03T20:07:00.608871: step 13503, loss 0.191344, acc 0.9375\n",
      "2017-04-03T20:07:00.818651: step 13504, loss 0.0999799, acc 0.96875\n",
      "2017-04-03T20:07:01.022548: step 13505, loss 0.18101, acc 0.9375\n",
      "2017-04-03T20:07:01.241579: step 13506, loss 0.252028, acc 0.921875\n",
      "2017-04-03T20:07:01.460078: step 13507, loss 0.300191, acc 0.9375\n",
      "2017-04-03T20:07:01.664849: step 13508, loss 0.222033, acc 0.921875\n",
      "2017-04-03T20:07:01.867576: step 13509, loss 0.106278, acc 0.96875\n",
      "2017-04-03T20:07:02.079836: step 13510, loss 0.0478517, acc 1\n",
      "2017-04-03T20:07:02.280400: step 13511, loss 0.0979045, acc 0.984375\n",
      "2017-04-03T20:07:02.427180: step 13512, loss 0.465475, acc 0.9375\n",
      "2017-04-03T20:07:02.631657: step 13513, loss 0.0637263, acc 0.984375\n",
      "2017-04-03T20:07:02.833565: step 13514, loss 0.239248, acc 0.90625\n",
      "2017-04-03T20:07:03.043356: step 13515, loss 0.0435276, acc 1\n",
      "2017-04-03T20:07:03.249507: step 13516, loss 0.165542, acc 0.953125\n",
      "2017-04-03T20:07:03.456452: step 13517, loss 0.125767, acc 0.9375\n",
      "2017-04-03T20:07:03.701847: step 13518, loss 0.0525024, acc 1\n",
      "2017-04-03T20:07:03.904203: step 13519, loss 0.103249, acc 0.953125\n",
      "2017-04-03T20:07:04.117547: step 13520, loss 0.100067, acc 0.96875\n",
      "2017-04-03T20:07:04.327067: step 13521, loss 0.108625, acc 0.984375\n",
      "2017-04-03T20:07:04.539612: step 13522, loss 0.195208, acc 0.9375\n",
      "2017-04-03T20:07:04.745472: step 13523, loss 0.122345, acc 0.953125\n",
      "2017-04-03T20:07:04.968581: step 13524, loss 0.241098, acc 0.90625\n",
      "2017-04-03T20:07:05.185242: step 13525, loss 0.0553032, acc 0.96875\n",
      "2017-04-03T20:07:05.387771: step 13526, loss 0.171845, acc 0.921875\n",
      "2017-04-03T20:07:05.606060: step 13527, loss 0.168826, acc 0.953125\n",
      "2017-04-03T20:07:05.817705: step 13528, loss 0.205615, acc 0.953125\n",
      "2017-04-03T20:07:06.020249: step 13529, loss 0.0761305, acc 0.984375\n",
      "2017-04-03T20:07:06.236885: step 13530, loss 0.122998, acc 0.96875\n",
      "2017-04-03T20:07:06.456059: step 13531, loss 0.152479, acc 0.953125\n",
      "2017-04-03T20:07:06.672958: step 13532, loss 0.180674, acc 0.9375\n",
      "2017-04-03T20:07:06.879286: step 13533, loss 0.164939, acc 0.9375\n",
      "2017-04-03T20:07:07.094781: step 13534, loss 0.124285, acc 0.96875\n",
      "2017-04-03T20:07:07.312868: step 13535, loss 0.0747238, acc 0.984375\n",
      "2017-04-03T20:07:07.524272: step 13536, loss 0.0844569, acc 0.96875\n",
      "2017-04-03T20:07:07.735753: step 13537, loss 0.339561, acc 0.921875\n",
      "2017-04-03T20:07:07.955776: step 13538, loss 0.154343, acc 0.953125\n",
      "2017-04-03T20:07:08.176795: step 13539, loss 0.118545, acc 0.96875\n",
      "2017-04-03T20:07:08.388867: step 13540, loss 0.219964, acc 0.953125\n",
      "2017-04-03T20:07:08.593614: step 13541, loss 0.0669888, acc 0.96875\n",
      "2017-04-03T20:07:08.800510: step 13542, loss 0.152802, acc 0.9375\n",
      "2017-04-03T20:07:09.015170: step 13543, loss 0.198619, acc 0.953125\n",
      "2017-04-03T20:07:09.223579: step 13544, loss 0.39563, acc 0.859375\n",
      "2017-04-03T20:07:09.477748: step 13545, loss 0.141738, acc 0.96875\n",
      "2017-04-03T20:07:09.679537: step 13546, loss 0.23253, acc 0.921875\n",
      "2017-04-03T20:07:09.878341: step 13547, loss 0.12146, acc 0.953125\n",
      "2017-04-03T20:07:10.077473: step 13548, loss 0.244502, acc 0.90625\n",
      "2017-04-03T20:07:10.329552: step 13549, loss 0.0716039, acc 0.984375\n",
      "2017-04-03T20:07:10.534646: step 13550, loss 0.0950896, acc 0.984375\n",
      "2017-04-03T20:07:10.736216: step 13551, loss 0.117055, acc 0.96875\n",
      "2017-04-03T20:07:10.940885: step 13552, loss 0.113559, acc 0.953125\n",
      "2017-04-03T20:07:11.150693: step 13553, loss 0.107696, acc 0.96875\n",
      "2017-04-03T20:07:11.368685: step 13554, loss 0.116233, acc 0.984375\n",
      "2017-04-03T20:07:11.568694: step 13555, loss 0.0575663, acc 0.984375\n",
      "2017-04-03T20:07:11.776513: step 13556, loss 0.169812, acc 0.9375\n",
      "2017-04-03T20:07:11.987482: step 13557, loss 0.293256, acc 0.90625\n",
      "2017-04-03T20:07:12.187949: step 13558, loss 0.0739234, acc 0.984375\n",
      "2017-04-03T20:07:12.388860: step 13559, loss 0.100929, acc 0.984375\n",
      "2017-04-03T20:07:12.589631: step 13560, loss 0.113637, acc 0.921875\n",
      "2017-04-03T20:07:12.792417: step 13561, loss 0.15715, acc 0.9375\n",
      "2017-04-03T20:07:12.998352: step 13562, loss 0.193359, acc 0.9375\n",
      "2017-04-03T20:07:13.202027: step 13563, loss 0.126062, acc 0.96875\n",
      "2017-04-03T20:07:13.404553: step 13564, loss 0.188674, acc 0.9375\n",
      "2017-04-03T20:07:13.608525: step 13565, loss 0.0585105, acc 0.984375\n",
      "2017-04-03T20:07:13.804206: step 13566, loss 0.255955, acc 0.90625\n",
      "2017-04-03T20:07:14.003803: step 13567, loss 0.183725, acc 0.953125\n",
      "2017-04-03T20:07:14.205523: step 13568, loss 0.0976676, acc 0.96875\n",
      "2017-04-03T20:07:14.406047: step 13569, loss 0.145913, acc 0.96875\n",
      "2017-04-03T20:07:14.608054: step 13570, loss 0.102894, acc 0.953125\n",
      "2017-04-03T20:07:14.811117: step 13571, loss 0.152361, acc 0.953125\n",
      "2017-04-03T20:07:15.015748: step 13572, loss 0.101044, acc 0.96875\n",
      "2017-04-03T20:07:15.217895: step 13573, loss 0.118941, acc 0.96875\n",
      "2017-04-03T20:07:15.425379: step 13574, loss 0.179124, acc 0.90625\n",
      "2017-04-03T20:07:15.635125: step 13575, loss 0.120805, acc 0.953125\n",
      "2017-04-03T20:07:15.836553: step 13576, loss 0.254556, acc 0.953125\n",
      "2017-04-03T20:07:16.047778: step 13577, loss 0.215159, acc 0.921875\n",
      "2017-04-03T20:07:16.260220: step 13578, loss 0.111539, acc 0.984375\n",
      "2017-04-03T20:07:16.503435: step 13579, loss 0.112912, acc 0.96875\n",
      "2017-04-03T20:07:16.743684: step 13580, loss 0.140046, acc 0.9375\n",
      "2017-04-03T20:07:16.959095: step 13581, loss 0.516623, acc 0.90625\n",
      "2017-04-03T20:07:17.169065: step 13582, loss 0.139072, acc 0.984375\n",
      "2017-04-03T20:07:17.371466: step 13583, loss 0.16436, acc 0.90625\n",
      "2017-04-03T20:07:17.574801: step 13584, loss 0.075784, acc 0.96875\n",
      "2017-04-03T20:07:17.789896: step 13585, loss 0.260239, acc 0.921875\n",
      "2017-04-03T20:07:17.999279: step 13586, loss 0.151788, acc 0.953125\n",
      "2017-04-03T20:07:18.200274: step 13587, loss 0.182205, acc 0.96875\n",
      "2017-04-03T20:07:18.445878: step 13588, loss 0.185514, acc 0.921875\n",
      "2017-04-03T20:07:18.647268: step 13589, loss 0.191355, acc 0.953125\n",
      "2017-04-03T20:07:18.850710: step 13590, loss 0.11298, acc 0.984375\n",
      "2017-04-03T20:07:19.055485: step 13591, loss 0.173929, acc 0.921875\n",
      "2017-04-03T20:07:19.260188: step 13592, loss 0.0861656, acc 0.953125\n",
      "2017-04-03T20:07:19.462431: step 13593, loss 0.133854, acc 0.96875\n",
      "2017-04-03T20:07:19.675224: step 13594, loss 0.219236, acc 0.921875\n",
      "2017-04-03T20:07:19.891196: step 13595, loss 0.083115, acc 0.984375\n",
      "2017-04-03T20:07:20.094799: step 13596, loss 0.110415, acc 0.96875\n",
      "2017-04-03T20:07:20.342212: step 13597, loss 0.155824, acc 0.96875\n",
      "2017-04-03T20:07:20.542583: step 13598, loss 0.0649484, acc 1\n",
      "2017-04-03T20:07:20.746632: step 13599, loss 0.139478, acc 0.953125\n",
      "2017-04-03T20:07:20.949015: step 13600, loss 0.0734522, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:07:23.088371: step 13600, loss 5.55522, acc 0.2985\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-13600\n",
      "\n",
      "2017-04-03T20:07:23.460523: step 13601, loss 0.163032, acc 0.96875\n",
      "2017-04-03T20:07:23.661327: step 13602, loss 0.162971, acc 0.9375\n",
      "2017-04-03T20:07:23.860760: step 13603, loss 0.140396, acc 0.984375\n",
      "2017-04-03T20:07:24.061166: step 13604, loss 0.176757, acc 0.9375\n",
      "2017-04-03T20:07:24.264308: step 13605, loss 0.0360295, acc 1\n",
      "2017-04-03T20:07:24.486284: step 13606, loss 0.247666, acc 0.921875\n",
      "2017-04-03T20:07:24.714710: step 13607, loss 0.0895444, acc 0.96875\n",
      "2017-04-03T20:07:24.921445: step 13608, loss 0.127793, acc 0.953125\n",
      "2017-04-03T20:07:25.125798: step 13609, loss 0.187294, acc 0.921875\n",
      "2017-04-03T20:07:25.377420: step 13610, loss 0.570493, acc 0.875\n",
      "2017-04-03T20:07:25.582197: step 13611, loss 0.113328, acc 0.953125\n",
      "2017-04-03T20:07:25.785783: step 13612, loss 0.106043, acc 0.96875\n",
      "2017-04-03T20:07:25.988783: step 13613, loss 0.244545, acc 0.953125\n",
      "2017-04-03T20:07:26.193571: step 13614, loss 0.14422, acc 0.953125\n",
      "2017-04-03T20:07:26.396624: step 13615, loss 0.166094, acc 0.953125\n",
      "2017-04-03T20:07:26.598748: step 13616, loss 0.243874, acc 0.9375\n",
      "2017-04-03T20:07:26.804025: step 13617, loss 0.0937592, acc 0.953125\n",
      "2017-04-03T20:07:27.054836: step 13618, loss 0.0440683, acc 0.984375\n",
      "2017-04-03T20:07:27.262566: step 13619, loss 0.179851, acc 0.984375\n",
      "2017-04-03T20:07:27.471136: step 13620, loss 0.1236, acc 0.9375\n",
      "2017-04-03T20:07:27.670967: step 13621, loss 0.23883, acc 0.953125\n",
      "2017-04-03T20:07:27.870506: step 13622, loss 0.160609, acc 0.96875\n",
      "2017-04-03T20:07:28.064612: step 13623, loss 0.154895, acc 0.96875\n",
      "2017-04-03T20:07:28.268479: step 13624, loss 0.119749, acc 0.9375\n",
      "2017-04-03T20:07:28.474203: step 13625, loss 0.0934903, acc 0.953125\n",
      "2017-04-03T20:07:28.690597: step 13626, loss 0.105854, acc 0.9375\n",
      "2017-04-03T20:07:28.909096: step 13627, loss 0.149747, acc 0.953125\n",
      "2017-04-03T20:07:29.118414: step 13628, loss 0.16654, acc 0.9375\n",
      "2017-04-03T20:07:29.319214: step 13629, loss 0.0462268, acc 0.984375\n",
      "2017-04-03T20:07:29.518989: step 13630, loss 0.157769, acc 0.953125\n",
      "2017-04-03T20:07:29.725758: step 13631, loss 0.0438476, acc 1\n",
      "2017-04-03T20:07:29.927916: step 13632, loss 0.251164, acc 0.9375\n",
      "2017-04-03T20:07:30.126942: step 13633, loss 0.0582866, acc 0.984375\n",
      "2017-04-03T20:07:30.329684: step 13634, loss 0.144082, acc 0.96875\n",
      "2017-04-03T20:07:30.573655: step 13635, loss 0.0765899, acc 0.9375\n",
      "2017-04-03T20:07:30.776638: step 13636, loss 0.194271, acc 0.96875\n",
      "2017-04-03T20:07:30.989525: step 13637, loss 0.149832, acc 0.96875\n",
      "2017-04-03T20:07:31.199918: step 13638, loss 0.117368, acc 0.9375\n",
      "2017-04-03T20:07:31.399876: step 13639, loss 0.0438814, acc 1\n",
      "2017-04-03T20:07:31.601043: step 13640, loss 0.139401, acc 0.96875\n",
      "2017-04-03T20:07:31.803303: step 13641, loss 0.132353, acc 0.953125\n",
      "2017-04-03T20:07:32.003718: step 13642, loss 0.160136, acc 0.953125\n",
      "2017-04-03T20:07:32.202622: step 13643, loss 0.076644, acc 0.984375\n",
      "2017-04-03T20:07:32.403341: step 13644, loss 0.135624, acc 0.9375\n",
      "2017-04-03T20:07:32.608449: step 13645, loss 0.092775, acc 0.984375\n",
      "2017-04-03T20:07:32.859544: step 13646, loss 0.268848, acc 0.921875\n",
      "2017-04-03T20:07:33.066125: step 13647, loss 0.101212, acc 0.953125\n",
      "2017-04-03T20:07:33.266357: step 13648, loss 0.277673, acc 0.890625\n",
      "2017-04-03T20:07:33.470607: step 13649, loss 0.067431, acc 0.984375\n",
      "2017-04-03T20:07:33.669713: step 13650, loss 0.0930055, acc 0.96875\n",
      "2017-04-03T20:07:33.913173: step 13651, loss 0.102646, acc 0.96875\n",
      "2017-04-03T20:07:34.111576: step 13652, loss 0.268568, acc 0.921875\n",
      "2017-04-03T20:07:34.317884: step 13653, loss 0.0652439, acc 1\n",
      "2017-04-03T20:07:34.519652: step 13654, loss 0.108183, acc 0.953125\n",
      "2017-04-03T20:07:34.747160: step 13655, loss 0.0790117, acc 0.953125\n",
      "2017-04-03T20:07:34.946646: step 13656, loss 0.0524526, acc 0.984375\n",
      "2017-04-03T20:07:35.148154: step 13657, loss 0.102036, acc 0.96875\n",
      "2017-04-03T20:07:35.350737: step 13658, loss 0.191698, acc 0.96875\n",
      "2017-04-03T20:07:35.549844: step 13659, loss 0.111721, acc 0.96875\n",
      "2017-04-03T20:07:35.756944: step 13660, loss 0.0210605, acc 1\n",
      "2017-04-03T20:07:35.999293: step 13661, loss 0.123685, acc 0.953125\n",
      "2017-04-03T20:07:36.200166: step 13662, loss 0.053979, acc 0.984375\n",
      "2017-04-03T20:07:36.401530: step 13663, loss 0.102559, acc 0.984375\n",
      "2017-04-03T20:07:36.603143: step 13664, loss 0.12889, acc 0.96875\n",
      "2017-04-03T20:07:36.803608: step 13665, loss 0.273108, acc 0.9375\n",
      "2017-04-03T20:07:37.009938: step 13666, loss 0.0597059, acc 1\n",
      "2017-04-03T20:07:37.212437: step 13667, loss 0.0929955, acc 0.984375\n",
      "2017-04-03T20:07:37.407554: step 13668, loss 0.080834, acc 0.984375\n",
      "2017-04-03T20:07:37.610282: step 13669, loss 0.12343, acc 0.96875\n",
      "2017-04-03T20:07:37.814207: step 13670, loss 0.177308, acc 0.9375\n",
      "2017-04-03T20:07:38.016462: step 13671, loss 0.136912, acc 0.96875\n",
      "2017-04-03T20:07:38.219865: step 13672, loss 0.200584, acc 0.921875\n",
      "2017-04-03T20:07:38.419564: step 13673, loss 0.118699, acc 0.953125\n",
      "2017-04-03T20:07:38.624335: step 13674, loss 0.189323, acc 0.9375\n",
      "2017-04-03T20:07:38.824082: step 13675, loss 0.110589, acc 0.953125\n",
      "2017-04-03T20:07:39.025831: step 13676, loss 0.128361, acc 0.953125\n",
      "2017-04-03T20:07:39.227546: step 13677, loss 0.156387, acc 0.921875\n",
      "2017-04-03T20:07:39.475834: step 13678, loss 0.0529726, acc 1\n",
      "2017-04-03T20:07:39.682121: step 13679, loss 0.0938444, acc 0.96875\n",
      "2017-04-03T20:07:39.882503: step 13680, loss 0.305928, acc 0.921875\n",
      "2017-04-03T20:07:40.084428: step 13681, loss 0.116273, acc 0.953125\n",
      "2017-04-03T20:07:40.288655: step 13682, loss 0.246498, acc 0.96875\n",
      "2017-04-03T20:07:40.532757: step 13683, loss 0.188077, acc 0.90625\n",
      "2017-04-03T20:07:40.777319: step 13684, loss 0.24741, acc 0.921875\n",
      "2017-04-03T20:07:40.985049: step 13685, loss 0.105685, acc 0.96875\n",
      "2017-04-03T20:07:41.184064: step 13686, loss 0.0833487, acc 0.953125\n",
      "2017-04-03T20:07:41.391421: step 13687, loss 0.0373674, acc 1\n",
      "2017-04-03T20:07:41.627453: step 13688, loss 0.404699, acc 0.921875\n",
      "2017-04-03T20:07:41.870159: step 13689, loss 0.136206, acc 0.953125\n",
      "2017-04-03T20:07:42.077642: step 13690, loss 0.11209, acc 0.9375\n",
      "2017-04-03T20:07:42.277435: step 13691, loss 0.122715, acc 0.953125\n",
      "2017-04-03T20:07:42.482654: step 13692, loss 0.164988, acc 0.953125\n",
      "2017-04-03T20:07:42.686023: step 13693, loss 0.277383, acc 0.9375\n",
      "2017-04-03T20:07:42.892131: step 13694, loss 0.0775521, acc 0.984375\n",
      "2017-04-03T20:07:43.134485: step 13695, loss 0.182879, acc 0.921875\n",
      "2017-04-03T20:07:43.345952: step 13696, loss 0.192174, acc 0.953125\n",
      "2017-04-03T20:07:43.562860: step 13697, loss 0.226402, acc 0.921875\n",
      "2017-04-03T20:07:43.764576: step 13698, loss 0.113602, acc 0.9375\n",
      "2017-04-03T20:07:43.963702: step 13699, loss 0.0978834, acc 0.984375\n",
      "2017-04-03T20:07:44.164668: step 13700, loss 0.178358, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:07:46.313480: step 13700, loss 5.56684, acc 0.29325\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-13700\n",
      "\n",
      "2017-04-03T20:07:46.645755: step 13701, loss 0.184185, acc 0.953125\n",
      "2017-04-03T20:07:46.892665: step 13702, loss 0.0784962, acc 0.96875\n",
      "2017-04-03T20:07:47.092737: step 13703, loss 0.131953, acc 0.953125\n",
      "2017-04-03T20:07:47.311174: step 13704, loss 0.15602, acc 0.96875\n",
      "2017-04-03T20:07:47.511524: step 13705, loss 0.128225, acc 0.96875\n",
      "2017-04-03T20:07:47.711916: step 13706, loss 0.103747, acc 0.953125\n",
      "2017-04-03T20:07:47.913111: step 13707, loss 0.150496, acc 0.921875\n",
      "2017-04-03T20:07:48.118704: step 13708, loss 0.217767, acc 0.921875\n",
      "2017-04-03T20:07:48.332964: step 13709, loss 0.214049, acc 0.953125\n",
      "2017-04-03T20:07:48.534751: step 13710, loss 0.162792, acc 0.984375\n",
      "2017-04-03T20:07:48.733962: step 13711, loss 0.0804602, acc 0.96875\n",
      "2017-04-03T20:07:48.935047: step 13712, loss 0.182874, acc 0.953125\n",
      "2017-04-03T20:07:49.136006: step 13713, loss 0.233682, acc 0.921875\n",
      "2017-04-03T20:07:49.341289: step 13714, loss 0.111781, acc 0.953125\n",
      "2017-04-03T20:07:49.542864: step 13715, loss 0.22584, acc 0.890625\n",
      "2017-04-03T20:07:49.787626: step 13716, loss 0.0574516, acc 0.984375\n",
      "2017-04-03T20:07:49.994083: step 13717, loss 0.156123, acc 0.96875\n",
      "2017-04-03T20:07:50.196659: step 13718, loss 0.142275, acc 0.953125\n",
      "2017-04-03T20:07:50.398516: step 13719, loss 0.0432686, acc 0.984375\n",
      "2017-04-03T20:07:50.599521: step 13720, loss 0.264234, acc 0.96875\n",
      "2017-04-03T20:07:50.800179: step 13721, loss 0.113862, acc 0.96875\n",
      "2017-04-03T20:07:51.004776: step 13722, loss 0.198104, acc 0.921875\n",
      "2017-04-03T20:07:51.205479: step 13723, loss 0.202023, acc 0.9375\n",
      "2017-04-03T20:07:51.411292: step 13724, loss 0.187753, acc 0.96875\n",
      "2017-04-03T20:07:51.617893: step 13725, loss 0.244784, acc 0.953125\n",
      "2017-04-03T20:07:51.823347: step 13726, loss 0.0768327, acc 0.96875\n",
      "2017-04-03T20:07:52.023904: step 13727, loss 0.138896, acc 0.953125\n",
      "2017-04-03T20:07:52.230382: step 13728, loss 0.0767979, acc 0.96875\n",
      "2017-04-03T20:07:52.431672: step 13729, loss 0.174052, acc 0.953125\n",
      "2017-04-03T20:07:52.636120: step 13730, loss 0.103963, acc 0.96875\n",
      "2017-04-03T20:07:52.835675: step 13731, loss 0.143551, acc 0.9375\n",
      "2017-04-03T20:07:53.041555: step 13732, loss 0.178144, acc 0.9375\n",
      "2017-04-03T20:07:53.247655: step 13733, loss 0.14185, acc 0.96875\n",
      "2017-04-03T20:07:53.491731: step 13734, loss 0.129454, acc 0.96875\n",
      "2017-04-03T20:07:53.696006: step 13735, loss 0.0922181, acc 0.96875\n",
      "2017-04-03T20:07:53.897513: step 13736, loss 0.315967, acc 0.9375\n",
      "2017-04-03T20:07:54.097316: step 13737, loss 0.182977, acc 0.921875\n",
      "2017-04-03T20:07:54.306549: step 13738, loss 0.231614, acc 0.90625\n",
      "2017-04-03T20:07:54.506650: step 13739, loss 0.134905, acc 0.9375\n",
      "2017-04-03T20:07:54.707445: step 13740, loss 0.177012, acc 0.953125\n",
      "2017-04-03T20:07:54.904722: step 13741, loss 0.114858, acc 0.953125\n",
      "2017-04-03T20:07:55.109450: step 13742, loss 0.19358, acc 0.921875\n",
      "2017-04-03T20:07:55.309014: step 13743, loss 0.164098, acc 0.9375\n",
      "2017-04-03T20:07:55.509717: step 13744, loss 0.14787, acc 0.984375\n",
      "2017-04-03T20:07:55.713540: step 13745, loss 0.114464, acc 0.9375\n",
      "2017-04-03T20:07:55.915223: step 13746, loss 0.287988, acc 0.921875\n",
      "2017-04-03T20:07:56.116743: step 13747, loss 0.084231, acc 0.984375\n",
      "2017-04-03T20:07:56.319882: step 13748, loss 0.0635161, acc 1\n",
      "2017-04-03T20:07:56.562550: step 13749, loss 0.216039, acc 0.921875\n",
      "2017-04-03T20:07:56.816165: step 13750, loss 0.272245, acc 0.90625\n",
      "2017-04-03T20:07:57.017155: step 13751, loss 0.127048, acc 0.9375\n",
      "2017-04-03T20:07:57.216475: step 13752, loss 0.125445, acc 0.953125\n",
      "2017-04-03T20:07:57.418264: step 13753, loss 0.157848, acc 0.96875\n",
      "2017-04-03T20:07:57.617092: step 13754, loss 0.1504, acc 0.953125\n",
      "2017-04-03T20:07:57.815938: step 13755, loss 0.180283, acc 0.921875\n",
      "2017-04-03T20:07:58.019739: step 13756, loss 0.184795, acc 0.921875\n",
      "2017-04-03T20:07:58.221445: step 13757, loss 0.247519, acc 0.921875\n",
      "2017-04-03T20:07:58.435447: step 13758, loss 0.145132, acc 0.96875\n",
      "2017-04-03T20:07:58.651647: step 13759, loss 0.203013, acc 0.9375\n",
      "2017-04-03T20:07:58.864328: step 13760, loss 0.180944, acc 0.953125\n",
      "2017-04-03T20:07:59.067097: step 13761, loss 0.113043, acc 0.96875\n",
      "2017-04-03T20:07:59.266227: step 13762, loss 0.20642, acc 0.9375\n",
      "2017-04-03T20:07:59.475588: step 13763, loss 0.0321891, acc 1\n",
      "2017-04-03T20:07:59.674328: step 13764, loss 0.374986, acc 0.890625\n",
      "2017-04-03T20:07:59.879507: step 13765, loss 0.184826, acc 0.921875\n",
      "2017-04-03T20:08:00.078775: step 13766, loss 0.336526, acc 0.859375\n",
      "2017-04-03T20:08:00.281178: step 13767, loss 0.0503616, acc 0.984375\n",
      "2017-04-03T20:08:00.479968: step 13768, loss 0.101754, acc 0.953125\n",
      "2017-04-03T20:08:00.681368: step 13769, loss 0.128051, acc 0.984375\n",
      "2017-04-03T20:08:00.924478: step 13770, loss 0.0991139, acc 0.96875\n",
      "2017-04-03T20:08:01.165769: step 13771, loss 0.119605, acc 0.984375\n",
      "2017-04-03T20:08:01.365691: step 13772, loss 0.115187, acc 0.96875\n",
      "2017-04-03T20:08:01.567369: step 13773, loss 0.0469565, acc 1\n",
      "2017-04-03T20:08:01.773981: step 13774, loss 0.169576, acc 0.921875\n",
      "2017-04-03T20:08:01.979338: step 13775, loss 0.161923, acc 0.9375\n",
      "2017-04-03T20:08:02.179404: step 13776, loss 0.189126, acc 0.953125\n",
      "2017-04-03T20:08:02.378290: step 13777, loss 0.120901, acc 0.96875\n",
      "2017-04-03T20:08:02.579024: step 13778, loss 0.212069, acc 0.921875\n",
      "2017-04-03T20:08:02.779717: step 13779, loss 0.100497, acc 0.953125\n",
      "2017-04-03T20:08:03.019548: step 13780, loss 0.124121, acc 0.984375\n",
      "2017-04-03T20:08:03.227135: step 13781, loss 0.0681637, acc 0.984375\n",
      "2017-04-03T20:08:03.431024: step 13782, loss 0.14326, acc 0.9375\n",
      "2017-04-03T20:08:03.633054: step 13783, loss 0.120192, acc 0.9375\n",
      "2017-04-03T20:08:03.832185: step 13784, loss 0.0522388, acc 1\n",
      "2017-04-03T20:08:04.031983: step 13785, loss 0.154959, acc 0.953125\n",
      "2017-04-03T20:08:04.235352: step 13786, loss 0.19697, acc 0.9375\n",
      "2017-04-03T20:08:04.432525: step 13787, loss 0.110248, acc 0.96875\n",
      "2017-04-03T20:08:04.638773: step 13788, loss 0.186178, acc 0.9375\n",
      "2017-04-03T20:08:04.841413: step 13789, loss 0.222967, acc 0.90625\n",
      "2017-04-03T20:08:05.047194: step 13790, loss 0.0831564, acc 0.984375\n",
      "2017-04-03T20:08:05.248701: step 13791, loss 0.112744, acc 0.984375\n",
      "2017-04-03T20:08:05.462606: step 13792, loss 0.169782, acc 0.921875\n",
      "2017-04-03T20:08:05.663180: step 13793, loss 0.339588, acc 0.90625\n",
      "2017-04-03T20:08:05.864332: step 13794, loss 0.211703, acc 0.921875\n",
      "2017-04-03T20:08:06.068472: step 13795, loss 0.11864, acc 0.96875\n",
      "2017-04-03T20:08:06.271656: step 13796, loss 0.171613, acc 0.96875\n",
      "2017-04-03T20:08:06.475956: step 13797, loss 0.23198, acc 0.9375\n",
      "2017-04-03T20:08:06.676246: step 13798, loss 0.167136, acc 0.953125\n",
      "2017-04-03T20:08:06.877875: step 13799, loss 0.178759, acc 0.9375\n",
      "2017-04-03T20:08:07.077992: step 13800, loss 0.197616, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:08:09.195055: step 13800, loss 5.67966, acc 0.2975\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-13800\n",
      "\n",
      "2017-04-03T20:08:09.530970: step 13801, loss 0.148357, acc 0.9375\n",
      "2017-04-03T20:08:09.730501: step 13802, loss 0.103823, acc 0.96875\n",
      "2017-04-03T20:08:09.933908: step 13803, loss 0.102583, acc 0.953125\n",
      "2017-04-03T20:08:10.132579: step 13804, loss 0.200768, acc 0.953125\n",
      "2017-04-03T20:08:10.330228: step 13805, loss 0.135398, acc 0.96875\n",
      "2017-04-03T20:08:10.532552: step 13806, loss 0.267035, acc 0.90625\n",
      "2017-04-03T20:08:10.734033: step 13807, loss 0.181595, acc 0.953125\n",
      "2017-04-03T20:08:10.934996: step 13808, loss 0.0844246, acc 0.96875\n",
      "2017-04-03T20:08:11.137795: step 13809, loss 0.159445, acc 0.9375\n",
      "2017-04-03T20:08:11.337344: step 13810, loss 0.185999, acc 0.9375\n",
      "2017-04-03T20:08:11.533567: step 13811, loss 0.0862032, acc 0.984375\n",
      "2017-04-03T20:08:11.732786: step 13812, loss 0.173925, acc 0.96875\n",
      "2017-04-03T20:08:11.931872: step 13813, loss 0.108505, acc 0.953125\n",
      "2017-04-03T20:08:12.136762: step 13814, loss 0.17302, acc 0.9375\n",
      "2017-04-03T20:08:12.334612: step 13815, loss 0.0697031, acc 0.984375\n",
      "2017-04-03T20:08:12.538006: step 13816, loss 0.170599, acc 0.953125\n",
      "2017-04-03T20:08:12.739896: step 13817, loss 0.150647, acc 0.9375\n",
      "2017-04-03T20:08:12.985935: step 13818, loss 0.0820578, acc 0.96875\n",
      "2017-04-03T20:08:13.186863: step 13819, loss 0.138531, acc 0.984375\n",
      "2017-04-03T20:08:13.388335: step 13820, loss 0.0947845, acc 0.96875\n",
      "2017-04-03T20:08:13.594893: step 13821, loss 0.194721, acc 0.9375\n",
      "2017-04-03T20:08:13.799102: step 13822, loss 0.12573, acc 0.9375\n",
      "2017-04-03T20:08:14.001405: step 13823, loss 0.109957, acc 0.984375\n",
      "2017-04-03T20:08:14.202007: step 13824, loss 0.192374, acc 0.921875\n",
      "2017-04-03T20:08:14.403154: step 13825, loss 0.287453, acc 0.921875\n",
      "2017-04-03T20:08:14.608938: step 13826, loss 0.0435944, acc 1\n",
      "2017-04-03T20:08:14.809655: step 13827, loss 0.0599537, acc 1\n",
      "2017-04-03T20:08:15.051688: step 13828, loss 0.0738155, acc 0.984375\n",
      "2017-04-03T20:08:15.257025: step 13829, loss 0.172654, acc 0.953125\n",
      "2017-04-03T20:08:15.499077: step 13830, loss 0.0982986, acc 0.96875\n",
      "2017-04-03T20:08:15.705477: step 13831, loss 0.160146, acc 0.9375\n",
      "2017-04-03T20:08:15.906215: step 13832, loss 0.133748, acc 0.984375\n",
      "2017-04-03T20:08:16.111899: step 13833, loss 0.0707381, acc 0.984375\n",
      "2017-04-03T20:08:16.311792: step 13834, loss 0.239679, acc 0.921875\n",
      "2017-04-03T20:08:16.514764: step 13835, loss 0.294798, acc 0.90625\n",
      "2017-04-03T20:08:16.713977: step 13836, loss 0.161162, acc 0.953125\n",
      "2017-04-03T20:08:16.912886: step 13837, loss 0.0722253, acc 1\n",
      "2017-04-03T20:08:17.117466: step 13838, loss 0.462022, acc 0.953125\n",
      "2017-04-03T20:08:17.318847: step 13839, loss 0.166074, acc 0.953125\n",
      "2017-04-03T20:08:17.557809: step 13840, loss 0.0886802, acc 0.984375\n",
      "2017-04-03T20:08:17.770776: step 13841, loss 0.158789, acc 0.9375\n",
      "2017-04-03T20:08:17.973524: step 13842, loss 0.181383, acc 0.96875\n",
      "2017-04-03T20:08:18.175653: step 13843, loss 0.156396, acc 0.953125\n",
      "2017-04-03T20:08:18.374137: step 13844, loss 0.0986007, acc 0.984375\n",
      "2017-04-03T20:08:18.584353: step 13845, loss 0.310009, acc 0.875\n",
      "2017-04-03T20:08:18.785527: step 13846, loss 0.182418, acc 0.9375\n",
      "2017-04-03T20:08:18.987573: step 13847, loss 0.390448, acc 0.859375\n",
      "2017-04-03T20:08:19.190365: step 13848, loss 0.179533, acc 0.953125\n",
      "2017-04-03T20:08:19.388625: step 13849, loss 0.185818, acc 0.921875\n",
      "2017-04-03T20:08:19.591441: step 13850, loss 0.208077, acc 0.9375\n",
      "2017-04-03T20:08:19.791325: step 13851, loss 0.177547, acc 0.96875\n",
      "2017-04-03T20:08:19.992579: step 13852, loss 0.126035, acc 0.9375\n",
      "2017-04-03T20:08:20.196652: step 13853, loss 0.313202, acc 0.921875\n",
      "2017-04-03T20:08:20.397944: step 13854, loss 0.239799, acc 0.921875\n",
      "2017-04-03T20:08:20.597670: step 13855, loss 0.132413, acc 0.953125\n",
      "2017-04-03T20:08:20.806927: step 13856, loss 0.151372, acc 0.9375\n",
      "2017-04-03T20:08:21.014077: step 13857, loss 0.168537, acc 0.9375\n",
      "2017-04-03T20:08:21.224407: step 13858, loss 0.135722, acc 0.96875\n",
      "2017-04-03T20:08:21.424355: step 13859, loss 0.0596041, acc 1\n",
      "2017-04-03T20:08:21.625142: step 13860, loss 0.0901552, acc 0.9375\n",
      "2017-04-03T20:08:21.869934: step 13861, loss 0.106612, acc 0.953125\n",
      "2017-04-03T20:08:22.087077: step 13862, loss 0.210107, acc 0.921875\n",
      "2017-04-03T20:08:22.291299: step 13863, loss 0.0211923, acc 1\n",
      "2017-04-03T20:08:22.493628: step 13864, loss 0.112155, acc 0.96875\n",
      "2017-04-03T20:08:22.705329: step 13865, loss 0.172267, acc 0.953125\n",
      "2017-04-03T20:08:22.909709: step 13866, loss 0.224031, acc 0.921875\n",
      "2017-04-03T20:08:23.114691: step 13867, loss 0.256981, acc 0.90625\n",
      "2017-04-03T20:08:23.314725: step 13868, loss 0.237741, acc 0.953125\n",
      "2017-04-03T20:08:23.517595: step 13869, loss 0.146729, acc 0.9375\n",
      "2017-04-03T20:08:23.718945: step 13870, loss 0.23912, acc 0.984375\n",
      "2017-04-03T20:08:23.924124: step 13871, loss 0.142898, acc 0.953125\n",
      "2017-04-03T20:08:24.135201: step 13872, loss 0.0783552, acc 0.96875\n",
      "2017-04-03T20:08:24.335572: step 13873, loss 0.139392, acc 0.96875\n",
      "2017-04-03T20:08:24.536040: step 13874, loss 0.171826, acc 0.9375\n",
      "2017-04-03T20:08:24.735386: step 13875, loss 0.384558, acc 0.921875\n",
      "2017-04-03T20:08:24.933108: step 13876, loss 0.108179, acc 0.96875\n",
      "2017-04-03T20:08:25.132018: step 13877, loss 0.0904107, acc 0.96875\n",
      "2017-04-03T20:08:25.330745: step 13878, loss 0.244491, acc 0.921875\n",
      "2017-04-03T20:08:25.544686: step 13879, loss 0.225529, acc 0.890625\n",
      "2017-04-03T20:08:25.742526: step 13880, loss 0.209397, acc 0.90625\n",
      "2017-04-03T20:08:25.948835: step 13881, loss 0.232055, acc 0.90625\n",
      "2017-04-03T20:08:26.157428: step 13882, loss 0.0485022, acc 1\n",
      "2017-04-03T20:08:26.366587: step 13883, loss 0.119909, acc 0.984375\n",
      "2017-04-03T20:08:26.612056: step 13884, loss 0.181637, acc 0.921875\n",
      "2017-04-03T20:08:26.820323: step 13885, loss 0.109625, acc 0.9375\n",
      "2017-04-03T20:08:27.021807: step 13886, loss 0.198377, acc 0.96875\n",
      "2017-04-03T20:08:27.216024: step 13887, loss 0.133865, acc 0.953125\n",
      "2017-04-03T20:08:27.418200: step 13888, loss 0.119873, acc 0.953125\n",
      "2017-04-03T20:08:27.644535: step 13889, loss 0.0760779, acc 0.984375\n",
      "2017-04-03T20:08:27.859726: step 13890, loss 0.0608653, acc 0.96875\n",
      "2017-04-03T20:08:28.058173: step 13891, loss 0.0947651, acc 0.96875\n",
      "2017-04-03T20:08:28.260479: step 13892, loss 0.168368, acc 0.9375\n",
      "2017-04-03T20:08:28.464548: step 13893, loss 0.17576, acc 0.96875\n",
      "2017-04-03T20:08:28.669492: step 13894, loss 0.0422057, acc 0.984375\n",
      "2017-04-03T20:08:28.873098: step 13895, loss 0.215224, acc 0.921875\n",
      "2017-04-03T20:08:29.076531: step 13896, loss 0.434537, acc 0.890625\n",
      "2017-04-03T20:08:29.318879: step 13897, loss 0.0885488, acc 0.96875\n",
      "2017-04-03T20:08:29.535750: step 13898, loss 0.12247, acc 0.984375\n",
      "2017-04-03T20:08:29.737304: step 13899, loss 0.143835, acc 0.953125\n",
      "2017-04-03T20:08:29.936177: step 13900, loss 0.113268, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:08:32.074677: step 13900, loss 5.61206, acc 0.29725\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-13900\n",
      "\n",
      "2017-04-03T20:08:32.445412: step 13901, loss 0.12512, acc 0.96875\n",
      "2017-04-03T20:08:32.648780: step 13902, loss 0.248386, acc 0.953125\n",
      "2017-04-03T20:08:32.850102: step 13903, loss 0.113964, acc 0.953125\n",
      "2017-04-03T20:08:33.052688: step 13904, loss 0.0586918, acc 0.984375\n",
      "2017-04-03T20:08:33.254832: step 13905, loss 0.126395, acc 0.953125\n",
      "2017-04-03T20:08:33.459527: step 13906, loss 0.169365, acc 0.9375\n",
      "2017-04-03T20:08:33.705829: step 13907, loss 0.061604, acc 1\n",
      "2017-04-03T20:08:33.915612: step 13908, loss 0.136745, acc 0.9375\n",
      "2017-04-03T20:08:34.119723: step 13909, loss 0.275466, acc 0.890625\n",
      "2017-04-03T20:08:34.323364: step 13910, loss 0.100893, acc 0.953125\n",
      "2017-04-03T20:08:34.558733: step 13911, loss 0.102835, acc 0.96875\n",
      "2017-04-03T20:08:34.756821: step 13912, loss 0.386472, acc 0.921875\n",
      "2017-04-03T20:08:35.001822: step 13913, loss 0.159482, acc 0.953125\n",
      "2017-04-03T20:08:35.210394: step 13914, loss 0.199801, acc 0.90625\n",
      "2017-04-03T20:08:35.421894: step 13915, loss 0.243826, acc 0.953125\n",
      "2017-04-03T20:08:35.624023: step 13916, loss 0.12923, acc 0.984375\n",
      "2017-04-03T20:08:35.823122: step 13917, loss 0.248701, acc 0.9375\n",
      "2017-04-03T20:08:36.069929: step 13918, loss 0.133226, acc 0.953125\n",
      "2017-04-03T20:08:36.281917: step 13919, loss 0.174439, acc 0.9375\n",
      "2017-04-03T20:08:36.482191: step 13920, loss 0.25048, acc 0.90625\n",
      "2017-04-03T20:08:36.725256: step 13921, loss 0.193494, acc 0.953125\n",
      "2017-04-03T20:08:36.931515: step 13922, loss 0.106451, acc 0.96875\n",
      "2017-04-03T20:08:37.131590: step 13923, loss 0.365159, acc 0.890625\n",
      "2017-04-03T20:08:37.337477: step 13924, loss 0.078904, acc 0.984375\n",
      "2017-04-03T20:08:37.539575: step 13925, loss 0.219754, acc 0.90625\n",
      "2017-04-03T20:08:37.747779: step 13926, loss 0.153371, acc 0.9375\n",
      "2017-04-03T20:08:37.953632: step 13927, loss 0.0374925, acc 1\n",
      "2017-04-03T20:08:38.153325: step 13928, loss 0.141431, acc 0.96875\n",
      "2017-04-03T20:08:38.395910: step 13929, loss 0.113784, acc 0.96875\n",
      "2017-04-03T20:08:38.623202: step 13930, loss 0.148675, acc 0.9375\n",
      "2017-04-03T20:08:38.829647: step 13931, loss 0.170884, acc 0.953125\n",
      "2017-04-03T20:08:39.029863: step 13932, loss 0.269027, acc 0.890625\n",
      "2017-04-03T20:08:39.233170: step 13933, loss 0.207221, acc 0.96875\n",
      "2017-04-03T20:08:39.437333: step 13934, loss 0.0546201, acc 0.984375\n",
      "2017-04-03T20:08:39.653173: step 13935, loss 0.205742, acc 0.9375\n",
      "2017-04-03T20:08:39.863621: step 13936, loss 0.112202, acc 0.96875\n",
      "2017-04-03T20:08:40.070009: step 13937, loss 0.0942217, acc 0.984375\n",
      "2017-04-03T20:08:40.268832: step 13938, loss 0.224741, acc 0.9375\n",
      "2017-04-03T20:08:40.470729: step 13939, loss 0.318397, acc 0.875\n",
      "2017-04-03T20:08:40.676274: step 13940, loss 0.211187, acc 0.953125\n",
      "2017-04-03T20:08:40.875715: step 13941, loss 0.0897104, acc 0.953125\n",
      "2017-04-03T20:08:41.080591: step 13942, loss 0.162326, acc 0.921875\n",
      "2017-04-03T20:08:41.284425: step 13943, loss 0.0645056, acc 0.96875\n",
      "2017-04-03T20:08:41.490306: step 13944, loss 0.170682, acc 0.953125\n",
      "2017-04-03T20:08:41.822238: step 13945, loss 0.344469, acc 0.953125\n",
      "2017-04-03T20:08:42.024589: step 13946, loss 0.269081, acc 0.921875\n",
      "2017-04-03T20:08:42.233334: step 13947, loss 0.141359, acc 0.96875\n",
      "2017-04-03T20:08:42.446658: step 13948, loss 0.361971, acc 0.96875\n",
      "2017-04-03T20:08:42.653623: step 13949, loss 0.158972, acc 0.921875\n",
      "2017-04-03T20:08:42.856594: step 13950, loss 0.18648, acc 0.9375\n",
      "2017-04-03T20:08:43.058311: step 13951, loss 0.119046, acc 0.984375\n",
      "2017-04-03T20:08:43.266834: step 13952, loss 0.225275, acc 0.9375\n",
      "2017-04-03T20:08:43.468292: step 13953, loss 0.162182, acc 0.953125\n",
      "2017-04-03T20:08:43.668294: step 13954, loss 0.15864, acc 0.9375\n",
      "2017-04-03T20:08:43.875492: step 13955, loss 0.112895, acc 0.96875\n",
      "2017-04-03T20:08:44.077737: step 13956, loss 0.233752, acc 0.953125\n",
      "2017-04-03T20:08:44.284826: step 13957, loss 0.343128, acc 0.9375\n",
      "2017-04-03T20:08:44.489507: step 13958, loss 0.139931, acc 0.953125\n",
      "2017-04-03T20:08:44.691298: step 13959, loss 0.228496, acc 0.921875\n",
      "2017-04-03T20:08:44.893922: step 13960, loss 0.150096, acc 0.96875\n",
      "2017-04-03T20:08:45.105086: step 13961, loss 0.109693, acc 0.984375\n",
      "2017-04-03T20:08:45.313903: step 13962, loss 0.174714, acc 0.953125\n",
      "2017-04-03T20:08:45.517850: step 13963, loss 0.242611, acc 0.921875\n",
      "2017-04-03T20:08:45.724352: step 13964, loss 0.205432, acc 0.953125\n",
      "2017-04-03T20:08:45.928812: step 13965, loss 0.229133, acc 0.90625\n",
      "2017-04-03T20:08:46.133638: step 13966, loss 0.19434, acc 0.953125\n",
      "2017-04-03T20:08:46.352243: step 13967, loss 0.174452, acc 0.953125\n",
      "2017-04-03T20:08:46.575724: step 13968, loss 0.408479, acc 0.9375\n",
      "2017-04-03T20:08:46.829211: step 13969, loss 0.195601, acc 0.9375\n",
      "2017-04-03T20:08:47.032906: step 13970, loss 0.0943196, acc 0.984375\n",
      "2017-04-03T20:08:47.248769: step 13971, loss 0.0814936, acc 1\n",
      "2017-04-03T20:08:47.465582: step 13972, loss 0.109306, acc 0.96875\n",
      "2017-04-03T20:08:47.675583: step 13973, loss 0.212168, acc 0.9375\n",
      "2017-04-03T20:08:47.884704: step 13974, loss 0.190334, acc 0.9375\n",
      "2017-04-03T20:08:48.081534: step 13975, loss 0.137063, acc 0.9375\n",
      "2017-04-03T20:08:48.286964: step 13976, loss 0.0625343, acc 0.984375\n",
      "2017-04-03T20:08:48.487421: step 13977, loss 0.0786309, acc 0.96875\n",
      "2017-04-03T20:08:48.687735: step 13978, loss 0.179679, acc 0.921875\n",
      "2017-04-03T20:08:48.890301: step 13979, loss 0.438116, acc 0.890625\n",
      "2017-04-03T20:08:49.094680: step 13980, loss 0.261084, acc 0.9375\n",
      "2017-04-03T20:08:49.295639: step 13981, loss 0.174739, acc 0.9375\n",
      "2017-04-03T20:08:49.534112: step 13982, loss 0.0722175, acc 0.984375\n",
      "2017-04-03T20:08:49.743144: step 13983, loss 0.135638, acc 0.9375\n",
      "2017-04-03T20:08:49.954910: step 13984, loss 0.0928273, acc 0.96875\n",
      "2017-04-03T20:08:50.200025: step 13985, loss 0.152982, acc 0.953125\n",
      "2017-04-03T20:08:50.406755: step 13986, loss 0.119785, acc 0.96875\n",
      "2017-04-03T20:08:50.609739: step 13987, loss 0.0797016, acc 0.96875\n",
      "2017-04-03T20:08:50.819191: step 13988, loss 0.0910076, acc 0.984375\n",
      "2017-04-03T20:08:51.021763: step 13989, loss 0.27865, acc 0.9375\n",
      "2017-04-03T20:08:51.226376: step 13990, loss 0.218019, acc 0.9375\n",
      "2017-04-03T20:08:51.426136: step 13991, loss 0.149328, acc 0.921875\n",
      "2017-04-03T20:08:51.632268: step 13992, loss 0.0586386, acc 0.984375\n",
      "2017-04-03T20:08:51.832845: step 13993, loss 0.153517, acc 0.953125\n",
      "2017-04-03T20:08:52.031316: step 13994, loss 0.0357932, acc 1\n",
      "2017-04-03T20:08:52.235965: step 13995, loss 0.0614769, acc 0.96875\n",
      "2017-04-03T20:08:52.446552: step 13996, loss 0.13354, acc 0.953125\n",
      "2017-04-03T20:08:52.646174: step 13997, loss 0.341962, acc 0.921875\n",
      "2017-04-03T20:08:52.850454: step 13998, loss 0.0454277, acc 0.984375\n",
      "2017-04-03T20:08:53.052558: step 13999, loss 0.17155, acc 0.953125\n",
      "2017-04-03T20:08:53.257344: step 14000, loss 0.257082, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:08:55.369888: step 14000, loss 5.60867, acc 0.29575\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-14000\n",
      "\n",
      "2017-04-03T20:08:55.712346: step 14001, loss 0.126972, acc 0.953125\n",
      "2017-04-03T20:08:55.916583: step 14002, loss 0.204425, acc 0.921875\n",
      "2017-04-03T20:08:56.158899: step 14003, loss 0.191, acc 0.96875\n",
      "2017-04-03T20:08:56.374111: step 14004, loss 0.281739, acc 0.875\n",
      "2017-04-03T20:08:56.631540: step 14005, loss 0.224898, acc 0.953125\n",
      "2017-04-03T20:08:56.856147: step 14006, loss 0.18536, acc 0.953125\n",
      "2017-04-03T20:08:57.074070: step 14007, loss 0.194403, acc 0.9375\n",
      "2017-04-03T20:08:57.319533: step 14008, loss 0.110049, acc 0.9375\n",
      "2017-04-03T20:08:57.520455: step 14009, loss 0.161752, acc 0.9375\n",
      "2017-04-03T20:08:57.721777: step 14010, loss 0.211882, acc 0.921875\n",
      "2017-04-03T20:08:57.923200: step 14011, loss 0.109208, acc 0.984375\n",
      "2017-04-03T20:08:58.127630: step 14012, loss 0.22848, acc 0.921875\n",
      "2017-04-03T20:08:58.334278: step 14013, loss 0.144749, acc 0.953125\n",
      "2017-04-03T20:08:58.542929: step 14014, loss 0.0981015, acc 0.96875\n",
      "2017-04-03T20:08:58.746280: step 14015, loss 0.0591684, acc 0.984375\n",
      "2017-04-03T20:08:58.951232: step 14016, loss 0.293676, acc 0.90625\n",
      "2017-04-03T20:08:59.152521: step 14017, loss 0.093949, acc 1\n",
      "2017-04-03T20:08:59.358157: step 14018, loss 0.0701041, acc 1\n",
      "2017-04-03T20:08:59.565679: step 14019, loss 0.39689, acc 0.90625\n",
      "2017-04-03T20:08:59.769309: step 14020, loss 0.285345, acc 0.921875\n",
      "2017-04-03T20:08:59.974292: step 14021, loss 0.146337, acc 0.96875\n",
      "2017-04-03T20:09:00.177189: step 14022, loss 0.244358, acc 0.90625\n",
      "2017-04-03T20:09:00.378228: step 14023, loss 0.210249, acc 0.921875\n",
      "2017-04-03T20:09:00.590908: step 14024, loss 0.12181, acc 0.953125\n",
      "2017-04-03T20:09:00.809976: step 14025, loss 0.237298, acc 0.921875\n",
      "2017-04-03T20:09:01.015931: step 14026, loss 0.317856, acc 0.953125\n",
      "2017-04-03T20:09:01.215682: step 14027, loss 0.070189, acc 0.984375\n",
      "2017-04-03T20:09:01.416980: step 14028, loss 0.108494, acc 0.953125\n",
      "2017-04-03T20:09:01.617510: step 14029, loss 0.117461, acc 0.953125\n",
      "2017-04-03T20:09:01.817778: step 14030, loss 0.169504, acc 0.9375\n",
      "2017-04-03T20:09:02.023023: step 14031, loss 0.187429, acc 0.921875\n",
      "2017-04-03T20:09:02.271083: step 14032, loss 0.241629, acc 0.921875\n",
      "2017-04-03T20:09:02.478838: step 14033, loss 0.108396, acc 0.96875\n",
      "2017-04-03T20:09:02.679424: step 14034, loss 0.250887, acc 0.890625\n",
      "2017-04-03T20:09:02.881802: step 14035, loss 0.166727, acc 0.9375\n",
      "2017-04-03T20:09:03.123345: step 14036, loss 0.138682, acc 0.96875\n",
      "2017-04-03T20:09:03.322359: step 14037, loss 0.227676, acc 0.953125\n",
      "2017-04-03T20:09:03.532044: step 14038, loss 0.109747, acc 0.96875\n",
      "2017-04-03T20:09:03.746521: step 14039, loss 0.144749, acc 0.9375\n",
      "2017-04-03T20:09:03.952094: step 14040, loss 0.0775666, acc 1\n",
      "2017-04-03T20:09:04.151600: step 14041, loss 0.112733, acc 0.953125\n",
      "2017-04-03T20:09:04.360302: step 14042, loss 0.12304, acc 0.9375\n",
      "2017-04-03T20:09:04.563292: step 14043, loss 0.340052, acc 0.953125\n",
      "2017-04-03T20:09:04.765768: step 14044, loss 0.199104, acc 0.953125\n",
      "2017-04-03T20:09:05.008838: step 14045, loss 0.101935, acc 0.96875\n",
      "2017-04-03T20:09:05.214304: step 14046, loss 0.302568, acc 0.890625\n",
      "2017-04-03T20:09:05.418444: step 14047, loss 0.125066, acc 0.953125\n",
      "2017-04-03T20:09:05.619442: step 14048, loss 0.265691, acc 0.875\n",
      "2017-04-03T20:09:05.830070: step 14049, loss 0.13931, acc 0.9375\n",
      "2017-04-03T20:09:06.042141: step 14050, loss 0.239457, acc 0.921875\n",
      "2017-04-03T20:09:06.266980: step 14051, loss 0.0700981, acc 0.984375\n",
      "2017-04-03T20:09:06.482783: step 14052, loss 0.223368, acc 0.90625\n",
      "2017-04-03T20:09:06.708258: step 14053, loss 0.154288, acc 0.9375\n",
      "2017-04-03T20:09:06.925731: step 14054, loss 0.189573, acc 0.9375\n",
      "2017-04-03T20:09:07.166144: step 14055, loss 0.147966, acc 0.953125\n",
      "2017-04-03T20:09:07.373359: step 14056, loss 0.100876, acc 0.953125\n",
      "2017-04-03T20:09:07.571648: step 14057, loss 0.327128, acc 0.921875\n",
      "2017-04-03T20:09:07.774863: step 14058, loss 0.441894, acc 0.875\n",
      "2017-04-03T20:09:07.985681: step 14059, loss 0.306272, acc 0.9375\n",
      "2017-04-03T20:09:08.189516: step 14060, loss 0.260523, acc 0.921875\n",
      "2017-04-03T20:09:08.398507: step 14061, loss 0.141535, acc 0.96875\n",
      "2017-04-03T20:09:08.601880: step 14062, loss 0.252271, acc 0.921875\n",
      "2017-04-03T20:09:08.807983: step 14063, loss 0.273573, acc 0.953125\n",
      "2017-04-03T20:09:09.059288: step 14064, loss 0.32518, acc 0.90625\n",
      "2017-04-03T20:09:09.267349: step 14065, loss 0.310183, acc 0.890625\n",
      "2017-04-03T20:09:09.469070: step 14066, loss 0.0615133, acc 1\n",
      "2017-04-03T20:09:09.672968: step 14067, loss 0.108331, acc 0.96875\n",
      "2017-04-03T20:09:09.883004: step 14068, loss 0.389343, acc 0.921875\n",
      "2017-04-03T20:09:10.087024: step 14069, loss 0.185527, acc 0.9375\n",
      "2017-04-03T20:09:10.289870: step 14070, loss 0.110844, acc 0.96875\n",
      "2017-04-03T20:09:10.489835: step 14071, loss 0.0758798, acc 0.96875\n",
      "2017-04-03T20:09:10.690314: step 14072, loss 0.16659, acc 0.9375\n",
      "2017-04-03T20:09:10.891988: step 14073, loss 0.237452, acc 0.90625\n",
      "2017-04-03T20:09:11.095855: step 14074, loss 0.17036, acc 0.921875\n",
      "2017-04-03T20:09:11.245738: step 14075, loss 0.0911508, acc 0.96875\n",
      "2017-04-03T20:09:11.453196: step 14076, loss 0.0500043, acc 0.984375\n",
      "2017-04-03T20:09:11.697755: step 14077, loss 0.142671, acc 0.96875\n",
      "2017-04-03T20:09:11.903547: step 14078, loss 0.0542906, acc 0.96875\n",
      "2017-04-03T20:09:12.113839: step 14079, loss 0.12313, acc 0.953125\n",
      "2017-04-03T20:09:12.318702: step 14080, loss 0.0926387, acc 0.984375\n",
      "2017-04-03T20:09:12.519857: step 14081, loss 0.122729, acc 0.984375\n",
      "2017-04-03T20:09:12.725140: step 14082, loss 0.204605, acc 0.9375\n",
      "2017-04-03T20:09:12.968197: step 14083, loss 0.155221, acc 0.96875\n",
      "2017-04-03T20:09:13.175680: step 14084, loss 0.187199, acc 0.984375\n",
      "2017-04-03T20:09:13.380507: step 14085, loss 0.166874, acc 0.9375\n",
      "2017-04-03T20:09:13.585282: step 14086, loss 0.181077, acc 0.9375\n",
      "2017-04-03T20:09:13.784599: step 14087, loss 0.0783816, acc 0.96875\n",
      "2017-04-03T20:09:13.990608: step 14088, loss 0.244382, acc 0.953125\n",
      "2017-04-03T20:09:14.194834: step 14089, loss 0.115084, acc 0.984375\n",
      "2017-04-03T20:09:14.399776: step 14090, loss 0.115271, acc 0.953125\n",
      "2017-04-03T20:09:14.601011: step 14091, loss 0.0753129, acc 1\n",
      "2017-04-03T20:09:14.803257: step 14092, loss 0.0673776, acc 0.984375\n",
      "2017-04-03T20:09:15.005785: step 14093, loss 0.117195, acc 0.953125\n",
      "2017-04-03T20:09:15.205906: step 14094, loss 0.217594, acc 0.921875\n",
      "2017-04-03T20:09:15.408971: step 14095, loss 0.100024, acc 0.96875\n",
      "2017-04-03T20:09:15.616546: step 14096, loss 0.234384, acc 0.921875\n",
      "2017-04-03T20:09:15.816073: step 14097, loss 0.0778219, acc 0.96875\n",
      "2017-04-03T20:09:16.022193: step 14098, loss 0.0810337, acc 0.984375\n",
      "2017-04-03T20:09:16.223674: step 14099, loss 0.277013, acc 0.9375\n",
      "2017-04-03T20:09:16.423024: step 14100, loss 0.0696824, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:09:18.572596: step 14100, loss 5.63296, acc 0.29575\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-14100\n",
      "\n",
      "2017-04-03T20:09:18.914311: step 14101, loss 0.363007, acc 0.921875\n",
      "2017-04-03T20:09:19.117589: step 14102, loss 0.181006, acc 0.90625\n",
      "2017-04-03T20:09:19.321884: step 14103, loss 0.145366, acc 0.953125\n",
      "2017-04-03T20:09:19.523800: step 14104, loss 0.154014, acc 0.890625\n",
      "2017-04-03T20:09:19.725656: step 14105, loss 0.0811904, acc 0.984375\n",
      "2017-04-03T20:09:19.932516: step 14106, loss 0.13361, acc 0.96875\n",
      "2017-04-03T20:09:20.141559: step 14107, loss 0.129118, acc 0.953125\n",
      "2017-04-03T20:09:20.358570: step 14108, loss 0.152027, acc 0.9375\n",
      "2017-04-03T20:09:20.617249: step 14109, loss 0.0585443, acc 0.984375\n",
      "2017-04-03T20:09:20.815861: step 14110, loss 0.130913, acc 0.9375\n",
      "2017-04-03T20:09:21.016041: step 14111, loss 0.0612294, acc 0.984375\n",
      "2017-04-03T20:09:21.221485: step 14112, loss 0.0533635, acc 1\n",
      "2017-04-03T20:09:21.428622: step 14113, loss 0.156853, acc 0.953125\n",
      "2017-04-03T20:09:21.630232: step 14114, loss 0.253126, acc 0.96875\n",
      "2017-04-03T20:09:21.831485: step 14115, loss 0.0882209, acc 0.984375\n",
      "2017-04-03T20:09:22.038879: step 14116, loss 0.0757556, acc 0.984375\n",
      "2017-04-03T20:09:22.238470: step 14117, loss 0.112767, acc 0.953125\n",
      "2017-04-03T20:09:22.446471: step 14118, loss 0.0924003, acc 0.984375\n",
      "2017-04-03T20:09:22.647256: step 14119, loss 0.0737227, acc 0.96875\n",
      "2017-04-03T20:09:22.893078: step 14120, loss 0.148725, acc 0.953125\n",
      "2017-04-03T20:09:23.147465: step 14121, loss 0.0887347, acc 0.96875\n",
      "2017-04-03T20:09:23.350933: step 14122, loss 0.112819, acc 0.96875\n",
      "2017-04-03T20:09:23.555329: step 14123, loss 0.0872972, acc 0.984375\n",
      "2017-04-03T20:09:23.756246: step 14124, loss 0.130367, acc 0.953125\n",
      "2017-04-03T20:09:23.975640: step 14125, loss 0.121804, acc 0.96875\n",
      "2017-04-03T20:09:24.175882: step 14126, loss 0.190395, acc 0.921875\n",
      "2017-04-03T20:09:24.400830: step 14127, loss 0.278548, acc 0.9375\n",
      "2017-04-03T20:09:24.609986: step 14128, loss 0.108516, acc 0.96875\n",
      "2017-04-03T20:09:24.814422: step 14129, loss 0.0722327, acc 0.96875\n",
      "2017-04-03T20:09:25.015106: step 14130, loss 0.12371, acc 0.96875\n",
      "2017-04-03T20:09:25.217930: step 14131, loss 0.0314166, acc 1\n",
      "2017-04-03T20:09:25.418817: step 14132, loss 0.149756, acc 0.9375\n",
      "2017-04-03T20:09:25.623095: step 14133, loss 0.261237, acc 0.953125\n",
      "2017-04-03T20:09:25.822634: step 14134, loss 0.121327, acc 0.953125\n",
      "2017-04-03T20:09:26.023994: step 14135, loss 0.185537, acc 0.9375\n",
      "2017-04-03T20:09:26.238625: step 14136, loss 0.165502, acc 0.9375\n",
      "2017-04-03T20:09:26.441404: step 14137, loss 0.187217, acc 0.953125\n",
      "2017-04-03T20:09:26.646957: step 14138, loss 0.138019, acc 0.953125\n",
      "2017-04-03T20:09:26.856307: step 14139, loss 0.185862, acc 0.90625\n",
      "2017-04-03T20:09:27.059013: step 14140, loss 0.129973, acc 0.96875\n",
      "2017-04-03T20:09:27.262037: step 14141, loss 0.05657, acc 0.984375\n",
      "2017-04-03T20:09:27.471341: step 14142, loss 0.219696, acc 0.9375\n",
      "2017-04-03T20:09:27.687143: step 14143, loss 0.31546, acc 0.953125\n",
      "2017-04-03T20:09:27.891603: step 14144, loss 0.0695368, acc 0.984375\n",
      "2017-04-03T20:09:28.093767: step 14145, loss 0.0609762, acc 0.984375\n",
      "2017-04-03T20:09:28.292065: step 14146, loss 0.0933534, acc 0.96875\n",
      "2017-04-03T20:09:28.502924: step 14147, loss 0.245039, acc 0.90625\n",
      "2017-04-03T20:09:28.703185: step 14148, loss 0.244435, acc 0.921875\n",
      "2017-04-03T20:09:28.916902: step 14149, loss 0.119322, acc 0.953125\n",
      "2017-04-03T20:09:29.115077: step 14150, loss 0.0537675, acc 0.96875\n",
      "2017-04-03T20:09:29.370839: step 14151, loss 0.11228, acc 0.96875\n",
      "2017-04-03T20:09:29.613377: step 14152, loss 0.284106, acc 0.953125\n",
      "2017-04-03T20:09:29.820442: step 14153, loss 0.369435, acc 0.921875\n",
      "2017-04-03T20:09:30.024919: step 14154, loss 0.134926, acc 0.9375\n",
      "2017-04-03T20:09:30.227780: step 14155, loss 0.225642, acc 0.9375\n",
      "2017-04-03T20:09:30.468210: step 14156, loss 0.162813, acc 0.921875\n",
      "2017-04-03T20:09:30.701757: step 14157, loss 0.143259, acc 0.9375\n",
      "2017-04-03T20:09:30.915071: step 14158, loss 0.0628648, acc 0.96875\n",
      "2017-04-03T20:09:31.116053: step 14159, loss 0.0596039, acc 0.984375\n",
      "2017-04-03T20:09:31.363532: step 14160, loss 0.179995, acc 0.96875\n",
      "2017-04-03T20:09:31.566228: step 14161, loss 0.172616, acc 0.9375\n",
      "2017-04-03T20:09:31.772025: step 14162, loss 0.100052, acc 0.984375\n",
      "2017-04-03T20:09:31.977860: step 14163, loss 0.249044, acc 0.90625\n",
      "2017-04-03T20:09:32.182653: step 14164, loss 0.143112, acc 0.90625\n",
      "2017-04-03T20:09:32.433981: step 14165, loss 0.150644, acc 0.9375\n",
      "2017-04-03T20:09:32.675645: step 14166, loss 0.203995, acc 0.96875\n",
      "2017-04-03T20:09:32.882067: step 14167, loss 0.256939, acc 0.921875\n",
      "2017-04-03T20:09:33.088974: step 14168, loss 0.105431, acc 0.96875\n",
      "2017-04-03T20:09:33.288007: step 14169, loss 0.0724649, acc 1\n",
      "2017-04-03T20:09:33.536417: step 14170, loss 0.151918, acc 0.953125\n",
      "2017-04-03T20:09:33.744214: step 14171, loss 0.0953099, acc 0.984375\n",
      "2017-04-03T20:09:33.951649: step 14172, loss 0.0295471, acc 1\n",
      "2017-04-03T20:09:34.155058: step 14173, loss 0.0523348, acc 0.984375\n",
      "2017-04-03T20:09:34.395718: step 14174, loss 0.168817, acc 0.9375\n",
      "2017-04-03T20:09:34.646867: step 14175, loss 0.109357, acc 0.96875\n",
      "2017-04-03T20:09:34.851259: step 14176, loss 0.136564, acc 0.9375\n",
      "2017-04-03T20:09:35.051107: step 14177, loss 0.171597, acc 0.9375\n",
      "2017-04-03T20:09:35.251439: step 14178, loss 0.1687, acc 0.9375\n",
      "2017-04-03T20:09:35.457434: step 14179, loss 0.279862, acc 0.9375\n",
      "2017-04-03T20:09:35.663286: step 14180, loss 0.0885417, acc 0.96875\n",
      "2017-04-03T20:09:35.862685: step 14181, loss 0.159317, acc 0.953125\n",
      "2017-04-03T20:09:36.064352: step 14182, loss 0.0506441, acc 0.984375\n",
      "2017-04-03T20:09:36.268301: step 14183, loss 0.100841, acc 0.984375\n",
      "2017-04-03T20:09:36.470809: step 14184, loss 0.106204, acc 0.984375\n",
      "2017-04-03T20:09:36.676180: step 14185, loss 0.0941069, acc 0.96875\n",
      "2017-04-03T20:09:36.878574: step 14186, loss 0.111655, acc 0.9375\n",
      "2017-04-03T20:09:37.082502: step 14187, loss 0.132981, acc 0.96875\n",
      "2017-04-03T20:09:37.280041: step 14188, loss 0.211338, acc 0.953125\n",
      "2017-04-03T20:09:37.526216: step 14189, loss 0.193865, acc 0.953125\n",
      "2017-04-03T20:09:37.730892: step 14190, loss 0.129726, acc 0.96875\n",
      "2017-04-03T20:09:37.932922: step 14191, loss 0.0804274, acc 1\n",
      "2017-04-03T20:09:38.135409: step 14192, loss 0.0842627, acc 0.96875\n",
      "2017-04-03T20:09:38.335352: step 14193, loss 0.129483, acc 0.921875\n",
      "2017-04-03T20:09:38.546753: step 14194, loss 0.252346, acc 0.9375\n",
      "2017-04-03T20:09:38.747774: step 14195, loss 0.170109, acc 0.921875\n",
      "2017-04-03T20:09:38.945819: step 14196, loss 0.130527, acc 0.953125\n",
      "2017-04-03T20:09:39.151260: step 14197, loss 0.285204, acc 0.9375\n",
      "2017-04-03T20:09:39.350080: step 14198, loss 0.119164, acc 0.96875\n",
      "2017-04-03T20:09:39.550603: step 14199, loss 0.216931, acc 0.921875\n",
      "2017-04-03T20:09:39.789694: step 14200, loss 0.137912, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:09:41.933775: step 14200, loss 5.71178, acc 0.29475\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-14200\n",
      "\n",
      "2017-04-03T20:09:42.276474: step 14201, loss 0.166213, acc 0.96875\n",
      "2017-04-03T20:09:42.521851: step 14202, loss 0.0549146, acc 1\n",
      "2017-04-03T20:09:42.731379: step 14203, loss 0.182085, acc 0.953125\n",
      "2017-04-03T20:09:42.932731: step 14204, loss 0.0864399, acc 0.984375\n",
      "2017-04-03T20:09:43.134509: step 14205, loss 0.128811, acc 0.984375\n",
      "2017-04-03T20:09:43.336736: step 14206, loss 0.0809679, acc 0.953125\n",
      "2017-04-03T20:09:43.538062: step 14207, loss 0.150447, acc 0.953125\n",
      "2017-04-03T20:09:43.737666: step 14208, loss 0.0789507, acc 0.96875\n",
      "2017-04-03T20:09:43.940671: step 14209, loss 0.0372898, acc 1\n",
      "2017-04-03T20:09:44.148074: step 14210, loss 0.159447, acc 0.953125\n",
      "2017-04-03T20:09:44.356325: step 14211, loss 0.0754784, acc 0.984375\n",
      "2017-04-03T20:09:44.553774: step 14212, loss 0.114958, acc 0.9375\n",
      "2017-04-03T20:09:44.751583: step 14213, loss 0.104349, acc 0.96875\n",
      "2017-04-03T20:09:44.966972: step 14214, loss 0.127964, acc 0.96875\n",
      "2017-04-03T20:09:45.169335: step 14215, loss 0.132885, acc 0.96875\n",
      "2017-04-03T20:09:45.371786: step 14216, loss 0.106817, acc 0.984375\n",
      "2017-04-03T20:09:45.572454: step 14217, loss 0.146958, acc 0.953125\n",
      "2017-04-03T20:09:45.778996: step 14218, loss 0.0997109, acc 0.96875\n",
      "2017-04-03T20:09:45.996335: step 14219, loss 0.0987033, acc 0.953125\n",
      "2017-04-03T20:09:46.199760: step 14220, loss 0.244655, acc 0.953125\n",
      "2017-04-03T20:09:46.400207: step 14221, loss 0.0714232, acc 0.984375\n",
      "2017-04-03T20:09:46.597130: step 14222, loss 0.114718, acc 0.953125\n",
      "2017-04-03T20:09:46.800773: step 14223, loss 0.0789149, acc 0.984375\n",
      "2017-04-03T20:09:47.000859: step 14224, loss 0.0851552, acc 0.96875\n",
      "2017-04-03T20:09:47.201624: step 14225, loss 0.172251, acc 0.953125\n",
      "2017-04-03T20:09:47.407641: step 14226, loss 0.144483, acc 0.953125\n",
      "2017-04-03T20:09:47.613386: step 14227, loss 0.114553, acc 0.96875\n",
      "2017-04-03T20:09:47.811959: step 14228, loss 0.0932876, acc 0.953125\n",
      "2017-04-03T20:09:48.021187: step 14229, loss 0.0824687, acc 0.984375\n",
      "2017-04-03T20:09:48.220815: step 14230, loss 0.271693, acc 0.921875\n",
      "2017-04-03T20:09:48.462409: step 14231, loss 0.182538, acc 0.984375\n",
      "2017-04-03T20:09:48.665805: step 14232, loss 0.108893, acc 0.96875\n",
      "2017-04-03T20:09:48.883509: step 14233, loss 0.136841, acc 0.953125\n",
      "2017-04-03T20:09:49.097638: step 14234, loss 0.232911, acc 0.96875\n",
      "2017-04-03T20:09:49.308074: step 14235, loss 0.121141, acc 0.96875\n",
      "2017-04-03T20:09:49.534925: step 14236, loss 0.159537, acc 0.921875\n",
      "2017-04-03T20:09:49.754841: step 14237, loss 0.108326, acc 0.984375\n",
      "2017-04-03T20:09:49.964939: step 14238, loss 0.261987, acc 0.890625\n",
      "2017-04-03T20:09:50.164384: step 14239, loss 0.131617, acc 0.9375\n",
      "2017-04-03T20:09:50.407016: step 14240, loss 0.0555385, acc 0.96875\n",
      "2017-04-03T20:09:50.608824: step 14241, loss 0.0942613, acc 0.953125\n",
      "2017-04-03T20:09:50.808756: step 14242, loss 0.107223, acc 0.984375\n",
      "2017-04-03T20:09:51.014989: step 14243, loss 0.0817567, acc 0.96875\n",
      "2017-04-03T20:09:51.214436: step 14244, loss 0.0771912, acc 0.953125\n",
      "2017-04-03T20:09:51.421524: step 14245, loss 0.108919, acc 0.984375\n",
      "2017-04-03T20:09:51.636315: step 14246, loss 0.120042, acc 0.953125\n",
      "2017-04-03T20:09:51.856138: step 14247, loss 0.0667624, acc 0.984375\n",
      "2017-04-03T20:09:52.057731: step 14248, loss 0.125465, acc 0.984375\n",
      "2017-04-03T20:09:52.298245: step 14249, loss 0.0487426, acc 1\n",
      "2017-04-03T20:09:52.497246: step 14250, loss 0.114993, acc 0.96875\n",
      "2017-04-03T20:09:52.697108: step 14251, loss 0.108812, acc 0.984375\n",
      "2017-04-03T20:09:52.903735: step 14252, loss 0.19503, acc 0.953125\n",
      "2017-04-03T20:09:53.107203: step 14253, loss 0.125123, acc 0.96875\n",
      "2017-04-03T20:09:53.305674: step 14254, loss 0.0694559, acc 0.984375\n",
      "2017-04-03T20:09:53.508372: step 14255, loss 0.213853, acc 0.953125\n",
      "2017-04-03T20:09:53.709021: step 14256, loss 0.0430169, acc 0.984375\n",
      "2017-04-03T20:09:53.918935: step 14257, loss 0.129923, acc 0.953125\n",
      "2017-04-03T20:09:54.117503: step 14258, loss 0.142035, acc 0.9375\n",
      "2017-04-03T20:09:54.324729: step 14259, loss 0.0951696, acc 0.953125\n",
      "2017-04-03T20:09:54.525691: step 14260, loss 0.237677, acc 0.859375\n",
      "2017-04-03T20:09:54.730784: step 14261, loss 0.083073, acc 0.984375\n",
      "2017-04-03T20:09:54.932732: step 14262, loss 0.0564057, acc 0.984375\n",
      "2017-04-03T20:09:55.136580: step 14263, loss 0.0836362, acc 0.96875\n",
      "2017-04-03T20:09:55.341677: step 14264, loss 0.182506, acc 0.953125\n",
      "2017-04-03T20:09:55.541992: step 14265, loss 0.111544, acc 0.953125\n",
      "2017-04-03T20:09:55.749916: step 14266, loss 0.128145, acc 0.96875\n",
      "2017-04-03T20:09:55.989673: step 14267, loss 0.11062, acc 0.953125\n",
      "2017-04-03T20:09:56.195808: step 14268, loss 0.0768937, acc 0.96875\n",
      "2017-04-03T20:09:56.400745: step 14269, loss 0.237313, acc 0.9375\n",
      "2017-04-03T20:09:56.606125: step 14270, loss 0.135494, acc 0.96875\n",
      "2017-04-03T20:09:56.812648: step 14271, loss 0.137999, acc 0.96875\n",
      "2017-04-03T20:09:57.011957: step 14272, loss 0.0606436, acc 0.984375\n",
      "2017-04-03T20:09:57.211024: step 14273, loss 0.146284, acc 0.96875\n",
      "2017-04-03T20:09:57.410960: step 14274, loss 0.17345, acc 0.984375\n",
      "2017-04-03T20:09:57.617213: step 14275, loss 0.295948, acc 0.890625\n",
      "2017-04-03T20:09:57.820182: step 14276, loss 0.269652, acc 0.921875\n",
      "2017-04-03T20:09:58.016307: step 14277, loss 0.0834606, acc 0.96875\n",
      "2017-04-03T20:09:58.216972: step 14278, loss 0.135642, acc 0.9375\n",
      "2017-04-03T20:09:58.417458: step 14279, loss 0.0506647, acc 1\n",
      "2017-04-03T20:09:58.623890: step 14280, loss 0.08836, acc 0.953125\n",
      "2017-04-03T20:09:58.824933: step 14281, loss 0.0626461, acc 1\n",
      "2017-04-03T20:09:59.038980: step 14282, loss 0.118897, acc 0.96875\n",
      "2017-04-03T20:09:59.255933: step 14283, loss 0.103144, acc 0.984375\n",
      "2017-04-03T20:09:59.457570: step 14284, loss 0.0996663, acc 0.984375\n",
      "2017-04-03T20:09:59.656575: step 14285, loss 0.230153, acc 0.96875\n",
      "2017-04-03T20:09:59.860486: step 14286, loss 0.0828071, acc 0.96875\n",
      "2017-04-03T20:10:00.058976: step 14287, loss 0.0942636, acc 0.9375\n",
      "2017-04-03T20:10:00.261907: step 14288, loss 0.243252, acc 0.9375\n",
      "2017-04-03T20:10:00.461703: step 14289, loss 0.0869104, acc 0.96875\n",
      "2017-04-03T20:10:00.666245: step 14290, loss 0.152938, acc 0.953125\n",
      "2017-04-03T20:10:00.866208: step 14291, loss 0.105617, acc 0.96875\n",
      "2017-04-03T20:10:01.072815: step 14292, loss 0.098848, acc 0.96875\n",
      "2017-04-03T20:10:01.280023: step 14293, loss 0.128407, acc 0.96875\n",
      "2017-04-03T20:10:01.483909: step 14294, loss 0.133347, acc 0.953125\n",
      "2017-04-03T20:10:01.683418: step 14295, loss 0.0586568, acc 0.984375\n",
      "2017-04-03T20:10:01.882796: step 14296, loss 0.19642, acc 0.9375\n",
      "2017-04-03T20:10:02.087681: step 14297, loss 0.076722, acc 0.984375\n",
      "2017-04-03T20:10:02.301785: step 14298, loss 0.0867024, acc 0.96875\n",
      "2017-04-03T20:10:02.493209: step 14299, loss 0.227914, acc 0.921875\n",
      "2017-04-03T20:10:02.737954: step 14300, loss 0.0771332, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:10:04.894242: step 14300, loss 5.74326, acc 0.2965\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-14300\n",
      "\n",
      "2017-04-03T20:10:05.230585: step 14301, loss 0.266977, acc 0.90625\n",
      "2017-04-03T20:10:05.431714: step 14302, loss 0.234045, acc 0.953125\n",
      "2017-04-03T20:10:05.633820: step 14303, loss 0.318596, acc 0.890625\n",
      "2017-04-03T20:10:05.836924: step 14304, loss 0.15133, acc 0.921875\n",
      "2017-04-03T20:10:06.037525: step 14305, loss 0.0565559, acc 0.984375\n",
      "2017-04-03T20:10:06.240829: step 14306, loss 0.104729, acc 0.953125\n",
      "2017-04-03T20:10:06.443635: step 14307, loss 0.148364, acc 0.953125\n",
      "2017-04-03T20:10:06.647166: step 14308, loss 0.154098, acc 0.96875\n",
      "2017-04-03T20:10:06.887557: step 14309, loss 0.0696743, acc 0.96875\n",
      "2017-04-03T20:10:07.100075: step 14310, loss 0.0902331, acc 0.953125\n",
      "2017-04-03T20:10:07.317220: step 14311, loss 0.181162, acc 0.9375\n",
      "2017-04-03T20:10:07.535796: step 14312, loss 0.17337, acc 0.953125\n",
      "2017-04-03T20:10:07.742866: step 14313, loss 0.144665, acc 0.9375\n",
      "2017-04-03T20:10:07.946930: step 14314, loss 0.0336333, acc 1\n",
      "2017-04-03T20:10:08.159257: step 14315, loss 0.145253, acc 0.953125\n",
      "2017-04-03T20:10:08.360416: step 14316, loss 0.144634, acc 0.953125\n",
      "2017-04-03T20:10:08.565865: step 14317, loss 0.143579, acc 0.953125\n",
      "2017-04-03T20:10:08.765062: step 14318, loss 0.110259, acc 0.9375\n",
      "2017-04-03T20:10:08.972070: step 14319, loss 0.223773, acc 0.90625\n",
      "2017-04-03T20:10:09.219623: step 14320, loss 0.169528, acc 0.96875\n",
      "2017-04-03T20:10:09.418021: step 14321, loss 0.353767, acc 0.921875\n",
      "2017-04-03T20:10:09.627576: step 14322, loss 0.138584, acc 0.953125\n",
      "2017-04-03T20:10:09.870186: step 14323, loss 0.0887031, acc 0.96875\n",
      "2017-04-03T20:10:10.120268: step 14324, loss 0.111442, acc 0.953125\n",
      "2017-04-03T20:10:10.323694: step 14325, loss 0.163163, acc 0.953125\n",
      "2017-04-03T20:10:10.525967: step 14326, loss 0.190588, acc 0.953125\n",
      "2017-04-03T20:10:10.726955: step 14327, loss 0.109972, acc 0.984375\n",
      "2017-04-03T20:10:10.930652: step 14328, loss 0.206872, acc 0.953125\n",
      "2017-04-03T20:10:11.144952: step 14329, loss 0.222503, acc 0.921875\n",
      "2017-04-03T20:10:11.346211: step 14330, loss 0.103056, acc 0.984375\n",
      "2017-04-03T20:10:11.597085: step 14331, loss 0.0613403, acc 1\n",
      "2017-04-03T20:10:11.842666: step 14332, loss 0.244879, acc 0.921875\n",
      "2017-04-03T20:10:12.043827: step 14333, loss 0.108968, acc 0.953125\n",
      "2017-04-03T20:10:12.243684: step 14334, loss 0.173315, acc 0.90625\n",
      "2017-04-03T20:10:12.443089: step 14335, loss 0.0781287, acc 0.984375\n",
      "2017-04-03T20:10:12.645461: step 14336, loss 0.124982, acc 0.96875\n",
      "2017-04-03T20:10:12.845965: step 14337, loss 0.0797928, acc 0.984375\n",
      "2017-04-03T20:10:13.043160: step 14338, loss 0.172893, acc 0.921875\n",
      "2017-04-03T20:10:13.242344: step 14339, loss 0.0976001, acc 0.953125\n",
      "2017-04-03T20:10:13.443455: step 14340, loss 0.125353, acc 0.96875\n",
      "2017-04-03T20:10:13.694269: step 14341, loss 0.223154, acc 0.9375\n",
      "2017-04-03T20:10:13.899380: step 14342, loss 0.172396, acc 0.953125\n",
      "2017-04-03T20:10:14.103500: step 14343, loss 0.546985, acc 0.828125\n",
      "2017-04-03T20:10:14.302780: step 14344, loss 0.196714, acc 0.953125\n",
      "2017-04-03T20:10:14.503101: step 14345, loss 0.239847, acc 0.9375\n",
      "2017-04-03T20:10:14.703638: step 14346, loss 0.112883, acc 0.953125\n",
      "2017-04-03T20:10:14.947397: step 14347, loss 0.131454, acc 0.96875\n",
      "2017-04-03T20:10:15.146582: step 14348, loss 0.0406277, acc 0.984375\n",
      "2017-04-03T20:10:15.350804: step 14349, loss 0.221751, acc 0.953125\n",
      "2017-04-03T20:10:15.549156: step 14350, loss 0.0584711, acc 1\n",
      "2017-04-03T20:10:15.750144: step 14351, loss 0.175342, acc 0.953125\n",
      "2017-04-03T20:10:15.950412: step 14352, loss 0.0741668, acc 0.953125\n",
      "2017-04-03T20:10:16.154675: step 14353, loss 0.104115, acc 0.953125\n",
      "2017-04-03T20:10:16.358423: step 14354, loss 0.231873, acc 0.953125\n",
      "2017-04-03T20:10:16.562345: step 14355, loss 0.0991482, acc 0.96875\n",
      "2017-04-03T20:10:16.763312: step 14356, loss 0.0680577, acc 0.984375\n",
      "2017-04-03T20:10:16.966253: step 14357, loss 0.106139, acc 0.953125\n",
      "2017-04-03T20:10:17.164626: step 14358, loss 0.166463, acc 0.9375\n",
      "2017-04-03T20:10:17.368077: step 14359, loss 0.128504, acc 0.96875\n",
      "2017-04-03T20:10:17.570160: step 14360, loss 0.0871636, acc 0.96875\n",
      "2017-04-03T20:10:17.774552: step 14361, loss 0.149804, acc 0.9375\n",
      "2017-04-03T20:10:17.972179: step 14362, loss 0.231713, acc 0.953125\n",
      "2017-04-03T20:10:18.175679: step 14363, loss 0.118808, acc 0.9375\n",
      "2017-04-03T20:10:18.377577: step 14364, loss 0.115819, acc 0.96875\n",
      "2017-04-03T20:10:18.581544: step 14365, loss 0.178239, acc 0.921875\n",
      "2017-04-03T20:10:18.813810: step 14366, loss 0.263093, acc 0.953125\n",
      "2017-04-03T20:10:19.023195: step 14367, loss 0.197525, acc 0.921875\n",
      "2017-04-03T20:10:19.223949: step 14368, loss 0.0615689, acc 0.984375\n",
      "2017-04-03T20:10:19.422665: step 14369, loss 0.106159, acc 0.96875\n",
      "2017-04-03T20:10:19.668772: step 14370, loss 0.172571, acc 0.921875\n",
      "2017-04-03T20:10:19.869310: step 14371, loss 0.0842611, acc 0.96875\n",
      "2017-04-03T20:10:20.075848: step 14372, loss 0.143398, acc 0.953125\n",
      "2017-04-03T20:10:20.284853: step 14373, loss 0.129476, acc 0.921875\n",
      "2017-04-03T20:10:20.491564: step 14374, loss 0.13618, acc 0.953125\n",
      "2017-04-03T20:10:20.694502: step 14375, loss 0.0670949, acc 0.984375\n",
      "2017-04-03T20:10:20.903154: step 14376, loss 0.0825071, acc 0.96875\n",
      "2017-04-03T20:10:21.100401: step 14377, loss 0.154162, acc 0.921875\n",
      "2017-04-03T20:10:21.298198: step 14378, loss 0.150264, acc 0.96875\n",
      "2017-04-03T20:10:21.500167: step 14379, loss 0.106949, acc 0.96875\n",
      "2017-04-03T20:10:21.751045: step 14380, loss 0.185661, acc 0.921875\n",
      "2017-04-03T20:10:21.950810: step 14381, loss 0.114105, acc 0.953125\n",
      "2017-04-03T20:10:22.151632: step 14382, loss 0.052998, acc 1\n",
      "2017-04-03T20:10:22.352828: step 14383, loss 0.237718, acc 0.921875\n",
      "2017-04-03T20:10:22.550173: step 14384, loss 0.20608, acc 0.9375\n",
      "2017-04-03T20:10:22.753644: step 14385, loss 0.0636661, acc 0.96875\n",
      "2017-04-03T20:10:23.004772: step 14386, loss 0.17359, acc 0.9375\n",
      "2017-04-03T20:10:23.211804: step 14387, loss 0.0462672, acc 1\n",
      "2017-04-03T20:10:23.410933: step 14388, loss 0.148636, acc 0.9375\n",
      "2017-04-03T20:10:23.615041: step 14389, loss 0.354507, acc 0.921875\n",
      "2017-04-03T20:10:23.817818: step 14390, loss 0.0845538, acc 0.984375\n",
      "2017-04-03T20:10:24.019507: step 14391, loss 0.207019, acc 0.921875\n",
      "2017-04-03T20:10:24.228012: step 14392, loss 0.121362, acc 0.984375\n",
      "2017-04-03T20:10:24.433069: step 14393, loss 0.0829989, acc 0.984375\n",
      "2017-04-03T20:10:24.632277: step 14394, loss 0.295073, acc 0.90625\n",
      "2017-04-03T20:10:24.826129: step 14395, loss 0.132406, acc 0.953125\n",
      "2017-04-03T20:10:25.035909: step 14396, loss 0.333952, acc 0.90625\n",
      "2017-04-03T20:10:25.238884: step 14397, loss 0.302846, acc 0.96875\n",
      "2017-04-03T20:10:25.437460: step 14398, loss 0.157488, acc 0.953125\n",
      "2017-04-03T20:10:25.639977: step 14399, loss 0.212545, acc 0.921875\n",
      "2017-04-03T20:10:25.844952: step 14400, loss 0.133992, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:10:28.014754: step 14400, loss 5.7682, acc 0.293\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-14400\n",
      "\n",
      "2017-04-03T20:10:28.352714: step 14401, loss 0.389695, acc 0.90625\n",
      "2017-04-03T20:10:28.550012: step 14402, loss 0.139147, acc 0.96875\n",
      "2017-04-03T20:10:28.744791: step 14403, loss 0.111791, acc 0.96875\n",
      "2017-04-03T20:10:28.948935: step 14404, loss 0.167326, acc 0.9375\n",
      "2017-04-03T20:10:29.152237: step 14405, loss 0.101862, acc 0.953125\n",
      "2017-04-03T20:10:29.354638: step 14406, loss 0.176216, acc 0.9375\n",
      "2017-04-03T20:10:29.565137: step 14407, loss 0.179465, acc 0.9375\n",
      "2017-04-03T20:10:29.782048: step 14408, loss 0.480739, acc 0.9375\n",
      "2017-04-03T20:10:29.987027: step 14409, loss 0.163326, acc 0.96875\n",
      "2017-04-03T20:10:30.225654: step 14410, loss 0.137963, acc 0.9375\n",
      "2017-04-03T20:10:30.429362: step 14411, loss 0.1371, acc 0.953125\n",
      "2017-04-03T20:10:30.637817: step 14412, loss 0.181819, acc 0.953125\n",
      "2017-04-03T20:10:30.838859: step 14413, loss 0.160201, acc 0.953125\n",
      "2017-04-03T20:10:31.081539: step 14414, loss 0.250687, acc 0.890625\n",
      "2017-04-03T20:10:31.283727: step 14415, loss 0.435046, acc 0.984375\n",
      "2017-04-03T20:10:31.483596: step 14416, loss 0.120115, acc 0.953125\n",
      "2017-04-03T20:10:31.732613: step 14417, loss 0.246596, acc 0.90625\n",
      "2017-04-03T20:10:31.980554: step 14418, loss 0.134006, acc 0.96875\n",
      "2017-04-03T20:10:32.186972: step 14419, loss 0.064441, acc 0.984375\n",
      "2017-04-03T20:10:32.387097: step 14420, loss 0.100282, acc 0.96875\n",
      "2017-04-03T20:10:32.594660: step 14421, loss 0.132824, acc 0.953125\n",
      "2017-04-03T20:10:32.795633: step 14422, loss 0.404452, acc 0.890625\n",
      "2017-04-03T20:10:33.004461: step 14423, loss 0.15833, acc 0.953125\n",
      "2017-04-03T20:10:33.252322: step 14424, loss 0.109989, acc 0.953125\n",
      "2017-04-03T20:10:33.458560: step 14425, loss 0.345369, acc 0.890625\n",
      "2017-04-03T20:10:33.665659: step 14426, loss 0.0744459, acc 0.96875\n",
      "2017-04-03T20:10:33.872806: step 14427, loss 0.0979796, acc 0.96875\n",
      "2017-04-03T20:10:34.080710: step 14428, loss 0.0957768, acc 0.96875\n",
      "2017-04-03T20:10:34.280192: step 14429, loss 0.0944082, acc 0.96875\n",
      "2017-04-03T20:10:34.481694: step 14430, loss 0.0656823, acc 1\n",
      "2017-04-03T20:10:34.688828: step 14431, loss 0.091312, acc 0.984375\n",
      "2017-04-03T20:10:34.901347: step 14432, loss 0.242691, acc 0.921875\n",
      "2017-04-03T20:10:35.104304: step 14433, loss 0.116888, acc 0.953125\n",
      "2017-04-03T20:10:35.344545: step 14434, loss 0.167448, acc 0.953125\n",
      "2017-04-03T20:10:35.547945: step 14435, loss 0.0876038, acc 0.96875\n",
      "2017-04-03T20:10:35.748410: step 14436, loss 0.235269, acc 0.90625\n",
      "2017-04-03T20:10:35.958326: step 14437, loss 0.0790931, acc 0.953125\n",
      "2017-04-03T20:10:36.158048: step 14438, loss 0.366052, acc 0.9375\n",
      "2017-04-03T20:10:36.360095: step 14439, loss 0.249505, acc 0.921875\n",
      "2017-04-03T20:10:36.561538: step 14440, loss 0.28219, acc 0.890625\n",
      "2017-04-03T20:10:36.768453: step 14441, loss 0.146221, acc 0.953125\n",
      "2017-04-03T20:10:36.973706: step 14442, loss 0.208714, acc 0.9375\n",
      "2017-04-03T20:10:37.176763: step 14443, loss 0.0520991, acc 0.984375\n",
      "2017-04-03T20:10:37.381720: step 14444, loss 0.249136, acc 0.9375\n",
      "2017-04-03T20:10:37.588729: step 14445, loss 0.138494, acc 0.953125\n",
      "2017-04-03T20:10:37.788720: step 14446, loss 0.131002, acc 0.9375\n",
      "2017-04-03T20:10:37.995785: step 14447, loss 0.245906, acc 0.953125\n",
      "2017-04-03T20:10:38.197765: step 14448, loss 0.0747912, acc 0.984375\n",
      "2017-04-03T20:10:38.398777: step 14449, loss 0.125509, acc 0.96875\n",
      "2017-04-03T20:10:38.599800: step 14450, loss 0.212596, acc 0.9375\n",
      "2017-04-03T20:10:38.801221: step 14451, loss 0.0823086, acc 1\n",
      "2017-04-03T20:10:39.013212: step 14452, loss 0.193804, acc 0.9375\n",
      "2017-04-03T20:10:39.214954: step 14453, loss 0.137889, acc 0.953125\n",
      "2017-04-03T20:10:39.422297: step 14454, loss 0.148636, acc 0.953125\n",
      "2017-04-03T20:10:39.628329: step 14455, loss 0.31778, acc 0.875\n",
      "2017-04-03T20:10:39.875556: step 14456, loss 0.196223, acc 0.9375\n",
      "2017-04-03T20:10:40.082087: step 14457, loss 0.0845728, acc 1\n",
      "2017-04-03T20:10:40.278280: step 14458, loss 0.0985769, acc 0.96875\n",
      "2017-04-03T20:10:40.518438: step 14459, loss 0.314582, acc 0.90625\n",
      "2017-04-03T20:10:40.725324: step 14460, loss 0.387176, acc 0.890625\n",
      "2017-04-03T20:10:40.928393: step 14461, loss 0.16183, acc 0.9375\n",
      "2017-04-03T20:10:41.128710: step 14462, loss 0.204127, acc 0.9375\n",
      "2017-04-03T20:10:41.332937: step 14463, loss 0.127302, acc 0.9375\n",
      "2017-04-03T20:10:41.536093: step 14464, loss 0.132216, acc 0.921875\n",
      "2017-04-03T20:10:41.736035: step 14465, loss 0.14333, acc 0.9375\n",
      "2017-04-03T20:10:41.940821: step 14466, loss 0.212357, acc 0.9375\n",
      "2017-04-03T20:10:42.166178: step 14467, loss 0.095057, acc 0.984375\n",
      "2017-04-03T20:10:42.381857: step 14468, loss 0.0864637, acc 0.96875\n",
      "2017-04-03T20:10:42.596318: step 14469, loss 0.0797545, acc 0.96875\n",
      "2017-04-03T20:10:42.800564: step 14470, loss 0.101747, acc 0.96875\n",
      "2017-04-03T20:10:43.003965: step 14471, loss 0.175121, acc 0.953125\n",
      "2017-04-03T20:10:43.201036: step 14472, loss 0.219629, acc 0.921875\n",
      "2017-04-03T20:10:43.406833: step 14473, loss 0.294047, acc 0.9375\n",
      "2017-04-03T20:10:43.616158: step 14474, loss 0.122774, acc 0.96875\n",
      "2017-04-03T20:10:43.843276: step 14475, loss 0.100321, acc 0.96875\n",
      "2017-04-03T20:10:44.062455: step 14476, loss 0.126101, acc 0.9375\n",
      "2017-04-03T20:10:44.263472: step 14477, loss 0.138449, acc 0.953125\n",
      "2017-04-03T20:10:44.463668: step 14478, loss 0.0780348, acc 0.96875\n",
      "2017-04-03T20:10:44.671797: step 14479, loss 0.188442, acc 0.921875\n",
      "2017-04-03T20:10:44.876428: step 14480, loss 0.123907, acc 0.953125\n",
      "2017-04-03T20:10:45.076306: step 14481, loss 0.158904, acc 0.921875\n",
      "2017-04-03T20:10:45.291879: step 14482, loss 0.209168, acc 0.9375\n",
      "2017-04-03T20:10:45.496655: step 14483, loss 0.137038, acc 0.96875\n",
      "2017-04-03T20:10:45.697073: step 14484, loss 0.12556, acc 0.96875\n",
      "2017-04-03T20:10:45.897551: step 14485, loss 0.228238, acc 0.90625\n",
      "2017-04-03T20:10:46.102760: step 14486, loss 0.268065, acc 0.90625\n",
      "2017-04-03T20:10:46.306056: step 14487, loss 0.104614, acc 0.984375\n",
      "2017-04-03T20:10:46.555744: step 14488, loss 0.112991, acc 0.96875\n",
      "2017-04-03T20:10:46.772582: step 14489, loss 0.280223, acc 0.875\n",
      "2017-04-03T20:10:46.968769: step 14490, loss 0.16651, acc 0.953125\n",
      "2017-04-03T20:10:47.169217: step 14491, loss 0.282471, acc 0.921875\n",
      "2017-04-03T20:10:47.370436: step 14492, loss 0.128648, acc 0.9375\n",
      "2017-04-03T20:10:47.582503: step 14493, loss 0.123475, acc 0.953125\n",
      "2017-04-03T20:10:47.786479: step 14494, loss 0.0263695, acc 1\n",
      "2017-04-03T20:10:47.986489: step 14495, loss 0.225659, acc 0.953125\n",
      "2017-04-03T20:10:48.191452: step 14496, loss 0.0465616, acc 0.96875\n",
      "2017-04-03T20:10:48.393713: step 14497, loss 0.131214, acc 0.953125\n",
      "2017-04-03T20:10:48.602399: step 14498, loss 0.0866544, acc 0.953125\n",
      "2017-04-03T20:10:48.803226: step 14499, loss 0.271241, acc 0.921875\n",
      "2017-04-03T20:10:49.002163: step 14500, loss 0.240471, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:10:51.154750: step 14500, loss 5.81772, acc 0.292\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-14500\n",
      "\n",
      "2017-04-03T20:10:51.494344: step 14501, loss 0.0797957, acc 0.984375\n",
      "2017-04-03T20:10:51.697017: step 14502, loss 0.0943487, acc 0.984375\n",
      "2017-04-03T20:10:51.898314: step 14503, loss 0.182115, acc 0.96875\n",
      "2017-04-03T20:10:52.099808: step 14504, loss 0.0837598, acc 1\n",
      "2017-04-03T20:10:52.301172: step 14505, loss 0.185761, acc 0.890625\n",
      "2017-04-03T20:10:52.503970: step 14506, loss 0.156545, acc 0.96875\n",
      "2017-04-03T20:10:52.702903: step 14507, loss 0.0859865, acc 0.96875\n",
      "2017-04-03T20:10:52.911907: step 14508, loss 0.0746076, acc 0.96875\n",
      "2017-04-03T20:10:53.113627: step 14509, loss 0.0800908, acc 0.96875\n",
      "2017-04-03T20:10:53.317865: step 14510, loss 0.215842, acc 0.890625\n",
      "2017-04-03T20:10:53.537623: step 14511, loss 0.185607, acc 0.96875\n",
      "2017-04-03T20:10:53.739083: step 14512, loss 0.0811197, acc 0.953125\n",
      "2017-04-03T20:10:53.954101: step 14513, loss 0.0682878, acc 0.96875\n",
      "2017-04-03T20:10:54.159013: step 14514, loss 0.397637, acc 0.90625\n",
      "2017-04-03T20:10:54.404213: step 14515, loss 0.157647, acc 0.953125\n",
      "2017-04-03T20:10:54.608526: step 14516, loss 0.0698242, acc 0.984375\n",
      "2017-04-03T20:10:54.811543: step 14517, loss 0.125379, acc 0.96875\n",
      "2017-04-03T20:10:55.017517: step 14518, loss 0.0535869, acc 0.984375\n",
      "2017-04-03T20:10:55.220830: step 14519, loss 0.135785, acc 0.96875\n",
      "2017-04-03T20:10:55.424590: step 14520, loss 0.147698, acc 0.9375\n",
      "2017-04-03T20:10:55.629158: step 14521, loss 0.134336, acc 0.953125\n",
      "2017-04-03T20:10:55.831793: step 14522, loss 0.122044, acc 0.953125\n",
      "2017-04-03T20:10:56.032045: step 14523, loss 0.143391, acc 0.96875\n",
      "2017-04-03T20:10:56.245058: step 14524, loss 0.165113, acc 0.9375\n",
      "2017-04-03T20:10:56.447409: step 14525, loss 0.165844, acc 0.9375\n",
      "2017-04-03T20:10:56.645206: step 14526, loss 0.0944967, acc 0.96875\n",
      "2017-04-03T20:10:56.856522: step 14527, loss 0.166932, acc 0.96875\n",
      "2017-04-03T20:10:57.070795: step 14528, loss 0.071225, acc 0.96875\n",
      "2017-04-03T20:10:57.295279: step 14529, loss 0.156734, acc 0.9375\n",
      "2017-04-03T20:10:57.496230: step 14530, loss 0.120537, acc 0.953125\n",
      "2017-04-03T20:10:57.744826: step 14531, loss 0.203043, acc 0.9375\n",
      "2017-04-03T20:10:57.954922: step 14532, loss 0.178577, acc 0.921875\n",
      "2017-04-03T20:10:58.160589: step 14533, loss 0.191331, acc 0.90625\n",
      "2017-04-03T20:10:58.382717: step 14534, loss 0.235473, acc 0.921875\n",
      "2017-04-03T20:10:58.589576: step 14535, loss 0.163774, acc 0.953125\n",
      "2017-04-03T20:10:58.793679: step 14536, loss 0.137233, acc 0.96875\n",
      "2017-04-03T20:10:59.007321: step 14537, loss 0.100136, acc 0.9375\n",
      "2017-04-03T20:10:59.260590: step 14538, loss 0.162254, acc 0.953125\n",
      "2017-04-03T20:10:59.509909: step 14539, loss 0.127271, acc 0.953125\n",
      "2017-04-03T20:10:59.714605: step 14540, loss 0.128612, acc 0.96875\n",
      "2017-04-03T20:10:59.915274: step 14541, loss 0.256558, acc 0.890625\n",
      "2017-04-03T20:11:00.121894: step 14542, loss 0.192647, acc 0.953125\n",
      "2017-04-03T20:11:00.342968: step 14543, loss 0.13683, acc 0.953125\n",
      "2017-04-03T20:11:00.555478: step 14544, loss 0.200754, acc 0.890625\n",
      "2017-04-03T20:11:00.763777: step 14545, loss 0.191925, acc 0.90625\n",
      "2017-04-03T20:11:00.969107: step 14546, loss 0.176066, acc 0.953125\n",
      "2017-04-03T20:11:01.175000: step 14547, loss 0.568207, acc 0.890625\n",
      "2017-04-03T20:11:01.379529: step 14548, loss 0.218882, acc 0.90625\n",
      "2017-04-03T20:11:01.582041: step 14549, loss 0.18285, acc 0.9375\n",
      "2017-04-03T20:11:01.779916: step 14550, loss 0.18791, acc 0.9375\n",
      "2017-04-03T20:11:01.978544: step 14551, loss 0.156291, acc 0.9375\n",
      "2017-04-03T20:11:02.190980: step 14552, loss 0.181181, acc 0.921875\n",
      "2017-04-03T20:11:02.394691: step 14553, loss 0.11854, acc 0.96875\n",
      "2017-04-03T20:11:02.598984: step 14554, loss 0.053655, acc 0.984375\n",
      "2017-04-03T20:11:02.798783: step 14555, loss 0.172036, acc 0.953125\n",
      "2017-04-03T20:11:03.006036: step 14556, loss 0.0253478, acc 1\n",
      "2017-04-03T20:11:03.207129: step 14557, loss 0.0363914, acc 1\n",
      "2017-04-03T20:11:03.412177: step 14558, loss 0.102985, acc 0.984375\n",
      "2017-04-03T20:11:03.618856: step 14559, loss 0.109401, acc 0.953125\n",
      "2017-04-03T20:11:03.822995: step 14560, loss 0.0419059, acc 0.984375\n",
      "2017-04-03T20:11:04.028324: step 14561, loss 0.297588, acc 0.875\n",
      "2017-04-03T20:11:04.224969: step 14562, loss 0.0986509, acc 0.984375\n",
      "2017-04-03T20:11:04.438475: step 14563, loss 0.274908, acc 0.890625\n",
      "2017-04-03T20:11:04.640736: step 14564, loss 0.279914, acc 0.9375\n",
      "2017-04-03T20:11:04.852292: step 14565, loss 0.112843, acc 0.953125\n",
      "2017-04-03T20:11:05.054100: step 14566, loss 0.1782, acc 0.921875\n",
      "2017-04-03T20:11:05.256305: step 14567, loss 0.147941, acc 0.953125\n",
      "2017-04-03T20:11:05.460430: step 14568, loss 0.124033, acc 0.953125\n",
      "2017-04-03T20:11:05.700109: step 14569, loss 0.33424, acc 0.953125\n",
      "2017-04-03T20:11:05.906060: step 14570, loss 0.170833, acc 0.984375\n",
      "2017-04-03T20:11:06.111633: step 14571, loss 0.186304, acc 0.953125\n",
      "2017-04-03T20:11:06.310719: step 14572, loss 0.150407, acc 0.9375\n",
      "2017-04-03T20:11:06.511717: step 14573, loss 0.0915509, acc 0.96875\n",
      "2017-04-03T20:11:06.717588: step 14574, loss 0.114217, acc 0.96875\n",
      "2017-04-03T20:11:06.928731: step 14575, loss 0.151321, acc 0.96875\n",
      "2017-04-03T20:11:07.131916: step 14576, loss 0.223564, acc 0.9375\n",
      "2017-04-03T20:11:07.339822: step 14577, loss 0.217031, acc 0.9375\n",
      "2017-04-03T20:11:07.592367: step 14578, loss 0.182213, acc 0.96875\n",
      "2017-04-03T20:11:07.797196: step 14579, loss 0.198616, acc 0.90625\n",
      "2017-04-03T20:11:08.000228: step 14580, loss 0.188365, acc 0.9375\n",
      "2017-04-03T20:11:08.217949: step 14581, loss 0.127728, acc 0.953125\n",
      "2017-04-03T20:11:08.434503: step 14582, loss 0.120497, acc 0.984375\n",
      "2017-04-03T20:11:08.684446: step 14583, loss 0.185486, acc 0.953125\n",
      "2017-04-03T20:11:08.892899: step 14584, loss 0.19063, acc 0.921875\n",
      "2017-04-03T20:11:09.097478: step 14585, loss 0.112466, acc 0.9375\n",
      "2017-04-03T20:11:09.295404: step 14586, loss 0.261692, acc 0.890625\n",
      "2017-04-03T20:11:09.544260: step 14587, loss 0.116172, acc 0.96875\n",
      "2017-04-03T20:11:09.757831: step 14588, loss 0.203184, acc 0.921875\n",
      "2017-04-03T20:11:09.963280: step 14589, loss 0.147397, acc 0.9375\n",
      "2017-04-03T20:11:10.168608: step 14590, loss 0.185849, acc 0.90625\n",
      "2017-04-03T20:11:10.370997: step 14591, loss 0.0892983, acc 0.984375\n",
      "2017-04-03T20:11:10.573366: step 14592, loss 0.195059, acc 0.953125\n",
      "2017-04-03T20:11:10.768631: step 14593, loss 0.0781349, acc 0.96875\n",
      "2017-04-03T20:11:10.972287: step 14594, loss 0.12349, acc 0.96875\n",
      "2017-04-03T20:11:11.184668: step 14595, loss 0.182523, acc 0.953125\n",
      "2017-04-03T20:11:11.395775: step 14596, loss 0.103165, acc 0.9375\n",
      "2017-04-03T20:11:11.602968: step 14597, loss 0.113579, acc 0.953125\n",
      "2017-04-03T20:11:11.815579: step 14598, loss 0.232753, acc 0.953125\n",
      "2017-04-03T20:11:12.064333: step 14599, loss 0.169904, acc 0.96875\n",
      "2017-04-03T20:11:12.280849: step 14600, loss 0.298176, acc 0.859375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:11:14.404977: step 14600, loss 5.81423, acc 0.29575\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-14600\n",
      "\n",
      "2017-04-03T20:11:14.751041: step 14601, loss 0.0405824, acc 1\n",
      "2017-04-03T20:11:14.970013: step 14602, loss 0.115617, acc 0.953125\n",
      "2017-04-03T20:11:15.173470: step 14603, loss 0.326674, acc 0.890625\n",
      "2017-04-03T20:11:15.420981: step 14604, loss 0.370093, acc 0.90625\n",
      "2017-04-03T20:11:15.622984: step 14605, loss 0.225734, acc 0.921875\n",
      "2017-04-03T20:11:15.827126: step 14606, loss 0.0772855, acc 0.984375\n",
      "2017-04-03T20:11:16.032751: step 14607, loss 0.111838, acc 0.953125\n",
      "2017-04-03T20:11:16.236967: step 14608, loss 0.0867941, acc 0.984375\n",
      "2017-04-03T20:11:16.438064: step 14609, loss 0.157907, acc 0.96875\n",
      "2017-04-03T20:11:16.641678: step 14610, loss 0.0868357, acc 0.984375\n",
      "2017-04-03T20:11:16.841712: step 14611, loss 0.203196, acc 0.90625\n",
      "2017-04-03T20:11:17.045176: step 14612, loss 0.155756, acc 0.953125\n",
      "2017-04-03T20:11:17.250837: step 14613, loss 0.0985278, acc 0.984375\n",
      "2017-04-03T20:11:17.455913: step 14614, loss 0.157611, acc 0.96875\n",
      "2017-04-03T20:11:17.664867: step 14615, loss 0.0887813, acc 0.96875\n",
      "2017-04-03T20:11:17.890812: step 14616, loss 0.253969, acc 0.90625\n",
      "2017-04-03T20:11:18.108617: step 14617, loss 0.165347, acc 0.953125\n",
      "2017-04-03T20:11:18.352356: step 14618, loss 0.192226, acc 0.9375\n",
      "2017-04-03T20:11:18.556610: step 14619, loss 0.208103, acc 0.921875\n",
      "2017-04-03T20:11:18.760211: step 14620, loss 0.124756, acc 0.953125\n",
      "2017-04-03T20:11:18.964146: step 14621, loss 0.28964, acc 0.875\n",
      "2017-04-03T20:11:19.162244: step 14622, loss 0.101497, acc 0.984375\n",
      "2017-04-03T20:11:19.381762: step 14623, loss 0.161575, acc 0.953125\n",
      "2017-04-03T20:11:19.585938: step 14624, loss 0.187758, acc 0.921875\n",
      "2017-04-03T20:11:19.787858: step 14625, loss 0.1345, acc 0.953125\n",
      "2017-04-03T20:11:20.003060: step 14626, loss 0.129837, acc 0.9375\n",
      "2017-04-03T20:11:20.208042: step 14627, loss 0.166643, acc 0.921875\n",
      "2017-04-03T20:11:20.410454: step 14628, loss 0.117194, acc 0.953125\n",
      "2017-04-03T20:11:20.612338: step 14629, loss 0.282064, acc 0.921875\n",
      "2017-04-03T20:11:20.820946: step 14630, loss 0.113521, acc 0.96875\n",
      "2017-04-03T20:11:21.028011: step 14631, loss 0.194479, acc 0.90625\n",
      "2017-04-03T20:11:21.233424: step 14632, loss 0.0871716, acc 0.96875\n",
      "2017-04-03T20:11:21.440806: step 14633, loss 0.116675, acc 0.96875\n",
      "2017-04-03T20:11:21.642507: step 14634, loss 0.233874, acc 0.9375\n",
      "2017-04-03T20:11:21.845206: step 14635, loss 0.287477, acc 0.90625\n",
      "2017-04-03T20:11:22.093439: step 14636, loss 0.151311, acc 0.9375\n",
      "2017-04-03T20:11:22.341089: step 14637, loss 0.040981, acc 1\n",
      "2017-04-03T20:11:22.487302: step 14638, loss 0.190183, acc 0.9375\n",
      "2017-04-03T20:11:22.735086: step 14639, loss 0.138948, acc 0.96875\n",
      "2017-04-03T20:11:22.938918: step 14640, loss 0.0463975, acc 0.984375\n",
      "2017-04-03T20:11:23.147397: step 14641, loss 0.0866333, acc 0.953125\n",
      "2017-04-03T20:11:23.350898: step 14642, loss 0.107052, acc 0.953125\n",
      "2017-04-03T20:11:23.553608: step 14643, loss 0.155466, acc 0.921875\n",
      "2017-04-03T20:11:23.754734: step 14644, loss 0.255762, acc 0.90625\n",
      "2017-04-03T20:11:23.958672: step 14645, loss 0.259738, acc 0.921875\n",
      "2017-04-03T20:11:24.171528: step 14646, loss 0.167944, acc 0.953125\n",
      "2017-04-03T20:11:24.372569: step 14647, loss 0.0416915, acc 1\n",
      "2017-04-03T20:11:24.575097: step 14648, loss 0.138072, acc 0.953125\n",
      "2017-04-03T20:11:24.783476: step 14649, loss 0.135606, acc 0.9375\n",
      "2017-04-03T20:11:24.991498: step 14650, loss 0.206291, acc 0.9375\n",
      "2017-04-03T20:11:25.190907: step 14651, loss 0.0826988, acc 1\n",
      "2017-04-03T20:11:25.393979: step 14652, loss 0.0488935, acc 0.984375\n",
      "2017-04-03T20:11:25.596042: step 14653, loss 0.0787154, acc 0.96875\n",
      "2017-04-03T20:11:25.793223: step 14654, loss 0.192499, acc 0.953125\n",
      "2017-04-03T20:11:25.991169: step 14655, loss 0.101704, acc 0.984375\n",
      "2017-04-03T20:11:26.196847: step 14656, loss 0.0684439, acc 0.984375\n",
      "2017-04-03T20:11:26.442532: step 14657, loss 0.0868701, acc 0.96875\n",
      "2017-04-03T20:11:26.651372: step 14658, loss 0.117827, acc 0.953125\n",
      "2017-04-03T20:11:26.859116: step 14659, loss 0.130441, acc 0.984375\n",
      "2017-04-03T20:11:27.061799: step 14660, loss 0.0840955, acc 0.984375\n",
      "2017-04-03T20:11:27.263587: step 14661, loss 0.144784, acc 0.9375\n",
      "2017-04-03T20:11:27.468919: step 14662, loss 0.0792465, acc 0.96875\n",
      "2017-04-03T20:11:27.668323: step 14663, loss 0.0703551, acc 0.96875\n",
      "2017-04-03T20:11:27.871203: step 14664, loss 0.191825, acc 0.953125\n",
      "2017-04-03T20:11:28.073057: step 14665, loss 0.178073, acc 0.921875\n",
      "2017-04-03T20:11:28.272147: step 14666, loss 0.131988, acc 0.9375\n",
      "2017-04-03T20:11:28.473544: step 14667, loss 0.101915, acc 0.953125\n",
      "2017-04-03T20:11:28.684202: step 14668, loss 0.0628613, acc 0.96875\n",
      "2017-04-03T20:11:28.887809: step 14669, loss 0.0853586, acc 0.96875\n",
      "2017-04-03T20:11:29.092516: step 14670, loss 0.0999857, acc 0.953125\n",
      "2017-04-03T20:11:29.341094: step 14671, loss 0.14936, acc 0.953125\n",
      "2017-04-03T20:11:29.542565: step 14672, loss 0.202818, acc 0.9375\n",
      "2017-04-03T20:11:29.743740: step 14673, loss 0.179246, acc 0.953125\n",
      "2017-04-03T20:11:29.946563: step 14674, loss 0.150554, acc 0.9375\n",
      "2017-04-03T20:11:30.150897: step 14675, loss 0.193433, acc 0.9375\n",
      "2017-04-03T20:11:30.357267: step 14676, loss 0.108941, acc 0.984375\n",
      "2017-04-03T20:11:30.561559: step 14677, loss 0.161877, acc 0.96875\n",
      "2017-04-03T20:11:30.767153: step 14678, loss 0.14018, acc 0.953125\n",
      "2017-04-03T20:11:30.972879: step 14679, loss 0.0359535, acc 0.984375\n",
      "2017-04-03T20:11:31.183365: step 14680, loss 0.183774, acc 0.953125\n",
      "2017-04-03T20:11:31.390368: step 14681, loss 0.104827, acc 0.984375\n",
      "2017-04-03T20:11:31.596902: step 14682, loss 0.0681763, acc 0.984375\n",
      "2017-04-03T20:11:31.802507: step 14683, loss 0.200576, acc 0.921875\n",
      "2017-04-03T20:11:32.004974: step 14684, loss 0.0644713, acc 1\n",
      "2017-04-03T20:11:32.203974: step 14685, loss 0.168412, acc 0.953125\n",
      "2017-04-03T20:11:32.423449: step 14686, loss 0.15946, acc 0.953125\n",
      "2017-04-03T20:11:32.633779: step 14687, loss 0.161384, acc 0.9375\n",
      "2017-04-03T20:11:32.836301: step 14688, loss 0.111104, acc 0.953125\n",
      "2017-04-03T20:11:33.034601: step 14689, loss 0.0865719, acc 0.96875\n",
      "2017-04-03T20:11:33.237133: step 14690, loss 0.248963, acc 0.9375\n",
      "2017-04-03T20:11:33.437933: step 14691, loss 0.0816303, acc 0.984375\n",
      "2017-04-03T20:11:33.641160: step 14692, loss 0.120377, acc 0.953125\n",
      "2017-04-03T20:11:33.842767: step 14693, loss 0.168895, acc 0.921875\n",
      "2017-04-03T20:11:34.046267: step 14694, loss 0.0751228, acc 0.96875\n",
      "2017-04-03T20:11:34.250002: step 14695, loss 0.0531663, acc 1\n",
      "2017-04-03T20:11:34.500239: step 14696, loss 0.101109, acc 0.96875\n",
      "2017-04-03T20:11:34.704756: step 14697, loss 0.197855, acc 0.9375\n",
      "2017-04-03T20:11:34.910722: step 14698, loss 0.104707, acc 0.96875\n",
      "2017-04-03T20:11:35.113294: step 14699, loss 0.179907, acc 0.953125\n",
      "2017-04-03T20:11:35.316262: step 14700, loss 0.0793007, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:11:37.474085: step 14700, loss 5.7876, acc 0.29775\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-14700\n",
      "\n",
      "2017-04-03T20:11:37.810796: step 14701, loss 0.146632, acc 0.9375\n",
      "2017-04-03T20:11:38.035588: step 14702, loss 0.200978, acc 0.90625\n",
      "2017-04-03T20:11:38.236704: step 14703, loss 0.134242, acc 0.96875\n",
      "2017-04-03T20:11:38.443240: step 14704, loss 0.222062, acc 0.953125\n",
      "2017-04-03T20:11:38.664131: step 14705, loss 0.0958084, acc 0.984375\n",
      "2017-04-03T20:11:38.908998: step 14706, loss 0.0727027, acc 0.96875\n",
      "2017-04-03T20:11:39.111921: step 14707, loss 0.135515, acc 0.96875\n",
      "2017-04-03T20:11:39.354550: step 14708, loss 0.0485993, acc 0.984375\n",
      "2017-04-03T20:11:39.577253: step 14709, loss 0.376509, acc 0.84375\n",
      "2017-04-03T20:11:39.778963: step 14710, loss 0.0579185, acc 0.96875\n",
      "2017-04-03T20:11:39.991626: step 14711, loss 0.0944311, acc 0.96875\n",
      "2017-04-03T20:11:40.197132: step 14712, loss 0.444337, acc 0.90625\n",
      "2017-04-03T20:11:40.398239: step 14713, loss 0.185335, acc 0.953125\n",
      "2017-04-03T20:11:40.600627: step 14714, loss 0.180915, acc 0.953125\n",
      "2017-04-03T20:11:40.806076: step 14715, loss 0.103467, acc 0.9375\n",
      "2017-04-03T20:11:41.007833: step 14716, loss 0.18769, acc 0.9375\n",
      "2017-04-03T20:11:41.214923: step 14717, loss 0.0406553, acc 1\n",
      "2017-04-03T20:11:41.417242: step 14718, loss 0.0842509, acc 0.984375\n",
      "2017-04-03T20:11:41.675644: step 14719, loss 0.131817, acc 0.953125\n",
      "2017-04-03T20:11:41.898948: step 14720, loss 0.120054, acc 0.953125\n",
      "2017-04-03T20:11:42.130908: step 14721, loss 0.0553086, acc 1\n",
      "2017-04-03T20:11:42.369455: step 14722, loss 0.107447, acc 0.953125\n",
      "2017-04-03T20:11:42.599306: step 14723, loss 0.211495, acc 0.921875\n",
      "2017-04-03T20:11:42.817721: step 14724, loss 0.0536651, acc 0.984375\n",
      "2017-04-03T20:11:43.028199: step 14725, loss 0.175604, acc 0.90625\n",
      "2017-04-03T20:11:43.240063: step 14726, loss 0.0927432, acc 0.984375\n",
      "2017-04-03T20:11:43.494867: step 14727, loss 0.0978803, acc 0.96875\n",
      "2017-04-03T20:11:43.738982: step 14728, loss 0.0443904, acc 1\n",
      "2017-04-03T20:11:43.941975: step 14729, loss 0.227623, acc 0.921875\n",
      "2017-04-03T20:11:44.148152: step 14730, loss 0.0977342, acc 0.96875\n",
      "2017-04-03T20:11:44.354253: step 14731, loss 0.089921, acc 0.984375\n",
      "2017-04-03T20:11:44.556289: step 14732, loss 0.0678661, acc 0.96875\n",
      "2017-04-03T20:11:44.762455: step 14733, loss 0.120056, acc 0.953125\n",
      "2017-04-03T20:11:44.968360: step 14734, loss 0.0525258, acc 0.984375\n",
      "2017-04-03T20:11:45.173130: step 14735, loss 0.11874, acc 0.953125\n",
      "2017-04-03T20:11:45.372431: step 14736, loss 0.0496421, acc 1\n",
      "2017-04-03T20:11:45.578218: step 14737, loss 0.158779, acc 0.953125\n",
      "2017-04-03T20:11:45.777563: step 14738, loss 0.0271209, acc 0.984375\n",
      "2017-04-03T20:11:45.984001: step 14739, loss 0.191946, acc 0.921875\n",
      "2017-04-03T20:11:46.190164: step 14740, loss 0.11642, acc 0.96875\n",
      "2017-04-03T20:11:46.434720: step 14741, loss 0.0686456, acc 1\n",
      "2017-04-03T20:11:46.638423: step 14742, loss 0.0648908, acc 0.96875\n",
      "2017-04-03T20:11:46.846147: step 14743, loss 0.176299, acc 0.9375\n",
      "2017-04-03T20:11:47.063784: step 14744, loss 0.0650149, acc 0.984375\n",
      "2017-04-03T20:11:47.283448: step 14745, loss 0.144165, acc 0.9375\n",
      "2017-04-03T20:11:47.484621: step 14746, loss 0.0859189, acc 0.953125\n",
      "2017-04-03T20:11:47.691622: step 14747, loss 0.0423357, acc 1\n",
      "2017-04-03T20:11:47.899659: step 14748, loss 0.186645, acc 0.953125\n",
      "2017-04-03T20:11:48.101328: step 14749, loss 0.303373, acc 0.921875\n",
      "2017-04-03T20:11:48.308425: step 14750, loss 0.0866742, acc 0.96875\n",
      "2017-04-03T20:11:48.509446: step 14751, loss 0.176378, acc 0.9375\n",
      "2017-04-03T20:11:48.715938: step 14752, loss 0.174097, acc 0.921875\n",
      "2017-04-03T20:11:48.956008: step 14753, loss 0.119508, acc 0.96875\n",
      "2017-04-03T20:11:49.172420: step 14754, loss 0.0931076, acc 0.953125\n",
      "2017-04-03T20:11:49.387832: step 14755, loss 0.071759, acc 1\n",
      "2017-04-03T20:11:49.594200: step 14756, loss 0.240538, acc 0.9375\n",
      "2017-04-03T20:11:49.802976: step 14757, loss 0.194683, acc 0.96875\n",
      "2017-04-03T20:11:50.003895: step 14758, loss 0.140547, acc 0.9375\n",
      "2017-04-03T20:11:50.207979: step 14759, loss 0.186573, acc 0.90625\n",
      "2017-04-03T20:11:50.408717: step 14760, loss 0.0741123, acc 0.984375\n",
      "2017-04-03T20:11:50.616933: step 14761, loss 0.213478, acc 0.96875\n",
      "2017-04-03T20:11:50.819733: step 14762, loss 0.169256, acc 0.953125\n",
      "2017-04-03T20:11:51.024774: step 14763, loss 0.053683, acc 0.96875\n",
      "2017-04-03T20:11:51.234263: step 14764, loss 0.183836, acc 0.890625\n",
      "2017-04-03T20:11:51.435507: step 14765, loss 0.140004, acc 0.9375\n",
      "2017-04-03T20:11:51.634167: step 14766, loss 0.0971754, acc 0.96875\n",
      "2017-04-03T20:11:51.840526: step 14767, loss 0.230672, acc 0.953125\n",
      "2017-04-03T20:11:52.044294: step 14768, loss 0.128861, acc 0.96875\n",
      "2017-04-03T20:11:52.248623: step 14769, loss 0.195016, acc 0.953125\n",
      "2017-04-03T20:11:52.497917: step 14770, loss 0.148846, acc 0.96875\n",
      "2017-04-03T20:11:52.703139: step 14771, loss 0.203835, acc 0.9375\n",
      "2017-04-03T20:11:52.907723: step 14772, loss 0.177936, acc 0.9375\n",
      "2017-04-03T20:11:53.114610: step 14773, loss 0.164332, acc 0.96875\n",
      "2017-04-03T20:11:53.316650: step 14774, loss 0.149533, acc 0.953125\n",
      "2017-04-03T20:11:53.521814: step 14775, loss 0.0928964, acc 0.984375\n",
      "2017-04-03T20:11:53.719879: step 14776, loss 0.11699, acc 0.953125\n",
      "2017-04-03T20:11:53.921126: step 14777, loss 0.223032, acc 0.9375\n",
      "2017-04-03T20:11:54.123489: step 14778, loss 0.14115, acc 0.953125\n",
      "2017-04-03T20:11:54.326719: step 14779, loss 0.195334, acc 0.953125\n",
      "2017-04-03T20:11:54.525254: step 14780, loss 0.215382, acc 0.90625\n",
      "2017-04-03T20:11:54.730592: step 14781, loss 0.1552, acc 0.953125\n",
      "2017-04-03T20:11:54.934044: step 14782, loss 0.201944, acc 0.9375\n",
      "2017-04-03T20:11:55.134077: step 14783, loss 0.060031, acc 0.984375\n",
      "2017-04-03T20:11:55.352170: step 14784, loss 0.130972, acc 0.96875\n",
      "2017-04-03T20:11:55.569110: step 14785, loss 0.105006, acc 0.96875\n",
      "2017-04-03T20:11:55.772089: step 14786, loss 0.126857, acc 0.96875\n",
      "2017-04-03T20:11:55.971314: step 14787, loss 0.244676, acc 0.921875\n",
      "2017-04-03T20:11:56.170681: step 14788, loss 0.0947493, acc 0.96875\n",
      "2017-04-03T20:11:56.379544: step 14789, loss 0.205646, acc 0.984375\n",
      "2017-04-03T20:11:56.584876: step 14790, loss 0.199406, acc 0.90625\n",
      "2017-04-03T20:11:56.783240: step 14791, loss 0.0848999, acc 0.984375\n",
      "2017-04-03T20:11:56.989538: step 14792, loss 0.183832, acc 0.953125\n",
      "2017-04-03T20:11:57.193602: step 14793, loss 0.167579, acc 0.921875\n",
      "2017-04-03T20:11:57.392720: step 14794, loss 0.155522, acc 0.921875\n",
      "2017-04-03T20:11:57.594403: step 14795, loss 0.10552, acc 0.953125\n",
      "2017-04-03T20:11:57.801865: step 14796, loss 0.181323, acc 0.9375\n",
      "2017-04-03T20:11:58.006188: step 14797, loss 0.123567, acc 0.96875\n",
      "2017-04-03T20:11:58.210403: step 14798, loss 0.186531, acc 0.953125\n",
      "2017-04-03T20:11:58.411887: step 14799, loss 0.149132, acc 0.921875\n",
      "2017-04-03T20:11:58.616314: step 14800, loss 0.0445601, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:12:00.747750: step 14800, loss 5.86319, acc 0.293\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-14800\n",
      "\n",
      "2017-04-03T20:12:01.087574: step 14801, loss 0.049449, acc 1\n",
      "2017-04-03T20:12:01.329404: step 14802, loss 0.134346, acc 0.96875\n",
      "2017-04-03T20:12:01.549661: step 14803, loss 0.0336647, acc 1\n",
      "2017-04-03T20:12:01.750815: step 14804, loss 0.16123, acc 0.90625\n",
      "2017-04-03T20:12:01.952037: step 14805, loss 0.156105, acc 0.953125\n",
      "2017-04-03T20:12:02.153499: step 14806, loss 0.104203, acc 0.953125\n",
      "2017-04-03T20:12:02.356995: step 14807, loss 0.0699571, acc 0.984375\n",
      "2017-04-03T20:12:02.558059: step 14808, loss 0.106118, acc 0.984375\n",
      "2017-04-03T20:12:02.757165: step 14809, loss 0.248926, acc 0.921875\n",
      "2017-04-03T20:12:02.964967: step 14810, loss 0.145567, acc 0.953125\n",
      "2017-04-03T20:12:03.165629: step 14811, loss 0.128847, acc 0.953125\n",
      "2017-04-03T20:12:03.412325: step 14812, loss 0.0744928, acc 0.96875\n",
      "2017-04-03T20:12:03.616325: step 14813, loss 0.113624, acc 0.96875\n",
      "2017-04-03T20:12:03.823997: step 14814, loss 0.270047, acc 0.921875\n",
      "2017-04-03T20:12:04.025807: step 14815, loss 0.0683664, acc 0.984375\n",
      "2017-04-03T20:12:04.227091: step 14816, loss 0.0852103, acc 0.984375\n",
      "2017-04-03T20:12:04.433801: step 14817, loss 0.107465, acc 0.953125\n",
      "2017-04-03T20:12:04.635988: step 14818, loss 0.0809035, acc 0.96875\n",
      "2017-04-03T20:12:04.834691: step 14819, loss 0.0877133, acc 1\n",
      "2017-04-03T20:12:05.038593: step 14820, loss 0.145471, acc 0.953125\n",
      "2017-04-03T20:12:05.237953: step 14821, loss 0.0850396, acc 0.96875\n",
      "2017-04-03T20:12:05.464959: step 14822, loss 0.0396145, acc 0.984375\n",
      "2017-04-03T20:12:05.667701: step 14823, loss 0.0857836, acc 0.96875\n",
      "2017-04-03T20:12:05.917046: step 14824, loss 0.0671026, acc 1\n",
      "2017-04-03T20:12:06.114852: step 14825, loss 0.224887, acc 0.9375\n",
      "2017-04-03T20:12:06.315630: step 14826, loss 0.136239, acc 0.96875\n",
      "2017-04-03T20:12:06.516834: step 14827, loss 0.142463, acc 0.953125\n",
      "2017-04-03T20:12:06.718778: step 14828, loss 0.0875157, acc 0.9375\n",
      "2017-04-03T20:12:06.923280: step 14829, loss 0.240855, acc 0.90625\n",
      "2017-04-03T20:12:07.124369: step 14830, loss 0.119986, acc 0.96875\n",
      "2017-04-03T20:12:07.323415: step 14831, loss 0.114157, acc 0.9375\n",
      "2017-04-03T20:12:07.524933: step 14832, loss 0.236298, acc 0.96875\n",
      "2017-04-03T20:12:07.726725: step 14833, loss 0.0743038, acc 0.984375\n",
      "2017-04-03T20:12:07.935740: step 14834, loss 0.150385, acc 0.953125\n",
      "2017-04-03T20:12:08.142486: step 14835, loss 0.14686, acc 0.953125\n",
      "2017-04-03T20:12:08.344092: step 14836, loss 0.105966, acc 0.953125\n",
      "2017-04-03T20:12:08.544323: step 14837, loss 0.112867, acc 0.9375\n",
      "2017-04-03T20:12:08.757903: step 14838, loss 0.217557, acc 0.96875\n",
      "2017-04-03T20:12:08.961506: step 14839, loss 0.0929595, acc 0.953125\n",
      "2017-04-03T20:12:09.162227: step 14840, loss 0.101975, acc 0.96875\n",
      "2017-04-03T20:12:09.362301: step 14841, loss 0.112009, acc 0.96875\n",
      "2017-04-03T20:12:09.564381: step 14842, loss 0.149238, acc 0.953125\n",
      "2017-04-03T20:12:09.763539: step 14843, loss 0.0466559, acc 0.984375\n",
      "2017-04-03T20:12:10.010257: step 14844, loss 0.0811395, acc 0.984375\n",
      "2017-04-03T20:12:10.220735: step 14845, loss 0.0877417, acc 0.96875\n",
      "2017-04-03T20:12:10.425472: step 14846, loss 0.148258, acc 0.921875\n",
      "2017-04-03T20:12:10.635574: step 14847, loss 0.147084, acc 0.953125\n",
      "2017-04-03T20:12:10.838747: step 14848, loss 0.10682, acc 0.96875\n",
      "2017-04-03T20:12:11.042489: step 14849, loss 0.0984325, acc 0.96875\n",
      "2017-04-03T20:12:11.247525: step 14850, loss 0.123833, acc 0.921875\n",
      "2017-04-03T20:12:11.488775: step 14851, loss 0.147862, acc 0.9375\n",
      "2017-04-03T20:12:11.691105: step 14852, loss 0.0867994, acc 0.96875\n",
      "2017-04-03T20:12:11.895107: step 14853, loss 0.104998, acc 0.953125\n",
      "2017-04-03T20:12:12.096962: step 14854, loss 0.190094, acc 0.9375\n",
      "2017-04-03T20:12:12.296383: step 14855, loss 0.243305, acc 0.953125\n",
      "2017-04-03T20:12:12.502677: step 14856, loss 0.210353, acc 0.921875\n",
      "2017-04-03T20:12:12.704906: step 14857, loss 0.162249, acc 0.953125\n",
      "2017-04-03T20:12:12.903892: step 14858, loss 0.11738, acc 0.96875\n",
      "2017-04-03T20:12:13.107036: step 14859, loss 0.106333, acc 0.96875\n",
      "2017-04-03T20:12:13.308169: step 14860, loss 0.0410091, acc 0.984375\n",
      "2017-04-03T20:12:13.512061: step 14861, loss 0.207292, acc 0.953125\n",
      "2017-04-03T20:12:13.729937: step 14862, loss 0.11896, acc 0.953125\n",
      "2017-04-03T20:12:13.940660: step 14863, loss 0.160118, acc 0.953125\n",
      "2017-04-03T20:12:14.144769: step 14864, loss 0.086921, acc 0.953125\n",
      "2017-04-03T20:12:14.353696: step 14865, loss 0.285941, acc 0.90625\n",
      "2017-04-03T20:12:14.564719: step 14866, loss 0.225228, acc 0.9375\n",
      "2017-04-03T20:12:14.766836: step 14867, loss 0.0972129, acc 0.984375\n",
      "2017-04-03T20:12:14.967077: step 14868, loss 0.136177, acc 0.9375\n",
      "2017-04-03T20:12:15.169545: step 14869, loss 0.156635, acc 0.921875\n",
      "2017-04-03T20:12:15.368559: step 14870, loss 0.17912, acc 0.953125\n",
      "2017-04-03T20:12:15.571889: step 14871, loss 0.0989176, acc 0.953125\n",
      "2017-04-03T20:12:15.776134: step 14872, loss 0.185651, acc 0.9375\n",
      "2017-04-03T20:12:15.983863: step 14873, loss 0.315531, acc 0.953125\n",
      "2017-04-03T20:12:16.187112: step 14874, loss 0.10693, acc 0.96875\n",
      "2017-04-03T20:12:16.386287: step 14875, loss 0.103502, acc 0.953125\n",
      "2017-04-03T20:12:16.594005: step 14876, loss 0.154191, acc 0.96875\n",
      "2017-04-03T20:12:16.796571: step 14877, loss 0.158766, acc 0.9375\n",
      "2017-04-03T20:12:16.994312: step 14878, loss 0.135879, acc 0.9375\n",
      "2017-04-03T20:12:17.208943: step 14879, loss 0.109548, acc 0.953125\n",
      "2017-04-03T20:12:17.411151: step 14880, loss 0.0780448, acc 0.984375\n",
      "2017-04-03T20:12:17.615371: step 14881, loss 0.115604, acc 0.96875\n",
      "2017-04-03T20:12:17.831854: step 14882, loss 0.100515, acc 0.953125\n",
      "2017-04-03T20:12:18.032639: step 14883, loss 0.0536741, acc 0.984375\n",
      "2017-04-03T20:12:18.231320: step 14884, loss 0.0970528, acc 0.96875\n",
      "2017-04-03T20:12:18.473564: step 14885, loss 0.136125, acc 0.96875\n",
      "2017-04-03T20:12:18.680558: step 14886, loss 0.192614, acc 0.9375\n",
      "2017-04-03T20:12:18.889661: step 14887, loss 0.0987451, acc 0.984375\n",
      "2017-04-03T20:12:19.100412: step 14888, loss 0.160895, acc 0.9375\n",
      "2017-04-03T20:12:19.320487: step 14889, loss 0.106817, acc 0.953125\n",
      "2017-04-03T20:12:19.543574: step 14890, loss 0.0993227, acc 0.921875\n",
      "2017-04-03T20:12:19.763969: step 14891, loss 0.200592, acc 0.890625\n",
      "2017-04-03T20:12:19.982582: step 14892, loss 0.0774278, acc 0.96875\n",
      "2017-04-03T20:12:20.184597: step 14893, loss 0.0464776, acc 1\n",
      "2017-04-03T20:12:20.381808: step 14894, loss 0.143133, acc 0.90625\n",
      "2017-04-03T20:12:20.580416: step 14895, loss 0.133125, acc 0.953125\n",
      "2017-04-03T20:12:20.783894: step 14896, loss 0.183399, acc 0.90625\n",
      "2017-04-03T20:12:20.999592: step 14897, loss 0.135997, acc 0.9375\n",
      "2017-04-03T20:12:21.203516: step 14898, loss 0.280374, acc 0.953125\n",
      "2017-04-03T20:12:21.447439: step 14899, loss 0.103978, acc 0.96875\n",
      "2017-04-03T20:12:21.685252: step 14900, loss 0.102784, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:12:23.901061: step 14900, loss 5.92875, acc 0.292\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-14900\n",
      "\n",
      "2017-04-03T20:12:24.227172: step 14901, loss 0.179198, acc 0.953125\n",
      "2017-04-03T20:12:24.473885: step 14902, loss 0.0601123, acc 0.984375\n",
      "2017-04-03T20:12:24.676068: step 14903, loss 0.142953, acc 0.984375\n",
      "2017-04-03T20:12:24.875160: step 14904, loss 0.122198, acc 0.953125\n",
      "2017-04-03T20:12:25.117394: step 14905, loss 0.083865, acc 0.984375\n",
      "2017-04-03T20:12:25.319835: step 14906, loss 0.0636536, acc 0.984375\n",
      "2017-04-03T20:12:25.526432: step 14907, loss 0.249808, acc 0.921875\n",
      "2017-04-03T20:12:25.722019: step 14908, loss 0.106916, acc 0.96875\n",
      "2017-04-03T20:12:25.923056: step 14909, loss 0.1251, acc 0.953125\n",
      "2017-04-03T20:12:26.128336: step 14910, loss 0.142174, acc 0.96875\n",
      "2017-04-03T20:12:26.335496: step 14911, loss 0.0580518, acc 1\n",
      "2017-04-03T20:12:26.544551: step 14912, loss 0.0441808, acc 0.984375\n",
      "2017-04-03T20:12:26.745354: step 14913, loss 0.148901, acc 0.953125\n",
      "2017-04-03T20:12:26.945184: step 14914, loss 0.171853, acc 0.921875\n",
      "2017-04-03T20:12:27.151347: step 14915, loss 0.142404, acc 0.953125\n",
      "2017-04-03T20:12:27.394682: step 14916, loss 0.147672, acc 0.9375\n",
      "2017-04-03T20:12:27.596420: step 14917, loss 0.176322, acc 0.921875\n",
      "2017-04-03T20:12:27.800317: step 14918, loss 0.0984338, acc 0.984375\n",
      "2017-04-03T20:12:28.004525: step 14919, loss 0.276868, acc 0.921875\n",
      "2017-04-03T20:12:28.204719: step 14920, loss 0.212124, acc 0.96875\n",
      "2017-04-03T20:12:28.407413: step 14921, loss 0.126406, acc 0.953125\n",
      "2017-04-03T20:12:28.609196: step 14922, loss 0.13865, acc 0.953125\n",
      "2017-04-03T20:12:28.811480: step 14923, loss 0.154829, acc 0.9375\n",
      "2017-04-03T20:12:29.012985: step 14924, loss 0.0744371, acc 0.984375\n",
      "2017-04-03T20:12:29.214354: step 14925, loss 0.140467, acc 0.953125\n",
      "2017-04-03T20:12:29.415293: step 14926, loss 0.358951, acc 0.90625\n",
      "2017-04-03T20:12:29.620444: step 14927, loss 0.108893, acc 0.953125\n",
      "2017-04-03T20:12:29.822011: step 14928, loss 0.0489892, acc 0.984375\n",
      "2017-04-03T20:12:30.025543: step 14929, loss 0.28735, acc 0.890625\n",
      "2017-04-03T20:12:30.226667: step 14930, loss 0.0927204, acc 0.96875\n",
      "2017-04-03T20:12:30.428162: step 14931, loss 0.142157, acc 0.96875\n",
      "2017-04-03T20:12:30.626935: step 14932, loss 0.0875313, acc 0.9375\n",
      "2017-04-03T20:12:30.836727: step 14933, loss 0.245371, acc 0.90625\n",
      "2017-04-03T20:12:31.038619: step 14934, loss 0.168044, acc 0.953125\n",
      "2017-04-03T20:12:31.239684: step 14935, loss 0.094083, acc 0.984375\n",
      "2017-04-03T20:12:31.438633: step 14936, loss 0.0177783, acc 1\n",
      "2017-04-03T20:12:31.644315: step 14937, loss 0.122364, acc 0.953125\n",
      "2017-04-03T20:12:31.855008: step 14938, loss 0.240011, acc 0.953125\n",
      "2017-04-03T20:12:32.057422: step 14939, loss 0.0634219, acc 0.984375\n",
      "2017-04-03T20:12:32.257455: step 14940, loss 0.0440259, acc 0.984375\n",
      "2017-04-03T20:12:32.458389: step 14941, loss 0.218002, acc 0.953125\n",
      "2017-04-03T20:12:32.656924: step 14942, loss 0.173932, acc 0.9375\n",
      "2017-04-03T20:12:32.860826: step 14943, loss 0.150769, acc 0.96875\n",
      "2017-04-03T20:12:33.101957: step 14944, loss 0.0477414, acc 0.984375\n",
      "2017-04-03T20:12:33.306194: step 14945, loss 0.106828, acc 0.96875\n",
      "2017-04-03T20:12:33.505181: step 14946, loss 0.163602, acc 0.953125\n",
      "2017-04-03T20:12:33.711529: step 14947, loss 0.327218, acc 0.90625\n",
      "2017-04-03T20:12:33.915376: step 14948, loss 0.143815, acc 0.921875\n",
      "2017-04-03T20:12:34.117336: step 14949, loss 0.169517, acc 0.921875\n",
      "2017-04-03T20:12:34.322399: step 14950, loss 0.157734, acc 0.953125\n",
      "2017-04-03T20:12:34.576653: step 14951, loss 0.0721318, acc 0.96875\n",
      "2017-04-03T20:12:34.776003: step 14952, loss 0.155818, acc 0.953125\n",
      "2017-04-03T20:12:34.984435: step 14953, loss 0.15425, acc 0.953125\n",
      "2017-04-03T20:12:35.186792: step 14954, loss 0.414178, acc 0.90625\n",
      "2017-04-03T20:12:35.389117: step 14955, loss 0.115914, acc 0.96875\n",
      "2017-04-03T20:12:35.591383: step 14956, loss 0.0648887, acc 0.984375\n",
      "2017-04-03T20:12:35.792623: step 14957, loss 0.129839, acc 0.9375\n",
      "2017-04-03T20:12:35.997949: step 14958, loss 0.0793121, acc 0.984375\n",
      "2017-04-03T20:12:36.201912: step 14959, loss 0.127612, acc 0.953125\n",
      "2017-04-03T20:12:36.404937: step 14960, loss 0.152454, acc 0.9375\n",
      "2017-04-03T20:12:36.610459: step 14961, loss 0.144191, acc 0.9375\n",
      "2017-04-03T20:12:36.813149: step 14962, loss 0.120517, acc 0.96875\n",
      "2017-04-03T20:12:37.015671: step 14963, loss 0.29101, acc 0.921875\n",
      "2017-04-03T20:12:37.221827: step 14964, loss 0.052415, acc 1\n",
      "2017-04-03T20:12:37.424242: step 14965, loss 0.131174, acc 0.9375\n",
      "2017-04-03T20:12:37.625883: step 14966, loss 0.161423, acc 0.921875\n",
      "2017-04-03T20:12:37.825750: step 14967, loss 0.10803, acc 0.96875\n",
      "2017-04-03T20:12:38.052116: step 14968, loss 0.102865, acc 0.96875\n",
      "2017-04-03T20:12:38.267748: step 14969, loss 0.129902, acc 0.9375\n",
      "2017-04-03T20:12:38.475659: step 14970, loss 0.127283, acc 0.953125\n",
      "2017-04-03T20:12:38.679573: step 14971, loss 0.168258, acc 0.953125\n",
      "2017-04-03T20:12:38.879755: step 14972, loss 0.146269, acc 0.9375\n",
      "2017-04-03T20:12:39.085885: step 14973, loss 0.0656671, acc 0.984375\n",
      "2017-04-03T20:12:39.290218: step 14974, loss 0.0414989, acc 0.984375\n",
      "2017-04-03T20:12:39.489569: step 14975, loss 0.045785, acc 1\n",
      "2017-04-03T20:12:39.688833: step 14976, loss 0.252425, acc 0.921875\n",
      "2017-04-03T20:12:39.908767: step 14977, loss 0.0694388, acc 0.984375\n",
      "2017-04-03T20:12:40.108905: step 14978, loss 0.330847, acc 0.96875\n",
      "2017-04-03T20:12:40.312401: step 14979, loss 0.0867028, acc 0.96875\n",
      "2017-04-03T20:12:40.554549: step 14980, loss 0.147099, acc 0.9375\n",
      "2017-04-03T20:12:40.757549: step 14981, loss 0.0731128, acc 0.984375\n",
      "2017-04-03T20:12:40.960696: step 14982, loss 0.118312, acc 0.984375\n",
      "2017-04-03T20:12:41.163341: step 14983, loss 0.115868, acc 0.953125\n",
      "2017-04-03T20:12:41.361973: step 14984, loss 0.133946, acc 0.96875\n",
      "2017-04-03T20:12:41.561610: step 14985, loss 0.0807718, acc 0.96875\n",
      "2017-04-03T20:12:41.775052: step 14986, loss 0.10662, acc 0.96875\n",
      "2017-04-03T20:12:41.991751: step 14987, loss 0.241646, acc 0.9375\n",
      "2017-04-03T20:12:42.204394: step 14988, loss 0.349127, acc 0.90625\n",
      "2017-04-03T20:12:42.407990: step 14989, loss 0.0406005, acc 0.984375\n",
      "2017-04-03T20:12:42.601056: step 14990, loss 0.0888282, acc 0.96875\n",
      "2017-04-03T20:12:42.809115: step 14991, loss 0.141114, acc 0.953125\n",
      "2017-04-03T20:12:43.022840: step 14992, loss 0.298934, acc 0.953125\n",
      "2017-04-03T20:12:43.228412: step 14993, loss 0.094153, acc 0.953125\n",
      "2017-04-03T20:12:43.428904: step 14994, loss 0.117414, acc 0.984375\n",
      "2017-04-03T20:12:43.634649: step 14995, loss 0.188558, acc 0.9375\n",
      "2017-04-03T20:12:43.836381: step 14996, loss 0.247917, acc 0.921875\n",
      "2017-04-03T20:12:44.037225: step 14997, loss 0.145612, acc 0.9375\n",
      "2017-04-03T20:12:44.242377: step 14998, loss 0.219471, acc 0.953125\n",
      "2017-04-03T20:12:44.491009: step 14999, loss 0.289117, acc 0.9375\n",
      "2017-04-03T20:12:44.701636: step 15000, loss 0.143572, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:12:46.725686: step 15000, loss 5.977, acc 0.294\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-15000\n",
      "\n",
      "2017-04-03T20:12:47.049331: step 15001, loss 0.154344, acc 0.9375\n",
      "2017-04-03T20:12:47.253286: step 15002, loss 0.0932303, acc 0.96875\n",
      "2017-04-03T20:12:47.455468: step 15003, loss 0.0889082, acc 0.953125\n",
      "2017-04-03T20:12:47.657634: step 15004, loss 0.122837, acc 0.96875\n",
      "2017-04-03T20:12:47.856392: step 15005, loss 0.0935518, acc 0.96875\n",
      "2017-04-03T20:12:48.116399: step 15006, loss 0.21457, acc 0.9375\n",
      "2017-04-03T20:12:48.318834: step 15007, loss 0.134622, acc 0.953125\n",
      "2017-04-03T20:12:48.520514: step 15008, loss 0.267664, acc 0.921875\n",
      "2017-04-03T20:12:48.763786: step 15009, loss 0.0861801, acc 0.953125\n",
      "2017-04-03T20:12:48.960904: step 15010, loss 0.124595, acc 0.96875\n",
      "2017-04-03T20:12:49.173125: step 15011, loss 0.148742, acc 0.953125\n",
      "2017-04-03T20:12:49.371460: step 15012, loss 0.127709, acc 0.9375\n",
      "2017-04-03T20:12:49.568379: step 15013, loss 0.184256, acc 0.9375\n",
      "2017-04-03T20:12:49.812959: step 15014, loss 0.20933, acc 0.921875\n",
      "2017-04-03T20:12:50.015712: step 15015, loss 0.249433, acc 0.9375\n",
      "2017-04-03T20:12:50.221145: step 15016, loss 0.131655, acc 0.96875\n",
      "2017-04-03T20:12:50.420834: step 15017, loss 0.116514, acc 0.953125\n",
      "2017-04-03T20:12:50.619402: step 15018, loss 0.0538215, acc 0.96875\n",
      "2017-04-03T20:12:50.823910: step 15019, loss 0.092877, acc 0.9375\n",
      "2017-04-03T20:12:51.031174: step 15020, loss 0.164845, acc 0.953125\n",
      "2017-04-03T20:12:51.280563: step 15021, loss 0.0878477, acc 0.984375\n",
      "2017-04-03T20:12:51.484488: step 15022, loss 0.139575, acc 0.953125\n",
      "2017-04-03T20:12:51.687585: step 15023, loss 0.085886, acc 0.96875\n",
      "2017-04-03T20:12:51.888019: step 15024, loss 0.0957657, acc 0.96875\n",
      "2017-04-03T20:12:52.099008: step 15025, loss 0.107588, acc 0.953125\n",
      "2017-04-03T20:12:52.309592: step 15026, loss 0.0899178, acc 0.984375\n",
      "2017-04-03T20:12:52.510704: step 15027, loss 0.150195, acc 0.9375\n",
      "2017-04-03T20:12:52.715517: step 15028, loss 0.140565, acc 0.9375\n",
      "2017-04-03T20:12:52.913087: step 15029, loss 0.109035, acc 0.984375\n",
      "2017-04-03T20:12:53.117278: step 15030, loss 0.0874883, acc 0.96875\n",
      "2017-04-03T20:12:53.318559: step 15031, loss 0.261413, acc 0.90625\n",
      "2017-04-03T20:12:53.518693: step 15032, loss 0.165349, acc 0.953125\n",
      "2017-04-03T20:12:53.728791: step 15033, loss 0.0777029, acc 0.984375\n",
      "2017-04-03T20:12:53.932760: step 15034, loss 0.0934328, acc 0.953125\n",
      "2017-04-03T20:12:54.134846: step 15035, loss 0.0523282, acc 0.984375\n",
      "2017-04-03T20:12:54.336004: step 15036, loss 0.0982236, acc 0.96875\n",
      "2017-04-03T20:12:54.536653: step 15037, loss 0.0715121, acc 0.984375\n",
      "2017-04-03T20:12:54.737063: step 15038, loss 0.13815, acc 0.96875\n",
      "2017-04-03T20:12:54.944804: step 15039, loss 0.115339, acc 0.96875\n",
      "2017-04-03T20:12:55.146440: step 15040, loss 0.0851629, acc 0.984375\n",
      "2017-04-03T20:12:55.390473: step 15041, loss 0.245327, acc 0.890625\n",
      "2017-04-03T20:12:55.591251: step 15042, loss 0.407709, acc 0.9375\n",
      "2017-04-03T20:12:55.796719: step 15043, loss 0.157895, acc 0.953125\n",
      "2017-04-03T20:12:56.002227: step 15044, loss 0.100629, acc 0.953125\n",
      "2017-04-03T20:12:56.216993: step 15045, loss 0.144082, acc 0.9375\n",
      "2017-04-03T20:12:56.444182: step 15046, loss 0.0811832, acc 0.953125\n",
      "2017-04-03T20:12:56.651526: step 15047, loss 0.205875, acc 0.90625\n",
      "2017-04-03T20:12:56.852702: step 15048, loss 0.0417949, acc 0.984375\n",
      "2017-04-03T20:12:57.059961: step 15049, loss 0.125429, acc 0.953125\n",
      "2017-04-03T20:12:57.265642: step 15050, loss 0.199373, acc 0.921875\n",
      "2017-04-03T20:12:57.477983: step 15051, loss 0.0758426, acc 0.984375\n",
      "2017-04-03T20:12:57.698784: step 15052, loss 0.0875703, acc 0.984375\n",
      "2017-04-03T20:12:57.898602: step 15053, loss 0.046818, acc 0.984375\n",
      "2017-04-03T20:12:58.127497: step 15054, loss 0.122562, acc 0.9375\n",
      "2017-04-03T20:12:58.337842: step 15055, loss 0.158991, acc 0.96875\n",
      "2017-04-03T20:12:58.590500: step 15056, loss 0.33774, acc 0.890625\n",
      "2017-04-03T20:12:58.791957: step 15057, loss 0.0642672, acc 0.984375\n",
      "2017-04-03T20:12:58.997738: step 15058, loss 0.107126, acc 0.984375\n",
      "2017-04-03T20:12:59.201267: step 15059, loss 0.143418, acc 0.96875\n",
      "2017-04-03T20:12:59.408288: step 15060, loss 0.134567, acc 0.96875\n",
      "2017-04-03T20:12:59.611514: step 15061, loss 0.128233, acc 0.9375\n",
      "2017-04-03T20:12:59.815178: step 15062, loss 0.0705278, acc 0.984375\n",
      "2017-04-03T20:13:00.024584: step 15063, loss 0.201759, acc 0.921875\n",
      "2017-04-03T20:13:00.228993: step 15064, loss 0.0725848, acc 0.96875\n",
      "2017-04-03T20:13:00.430580: step 15065, loss 0.27509, acc 0.90625\n",
      "2017-04-03T20:13:00.641175: step 15066, loss 0.183899, acc 0.953125\n",
      "2017-04-03T20:13:00.870928: step 15067, loss 0.248662, acc 0.890625\n",
      "2017-04-03T20:13:01.086222: step 15068, loss 0.0666505, acc 0.984375\n",
      "2017-04-03T20:13:01.310506: step 15069, loss 0.232774, acc 0.9375\n",
      "2017-04-03T20:13:01.521110: step 15070, loss 0.163399, acc 0.953125\n",
      "2017-04-03T20:13:01.724684: step 15071, loss 0.0730923, acc 0.96875\n",
      "2017-04-03T20:13:01.928838: step 15072, loss 0.12503, acc 0.96875\n",
      "2017-04-03T20:13:02.131860: step 15073, loss 0.101208, acc 0.96875\n",
      "2017-04-03T20:13:02.331918: step 15074, loss 0.216661, acc 0.90625\n",
      "2017-04-03T20:13:02.534225: step 15075, loss 0.083854, acc 0.984375\n",
      "2017-04-03T20:13:02.731368: step 15076, loss 0.186285, acc 0.921875\n",
      "2017-04-03T20:13:02.935590: step 15077, loss 0.207612, acc 0.953125\n",
      "2017-04-03T20:13:03.142497: step 15078, loss 0.118304, acc 0.953125\n",
      "2017-04-03T20:13:03.360258: step 15079, loss 0.179592, acc 0.9375\n",
      "2017-04-03T20:13:03.571429: step 15080, loss 0.175836, acc 0.953125\n",
      "2017-04-03T20:13:03.770915: step 15081, loss 0.114432, acc 0.96875\n",
      "2017-04-03T20:13:03.969694: step 15082, loss 0.219627, acc 0.921875\n",
      "2017-04-03T20:13:04.178374: step 15083, loss 0.131086, acc 0.921875\n",
      "2017-04-03T20:13:04.382971: step 15084, loss 0.143562, acc 0.953125\n",
      "2017-04-03T20:13:04.583158: step 15085, loss 0.125623, acc 0.953125\n",
      "2017-04-03T20:13:04.790891: step 15086, loss 0.125387, acc 0.921875\n",
      "2017-04-03T20:13:05.003118: step 15087, loss 0.135192, acc 0.953125\n",
      "2017-04-03T20:13:05.209172: step 15088, loss 0.217824, acc 0.921875\n",
      "2017-04-03T20:13:05.410885: step 15089, loss 0.0668948, acc 0.984375\n",
      "2017-04-03T20:13:05.655791: step 15090, loss 0.137692, acc 0.96875\n",
      "2017-04-03T20:13:05.855797: step 15091, loss 0.268444, acc 0.953125\n",
      "2017-04-03T20:13:06.055388: step 15092, loss 0.0972524, acc 0.96875\n",
      "2017-04-03T20:13:06.292654: step 15093, loss 0.141528, acc 0.96875\n",
      "2017-04-03T20:13:06.547038: step 15094, loss 0.147011, acc 0.953125\n",
      "2017-04-03T20:13:06.760285: step 15095, loss 0.287216, acc 0.9375\n",
      "2017-04-03T20:13:06.976759: step 15096, loss 0.121869, acc 0.953125\n",
      "2017-04-03T20:13:07.177329: step 15097, loss 0.0837989, acc 0.96875\n",
      "2017-04-03T20:13:07.377585: step 15098, loss 0.107904, acc 0.96875\n",
      "2017-04-03T20:13:07.626488: step 15099, loss 0.069274, acc 0.984375\n",
      "2017-04-03T20:13:07.831066: step 15100, loss 0.160453, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:13:09.973126: step 15100, loss 5.9628, acc 0.299\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-15100\n",
      "\n",
      "2017-04-03T20:13:10.348452: step 15101, loss 0.184506, acc 0.9375\n",
      "2017-04-03T20:13:10.553843: step 15102, loss 0.120295, acc 0.953125\n",
      "2017-04-03T20:13:10.765081: step 15103, loss 0.25108, acc 0.921875\n",
      "2017-04-03T20:13:10.980117: step 15104, loss 0.209629, acc 0.9375\n",
      "2017-04-03T20:13:11.184053: step 15105, loss 0.1717, acc 0.921875\n",
      "2017-04-03T20:13:11.388681: step 15106, loss 0.146829, acc 0.953125\n",
      "2017-04-03T20:13:11.589862: step 15107, loss 0.115946, acc 0.953125\n",
      "2017-04-03T20:13:11.792082: step 15108, loss 0.101499, acc 0.96875\n",
      "2017-04-03T20:13:12.000556: step 15109, loss 0.126583, acc 0.9375\n",
      "2017-04-03T20:13:12.206999: step 15110, loss 0.176509, acc 0.953125\n",
      "2017-04-03T20:13:12.402691: step 15111, loss 0.0930462, acc 0.984375\n",
      "2017-04-03T20:13:12.604710: step 15112, loss 0.129551, acc 0.921875\n",
      "2017-04-03T20:13:12.805870: step 15113, loss 0.0551683, acc 1\n",
      "2017-04-03T20:13:13.007916: step 15114, loss 0.0884026, acc 0.984375\n",
      "2017-04-03T20:13:13.207338: step 15115, loss 0.14865, acc 0.953125\n",
      "2017-04-03T20:13:13.414135: step 15116, loss 0.0443985, acc 0.984375\n",
      "2017-04-03T20:13:13.658680: step 15117, loss 0.121127, acc 0.984375\n",
      "2017-04-03T20:13:13.859967: step 15118, loss 0.124521, acc 0.953125\n",
      "2017-04-03T20:13:14.064945: step 15119, loss 0.117268, acc 0.96875\n",
      "2017-04-03T20:13:14.265003: step 15120, loss 0.242133, acc 0.921875\n",
      "2017-04-03T20:13:14.474351: step 15121, loss 0.0950142, acc 0.984375\n",
      "2017-04-03T20:13:14.680179: step 15122, loss 0.14817, acc 0.96875\n",
      "2017-04-03T20:13:14.886977: step 15123, loss 0.215202, acc 0.9375\n",
      "2017-04-03T20:13:15.090297: step 15124, loss 0.371268, acc 0.921875\n",
      "2017-04-03T20:13:15.340939: step 15125, loss 0.0471967, acc 0.984375\n",
      "2017-04-03T20:13:15.543869: step 15126, loss 0.138305, acc 0.9375\n",
      "2017-04-03T20:13:15.749718: step 15127, loss 0.207735, acc 0.9375\n",
      "2017-04-03T20:13:15.958994: step 15128, loss 0.130905, acc 0.984375\n",
      "2017-04-03T20:13:16.161671: step 15129, loss 0.0262695, acc 1\n",
      "2017-04-03T20:13:16.364936: step 15130, loss 0.157695, acc 0.96875\n",
      "2017-04-03T20:13:16.567027: step 15131, loss 0.116788, acc 0.953125\n",
      "2017-04-03T20:13:16.776559: step 15132, loss 0.392555, acc 0.96875\n",
      "2017-04-03T20:13:16.981082: step 15133, loss 0.0655394, acc 0.984375\n",
      "2017-04-03T20:13:17.216951: step 15134, loss 0.213471, acc 0.921875\n",
      "2017-04-03T20:13:17.424270: step 15135, loss 0.158805, acc 0.9375\n",
      "2017-04-03T20:13:17.631241: step 15136, loss 0.181495, acc 0.9375\n",
      "2017-04-03T20:13:17.840147: step 15137, loss 0.233036, acc 0.90625\n",
      "2017-04-03T20:13:18.048958: step 15138, loss 0.126452, acc 0.953125\n",
      "2017-04-03T20:13:18.251155: step 15139, loss 0.103661, acc 0.96875\n",
      "2017-04-03T20:13:18.458045: step 15140, loss 0.261758, acc 0.921875\n",
      "2017-04-03T20:13:18.660889: step 15141, loss 0.063981, acc 1\n",
      "2017-04-03T20:13:18.865272: step 15142, loss 0.207606, acc 0.890625\n",
      "2017-04-03T20:13:19.071102: step 15143, loss 0.158111, acc 0.9375\n",
      "2017-04-03T20:13:19.288610: step 15144, loss 0.0882825, acc 0.953125\n",
      "2017-04-03T20:13:19.492673: step 15145, loss 0.210046, acc 0.9375\n",
      "2017-04-03T20:13:19.694012: step 15146, loss 0.0933907, acc 0.96875\n",
      "2017-04-03T20:13:19.900653: step 15147, loss 0.110978, acc 0.953125\n",
      "2017-04-03T20:13:20.103885: step 15148, loss 0.117805, acc 0.984375\n",
      "2017-04-03T20:13:20.308064: step 15149, loss 0.0761088, acc 0.96875\n",
      "2017-04-03T20:13:20.555403: step 15150, loss 0.218067, acc 0.921875\n",
      "2017-04-03T20:13:20.762543: step 15151, loss 0.224098, acc 0.921875\n",
      "2017-04-03T20:13:20.967737: step 15152, loss 0.0626998, acc 0.984375\n",
      "2017-04-03T20:13:21.197981: step 15153, loss 0.109486, acc 0.953125\n",
      "2017-04-03T20:13:21.414089: step 15154, loss 0.126466, acc 0.96875\n",
      "2017-04-03T20:13:21.620695: step 15155, loss 0.114968, acc 0.96875\n",
      "2017-04-03T20:13:21.840845: step 15156, loss 0.165874, acc 0.953125\n",
      "2017-04-03T20:13:22.046007: step 15157, loss 0.0716384, acc 0.984375\n",
      "2017-04-03T20:13:22.254342: step 15158, loss 0.154751, acc 0.96875\n",
      "2017-04-03T20:13:22.460853: step 15159, loss 0.0885106, acc 0.96875\n",
      "2017-04-03T20:13:22.664416: step 15160, loss 0.108783, acc 0.96875\n",
      "2017-04-03T20:13:22.869935: step 15161, loss 0.378425, acc 0.859375\n",
      "2017-04-03T20:13:23.081019: step 15162, loss 0.286201, acc 0.921875\n",
      "2017-04-03T20:13:23.282596: step 15163, loss 0.229337, acc 0.96875\n",
      "2017-04-03T20:13:23.490373: step 15164, loss 0.146478, acc 0.953125\n",
      "2017-04-03T20:13:23.695536: step 15165, loss 0.207513, acc 0.9375\n",
      "2017-04-03T20:13:23.899926: step 15166, loss 0.0861843, acc 0.96875\n",
      "2017-04-03T20:13:24.101647: step 15167, loss 0.0935908, acc 0.96875\n",
      "2017-04-03T20:13:24.305147: step 15168, loss 0.204356, acc 0.953125\n",
      "2017-04-03T20:13:24.506744: step 15169, loss 0.285176, acc 0.90625\n",
      "2017-04-03T20:13:24.710604: step 15170, loss 0.107056, acc 0.9375\n",
      "2017-04-03T20:13:24.939563: step 15171, loss 0.117519, acc 0.984375\n",
      "2017-04-03T20:13:25.145826: step 15172, loss 0.197279, acc 0.984375\n",
      "2017-04-03T20:13:25.346769: step 15173, loss 0.281198, acc 0.90625\n",
      "2017-04-03T20:13:25.552865: step 15174, loss 0.377374, acc 0.9375\n",
      "2017-04-03T20:13:25.765146: step 15175, loss 0.123924, acc 0.96875\n",
      "2017-04-03T20:13:25.970021: step 15176, loss 0.121377, acc 0.984375\n",
      "2017-04-03T20:13:26.171335: step 15177, loss 0.156948, acc 0.984375\n",
      "2017-04-03T20:13:26.375731: step 15178, loss 0.219937, acc 0.921875\n",
      "2017-04-03T20:13:26.577172: step 15179, loss 0.121283, acc 0.921875\n",
      "2017-04-03T20:13:26.783010: step 15180, loss 0.0634471, acc 0.984375\n",
      "2017-04-03T20:13:26.984227: step 15181, loss 0.173979, acc 0.9375\n",
      "2017-04-03T20:13:27.185774: step 15182, loss 0.0738404, acc 0.984375\n",
      "2017-04-03T20:13:27.385630: step 15183, loss 0.153448, acc 0.9375\n",
      "2017-04-03T20:13:27.583492: step 15184, loss 0.0964592, acc 0.953125\n",
      "2017-04-03T20:13:27.803712: step 15185, loss 0.116618, acc 0.9375\n",
      "2017-04-03T20:13:28.049145: step 15186, loss 0.212536, acc 0.921875\n",
      "2017-04-03T20:13:28.251991: step 15187, loss 0.283853, acc 0.953125\n",
      "2017-04-03T20:13:28.456745: step 15188, loss 0.0951222, acc 0.96875\n",
      "2017-04-03T20:13:28.662278: step 15189, loss 0.156371, acc 0.9375\n",
      "2017-04-03T20:13:28.869888: step 15190, loss 0.117131, acc 0.96875\n",
      "2017-04-03T20:13:29.072461: step 15191, loss 0.0601457, acc 0.984375\n",
      "2017-04-03T20:13:29.272959: step 15192, loss 0.228938, acc 0.9375\n",
      "2017-04-03T20:13:29.518999: step 15193, loss 0.142195, acc 0.9375\n",
      "2017-04-03T20:13:29.724339: step 15194, loss 0.385703, acc 0.921875\n",
      "2017-04-03T20:13:29.932900: step 15195, loss 0.122296, acc 0.96875\n",
      "2017-04-03T20:13:30.143078: step 15196, loss 0.092684, acc 0.984375\n",
      "2017-04-03T20:13:30.344790: step 15197, loss 0.162724, acc 0.9375\n",
      "2017-04-03T20:13:30.547767: step 15198, loss 0.0632949, acc 0.984375\n",
      "2017-04-03T20:13:30.750566: step 15199, loss 0.0755409, acc 0.984375\n",
      "2017-04-03T20:13:30.952515: step 15200, loss 0.132701, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:13:33.099565: step 15200, loss 6.02019, acc 0.29325\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-15200\n",
      "\n",
      "2017-04-03T20:13:33.379602: step 15201, loss 0.118757, acc 0.96875\n",
      "2017-04-03T20:13:33.619421: step 15202, loss 0.061421, acc 0.984375\n",
      "2017-04-03T20:13:33.836854: step 15203, loss 0.201962, acc 0.921875\n",
      "2017-04-03T20:13:34.055187: step 15204, loss 0.187471, acc 0.953125\n",
      "2017-04-03T20:13:34.262582: step 15205, loss 0.346361, acc 0.90625\n",
      "2017-04-03T20:13:34.470277: step 15206, loss 0.175369, acc 0.96875\n",
      "2017-04-03T20:13:34.670554: step 15207, loss 0.112213, acc 0.9375\n",
      "2017-04-03T20:13:34.873185: step 15208, loss 0.086168, acc 1\n",
      "2017-04-03T20:13:35.077612: step 15209, loss 0.406824, acc 0.84375\n",
      "2017-04-03T20:13:35.280013: step 15210, loss 0.0555922, acc 0.984375\n",
      "2017-04-03T20:13:35.484801: step 15211, loss 0.206091, acc 0.90625\n",
      "2017-04-03T20:13:35.693470: step 15212, loss 0.154738, acc 0.953125\n",
      "2017-04-03T20:13:35.939360: step 15213, loss 0.2415, acc 0.90625\n",
      "2017-04-03T20:13:36.141877: step 15214, loss 0.0442534, acc 1\n",
      "2017-04-03T20:13:36.343851: step 15215, loss 0.0609456, acc 0.984375\n",
      "2017-04-03T20:13:36.551206: step 15216, loss 0.0270046, acc 1\n",
      "2017-04-03T20:13:36.752337: step 15217, loss 0.14665, acc 0.9375\n",
      "2017-04-03T20:13:36.997558: step 15218, loss 0.330842, acc 0.921875\n",
      "2017-04-03T20:13:37.203324: step 15219, loss 0.102861, acc 0.96875\n",
      "2017-04-03T20:13:37.411084: step 15220, loss 0.0969584, acc 0.984375\n",
      "2017-04-03T20:13:37.616246: step 15221, loss 0.127541, acc 0.96875\n",
      "2017-04-03T20:13:37.828303: step 15222, loss 0.174037, acc 0.921875\n",
      "2017-04-03T20:13:38.050806: step 15223, loss 0.0932258, acc 0.96875\n",
      "2017-04-03T20:13:38.262124: step 15224, loss 0.0878124, acc 0.984375\n",
      "2017-04-03T20:13:38.469556: step 15225, loss 0.0374688, acc 1\n",
      "2017-04-03T20:13:38.664784: step 15226, loss 0.26972, acc 0.9375\n",
      "2017-04-03T20:13:38.868678: step 15227, loss 0.104078, acc 0.96875\n",
      "2017-04-03T20:13:39.077011: step 15228, loss 0.174641, acc 0.90625\n",
      "2017-04-03T20:13:39.279895: step 15229, loss 0.0939354, acc 0.96875\n",
      "2017-04-03T20:13:39.485333: step 15230, loss 0.112147, acc 0.984375\n",
      "2017-04-03T20:13:39.692013: step 15231, loss 0.0841003, acc 0.96875\n",
      "2017-04-03T20:13:39.906301: step 15232, loss 0.0815025, acc 0.96875\n",
      "2017-04-03T20:13:40.115943: step 15233, loss 0.161643, acc 0.953125\n",
      "2017-04-03T20:13:40.315339: step 15234, loss 0.0916215, acc 0.9375\n",
      "2017-04-03T20:13:40.559823: step 15235, loss 0.389533, acc 0.96875\n",
      "2017-04-03T20:13:40.802882: step 15236, loss 0.205818, acc 0.9375\n",
      "2017-04-03T20:13:41.006997: step 15237, loss 0.128916, acc 0.953125\n",
      "2017-04-03T20:13:41.223956: step 15238, loss 0.167848, acc 0.90625\n",
      "2017-04-03T20:13:41.446473: step 15239, loss 0.118942, acc 0.953125\n",
      "2017-04-03T20:13:41.647243: step 15240, loss 0.0981597, acc 0.96875\n",
      "2017-04-03T20:13:41.849476: step 15241, loss 0.0602252, acc 0.984375\n",
      "2017-04-03T20:13:42.058178: step 15242, loss 0.0844212, acc 0.984375\n",
      "2017-04-03T20:13:42.269276: step 15243, loss 0.112059, acc 0.96875\n",
      "2017-04-03T20:13:42.469100: step 15244, loss 0.178049, acc 0.953125\n",
      "2017-04-03T20:13:42.678331: step 15245, loss 0.185781, acc 0.953125\n",
      "2017-04-03T20:13:42.890081: step 15246, loss 0.0873729, acc 0.96875\n",
      "2017-04-03T20:13:43.093460: step 15247, loss 0.0542274, acc 0.96875\n",
      "2017-04-03T20:13:43.293699: step 15248, loss 0.126065, acc 0.9375\n",
      "2017-04-03T20:13:43.490213: step 15249, loss 0.0933324, acc 0.96875\n",
      "2017-04-03T20:13:43.697613: step 15250, loss 0.108762, acc 0.96875\n",
      "2017-04-03T20:13:43.900886: step 15251, loss 0.0447596, acc 1\n",
      "2017-04-03T20:13:44.104453: step 15252, loss 0.0928631, acc 0.953125\n",
      "2017-04-03T20:13:44.303488: step 15253, loss 0.208912, acc 0.9375\n",
      "2017-04-03T20:13:44.546548: step 15254, loss 0.121932, acc 0.96875\n",
      "2017-04-03T20:13:44.762098: step 15255, loss 0.11514, acc 0.953125\n",
      "2017-04-03T20:13:44.964578: step 15256, loss 0.116997, acc 0.96875\n",
      "2017-04-03T20:13:45.222787: step 15257, loss 0.167025, acc 0.953125\n",
      "2017-04-03T20:13:45.474529: step 15258, loss 0.202159, acc 0.9375\n",
      "2017-04-03T20:13:45.681893: step 15259, loss 0.0782499, acc 0.96875\n",
      "2017-04-03T20:13:45.882864: step 15260, loss 0.0831876, acc 0.984375\n",
      "2017-04-03T20:13:46.086301: step 15261, loss 0.0847553, acc 0.96875\n",
      "2017-04-03T20:13:46.287829: step 15262, loss 0.153169, acc 0.921875\n",
      "2017-04-03T20:13:46.489953: step 15263, loss 0.0823153, acc 0.984375\n",
      "2017-04-03T20:13:46.731334: step 15264, loss 0.129893, acc 0.953125\n",
      "2017-04-03T20:13:46.936039: step 15265, loss 0.0726016, acc 0.984375\n",
      "2017-04-03T20:13:47.179702: step 15266, loss 0.0503772, acc 0.984375\n",
      "2017-04-03T20:13:47.380936: step 15267, loss 0.0664701, acc 0.984375\n",
      "2017-04-03T20:13:47.599256: step 15268, loss 0.0611503, acc 0.984375\n",
      "2017-04-03T20:13:47.815521: step 15269, loss 0.17758, acc 0.953125\n",
      "2017-04-03T20:13:48.017078: step 15270, loss 0.114753, acc 0.96875\n",
      "2017-04-03T20:13:48.228427: step 15271, loss 0.0893888, acc 0.953125\n",
      "2017-04-03T20:13:48.435003: step 15272, loss 0.251694, acc 0.859375\n",
      "2017-04-03T20:13:48.635734: step 15273, loss 0.145159, acc 0.9375\n",
      "2017-04-03T20:13:48.848167: step 15274, loss 0.0625386, acc 0.96875\n",
      "2017-04-03T20:13:49.096016: step 15275, loss 0.0756263, acc 0.984375\n",
      "2017-04-03T20:13:49.301697: step 15276, loss 0.15888, acc 0.984375\n",
      "2017-04-03T20:13:49.505678: step 15277, loss 0.158265, acc 0.9375\n",
      "2017-04-03T20:13:49.712685: step 15278, loss 0.0956486, acc 0.984375\n",
      "2017-04-03T20:13:49.922981: step 15279, loss 0.309263, acc 0.9375\n",
      "2017-04-03T20:13:50.124466: step 15280, loss 0.18538, acc 0.953125\n",
      "2017-04-03T20:13:50.322903: step 15281, loss 0.0347717, acc 0.984375\n",
      "2017-04-03T20:13:50.527021: step 15282, loss 0.113766, acc 0.96875\n",
      "2017-04-03T20:13:50.729701: step 15283, loss 0.135234, acc 0.96875\n",
      "2017-04-03T20:13:50.929949: step 15284, loss 0.0736389, acc 0.96875\n",
      "2017-04-03T20:13:51.131878: step 15285, loss 0.213355, acc 0.953125\n",
      "2017-04-03T20:13:51.336650: step 15286, loss 0.0838056, acc 0.96875\n",
      "2017-04-03T20:13:51.535507: step 15287, loss 0.055129, acc 0.984375\n",
      "2017-04-03T20:13:51.734731: step 15288, loss 0.0822921, acc 0.953125\n",
      "2017-04-03T20:13:51.935583: step 15289, loss 0.160547, acc 0.921875\n",
      "2017-04-03T20:13:52.141225: step 15290, loss 0.0873759, acc 0.96875\n",
      "2017-04-03T20:13:52.341516: step 15291, loss 0.0858528, acc 0.96875\n",
      "2017-04-03T20:13:52.545322: step 15292, loss 0.0209136, acc 1\n",
      "2017-04-03T20:13:52.746991: step 15293, loss 0.0402975, acc 1\n",
      "2017-04-03T20:13:52.995968: step 15294, loss 0.153806, acc 0.953125\n",
      "2017-04-03T20:13:53.200921: step 15295, loss 0.456625, acc 0.90625\n",
      "2017-04-03T20:13:53.404390: step 15296, loss 0.0625439, acc 1\n",
      "2017-04-03T20:13:53.605532: step 15297, loss 0.0880885, acc 0.953125\n",
      "2017-04-03T20:13:53.808230: step 15298, loss 0.0463867, acc 1\n",
      "2017-04-03T20:13:54.011962: step 15299, loss 0.116991, acc 0.984375\n",
      "2017-04-03T20:13:54.210632: step 15300, loss 0.16668, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:13:56.310531: step 15300, loss 6.01012, acc 0.293\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-15300\n",
      "\n",
      "2017-04-03T20:13:56.644391: step 15301, loss 0.0456177, acc 0.984375\n",
      "2017-04-03T20:13:56.848017: step 15302, loss 0.182318, acc 0.9375\n",
      "2017-04-03T20:13:57.051927: step 15303, loss 0.0717948, acc 0.984375\n",
      "2017-04-03T20:13:57.257586: step 15304, loss 0.149323, acc 0.9375\n",
      "2017-04-03T20:13:57.460207: step 15305, loss 0.0719873, acc 0.96875\n",
      "2017-04-03T20:13:57.668483: step 15306, loss 0.0426064, acc 0.984375\n",
      "2017-04-03T20:13:57.922155: step 15307, loss 0.0563009, acc 0.984375\n",
      "2017-04-03T20:13:58.124352: step 15308, loss 0.0637653, acc 0.984375\n",
      "2017-04-03T20:13:58.328835: step 15309, loss 0.164991, acc 0.96875\n",
      "2017-04-03T20:13:58.527711: step 15310, loss 0.0573674, acc 0.984375\n",
      "2017-04-03T20:13:58.730541: step 15311, loss 0.0436078, acc 1\n",
      "2017-04-03T20:13:58.936564: step 15312, loss 0.0833631, acc 0.96875\n",
      "2017-04-03T20:13:59.138089: step 15313, loss 0.0831674, acc 0.96875\n",
      "2017-04-03T20:13:59.346854: step 15314, loss 0.303365, acc 0.921875\n",
      "2017-04-03T20:13:59.553649: step 15315, loss 0.115838, acc 0.984375\n",
      "2017-04-03T20:13:59.753052: step 15316, loss 0.180242, acc 0.90625\n",
      "2017-04-03T20:13:59.955261: step 15317, loss 0.170748, acc 0.953125\n",
      "2017-04-03T20:14:00.167493: step 15318, loss 0.400175, acc 0.921875\n",
      "2017-04-03T20:14:00.380873: step 15319, loss 0.101828, acc 0.953125\n",
      "2017-04-03T20:14:00.579965: step 15320, loss 0.0693694, acc 0.984375\n",
      "2017-04-03T20:14:00.780838: step 15321, loss 0.135256, acc 0.953125\n",
      "2017-04-03T20:14:00.984673: step 15322, loss 0.174147, acc 0.9375\n",
      "2017-04-03T20:14:01.186100: step 15323, loss 0.145582, acc 0.96875\n",
      "2017-04-03T20:14:01.394041: step 15324, loss 0.233218, acc 0.9375\n",
      "2017-04-03T20:14:01.602768: step 15325, loss 0.298825, acc 0.921875\n",
      "2017-04-03T20:14:01.820343: step 15326, loss 0.104985, acc 0.984375\n",
      "2017-04-03T20:14:02.039563: step 15327, loss 0.0813327, acc 0.984375\n",
      "2017-04-03T20:14:02.250807: step 15328, loss 0.127878, acc 0.96875\n",
      "2017-04-03T20:14:02.452433: step 15329, loss 0.175196, acc 0.921875\n",
      "2017-04-03T20:14:02.655165: step 15330, loss 0.241567, acc 0.96875\n",
      "2017-04-03T20:14:02.856459: step 15331, loss 0.116971, acc 0.953125\n",
      "2017-04-03T20:14:03.098176: step 15332, loss 0.12573, acc 0.953125\n",
      "2017-04-03T20:14:03.319479: step 15333, loss 0.130729, acc 0.953125\n",
      "2017-04-03T20:14:03.521227: step 15334, loss 0.172046, acc 0.953125\n",
      "2017-04-03T20:14:03.724805: step 15335, loss 0.0876845, acc 0.984375\n",
      "2017-04-03T20:14:03.925854: step 15336, loss 0.217626, acc 0.96875\n",
      "2017-04-03T20:14:04.138270: step 15337, loss 0.059623, acc 0.984375\n",
      "2017-04-03T20:14:04.343723: step 15338, loss 0.147225, acc 0.9375\n",
      "2017-04-03T20:14:04.545875: step 15339, loss 0.0449894, acc 0.96875\n",
      "2017-04-03T20:14:04.751897: step 15340, loss 0.0507179, acc 0.984375\n",
      "2017-04-03T20:14:04.949672: step 15341, loss 0.241712, acc 0.953125\n",
      "2017-04-03T20:14:05.152206: step 15342, loss 0.0430253, acc 1\n",
      "2017-04-03T20:14:05.355120: step 15343, loss 0.140436, acc 0.9375\n",
      "2017-04-03T20:14:05.562954: step 15344, loss 0.126795, acc 0.984375\n",
      "2017-04-03T20:14:05.771928: step 15345, loss 0.228758, acc 0.90625\n",
      "2017-04-03T20:14:05.972829: step 15346, loss 0.0504875, acc 0.984375\n",
      "2017-04-03T20:14:06.176147: step 15347, loss 0.161902, acc 0.9375\n",
      "2017-04-03T20:14:06.370577: step 15348, loss 0.102565, acc 0.9375\n",
      "2017-04-03T20:14:06.573401: step 15349, loss 0.139537, acc 0.9375\n",
      "2017-04-03T20:14:06.775221: step 15350, loss 0.0752539, acc 0.984375\n",
      "2017-04-03T20:14:06.985083: step 15351, loss 0.106229, acc 0.96875\n",
      "2017-04-03T20:14:07.194586: step 15352, loss 0.248157, acc 0.9375\n",
      "2017-04-03T20:14:07.397746: step 15353, loss 0.167141, acc 0.953125\n",
      "2017-04-03T20:14:07.598690: step 15354, loss 0.0456811, acc 0.984375\n",
      "2017-04-03T20:14:07.797096: step 15355, loss 0.295425, acc 0.9375\n",
      "2017-04-03T20:14:07.996419: step 15356, loss 0.0195323, acc 1\n",
      "2017-04-03T20:14:08.198779: step 15357, loss 0.0976846, acc 0.96875\n",
      "2017-04-03T20:14:08.440903: step 15358, loss 0.121972, acc 0.953125\n",
      "2017-04-03T20:14:08.642476: step 15359, loss 0.060548, acc 0.984375\n",
      "2017-04-03T20:14:08.844495: step 15360, loss 0.23053, acc 0.9375\n",
      "2017-04-03T20:14:09.065866: step 15361, loss 0.0664853, acc 0.984375\n",
      "2017-04-03T20:14:09.320342: step 15362, loss 0.209744, acc 0.90625\n",
      "2017-04-03T20:14:09.524323: step 15363, loss 0.180036, acc 0.9375\n",
      "2017-04-03T20:14:09.724905: step 15364, loss 0.147698, acc 0.96875\n",
      "2017-04-03T20:14:09.969571: step 15365, loss 0.204536, acc 0.921875\n",
      "2017-04-03T20:14:10.174387: step 15366, loss 0.172271, acc 0.90625\n",
      "2017-04-03T20:14:10.377833: step 15367, loss 0.0702949, acc 0.984375\n",
      "2017-04-03T20:14:10.580348: step 15368, loss 0.190338, acc 0.9375\n",
      "2017-04-03T20:14:10.788343: step 15369, loss 0.185726, acc 0.953125\n",
      "2017-04-03T20:14:10.987640: step 15370, loss 0.0545047, acc 0.96875\n",
      "2017-04-03T20:14:11.188467: step 15371, loss 0.124031, acc 0.9375\n",
      "2017-04-03T20:14:11.392088: step 15372, loss 0.186017, acc 0.953125\n",
      "2017-04-03T20:14:11.591052: step 15373, loss 0.0524064, acc 0.984375\n",
      "2017-04-03T20:14:11.795050: step 15374, loss 0.173674, acc 0.921875\n",
      "2017-04-03T20:14:12.007827: step 15375, loss 0.141209, acc 0.96875\n",
      "2017-04-03T20:14:12.208359: step 15376, loss 0.119944, acc 0.96875\n",
      "2017-04-03T20:14:12.406005: step 15377, loss 0.140605, acc 0.96875\n",
      "2017-04-03T20:14:12.607854: step 15378, loss 0.075286, acc 0.984375\n",
      "2017-04-03T20:14:12.808809: step 15379, loss 0.0884386, acc 0.96875\n",
      "2017-04-03T20:14:13.051973: step 15380, loss 0.0984752, acc 0.96875\n",
      "2017-04-03T20:14:13.255918: step 15381, loss 0.103405, acc 0.96875\n",
      "2017-04-03T20:14:13.456837: step 15382, loss 0.120305, acc 0.984375\n",
      "2017-04-03T20:14:13.661700: step 15383, loss 0.104311, acc 0.984375\n",
      "2017-04-03T20:14:13.861135: step 15384, loss 0.157682, acc 0.953125\n",
      "2017-04-03T20:14:14.063688: step 15385, loss 0.189272, acc 0.9375\n",
      "2017-04-03T20:14:14.261803: step 15386, loss 0.124172, acc 0.9375\n",
      "2017-04-03T20:14:14.478190: step 15387, loss 0.100231, acc 0.953125\n",
      "2017-04-03T20:14:14.689502: step 15388, loss 0.0358032, acc 1\n",
      "2017-04-03T20:14:14.892991: step 15389, loss 0.167253, acc 0.9375\n",
      "2017-04-03T20:14:15.095874: step 15390, loss 0.0751565, acc 0.96875\n",
      "2017-04-03T20:14:15.297687: step 15391, loss 0.0669675, acc 0.984375\n",
      "2017-04-03T20:14:15.499069: step 15392, loss 0.085209, acc 0.96875\n",
      "2017-04-03T20:14:15.700956: step 15393, loss 0.138051, acc 0.953125\n",
      "2017-04-03T20:14:15.901168: step 15394, loss 0.0922519, acc 0.953125\n",
      "2017-04-03T20:14:16.100241: step 15395, loss 0.274882, acc 0.9375\n",
      "2017-04-03T20:14:16.302638: step 15396, loss 0.279721, acc 0.90625\n",
      "2017-04-03T20:14:16.497594: step 15397, loss 0.153846, acc 0.9375\n",
      "2017-04-03T20:14:16.705891: step 15398, loss 0.0662268, acc 0.96875\n",
      "2017-04-03T20:14:16.909179: step 15399, loss 0.110037, acc 0.984375\n",
      "2017-04-03T20:14:17.111928: step 15400, loss 0.158131, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:14:19.225547: step 15400, loss 6.04556, acc 0.292\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-15400\n",
      "\n",
      "2017-04-03T20:14:19.594692: step 15401, loss 0.208671, acc 0.921875\n",
      "2017-04-03T20:14:19.801177: step 15402, loss 0.0698121, acc 0.953125\n",
      "2017-04-03T20:14:20.030671: step 15403, loss 0.300505, acc 0.953125\n",
      "2017-04-03T20:14:20.230324: step 15404, loss 0.0896392, acc 0.953125\n",
      "2017-04-03T20:14:20.473052: step 15405, loss 0.257881, acc 0.9375\n",
      "2017-04-03T20:14:20.674244: step 15406, loss 0.133289, acc 0.953125\n",
      "2017-04-03T20:14:20.878516: step 15407, loss 0.130883, acc 0.953125\n",
      "2017-04-03T20:14:21.083505: step 15408, loss 0.0942908, acc 0.9375\n",
      "2017-04-03T20:14:21.286130: step 15409, loss 0.0659936, acc 0.984375\n",
      "2017-04-03T20:14:21.487168: step 15410, loss 0.0195832, acc 1\n",
      "2017-04-03T20:14:21.691078: step 15411, loss 0.256562, acc 0.921875\n",
      "2017-04-03T20:14:21.892671: step 15412, loss 0.174687, acc 0.9375\n",
      "2017-04-03T20:14:22.085292: step 15413, loss 0.0833944, acc 0.984375\n",
      "2017-04-03T20:14:22.284303: step 15414, loss 0.0903271, acc 0.984375\n",
      "2017-04-03T20:14:22.484462: step 15415, loss 0.150015, acc 0.984375\n",
      "2017-04-03T20:14:22.691759: step 15416, loss 0.0989712, acc 0.96875\n",
      "2017-04-03T20:14:22.892168: step 15417, loss 0.311966, acc 0.9375\n",
      "2017-04-03T20:14:23.095279: step 15418, loss 0.207444, acc 0.953125\n",
      "2017-04-03T20:14:23.298342: step 15419, loss 0.152935, acc 0.953125\n",
      "2017-04-03T20:14:23.506111: step 15420, loss 0.151188, acc 0.96875\n",
      "2017-04-03T20:14:23.711269: step 15421, loss 0.109336, acc 0.984375\n",
      "2017-04-03T20:14:23.911581: step 15422, loss 0.106576, acc 0.96875\n",
      "2017-04-03T20:14:24.116951: step 15423, loss 0.0985446, acc 0.96875\n",
      "2017-04-03T20:14:24.320070: step 15424, loss 0.125567, acc 0.953125\n",
      "2017-04-03T20:14:24.522932: step 15425, loss 0.131987, acc 0.9375\n",
      "2017-04-03T20:14:24.726487: step 15426, loss 0.0945535, acc 0.984375\n",
      "2017-04-03T20:14:24.927181: step 15427, loss 0.136375, acc 0.953125\n",
      "2017-04-03T20:14:25.130212: step 15428, loss 0.0513497, acc 1\n",
      "2017-04-03T20:14:25.335541: step 15429, loss 0.134319, acc 0.9375\n",
      "2017-04-03T20:14:25.537485: step 15430, loss 0.0816552, acc 0.96875\n",
      "2017-04-03T20:14:25.740563: step 15431, loss 0.23315, acc 0.96875\n",
      "2017-04-03T20:14:25.939425: step 15432, loss 0.0658237, acc 0.984375\n",
      "2017-04-03T20:14:26.136729: step 15433, loss 0.12826, acc 0.9375\n",
      "2017-04-03T20:14:26.339006: step 15434, loss 0.107143, acc 0.984375\n",
      "2017-04-03T20:14:26.540702: step 15435, loss 0.176476, acc 0.953125\n",
      "2017-04-03T20:14:26.746893: step 15436, loss 0.0907051, acc 0.984375\n",
      "2017-04-03T20:14:26.950951: step 15437, loss 0.0360171, acc 1\n",
      "2017-04-03T20:14:27.148270: step 15438, loss 0.0586324, acc 0.96875\n",
      "2017-04-03T20:14:27.348353: step 15439, loss 0.180131, acc 0.953125\n",
      "2017-04-03T20:14:27.548531: step 15440, loss 0.0940533, acc 0.953125\n",
      "2017-04-03T20:14:27.791867: step 15441, loss 0.116964, acc 0.953125\n",
      "2017-04-03T20:14:27.996984: step 15442, loss 0.120619, acc 0.984375\n",
      "2017-04-03T20:14:28.199039: step 15443, loss 0.115858, acc 0.9375\n",
      "2017-04-03T20:14:28.399375: step 15444, loss 0.0621066, acc 0.96875\n",
      "2017-04-03T20:14:28.599394: step 15445, loss 0.157561, acc 0.953125\n",
      "2017-04-03T20:14:28.798089: step 15446, loss 0.059004, acc 0.984375\n",
      "2017-04-03T20:14:29.007385: step 15447, loss 0.0855372, acc 0.984375\n",
      "2017-04-03T20:14:29.208734: step 15448, loss 0.157226, acc 0.9375\n",
      "2017-04-03T20:14:29.409619: step 15449, loss 0.0977289, acc 0.96875\n",
      "2017-04-03T20:14:29.610078: step 15450, loss 0.0953637, acc 0.96875\n",
      "2017-04-03T20:14:29.814680: step 15451, loss 0.174928, acc 0.984375\n",
      "2017-04-03T20:14:30.058458: step 15452, loss 0.18627, acc 0.9375\n",
      "2017-04-03T20:14:30.260252: step 15453, loss 0.113946, acc 0.953125\n",
      "2017-04-03T20:14:30.502456: step 15454, loss 0.0952769, acc 0.953125\n",
      "2017-04-03T20:14:30.701834: step 15455, loss 0.185115, acc 0.953125\n",
      "2017-04-03T20:14:30.902060: step 15456, loss 0.0707627, acc 0.96875\n",
      "2017-04-03T20:14:31.115167: step 15457, loss 0.149602, acc 0.9375\n",
      "2017-04-03T20:14:31.317899: step 15458, loss 0.0888083, acc 0.96875\n",
      "2017-04-03T20:14:31.521725: step 15459, loss 0.076641, acc 0.96875\n",
      "2017-04-03T20:14:31.722837: step 15460, loss 0.134921, acc 0.9375\n",
      "2017-04-03T20:14:31.927352: step 15461, loss 0.081395, acc 0.984375\n",
      "2017-04-03T20:14:32.143160: step 15462, loss 0.172984, acc 0.953125\n",
      "2017-04-03T20:14:32.349778: step 15463, loss 0.123914, acc 0.984375\n",
      "2017-04-03T20:14:32.551337: step 15464, loss 0.0830041, acc 0.96875\n",
      "2017-04-03T20:14:32.750941: step 15465, loss 0.234244, acc 0.921875\n",
      "2017-04-03T20:14:32.954023: step 15466, loss 0.229465, acc 0.953125\n",
      "2017-04-03T20:14:33.155066: step 15467, loss 0.131732, acc 0.9375\n",
      "2017-04-03T20:14:33.357554: step 15468, loss 0.119663, acc 0.96875\n",
      "2017-04-03T20:14:33.555779: step 15469, loss 0.163775, acc 0.9375\n",
      "2017-04-03T20:14:33.759219: step 15470, loss 0.0520932, acc 0.96875\n",
      "2017-04-03T20:14:33.964255: step 15471, loss 0.12444, acc 0.953125\n",
      "2017-04-03T20:14:34.206275: step 15472, loss 0.0848467, acc 0.96875\n",
      "2017-04-03T20:14:34.409762: step 15473, loss 0.162539, acc 0.953125\n",
      "2017-04-03T20:14:34.616952: step 15474, loss 0.147258, acc 0.9375\n",
      "2017-04-03T20:14:34.815323: step 15475, loss 0.123262, acc 0.953125\n",
      "2017-04-03T20:14:35.016987: step 15476, loss 0.209132, acc 0.9375\n",
      "2017-04-03T20:14:35.222118: step 15477, loss 0.0945001, acc 0.984375\n",
      "2017-04-03T20:14:35.430889: step 15478, loss 0.354601, acc 0.921875\n",
      "2017-04-03T20:14:35.632767: step 15479, loss 0.239841, acc 0.9375\n",
      "2017-04-03T20:14:35.835005: step 15480, loss 0.0839227, acc 0.96875\n",
      "2017-04-03T20:14:36.077048: step 15481, loss 0.0916514, acc 0.953125\n",
      "2017-04-03T20:14:36.284904: step 15482, loss 0.0935794, acc 0.96875\n",
      "2017-04-03T20:14:36.481303: step 15483, loss 0.122177, acc 0.953125\n",
      "2017-04-03T20:14:36.679848: step 15484, loss 0.102335, acc 0.96875\n",
      "2017-04-03T20:14:36.922880: step 15485, loss 0.0921264, acc 0.96875\n",
      "2017-04-03T20:14:37.128233: step 15486, loss 0.0560108, acc 0.984375\n",
      "2017-04-03T20:14:37.333310: step 15487, loss 0.224507, acc 0.953125\n",
      "2017-04-03T20:14:37.579013: step 15488, loss 0.283394, acc 0.921875\n",
      "2017-04-03T20:14:37.783464: step 15489, loss 0.197324, acc 0.9375\n",
      "2017-04-03T20:14:37.998008: step 15490, loss 0.158725, acc 0.9375\n",
      "2017-04-03T20:14:38.214293: step 15491, loss 0.215224, acc 0.9375\n",
      "2017-04-03T20:14:38.436570: step 15492, loss 0.0784445, acc 1\n",
      "2017-04-03T20:14:38.635226: step 15493, loss 0.155464, acc 0.9375\n",
      "2017-04-03T20:14:38.835407: step 15494, loss 0.0676166, acc 0.984375\n",
      "2017-04-03T20:14:39.037796: step 15495, loss 0.13611, acc 0.953125\n",
      "2017-04-03T20:14:39.241243: step 15496, loss 0.226684, acc 0.921875\n",
      "2017-04-03T20:14:39.442361: step 15497, loss 0.315327, acc 0.921875\n",
      "2017-04-03T20:14:39.644124: step 15498, loss 0.190028, acc 0.90625\n",
      "2017-04-03T20:14:39.845644: step 15499, loss 0.140383, acc 0.9375\n",
      "2017-04-03T20:14:40.046382: step 15500, loss 0.131302, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:14:42.092718: step 15500, loss 6.06175, acc 0.2815\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-15500\n",
      "\n",
      "2017-04-03T20:14:42.423510: step 15501, loss 0.261961, acc 0.921875\n",
      "2017-04-03T20:14:42.627829: step 15502, loss 0.123012, acc 0.984375\n",
      "2017-04-03T20:14:42.829296: step 15503, loss 0.238685, acc 0.921875\n",
      "2017-04-03T20:14:43.029100: step 15504, loss 0.0601864, acc 1\n",
      "2017-04-03T20:14:43.235963: step 15505, loss 0.197853, acc 0.9375\n",
      "2017-04-03T20:14:43.437519: step 15506, loss 0.132974, acc 0.953125\n",
      "2017-04-03T20:14:43.637755: step 15507, loss 0.0844319, acc 0.984375\n",
      "2017-04-03T20:14:43.840679: step 15508, loss 0.0678619, acc 0.96875\n",
      "2017-04-03T20:14:44.055622: step 15509, loss 0.185597, acc 0.9375\n",
      "2017-04-03T20:14:44.255447: step 15510, loss 0.117896, acc 0.96875\n",
      "2017-04-03T20:14:44.457493: step 15511, loss 0.266949, acc 0.921875\n",
      "2017-04-03T20:14:44.662014: step 15512, loss 0.125568, acc 0.953125\n",
      "2017-04-03T20:14:44.865667: step 15513, loss 0.0669779, acc 1\n",
      "2017-04-03T20:14:45.073528: step 15514, loss 0.042234, acc 0.984375\n",
      "2017-04-03T20:14:45.284234: step 15515, loss 0.242558, acc 0.90625\n",
      "2017-04-03T20:14:45.488050: step 15516, loss 0.131786, acc 0.96875\n",
      "2017-04-03T20:14:45.688457: step 15517, loss 0.0900051, acc 0.953125\n",
      "2017-04-03T20:14:45.897120: step 15518, loss 0.0948802, acc 0.984375\n",
      "2017-04-03T20:14:46.097412: step 15519, loss 0.206479, acc 0.953125\n",
      "2017-04-03T20:14:46.298731: step 15520, loss 0.17775, acc 0.9375\n",
      "2017-04-03T20:14:46.502708: step 15521, loss 0.149305, acc 0.96875\n",
      "2017-04-03T20:14:46.739011: step 15522, loss 0.138558, acc 0.96875\n",
      "2017-04-03T20:14:46.945944: step 15523, loss 0.198148, acc 0.9375\n",
      "2017-04-03T20:14:47.194018: step 15524, loss 0.104518, acc 0.953125\n",
      "2017-04-03T20:14:47.441515: step 15525, loss 0.169703, acc 0.9375\n",
      "2017-04-03T20:14:47.648176: step 15526, loss 0.138202, acc 0.96875\n",
      "2017-04-03T20:14:47.855419: step 15527, loss 0.14557, acc 0.953125\n",
      "2017-04-03T20:14:48.056976: step 15528, loss 0.128939, acc 0.953125\n",
      "2017-04-03T20:14:48.260855: step 15529, loss 0.0802076, acc 0.953125\n",
      "2017-04-03T20:14:48.461850: step 15530, loss 0.134558, acc 0.96875\n",
      "2017-04-03T20:14:48.666575: step 15531, loss 0.200554, acc 0.921875\n",
      "2017-04-03T20:14:48.870029: step 15532, loss 0.193521, acc 0.9375\n",
      "2017-04-03T20:14:49.075387: step 15533, loss 0.104917, acc 0.953125\n",
      "2017-04-03T20:14:49.276321: step 15534, loss 0.0436624, acc 1\n",
      "2017-04-03T20:14:49.479223: step 15535, loss 0.071196, acc 0.984375\n",
      "2017-04-03T20:14:49.679977: step 15536, loss 0.0811246, acc 0.984375\n",
      "2017-04-03T20:14:49.885405: step 15537, loss 0.0835739, acc 0.984375\n",
      "2017-04-03T20:14:50.088451: step 15538, loss 0.138711, acc 0.9375\n",
      "2017-04-03T20:14:50.288924: step 15539, loss 0.106559, acc 0.96875\n",
      "2017-04-03T20:14:50.496142: step 15540, loss 0.182102, acc 0.9375\n",
      "2017-04-03T20:14:50.696955: step 15541, loss 0.113753, acc 0.984375\n",
      "2017-04-03T20:14:50.905759: step 15542, loss 0.188288, acc 0.875\n",
      "2017-04-03T20:14:51.106161: step 15543, loss 0.217601, acc 0.90625\n",
      "2017-04-03T20:14:51.310087: step 15544, loss 0.208219, acc 0.90625\n",
      "2017-04-03T20:14:51.553184: step 15545, loss 0.200517, acc 0.953125\n",
      "2017-04-03T20:14:51.760454: step 15546, loss 0.243085, acc 0.9375\n",
      "2017-04-03T20:14:51.958415: step 15547, loss 0.243577, acc 0.9375\n",
      "2017-04-03T20:14:52.162722: step 15548, loss 0.156299, acc 0.9375\n",
      "2017-04-03T20:14:52.364248: step 15549, loss 0.264805, acc 0.9375\n",
      "2017-04-03T20:14:52.609800: step 15550, loss 0.143556, acc 0.921875\n",
      "2017-04-03T20:14:52.807882: step 15551, loss 0.156187, acc 0.953125\n",
      "2017-04-03T20:14:53.010622: step 15552, loss 0.155164, acc 0.953125\n",
      "2017-04-03T20:14:53.212076: step 15553, loss 0.0421699, acc 0.984375\n",
      "2017-04-03T20:14:53.422619: step 15554, loss 0.093733, acc 0.96875\n",
      "2017-04-03T20:14:53.627460: step 15555, loss 0.145959, acc 0.953125\n",
      "2017-04-03T20:14:53.847661: step 15556, loss 0.162832, acc 0.9375\n",
      "2017-04-03T20:14:54.062835: step 15557, loss 0.10533, acc 0.984375\n",
      "2017-04-03T20:14:54.264089: step 15558, loss 0.114523, acc 0.96875\n",
      "2017-04-03T20:14:54.465374: step 15559, loss 0.194474, acc 0.921875\n",
      "2017-04-03T20:14:54.663086: step 15560, loss 0.104224, acc 0.953125\n",
      "2017-04-03T20:14:54.879395: step 15561, loss 0.0772932, acc 0.953125\n",
      "2017-04-03T20:14:55.098258: step 15562, loss 0.111567, acc 0.9375\n",
      "2017-04-03T20:14:55.299357: step 15563, loss 0.113224, acc 0.96875\n",
      "2017-04-03T20:14:55.500931: step 15564, loss 0.14639, acc 0.96875\n",
      "2017-04-03T20:14:55.742573: step 15565, loss 0.0778634, acc 0.984375\n",
      "2017-04-03T20:14:55.943693: step 15566, loss 0.29543, acc 0.890625\n",
      "2017-04-03T20:14:56.149027: step 15567, loss 0.112603, acc 0.921875\n",
      "2017-04-03T20:14:56.350355: step 15568, loss 0.179873, acc 0.921875\n",
      "2017-04-03T20:14:56.555465: step 15569, loss 0.210148, acc 0.9375\n",
      "2017-04-03T20:14:56.757417: step 15570, loss 0.0949853, acc 0.96875\n",
      "2017-04-03T20:14:56.986075: step 15571, loss 0.151983, acc 0.953125\n",
      "2017-04-03T20:14:57.192648: step 15572, loss 0.238259, acc 0.9375\n",
      "2017-04-03T20:14:57.394815: step 15573, loss 0.243681, acc 0.953125\n",
      "2017-04-03T20:14:57.594501: step 15574, loss 0.29185, acc 0.96875\n",
      "2017-04-03T20:14:57.789384: step 15575, loss 0.149457, acc 0.96875\n",
      "2017-04-03T20:14:57.998239: step 15576, loss 0.153224, acc 0.9375\n",
      "2017-04-03T20:14:58.201793: step 15577, loss 0.0590851, acc 1\n",
      "2017-04-03T20:14:58.409927: step 15578, loss 0.089654, acc 0.9375\n",
      "2017-04-03T20:14:58.614382: step 15579, loss 0.115748, acc 0.96875\n",
      "2017-04-03T20:14:58.814781: step 15580, loss 0.0815919, acc 0.96875\n",
      "2017-04-03T20:14:59.060556: step 15581, loss 0.15339, acc 0.90625\n",
      "2017-04-03T20:14:59.260829: step 15582, loss 0.057096, acc 0.984375\n",
      "2017-04-03T20:14:59.509468: step 15583, loss 0.51093, acc 0.9375\n",
      "2017-04-03T20:14:59.715337: step 15584, loss 0.251949, acc 0.9375\n",
      "2017-04-03T20:14:59.916862: step 15585, loss 0.130742, acc 0.921875\n",
      "2017-04-03T20:15:00.117963: step 15586, loss 0.0892238, acc 0.984375\n",
      "2017-04-03T20:15:00.320730: step 15587, loss 0.169149, acc 0.9375\n",
      "2017-04-03T20:15:00.524931: step 15588, loss 0.0790994, acc 0.984375\n",
      "2017-04-03T20:15:00.726212: step 15589, loss 0.217624, acc 0.9375\n",
      "2017-04-03T20:15:00.928079: step 15590, loss 0.257936, acc 0.921875\n",
      "2017-04-03T20:15:01.131935: step 15591, loss 0.14967, acc 0.953125\n",
      "2017-04-03T20:15:01.332557: step 15592, loss 0.051236, acc 0.984375\n",
      "2017-04-03T20:15:01.535338: step 15593, loss 0.214206, acc 0.921875\n",
      "2017-04-03T20:15:01.738307: step 15594, loss 0.0766694, acc 1\n",
      "2017-04-03T20:15:01.946136: step 15595, loss 0.0398759, acc 1\n",
      "2017-04-03T20:15:02.146424: step 15596, loss 0.184287, acc 0.921875\n",
      "2017-04-03T20:15:02.348885: step 15597, loss 0.330051, acc 0.90625\n",
      "2017-04-03T20:15:02.554098: step 15598, loss 0.0426009, acc 1\n",
      "2017-04-03T20:15:02.758644: step 15599, loss 0.34504, acc 0.90625\n",
      "2017-04-03T20:15:02.965421: step 15600, loss 0.0931354, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:15:05.118922: step 15600, loss 6.11355, acc 0.28675\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-15600\n",
      "\n",
      "2017-04-03T20:15:05.448824: step 15601, loss 0.117431, acc 0.953125\n",
      "2017-04-03T20:15:05.689033: step 15602, loss 0.10909, acc 0.953125\n",
      "2017-04-03T20:15:05.938559: step 15603, loss 0.309729, acc 0.953125\n",
      "2017-04-03T20:15:06.137591: step 15604, loss 0.160071, acc 0.9375\n",
      "2017-04-03T20:15:06.341103: step 15605, loss 0.148896, acc 0.953125\n",
      "2017-04-03T20:15:06.540623: step 15606, loss 0.092452, acc 0.96875\n",
      "2017-04-03T20:15:06.741780: step 15607, loss 0.147656, acc 0.953125\n",
      "2017-04-03T20:15:06.954068: step 15608, loss 0.0640653, acc 0.984375\n",
      "2017-04-03T20:15:07.162801: step 15609, loss 0.0867519, acc 0.96875\n",
      "2017-04-03T20:15:07.363351: step 15610, loss 0.111345, acc 0.984375\n",
      "2017-04-03T20:15:07.563805: step 15611, loss 0.0810999, acc 0.984375\n",
      "2017-04-03T20:15:07.767438: step 15612, loss 0.183921, acc 0.953125\n",
      "2017-04-03T20:15:07.980899: step 15613, loss 0.237077, acc 0.9375\n",
      "2017-04-03T20:15:08.191590: step 15614, loss 0.204346, acc 0.96875\n",
      "2017-04-03T20:15:08.394132: step 15615, loss 0.128096, acc 0.96875\n",
      "2017-04-03T20:15:08.593660: step 15616, loss 0.134437, acc 0.9375\n",
      "2017-04-03T20:15:08.802170: step 15617, loss 0.209808, acc 0.96875\n",
      "2017-04-03T20:15:09.015087: step 15618, loss 0.19401, acc 0.890625\n",
      "2017-04-03T20:15:09.216032: step 15619, loss 0.101936, acc 0.96875\n",
      "2017-04-03T20:15:09.414276: step 15620, loss 0.161296, acc 0.96875\n",
      "2017-04-03T20:15:09.613650: step 15621, loss 0.147762, acc 0.953125\n",
      "2017-04-03T20:15:09.825346: step 15622, loss 0.062816, acc 1\n",
      "2017-04-03T20:15:10.036475: step 15623, loss 0.109761, acc 0.96875\n",
      "2017-04-03T20:15:10.238033: step 15624, loss 0.127076, acc 0.9375\n",
      "2017-04-03T20:15:10.479634: step 15625, loss 0.113131, acc 0.96875\n",
      "2017-04-03T20:15:10.706012: step 15626, loss 0.0548373, acc 0.984375\n",
      "2017-04-03T20:15:10.909277: step 15627, loss 0.0928165, acc 0.96875\n",
      "2017-04-03T20:15:11.108463: step 15628, loss 0.144057, acc 0.953125\n",
      "2017-04-03T20:15:11.319171: step 15629, loss 0.140225, acc 0.953125\n",
      "2017-04-03T20:15:11.527448: step 15630, loss 0.0997984, acc 0.96875\n",
      "2017-04-03T20:15:11.776964: step 15631, loss 0.138721, acc 0.96875\n",
      "2017-04-03T20:15:11.976914: step 15632, loss 0.0376742, acc 1\n",
      "2017-04-03T20:15:12.177976: step 15633, loss 0.266878, acc 0.9375\n",
      "2017-04-03T20:15:12.381507: step 15634, loss 0.238355, acc 0.890625\n",
      "2017-04-03T20:15:12.592296: step 15635, loss 0.12387, acc 0.96875\n",
      "2017-04-03T20:15:12.792267: step 15636, loss 0.0836212, acc 0.984375\n",
      "2017-04-03T20:15:13.006892: step 15637, loss 0.122118, acc 0.96875\n",
      "2017-04-03T20:15:13.209545: step 15638, loss 0.0948815, acc 0.96875\n",
      "2017-04-03T20:15:13.414060: step 15639, loss 0.12056, acc 0.953125\n",
      "2017-04-03T20:15:13.620936: step 15640, loss 0.0756579, acc 0.96875\n",
      "2017-04-03T20:15:13.823556: step 15641, loss 0.0828951, acc 0.96875\n",
      "2017-04-03T20:15:14.027399: step 15642, loss 0.132235, acc 0.953125\n",
      "2017-04-03T20:15:14.270973: step 15643, loss 0.138802, acc 0.9375\n",
      "2017-04-03T20:15:14.492141: step 15644, loss 0.118023, acc 0.953125\n",
      "2017-04-03T20:15:14.692727: step 15645, loss 0.162344, acc 0.96875\n",
      "2017-04-03T20:15:14.894225: step 15646, loss 0.166656, acc 0.9375\n",
      "2017-04-03T20:15:15.097776: step 15647, loss 0.0674614, acc 0.96875\n",
      "2017-04-03T20:15:15.345112: step 15648, loss 0.259678, acc 0.96875\n",
      "2017-04-03T20:15:15.549509: step 15649, loss 0.170434, acc 0.953125\n",
      "2017-04-03T20:15:15.748470: step 15650, loss 0.0994301, acc 0.96875\n",
      "2017-04-03T20:15:15.994425: step 15651, loss 0.133242, acc 0.9375\n",
      "2017-04-03T20:15:16.251738: step 15652, loss 0.136528, acc 0.96875\n",
      "2017-04-03T20:15:16.456196: step 15653, loss 0.177371, acc 0.9375\n",
      "2017-04-03T20:15:16.656698: step 15654, loss 0.0848733, acc 0.984375\n",
      "2017-04-03T20:15:16.857023: step 15655, loss 0.082637, acc 1\n",
      "2017-04-03T20:15:17.057841: step 15656, loss 0.276351, acc 0.90625\n",
      "2017-04-03T20:15:17.299537: step 15657, loss 0.10236, acc 0.953125\n",
      "2017-04-03T20:15:17.541959: step 15658, loss 0.127877, acc 0.953125\n",
      "2017-04-03T20:15:17.753876: step 15659, loss 0.170602, acc 0.953125\n",
      "2017-04-03T20:15:17.956268: step 15660, loss 0.212828, acc 0.953125\n",
      "2017-04-03T20:15:18.156498: step 15661, loss 0.153567, acc 0.96875\n",
      "2017-04-03T20:15:18.397214: step 15662, loss 0.172587, acc 0.9375\n",
      "2017-04-03T20:15:18.650551: step 15663, loss 0.224841, acc 0.9375\n",
      "2017-04-03T20:15:18.859459: step 15664, loss 0.226669, acc 0.890625\n",
      "2017-04-03T20:15:19.059072: step 15665, loss 0.176358, acc 0.9375\n",
      "2017-04-03T20:15:19.262273: step 15666, loss 0.225278, acc 0.9375\n",
      "2017-04-03T20:15:19.463742: step 15667, loss 0.128109, acc 0.953125\n",
      "2017-04-03T20:15:19.665470: step 15668, loss 0.101902, acc 0.96875\n",
      "2017-04-03T20:15:19.878483: step 15669, loss 0.0337654, acc 1\n",
      "2017-04-03T20:15:20.078885: step 15670, loss 0.206246, acc 0.9375\n",
      "2017-04-03T20:15:20.297655: step 15671, loss 0.142535, acc 0.9375\n",
      "2017-04-03T20:15:20.512457: step 15672, loss 0.0598854, acc 0.984375\n",
      "2017-04-03T20:15:20.715104: step 15673, loss 0.169717, acc 0.90625\n",
      "2017-04-03T20:15:20.917901: step 15674, loss 0.357509, acc 0.953125\n",
      "2017-04-03T20:15:21.121782: step 15675, loss 0.143063, acc 0.9375\n",
      "2017-04-03T20:15:21.324640: step 15676, loss 0.14563, acc 0.96875\n",
      "2017-04-03T20:15:21.525725: step 15677, loss 0.114775, acc 0.984375\n",
      "2017-04-03T20:15:21.728685: step 15678, loss 0.199579, acc 0.9375\n",
      "2017-04-03T20:15:21.932627: step 15679, loss 0.1532, acc 0.9375\n",
      "2017-04-03T20:15:22.137154: step 15680, loss 0.260043, acc 0.953125\n",
      "2017-04-03T20:15:22.350637: step 15681, loss 0.170745, acc 0.953125\n",
      "2017-04-03T20:15:22.601653: step 15682, loss 0.0982521, acc 0.984375\n",
      "2017-04-03T20:15:22.803136: step 15683, loss 0.127154, acc 0.953125\n",
      "2017-04-03T20:15:23.007561: step 15684, loss 0.222677, acc 0.9375\n",
      "2017-04-03T20:15:23.210725: step 15685, loss 0.171088, acc 0.96875\n",
      "2017-04-03T20:15:23.412502: step 15686, loss 0.060871, acc 1\n",
      "2017-04-03T20:15:23.620753: step 15687, loss 0.151362, acc 0.953125\n",
      "2017-04-03T20:15:23.817999: step 15688, loss 0.0813629, acc 0.96875\n",
      "2017-04-03T20:15:24.045506: step 15689, loss 0.138829, acc 0.9375\n",
      "2017-04-03T20:15:24.257711: step 15690, loss 0.151587, acc 0.9375\n",
      "2017-04-03T20:15:24.460556: step 15691, loss 0.150239, acc 0.953125\n",
      "2017-04-03T20:15:24.664198: step 15692, loss 0.108594, acc 0.953125\n",
      "2017-04-03T20:15:24.909991: step 15693, loss 0.16218, acc 0.984375\n",
      "2017-04-03T20:15:25.122815: step 15694, loss 0.13874, acc 0.953125\n",
      "2017-04-03T20:15:25.324697: step 15695, loss 0.184945, acc 0.96875\n",
      "2017-04-03T20:15:25.522717: step 15696, loss 0.154606, acc 0.953125\n",
      "2017-04-03T20:15:25.724214: step 15697, loss 0.146153, acc 0.953125\n",
      "2017-04-03T20:15:25.927043: step 15698, loss 0.130327, acc 0.984375\n",
      "2017-04-03T20:15:26.175405: step 15699, loss 0.0893966, acc 0.984375\n",
      "2017-04-03T20:15:26.396625: step 15700, loss 0.109599, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:15:28.529867: step 15700, loss 6.17507, acc 0.2895\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-15700\n",
      "\n",
      "2017-04-03T20:15:28.863500: step 15701, loss 0.112542, acc 0.96875\n",
      "2017-04-03T20:15:29.071321: step 15702, loss 0.210835, acc 0.9375\n",
      "2017-04-03T20:15:29.276146: step 15703, loss 0.147129, acc 0.984375\n",
      "2017-04-03T20:15:29.480764: step 15704, loss 0.0928812, acc 0.984375\n",
      "2017-04-03T20:15:29.688946: step 15705, loss 0.0747101, acc 0.96875\n",
      "2017-04-03T20:15:29.894876: step 15706, loss 0.266563, acc 0.9375\n",
      "2017-04-03T20:15:30.103908: step 15707, loss 0.0999188, acc 0.953125\n",
      "2017-04-03T20:15:30.348587: step 15708, loss 0.0759267, acc 0.984375\n",
      "2017-04-03T20:15:30.560004: step 15709, loss 0.186395, acc 0.921875\n",
      "2017-04-03T20:15:30.761997: step 15710, loss 0.152166, acc 0.953125\n",
      "2017-04-03T20:15:30.972288: step 15711, loss 0.115516, acc 0.953125\n",
      "2017-04-03T20:15:31.173857: step 15712, loss 0.0798662, acc 0.984375\n",
      "2017-04-03T20:15:31.380160: step 15713, loss 0.25472, acc 0.953125\n",
      "2017-04-03T20:15:31.580981: step 15714, loss 0.167739, acc 0.9375\n",
      "2017-04-03T20:15:31.790339: step 15715, loss 0.186425, acc 0.953125\n",
      "2017-04-03T20:15:31.992520: step 15716, loss 0.0737726, acc 0.984375\n",
      "2017-04-03T20:15:32.201098: step 15717, loss 0.287934, acc 0.875\n",
      "2017-04-03T20:15:32.401817: step 15718, loss 0.22202, acc 0.890625\n",
      "2017-04-03T20:15:32.605386: step 15719, loss 0.222565, acc 0.921875\n",
      "2017-04-03T20:15:32.806794: step 15720, loss 0.0601487, acc 0.984375\n",
      "2017-04-03T20:15:33.007652: step 15721, loss 0.175741, acc 0.953125\n",
      "2017-04-03T20:15:33.253189: step 15722, loss 0.218163, acc 0.953125\n",
      "2017-04-03T20:15:33.457824: step 15723, loss 0.13787, acc 0.9375\n",
      "2017-04-03T20:15:33.704790: step 15724, loss 0.31704, acc 0.921875\n",
      "2017-04-03T20:15:33.918492: step 15725, loss 0.0819772, acc 0.953125\n",
      "2017-04-03T20:15:34.170068: step 15726, loss 0.181086, acc 0.984375\n",
      "2017-04-03T20:15:34.385924: step 15727, loss 0.0983346, acc 0.96875\n",
      "2017-04-03T20:15:34.598808: step 15728, loss 0.121812, acc 0.953125\n",
      "2017-04-03T20:15:34.800331: step 15729, loss 0.0855866, acc 0.96875\n",
      "2017-04-03T20:15:35.003168: step 15730, loss 0.261101, acc 0.90625\n",
      "2017-04-03T20:15:35.209027: step 15731, loss 0.21101, acc 0.9375\n",
      "2017-04-03T20:15:35.409706: step 15732, loss 0.0838846, acc 0.953125\n",
      "2017-04-03T20:15:35.610345: step 15733, loss 0.128819, acc 0.953125\n",
      "2017-04-03T20:15:35.811367: step 15734, loss 0.207918, acc 0.890625\n",
      "2017-04-03T20:15:36.024684: step 15735, loss 0.152787, acc 0.953125\n",
      "2017-04-03T20:15:36.232174: step 15736, loss 0.296946, acc 0.9375\n",
      "2017-04-03T20:15:36.440869: step 15737, loss 0.0943996, acc 0.96875\n",
      "2017-04-03T20:15:36.659456: step 15738, loss 0.221907, acc 0.9375\n",
      "2017-04-03T20:15:36.875035: step 15739, loss 0.0874431, acc 0.96875\n",
      "2017-04-03T20:15:37.122671: step 15740, loss 0.158821, acc 0.96875\n",
      "2017-04-03T20:15:37.326032: step 15741, loss 0.21511, acc 0.953125\n",
      "2017-04-03T20:15:37.525986: step 15742, loss 0.279816, acc 0.90625\n",
      "2017-04-03T20:15:37.727938: step 15743, loss 0.144666, acc 0.953125\n",
      "2017-04-03T20:15:37.934733: step 15744, loss 0.1456, acc 0.9375\n",
      "2017-04-03T20:15:38.139289: step 15745, loss 0.120048, acc 0.953125\n",
      "2017-04-03T20:15:38.345696: step 15746, loss 0.144121, acc 0.953125\n",
      "2017-04-03T20:15:38.550380: step 15747, loss 0.0883764, acc 0.96875\n",
      "2017-04-03T20:15:38.756787: step 15748, loss 0.189643, acc 0.9375\n",
      "2017-04-03T20:15:38.962136: step 15749, loss 0.118561, acc 0.953125\n",
      "2017-04-03T20:15:39.162194: step 15750, loss 0.119832, acc 0.9375\n",
      "2017-04-03T20:15:39.372687: step 15751, loss 0.0184872, acc 1\n",
      "2017-04-03T20:15:39.579899: step 15752, loss 0.174292, acc 0.96875\n",
      "2017-04-03T20:15:39.801319: step 15753, loss 0.0819017, acc 0.96875\n",
      "2017-04-03T20:15:40.014112: step 15754, loss 0.16781, acc 0.953125\n",
      "2017-04-03T20:15:40.218904: step 15755, loss 0.19151, acc 0.921875\n",
      "2017-04-03T20:15:40.423816: step 15756, loss 0.140153, acc 0.96875\n",
      "2017-04-03T20:15:40.627809: step 15757, loss 0.123517, acc 0.9375\n",
      "2017-04-03T20:15:40.849044: step 15758, loss 0.163718, acc 0.953125\n",
      "2017-04-03T20:15:41.050586: step 15759, loss 0.260165, acc 0.9375\n",
      "2017-04-03T20:15:41.250712: step 15760, loss 0.17893, acc 0.953125\n",
      "2017-04-03T20:15:41.450167: step 15761, loss 0.173435, acc 0.953125\n",
      "2017-04-03T20:15:41.663680: step 15762, loss 0.255399, acc 0.921875\n",
      "2017-04-03T20:15:41.865516: step 15763, loss 0.214014, acc 0.90625\n",
      "2017-04-03T20:15:42.014490: step 15764, loss 0.146381, acc 0.96875\n",
      "2017-04-03T20:15:42.268508: step 15765, loss 0.166653, acc 0.96875\n",
      "2017-04-03T20:15:42.474509: step 15766, loss 0.0467996, acc 1\n",
      "2017-04-03T20:15:42.680248: step 15767, loss 0.1344, acc 0.953125\n",
      "2017-04-03T20:15:42.893235: step 15768, loss 0.0906435, acc 0.96875\n",
      "2017-04-03T20:15:43.113130: step 15769, loss 0.157682, acc 0.953125\n",
      "2017-04-03T20:15:43.321381: step 15770, loss 0.100541, acc 0.96875\n",
      "2017-04-03T20:15:43.524842: step 15771, loss 0.0852743, acc 0.96875\n",
      "2017-04-03T20:15:43.726403: step 15772, loss 0.20772, acc 0.96875\n",
      "2017-04-03T20:15:43.971245: step 15773, loss 0.175239, acc 0.9375\n",
      "2017-04-03T20:15:44.182882: step 15774, loss 0.11472, acc 0.96875\n",
      "2017-04-03T20:15:44.382325: step 15775, loss 0.117469, acc 0.9375\n",
      "2017-04-03T20:15:44.581933: step 15776, loss 0.152319, acc 0.96875\n",
      "2017-04-03T20:15:44.793176: step 15777, loss 0.0603958, acc 0.984375\n",
      "2017-04-03T20:15:45.002838: step 15778, loss 0.0445367, acc 0.96875\n",
      "2017-04-03T20:15:45.201859: step 15779, loss 0.204194, acc 0.9375\n",
      "2017-04-03T20:15:45.406087: step 15780, loss 0.154071, acc 0.9375\n",
      "2017-04-03T20:15:45.615501: step 15781, loss 0.102767, acc 0.953125\n",
      "2017-04-03T20:15:45.819800: step 15782, loss 0.0391825, acc 1\n",
      "2017-04-03T20:15:46.037931: step 15783, loss 0.126445, acc 0.953125\n",
      "2017-04-03T20:15:46.257591: step 15784, loss 0.119621, acc 0.96875\n",
      "2017-04-03T20:15:46.464446: step 15785, loss 0.107806, acc 0.96875\n",
      "2017-04-03T20:15:46.709394: step 15786, loss 0.0885864, acc 0.96875\n",
      "2017-04-03T20:15:46.916274: step 15787, loss 0.190437, acc 0.921875\n",
      "2017-04-03T20:15:47.122713: step 15788, loss 0.0808517, acc 0.96875\n",
      "2017-04-03T20:15:47.330647: step 15789, loss 0.0611293, acc 0.984375\n",
      "2017-04-03T20:15:47.533585: step 15790, loss 0.0875828, acc 0.96875\n",
      "2017-04-03T20:15:47.741612: step 15791, loss 0.0986737, acc 0.96875\n",
      "2017-04-03T20:15:47.944243: step 15792, loss 0.0331015, acc 0.984375\n",
      "2017-04-03T20:15:48.148539: step 15793, loss 0.204076, acc 0.90625\n",
      "2017-04-03T20:15:48.352987: step 15794, loss 0.134699, acc 0.9375\n",
      "2017-04-03T20:15:48.556526: step 15795, loss 0.038477, acc 0.984375\n",
      "2017-04-03T20:15:48.789300: step 15796, loss 0.122234, acc 0.984375\n",
      "2017-04-03T20:15:49.006906: step 15797, loss 0.125148, acc 0.953125\n",
      "2017-04-03T20:15:49.216697: step 15798, loss 0.166939, acc 0.96875\n",
      "2017-04-03T20:15:49.436958: step 15799, loss 0.0512319, acc 0.96875\n",
      "2017-04-03T20:15:49.643298: step 15800, loss 0.144512, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:15:51.767602: step 15800, loss 6.17626, acc 0.29375\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-15800\n",
      "\n",
      "2017-04-03T20:15:52.094692: step 15801, loss 0.102957, acc 0.96875\n",
      "2017-04-03T20:15:52.305798: step 15802, loss 0.0550712, acc 0.984375\n",
      "2017-04-03T20:15:52.509167: step 15803, loss 0.0667741, acc 0.984375\n",
      "2017-04-03T20:15:52.722938: step 15804, loss 0.111038, acc 0.953125\n",
      "2017-04-03T20:15:52.927014: step 15805, loss 0.197267, acc 0.9375\n",
      "2017-04-03T20:15:53.126790: step 15806, loss 0.0970128, acc 0.984375\n",
      "2017-04-03T20:15:53.328795: step 15807, loss 0.0684937, acc 1\n",
      "2017-04-03T20:15:53.546558: step 15808, loss 0.148727, acc 0.96875\n",
      "2017-04-03T20:15:53.766172: step 15809, loss 0.0835419, acc 0.984375\n",
      "2017-04-03T20:15:53.969016: step 15810, loss 0.116561, acc 0.921875\n",
      "2017-04-03T20:15:54.166921: step 15811, loss 0.0597457, acc 0.96875\n",
      "2017-04-03T20:15:54.368401: step 15812, loss 0.214492, acc 0.90625\n",
      "2017-04-03T20:15:54.568250: step 15813, loss 0.0742049, acc 0.96875\n",
      "2017-04-03T20:15:54.768632: step 15814, loss 0.0916867, acc 0.96875\n",
      "2017-04-03T20:15:54.967568: step 15815, loss 0.120626, acc 0.953125\n",
      "2017-04-03T20:15:55.166944: step 15816, loss 0.102947, acc 0.953125\n",
      "2017-04-03T20:15:55.371690: step 15817, loss 0.063687, acc 1\n",
      "2017-04-03T20:15:55.574699: step 15818, loss 0.103719, acc 0.984375\n",
      "2017-04-03T20:15:55.780085: step 15819, loss 0.0773804, acc 0.96875\n",
      "2017-04-03T20:15:56.025668: step 15820, loss 0.114886, acc 0.953125\n",
      "2017-04-03T20:15:56.230861: step 15821, loss 0.0943826, acc 0.96875\n",
      "2017-04-03T20:15:56.432187: step 15822, loss 0.0526683, acc 1\n",
      "2017-04-03T20:15:56.633898: step 15823, loss 0.0743063, acc 0.984375\n",
      "2017-04-03T20:15:56.839557: step 15824, loss 0.146851, acc 0.96875\n",
      "2017-04-03T20:15:57.055408: step 15825, loss 0.0749062, acc 0.984375\n",
      "2017-04-03T20:15:57.263751: step 15826, loss 0.361286, acc 0.921875\n",
      "2017-04-03T20:15:57.489741: step 15827, loss 0.0276272, acc 1\n",
      "2017-04-03T20:15:57.692112: step 15828, loss 0.109452, acc 0.9375\n",
      "2017-04-03T20:15:57.896928: step 15829, loss 0.0986583, acc 0.9375\n",
      "2017-04-03T20:15:58.101733: step 15830, loss 0.107894, acc 0.96875\n",
      "2017-04-03T20:15:58.307780: step 15831, loss 0.163308, acc 0.953125\n",
      "2017-04-03T20:15:58.509739: step 15832, loss 0.0900452, acc 0.96875\n",
      "2017-04-03T20:15:58.711697: step 15833, loss 0.0875703, acc 0.984375\n",
      "2017-04-03T20:15:58.912827: step 15834, loss 0.120613, acc 0.953125\n",
      "2017-04-03T20:15:59.117084: step 15835, loss 0.139813, acc 0.953125\n",
      "2017-04-03T20:15:59.320504: step 15836, loss 0.205646, acc 0.9375\n",
      "2017-04-03T20:15:59.530642: step 15837, loss 0.105041, acc 0.984375\n",
      "2017-04-03T20:15:59.732980: step 15838, loss 0.133525, acc 0.96875\n",
      "2017-04-03T20:15:59.982153: step 15839, loss 0.0763756, acc 0.96875\n",
      "2017-04-03T20:16:00.184812: step 15840, loss 0.0802604, acc 0.984375\n",
      "2017-04-03T20:16:00.388192: step 15841, loss 0.0944679, acc 0.953125\n",
      "2017-04-03T20:16:00.591221: step 15842, loss 0.0858677, acc 0.96875\n",
      "2017-04-03T20:16:00.795805: step 15843, loss 0.106883, acc 0.953125\n",
      "2017-04-03T20:16:01.004675: step 15844, loss 0.0744255, acc 0.984375\n",
      "2017-04-03T20:16:01.205859: step 15845, loss 0.0774092, acc 0.984375\n",
      "2017-04-03T20:16:01.412604: step 15846, loss 0.0951736, acc 0.953125\n",
      "2017-04-03T20:16:01.619389: step 15847, loss 0.057026, acc 1\n",
      "2017-04-03T20:16:01.821660: step 15848, loss 0.0967735, acc 0.96875\n",
      "2017-04-03T20:16:02.023441: step 15849, loss 0.0260833, acc 1\n",
      "2017-04-03T20:16:02.224611: step 15850, loss 0.131093, acc 0.96875\n",
      "2017-04-03T20:16:02.472354: step 15851, loss 0.0713497, acc 0.953125\n",
      "2017-04-03T20:16:02.682358: step 15852, loss 0.119422, acc 0.96875\n",
      "2017-04-03T20:16:02.883293: step 15853, loss 0.0974173, acc 0.96875\n",
      "2017-04-03T20:16:03.087600: step 15854, loss 0.222872, acc 0.9375\n",
      "2017-04-03T20:16:03.292323: step 15855, loss 0.0636155, acc 0.984375\n",
      "2017-04-03T20:16:03.497632: step 15856, loss 0.173995, acc 0.9375\n",
      "2017-04-03T20:16:03.738299: step 15857, loss 0.151289, acc 0.953125\n",
      "2017-04-03T20:16:03.949135: step 15858, loss 0.234493, acc 0.9375\n",
      "2017-04-03T20:16:04.163292: step 15859, loss 0.0946554, acc 0.96875\n",
      "2017-04-03T20:16:04.383301: step 15860, loss 0.0352267, acc 1\n",
      "2017-04-03T20:16:04.599820: step 15861, loss 0.0978423, acc 0.96875\n",
      "2017-04-03T20:16:04.817230: step 15862, loss 0.116433, acc 0.9375\n",
      "2017-04-03T20:16:05.034882: step 15863, loss 0.0720134, acc 0.984375\n",
      "2017-04-03T20:16:05.248864: step 15864, loss 0.0738457, acc 0.953125\n",
      "2017-04-03T20:16:05.499722: step 15865, loss 0.0669586, acc 0.96875\n",
      "2017-04-03T20:16:05.702309: step 15866, loss 0.158738, acc 0.921875\n",
      "2017-04-03T20:16:05.912730: step 15867, loss 0.211981, acc 0.96875\n",
      "2017-04-03T20:16:06.129003: step 15868, loss 0.062594, acc 0.984375\n",
      "2017-04-03T20:16:06.332113: step 15869, loss 0.152192, acc 0.953125\n",
      "2017-04-03T20:16:06.531760: step 15870, loss 0.105266, acc 0.953125\n",
      "2017-04-03T20:16:06.734843: step 15871, loss 0.104632, acc 0.953125\n",
      "2017-04-03T20:16:06.938138: step 15872, loss 0.104744, acc 0.953125\n",
      "2017-04-03T20:16:07.140703: step 15873, loss 0.131054, acc 0.953125\n",
      "2017-04-03T20:16:07.343144: step 15874, loss 0.0951359, acc 0.96875\n",
      "2017-04-03T20:16:07.543227: step 15875, loss 0.130926, acc 0.953125\n",
      "2017-04-03T20:16:07.746975: step 15876, loss 0.0285539, acc 1\n",
      "2017-04-03T20:16:07.946116: step 15877, loss 0.206791, acc 0.953125\n",
      "2017-04-03T20:16:08.175825: step 15878, loss 0.163566, acc 0.9375\n",
      "2017-04-03T20:16:08.399186: step 15879, loss 0.0911368, acc 0.96875\n",
      "2017-04-03T20:16:08.604896: step 15880, loss 0.126266, acc 0.953125\n",
      "2017-04-03T20:16:08.804032: step 15881, loss 0.0697904, acc 0.984375\n",
      "2017-04-03T20:16:09.004723: step 15882, loss 0.0809918, acc 0.96875\n",
      "2017-04-03T20:16:09.209050: step 15883, loss 0.156901, acc 0.9375\n",
      "2017-04-03T20:16:09.413807: step 15884, loss 0.0475771, acc 1\n",
      "2017-04-03T20:16:09.649546: step 15885, loss 0.0365408, acc 1\n",
      "2017-04-03T20:16:09.907209: step 15886, loss 0.199366, acc 0.921875\n",
      "2017-04-03T20:16:10.106929: step 15887, loss 0.196143, acc 0.9375\n",
      "2017-04-03T20:16:10.319170: step 15888, loss 0.13793, acc 0.9375\n",
      "2017-04-03T20:16:10.518430: step 15889, loss 0.126586, acc 0.953125\n",
      "2017-04-03T20:16:10.722769: step 15890, loss 0.156711, acc 0.9375\n",
      "2017-04-03T20:16:10.929252: step 15891, loss 0.121717, acc 0.953125\n",
      "2017-04-03T20:16:11.147660: step 15892, loss 0.093395, acc 0.953125\n",
      "2017-04-03T20:16:11.406311: step 15893, loss 0.116983, acc 0.984375\n",
      "2017-04-03T20:16:11.606398: step 15894, loss 0.0567183, acc 1\n",
      "2017-04-03T20:16:11.815389: step 15895, loss 0.146949, acc 0.921875\n",
      "2017-04-03T20:16:12.015274: step 15896, loss 0.158546, acc 0.9375\n",
      "2017-04-03T20:16:12.221366: step 15897, loss 0.0896297, acc 0.984375\n",
      "2017-04-03T20:16:12.420280: step 15898, loss 0.109645, acc 0.953125\n",
      "2017-04-03T20:16:12.616037: step 15899, loss 0.147547, acc 0.9375\n",
      "2017-04-03T20:16:12.818358: step 15900, loss 0.119924, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:16:14.929469: step 15900, loss 6.25174, acc 0.29\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-15900\n",
      "\n",
      "2017-04-03T20:16:15.272035: step 15901, loss 0.180174, acc 0.96875\n",
      "2017-04-03T20:16:15.473468: step 15902, loss 0.07582, acc 0.984375\n",
      "2017-04-03T20:16:15.713487: step 15903, loss 0.0785426, acc 0.96875\n",
      "2017-04-03T20:16:15.920826: step 15904, loss 0.132272, acc 0.953125\n",
      "2017-04-03T20:16:16.122247: step 15905, loss 0.0823604, acc 0.984375\n",
      "2017-04-03T20:16:16.326763: step 15906, loss 0.041609, acc 1\n",
      "2017-04-03T20:16:16.529209: step 15907, loss 0.137789, acc 0.953125\n",
      "2017-04-03T20:16:16.772141: step 15908, loss 0.26304, acc 0.890625\n",
      "2017-04-03T20:16:16.977909: step 15909, loss 0.205865, acc 0.953125\n",
      "2017-04-03T20:16:17.186333: step 15910, loss 0.11137, acc 0.96875\n",
      "2017-04-03T20:16:17.392281: step 15911, loss 0.111222, acc 0.96875\n",
      "2017-04-03T20:16:17.592593: step 15912, loss 0.166536, acc 0.96875\n",
      "2017-04-03T20:16:17.793800: step 15913, loss 0.0376318, acc 1\n",
      "2017-04-03T20:16:18.003491: step 15914, loss 0.131514, acc 0.96875\n",
      "2017-04-03T20:16:18.207892: step 15915, loss 0.248171, acc 0.96875\n",
      "2017-04-03T20:16:18.409006: step 15916, loss 0.0846564, acc 0.984375\n",
      "2017-04-03T20:16:18.610049: step 15917, loss 0.107432, acc 0.984375\n",
      "2017-04-03T20:16:18.821457: step 15918, loss 0.175151, acc 0.921875\n",
      "2017-04-03T20:16:19.036377: step 15919, loss 0.113642, acc 0.984375\n",
      "2017-04-03T20:16:19.249018: step 15920, loss 0.209424, acc 0.921875\n",
      "2017-04-03T20:16:19.459577: step 15921, loss 0.0368508, acc 1\n",
      "2017-04-03T20:16:19.668840: step 15922, loss 0.0183092, acc 1\n",
      "2017-04-03T20:16:19.868460: step 15923, loss 0.092095, acc 0.953125\n",
      "2017-04-03T20:16:20.071251: step 15924, loss 0.172382, acc 0.9375\n",
      "2017-04-03T20:16:20.276404: step 15925, loss 0.29378, acc 0.921875\n",
      "2017-04-03T20:16:20.477478: step 15926, loss 0.0772019, acc 0.96875\n",
      "2017-04-03T20:16:20.680186: step 15927, loss 0.123655, acc 0.9375\n",
      "2017-04-03T20:16:20.879796: step 15928, loss 0.119089, acc 0.96875\n",
      "2017-04-03T20:16:21.081859: step 15929, loss 0.142208, acc 0.953125\n",
      "2017-04-03T20:16:21.282978: step 15930, loss 0.0899348, acc 0.984375\n",
      "2017-04-03T20:16:21.484302: step 15931, loss 0.0705594, acc 0.984375\n",
      "2017-04-03T20:16:21.690425: step 15932, loss 0.0480782, acc 1\n",
      "2017-04-03T20:16:21.893407: step 15933, loss 0.211947, acc 0.953125\n",
      "2017-04-03T20:16:22.096155: step 15934, loss 0.0578145, acc 1\n",
      "2017-04-03T20:16:22.297397: step 15935, loss 0.110382, acc 0.953125\n",
      "2017-04-03T20:16:22.536083: step 15936, loss 0.0498965, acc 0.984375\n",
      "2017-04-03T20:16:22.736710: step 15937, loss 0.165558, acc 0.953125\n",
      "2017-04-03T20:16:22.936962: step 15938, loss 0.0635936, acc 0.96875\n",
      "2017-04-03T20:16:23.142059: step 15939, loss 0.087246, acc 0.96875\n",
      "2017-04-03T20:16:23.345059: step 15940, loss 0.158182, acc 0.953125\n",
      "2017-04-03T20:16:23.544378: step 15941, loss 0.159068, acc 0.9375\n",
      "2017-04-03T20:16:23.745485: step 15942, loss 0.464733, acc 0.90625\n",
      "2017-04-03T20:16:23.951065: step 15943, loss 0.0878112, acc 0.953125\n",
      "2017-04-03T20:16:24.149225: step 15944, loss 0.109569, acc 0.953125\n",
      "2017-04-03T20:16:24.353259: step 15945, loss 0.06094, acc 0.96875\n",
      "2017-04-03T20:16:24.549885: step 15946, loss 0.0852787, acc 0.96875\n",
      "2017-04-03T20:16:24.752633: step 15947, loss 0.104356, acc 0.96875\n",
      "2017-04-03T20:16:24.955598: step 15948, loss 0.109915, acc 0.984375\n",
      "2017-04-03T20:16:25.157313: step 15949, loss 0.12951, acc 0.9375\n",
      "2017-04-03T20:16:25.357530: step 15950, loss 0.144535, acc 0.921875\n",
      "2017-04-03T20:16:25.561828: step 15951, loss 0.107279, acc 0.953125\n",
      "2017-04-03T20:16:25.764067: step 15952, loss 0.170988, acc 0.9375\n",
      "2017-04-03T20:16:25.964795: step 15953, loss 0.234501, acc 0.953125\n",
      "2017-04-03T20:16:26.165198: step 15954, loss 0.017186, acc 1\n",
      "2017-04-03T20:16:26.369590: step 15955, loss 0.146279, acc 0.96875\n",
      "2017-04-03T20:16:26.575116: step 15956, loss 0.126897, acc 0.953125\n",
      "2017-04-03T20:16:26.776587: step 15957, loss 0.0921428, acc 0.953125\n",
      "2017-04-03T20:16:26.980500: step 15958, loss 0.117803, acc 0.9375\n",
      "2017-04-03T20:16:27.184655: step 15959, loss 0.0638813, acc 0.984375\n",
      "2017-04-03T20:16:27.387150: step 15960, loss 0.256863, acc 0.953125\n",
      "2017-04-03T20:16:27.588319: step 15961, loss 0.0644305, acc 0.96875\n",
      "2017-04-03T20:16:27.791050: step 15962, loss 0.108757, acc 0.953125\n",
      "2017-04-03T20:16:28.002685: step 15963, loss 0.0596718, acc 0.984375\n",
      "2017-04-03T20:16:28.243119: step 15964, loss 0.0624295, acc 1\n",
      "2017-04-03T20:16:28.451040: step 15965, loss 0.219804, acc 0.9375\n",
      "2017-04-03T20:16:28.652242: step 15966, loss 0.177275, acc 0.921875\n",
      "2017-04-03T20:16:28.856311: step 15967, loss 0.0500339, acc 0.984375\n",
      "2017-04-03T20:16:29.070062: step 15968, loss 0.206621, acc 0.921875\n",
      "2017-04-03T20:16:29.283885: step 15969, loss 0.0708049, acc 0.984375\n",
      "2017-04-03T20:16:29.486804: step 15970, loss 0.127373, acc 0.96875\n",
      "2017-04-03T20:16:29.690572: step 15971, loss 0.0880983, acc 0.984375\n",
      "2017-04-03T20:16:29.931396: step 15972, loss 0.0422108, acc 1\n",
      "2017-04-03T20:16:30.135049: step 15973, loss 0.0704746, acc 0.984375\n",
      "2017-04-03T20:16:30.381449: step 15974, loss 0.149437, acc 0.9375\n",
      "2017-04-03T20:16:30.590410: step 15975, loss 0.0944169, acc 0.96875\n",
      "2017-04-03T20:16:30.789753: step 15976, loss 0.140904, acc 0.96875\n",
      "2017-04-03T20:16:30.993907: step 15977, loss 0.361852, acc 0.921875\n",
      "2017-04-03T20:16:31.201396: step 15978, loss 0.0938711, acc 0.96875\n",
      "2017-04-03T20:16:31.402938: step 15979, loss 0.0117575, acc 1\n",
      "2017-04-03T20:16:31.608130: step 15980, loss 0.100411, acc 0.984375\n",
      "2017-04-03T20:16:31.806347: step 15981, loss 0.130616, acc 0.96875\n",
      "2017-04-03T20:16:32.017628: step 15982, loss 0.224049, acc 0.890625\n",
      "2017-04-03T20:16:32.231619: step 15983, loss 0.0402325, acc 0.984375\n",
      "2017-04-03T20:16:32.438808: step 15984, loss 0.0818485, acc 0.96875\n",
      "2017-04-03T20:16:32.641599: step 15985, loss 0.121688, acc 0.953125\n",
      "2017-04-03T20:16:32.843936: step 15986, loss 0.0814575, acc 0.984375\n",
      "2017-04-03T20:16:33.059409: step 15987, loss 0.132425, acc 0.953125\n",
      "2017-04-03T20:16:33.301570: step 15988, loss 0.111008, acc 0.96875\n",
      "2017-04-03T20:16:33.521837: step 15989, loss 0.157981, acc 0.921875\n",
      "2017-04-03T20:16:33.723051: step 15990, loss 0.224572, acc 0.9375\n",
      "2017-04-03T20:16:33.924853: step 15991, loss 0.0937356, acc 0.96875\n",
      "2017-04-03T20:16:34.131564: step 15992, loss 0.055393, acc 0.984375\n",
      "2017-04-03T20:16:34.332024: step 15993, loss 0.0947194, acc 0.96875\n",
      "2017-04-03T20:16:34.526229: step 15994, loss 0.361661, acc 0.921875\n",
      "2017-04-03T20:16:34.727380: step 15995, loss 0.0782125, acc 0.96875\n",
      "2017-04-03T20:16:34.973675: step 15996, loss 0.0870474, acc 0.96875\n",
      "2017-04-03T20:16:35.178668: step 15997, loss 0.103669, acc 0.96875\n",
      "2017-04-03T20:16:35.376076: step 15998, loss 0.138333, acc 0.96875\n",
      "2017-04-03T20:16:35.578701: step 15999, loss 0.0206023, acc 1\n",
      "2017-04-03T20:16:35.822357: step 16000, loss 0.1468, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:16:37.942648: step 16000, loss 6.26533, acc 0.28525\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-16000\n",
      "\n",
      "2017-04-03T20:16:38.278788: step 16001, loss 0.109442, acc 0.984375\n",
      "2017-04-03T20:16:38.481655: step 16002, loss 0.255559, acc 0.921875\n",
      "2017-04-03T20:16:38.678948: step 16003, loss 0.107398, acc 0.96875\n",
      "2017-04-03T20:16:38.881155: step 16004, loss 0.0999502, acc 0.984375\n",
      "2017-04-03T20:16:39.082419: step 16005, loss 0.338664, acc 0.90625\n",
      "2017-04-03T20:16:39.325829: step 16006, loss 0.0582572, acc 0.984375\n",
      "2017-04-03T20:16:39.530066: step 16007, loss 0.0990899, acc 0.96875\n",
      "2017-04-03T20:16:39.771031: step 16008, loss 0.0709256, acc 0.984375\n",
      "2017-04-03T20:16:39.975049: step 16009, loss 0.0379988, acc 0.984375\n",
      "2017-04-03T20:16:40.177563: step 16010, loss 0.0385628, acc 1\n",
      "2017-04-03T20:16:40.378053: step 16011, loss 0.0667423, acc 0.96875\n",
      "2017-04-03T20:16:40.584135: step 16012, loss 0.103295, acc 0.96875\n",
      "2017-04-03T20:16:40.830502: step 16013, loss 0.0571547, acc 0.984375\n",
      "2017-04-03T20:16:41.034127: step 16014, loss 0.208216, acc 0.953125\n",
      "2017-04-03T20:16:41.239881: step 16015, loss 0.0702045, acc 0.984375\n",
      "2017-04-03T20:16:41.439256: step 16016, loss 0.171304, acc 0.96875\n",
      "2017-04-03T20:16:41.640392: step 16017, loss 0.100693, acc 0.96875\n",
      "2017-04-03T20:16:41.844942: step 16018, loss 0.0771871, acc 0.953125\n",
      "2017-04-03T20:16:42.046694: step 16019, loss 0.106924, acc 0.953125\n",
      "2017-04-03T20:16:42.283089: step 16020, loss 0.188626, acc 0.953125\n",
      "2017-04-03T20:16:42.483981: step 16021, loss 0.0561096, acc 0.984375\n",
      "2017-04-03T20:16:42.695821: step 16022, loss 0.105347, acc 0.96875\n",
      "2017-04-03T20:16:42.909398: step 16023, loss 0.106115, acc 0.953125\n",
      "2017-04-03T20:16:43.113208: step 16024, loss 0.213661, acc 0.90625\n",
      "2017-04-03T20:16:43.316993: step 16025, loss 0.0925284, acc 0.96875\n",
      "2017-04-03T20:16:43.515777: step 16026, loss 0.123103, acc 0.953125\n",
      "2017-04-03T20:16:43.716040: step 16027, loss 0.085488, acc 0.96875\n",
      "2017-04-03T20:16:43.921445: step 16028, loss 0.0780006, acc 1\n",
      "2017-04-03T20:16:44.127818: step 16029, loss 0.120168, acc 0.953125\n",
      "2017-04-03T20:16:44.325604: step 16030, loss 0.155167, acc 0.9375\n",
      "2017-04-03T20:16:44.531031: step 16031, loss 0.130228, acc 0.953125\n",
      "2017-04-03T20:16:44.732239: step 16032, loss 0.0961351, acc 0.96875\n",
      "2017-04-03T20:16:44.929006: step 16033, loss 0.0648663, acc 0.96875\n",
      "2017-04-03T20:16:45.127327: step 16034, loss 0.107477, acc 0.953125\n",
      "2017-04-03T20:16:45.327271: step 16035, loss 0.18713, acc 0.9375\n",
      "2017-04-03T20:16:45.526710: step 16036, loss 0.0557097, acc 0.96875\n",
      "2017-04-03T20:16:45.728772: step 16037, loss 0.0713646, acc 0.96875\n",
      "2017-04-03T20:16:45.930344: step 16038, loss 0.128896, acc 0.953125\n",
      "2017-04-03T20:16:46.135898: step 16039, loss 0.114237, acc 0.953125\n",
      "2017-04-03T20:16:46.336395: step 16040, loss 0.178214, acc 0.953125\n",
      "2017-04-03T20:16:46.539314: step 16041, loss 0.184905, acc 0.953125\n",
      "2017-04-03T20:16:46.738775: step 16042, loss 0.106103, acc 0.953125\n",
      "2017-04-03T20:16:46.941255: step 16043, loss 0.0394951, acc 1\n",
      "2017-04-03T20:16:47.143333: step 16044, loss 0.0844099, acc 0.96875\n",
      "2017-04-03T20:16:47.344594: step 16045, loss 0.183506, acc 0.921875\n",
      "2017-04-03T20:16:47.592651: step 16046, loss 0.196881, acc 0.9375\n",
      "2017-04-03T20:16:47.796438: step 16047, loss 0.110185, acc 0.953125\n",
      "2017-04-03T20:16:47.999962: step 16048, loss 0.255138, acc 0.9375\n",
      "2017-04-03T20:16:48.200962: step 16049, loss 0.0815771, acc 0.96875\n",
      "2017-04-03T20:16:48.403389: step 16050, loss 0.148828, acc 0.953125\n",
      "2017-04-03T20:16:48.615003: step 16051, loss 0.188603, acc 0.96875\n",
      "2017-04-03T20:16:48.815490: step 16052, loss 0.167266, acc 0.953125\n",
      "2017-04-03T20:16:49.017569: step 16053, loss 0.0907016, acc 0.984375\n",
      "2017-04-03T20:16:49.218897: step 16054, loss 0.0718972, acc 0.984375\n",
      "2017-04-03T20:16:49.423747: step 16055, loss 0.0661219, acc 0.984375\n",
      "2017-04-03T20:16:49.626298: step 16056, loss 0.123844, acc 0.96875\n",
      "2017-04-03T20:16:49.827242: step 16057, loss 0.142656, acc 0.9375\n",
      "2017-04-03T20:16:50.035382: step 16058, loss 0.329531, acc 0.9375\n",
      "2017-04-03T20:16:50.241755: step 16059, loss 0.131873, acc 0.9375\n",
      "2017-04-03T20:16:50.441671: step 16060, loss 0.141293, acc 0.9375\n",
      "2017-04-03T20:16:50.642465: step 16061, loss 0.0669308, acc 0.984375\n",
      "2017-04-03T20:16:50.846520: step 16062, loss 0.110154, acc 0.953125\n",
      "2017-04-03T20:16:51.065312: step 16063, loss 0.168905, acc 0.9375\n",
      "2017-04-03T20:16:51.267460: step 16064, loss 0.0451986, acc 0.984375\n",
      "2017-04-03T20:16:51.465780: step 16065, loss 0.221403, acc 0.9375\n",
      "2017-04-03T20:16:51.672540: step 16066, loss 0.136389, acc 0.96875\n",
      "2017-04-03T20:16:51.880835: step 16067, loss 0.071, acc 0.984375\n",
      "2017-04-03T20:16:52.129233: step 16068, loss 0.104047, acc 0.953125\n",
      "2017-04-03T20:16:52.338345: step 16069, loss 0.143318, acc 0.96875\n",
      "2017-04-03T20:16:52.536785: step 16070, loss 0.211919, acc 0.921875\n",
      "2017-04-03T20:16:52.737297: step 16071, loss 0.114723, acc 0.96875\n",
      "2017-04-03T20:16:52.940272: step 16072, loss 0.217844, acc 0.9375\n",
      "2017-04-03T20:16:53.144355: step 16073, loss 0.140881, acc 0.9375\n",
      "2017-04-03T20:16:53.347094: step 16074, loss 0.133754, acc 0.9375\n",
      "2017-04-03T20:16:53.546059: step 16075, loss 0.218748, acc 0.90625\n",
      "2017-04-03T20:16:53.749628: step 16076, loss 0.0706745, acc 0.984375\n",
      "2017-04-03T20:16:53.952199: step 16077, loss 0.103536, acc 0.953125\n",
      "2017-04-03T20:16:54.151094: step 16078, loss 0.107576, acc 0.984375\n",
      "2017-04-03T20:16:54.354811: step 16079, loss 0.0862929, acc 0.984375\n",
      "2017-04-03T20:16:54.553273: step 16080, loss 0.155139, acc 0.9375\n",
      "2017-04-03T20:16:54.754628: step 16081, loss 0.0933135, acc 0.96875\n",
      "2017-04-03T20:16:54.952861: step 16082, loss 0.127159, acc 0.96875\n",
      "2017-04-03T20:16:55.180688: step 16083, loss 0.133612, acc 0.953125\n",
      "2017-04-03T20:16:55.403765: step 16084, loss 0.0380487, acc 1\n",
      "2017-04-03T20:16:55.604039: step 16085, loss 0.0991087, acc 0.96875\n",
      "2017-04-03T20:16:55.805033: step 16086, loss 0.298354, acc 0.9375\n",
      "2017-04-03T20:16:56.013560: step 16087, loss 0.0683866, acc 0.96875\n",
      "2017-04-03T20:16:56.256869: step 16088, loss 0.190523, acc 0.9375\n",
      "2017-04-03T20:16:56.460100: step 16089, loss 0.0979803, acc 0.96875\n",
      "2017-04-03T20:16:56.664172: step 16090, loss 0.21767, acc 0.953125\n",
      "2017-04-03T20:16:56.864645: step 16091, loss 0.0806291, acc 0.96875\n",
      "2017-04-03T20:16:57.064399: step 16092, loss 0.09935, acc 0.96875\n",
      "2017-04-03T20:16:57.264679: step 16093, loss 0.208674, acc 0.921875\n",
      "2017-04-03T20:16:57.473613: step 16094, loss 0.151586, acc 0.921875\n",
      "2017-04-03T20:16:57.681951: step 16095, loss 0.148691, acc 0.953125\n",
      "2017-04-03T20:16:57.881020: step 16096, loss 0.16161, acc 0.953125\n",
      "2017-04-03T20:16:58.082640: step 16097, loss 0.118372, acc 0.9375\n",
      "2017-04-03T20:16:58.280408: step 16098, loss 0.124511, acc 0.984375\n",
      "2017-04-03T20:16:58.480839: step 16099, loss 0.0735, acc 0.96875\n",
      "2017-04-03T20:16:58.692676: step 16100, loss 0.0807756, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:17:00.777720: step 16100, loss 6.23242, acc 0.284\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-16100\n",
      "\n",
      "2017-04-03T20:17:01.102003: step 16101, loss 0.192187, acc 0.9375\n",
      "2017-04-03T20:17:01.304708: step 16102, loss 0.137344, acc 0.9375\n",
      "2017-04-03T20:17:01.508595: step 16103, loss 0.120066, acc 0.984375\n",
      "2017-04-03T20:17:01.716356: step 16104, loss 0.0710867, acc 0.984375\n",
      "2017-04-03T20:17:01.965807: step 16105, loss 0.117922, acc 0.96875\n",
      "2017-04-03T20:17:02.213297: step 16106, loss 0.102099, acc 0.953125\n",
      "2017-04-03T20:17:02.421385: step 16107, loss 0.21408, acc 0.9375\n",
      "2017-04-03T20:17:02.629406: step 16108, loss 0.169102, acc 0.96875\n",
      "2017-04-03T20:17:02.836436: step 16109, loss 0.17108, acc 0.921875\n",
      "2017-04-03T20:17:03.038295: step 16110, loss 0.179994, acc 0.921875\n",
      "2017-04-03T20:17:03.239023: step 16111, loss 0.10539, acc 0.953125\n",
      "2017-04-03T20:17:03.443631: step 16112, loss 0.166914, acc 0.953125\n",
      "2017-04-03T20:17:03.648514: step 16113, loss 0.160399, acc 0.953125\n",
      "2017-04-03T20:17:03.851339: step 16114, loss 0.0841974, acc 0.953125\n",
      "2017-04-03T20:17:04.050521: step 16115, loss 0.123134, acc 0.96875\n",
      "2017-04-03T20:17:04.252806: step 16116, loss 0.12173, acc 0.953125\n",
      "2017-04-03T20:17:04.458790: step 16117, loss 0.0635276, acc 1\n",
      "2017-04-03T20:17:04.659910: step 16118, loss 0.0423442, acc 1\n",
      "2017-04-03T20:17:04.861641: step 16119, loss 0.0918361, acc 0.953125\n",
      "2017-04-03T20:17:05.060653: step 16120, loss 0.0885202, acc 0.953125\n",
      "2017-04-03T20:17:05.268641: step 16121, loss 0.0680833, acc 0.984375\n",
      "2017-04-03T20:17:05.470638: step 16122, loss 0.0460362, acc 1\n",
      "2017-04-03T20:17:05.670252: step 16123, loss 0.140152, acc 0.9375\n",
      "2017-04-03T20:17:05.889922: step 16124, loss 0.189049, acc 0.9375\n",
      "2017-04-03T20:17:06.110879: step 16125, loss 0.194599, acc 0.9375\n",
      "2017-04-03T20:17:06.313159: step 16126, loss 0.177883, acc 0.953125\n",
      "2017-04-03T20:17:06.515651: step 16127, loss 0.054664, acc 0.984375\n",
      "2017-04-03T20:17:06.717176: step 16128, loss 0.0873944, acc 1\n",
      "2017-04-03T20:17:06.923999: step 16129, loss 0.0947402, acc 0.953125\n",
      "2017-04-03T20:17:07.123841: step 16130, loss 0.241293, acc 0.921875\n",
      "2017-04-03T20:17:07.327825: step 16131, loss 0.0819968, acc 0.984375\n",
      "2017-04-03T20:17:07.528794: step 16132, loss 0.17251, acc 0.953125\n",
      "2017-04-03T20:17:07.736327: step 16133, loss 0.136013, acc 0.9375\n",
      "2017-04-03T20:17:07.935688: step 16134, loss 0.147484, acc 0.953125\n",
      "2017-04-03T20:17:08.182114: step 16135, loss 0.0847947, acc 0.96875\n",
      "2017-04-03T20:17:08.428003: step 16136, loss 0.165295, acc 0.96875\n",
      "2017-04-03T20:17:08.630707: step 16137, loss 0.122206, acc 0.953125\n",
      "2017-04-03T20:17:08.849369: step 16138, loss 0.0354437, acc 1\n",
      "2017-04-03T20:17:09.050085: step 16139, loss 0.142586, acc 0.953125\n",
      "2017-04-03T20:17:09.252002: step 16140, loss 0.0300579, acc 0.984375\n",
      "2017-04-03T20:17:09.457097: step 16141, loss 0.125699, acc 0.96875\n",
      "2017-04-03T20:17:09.655688: step 16142, loss 0.144154, acc 0.9375\n",
      "2017-04-03T20:17:09.857368: step 16143, loss 0.0939148, acc 0.984375\n",
      "2017-04-03T20:17:10.063295: step 16144, loss 0.100624, acc 0.984375\n",
      "2017-04-03T20:17:10.304968: step 16145, loss 0.20917, acc 0.9375\n",
      "2017-04-03T20:17:10.510192: step 16146, loss 0.226966, acc 0.90625\n",
      "2017-04-03T20:17:10.707448: step 16147, loss 0.120175, acc 0.96875\n",
      "2017-04-03T20:17:10.910206: step 16148, loss 0.0661397, acc 0.984375\n",
      "2017-04-03T20:17:11.110436: step 16149, loss 0.0726704, acc 1\n",
      "2017-04-03T20:17:11.320613: step 16150, loss 0.148085, acc 0.953125\n",
      "2017-04-03T20:17:11.520733: step 16151, loss 0.183596, acc 0.953125\n",
      "2017-04-03T20:17:11.731787: step 16152, loss 0.230513, acc 0.9375\n",
      "2017-04-03T20:17:11.942874: step 16153, loss 0.0714715, acc 0.984375\n",
      "2017-04-03T20:17:12.192425: step 16154, loss 0.0910704, acc 0.96875\n",
      "2017-04-03T20:17:12.453333: step 16155, loss 0.205443, acc 0.921875\n",
      "2017-04-03T20:17:12.656190: step 16156, loss 0.220231, acc 0.90625\n",
      "2017-04-03T20:17:12.857852: step 16157, loss 0.157407, acc 0.90625\n",
      "2017-04-03T20:17:13.059571: step 16158, loss 0.158686, acc 0.953125\n",
      "2017-04-03T20:17:13.260925: step 16159, loss 0.126771, acc 0.96875\n",
      "2017-04-03T20:17:13.462453: step 16160, loss 0.135848, acc 0.921875\n",
      "2017-04-03T20:17:13.675400: step 16161, loss 0.0715185, acc 0.984375\n",
      "2017-04-03T20:17:13.881905: step 16162, loss 0.156947, acc 0.953125\n",
      "2017-04-03T20:17:14.085908: step 16163, loss 0.225494, acc 0.953125\n",
      "2017-04-03T20:17:14.287056: step 16164, loss 0.110016, acc 0.984375\n",
      "2017-04-03T20:17:14.494920: step 16165, loss 0.0779452, acc 1\n",
      "2017-04-03T20:17:14.697430: step 16166, loss 0.0839054, acc 0.953125\n",
      "2017-04-03T20:17:14.897381: step 16167, loss 0.0606029, acc 1\n",
      "2017-04-03T20:17:15.141819: step 16168, loss 0.170989, acc 0.953125\n",
      "2017-04-03T20:17:15.351231: step 16169, loss 0.116824, acc 0.953125\n",
      "2017-04-03T20:17:15.558667: step 16170, loss 0.0447311, acc 1\n",
      "2017-04-03T20:17:15.753115: step 16171, loss 0.056316, acc 0.984375\n",
      "2017-04-03T20:17:16.007156: step 16172, loss 0.0813556, acc 0.96875\n",
      "2017-04-03T20:17:16.214418: step 16173, loss 0.102643, acc 0.96875\n",
      "2017-04-03T20:17:16.421520: step 16174, loss 0.174641, acc 0.9375\n",
      "2017-04-03T20:17:16.636878: step 16175, loss 0.082668, acc 0.96875\n",
      "2017-04-03T20:17:16.839946: step 16176, loss 0.0954078, acc 0.984375\n",
      "2017-04-03T20:17:17.044508: step 16177, loss 0.125304, acc 0.921875\n",
      "2017-04-03T20:17:17.295552: step 16178, loss 0.0582809, acc 1\n",
      "2017-04-03T20:17:17.503320: step 16179, loss 0.0516228, acc 0.984375\n",
      "2017-04-03T20:17:17.705523: step 16180, loss 0.149687, acc 0.9375\n",
      "2017-04-03T20:17:17.916838: step 16181, loss 0.0810384, acc 0.96875\n",
      "2017-04-03T20:17:18.125313: step 16182, loss 0.230306, acc 0.9375\n",
      "2017-04-03T20:17:18.346702: step 16183, loss 0.112402, acc 0.96875\n",
      "2017-04-03T20:17:18.546445: step 16184, loss 0.115438, acc 0.953125\n",
      "2017-04-03T20:17:18.750561: step 16185, loss 0.267757, acc 0.921875\n",
      "2017-04-03T20:17:18.966263: step 16186, loss 0.152436, acc 0.9375\n",
      "2017-04-03T20:17:19.182877: step 16187, loss 0.0880486, acc 0.96875\n",
      "2017-04-03T20:17:19.388360: step 16188, loss 0.131598, acc 0.96875\n",
      "2017-04-03T20:17:19.595487: step 16189, loss 0.189803, acc 0.9375\n",
      "2017-04-03T20:17:19.796056: step 16190, loss 0.192619, acc 0.9375\n",
      "2017-04-03T20:17:20.003399: step 16191, loss 0.106644, acc 0.96875\n",
      "2017-04-03T20:17:20.209396: step 16192, loss 0.0521229, acc 0.984375\n",
      "2017-04-03T20:17:20.408715: step 16193, loss 0.103381, acc 0.96875\n",
      "2017-04-03T20:17:20.611690: step 16194, loss 0.0627545, acc 0.953125\n",
      "2017-04-03T20:17:20.815909: step 16195, loss 0.118307, acc 0.96875\n",
      "2017-04-03T20:17:21.015860: step 16196, loss 0.363761, acc 0.90625\n",
      "2017-04-03T20:17:21.218338: step 16197, loss 0.191525, acc 0.90625\n",
      "2017-04-03T20:17:21.419003: step 16198, loss 0.0794778, acc 0.984375\n",
      "2017-04-03T20:17:21.620243: step 16199, loss 0.106255, acc 0.96875\n",
      "2017-04-03T20:17:21.823213: step 16200, loss 0.0819027, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:17:23.992603: step 16200, loss 6.34525, acc 0.29075\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-16200\n",
      "\n",
      "2017-04-03T20:17:24.324757: step 16201, loss 0.162981, acc 0.984375\n",
      "2017-04-03T20:17:24.549015: step 16202, loss 0.189728, acc 0.90625\n",
      "2017-04-03T20:17:24.766698: step 16203, loss 0.0489065, acc 1\n",
      "2017-04-03T20:17:25.019556: step 16204, loss 0.116666, acc 0.984375\n",
      "2017-04-03T20:17:25.226600: step 16205, loss 0.211436, acc 0.90625\n",
      "2017-04-03T20:17:25.429181: step 16206, loss 0.0717937, acc 0.984375\n",
      "2017-04-03T20:17:25.627601: step 16207, loss 0.194199, acc 0.953125\n",
      "2017-04-03T20:17:25.827795: step 16208, loss 0.164037, acc 0.9375\n",
      "2017-04-03T20:17:26.032714: step 16209, loss 0.0761524, acc 0.984375\n",
      "2017-04-03T20:17:26.237508: step 16210, loss 0.259496, acc 0.890625\n",
      "2017-04-03T20:17:26.436237: step 16211, loss 0.130391, acc 0.9375\n",
      "2017-04-03T20:17:26.642731: step 16212, loss 0.0733472, acc 0.984375\n",
      "2017-04-03T20:17:26.847102: step 16213, loss 0.21614, acc 0.9375\n",
      "2017-04-03T20:17:27.055704: step 16214, loss 0.123804, acc 0.9375\n",
      "2017-04-03T20:17:27.255141: step 16215, loss 0.072168, acc 0.953125\n",
      "2017-04-03T20:17:27.460421: step 16216, loss 0.132013, acc 0.9375\n",
      "2017-04-03T20:17:27.663452: step 16217, loss 0.161262, acc 0.9375\n",
      "2017-04-03T20:17:27.867253: step 16218, loss 0.125989, acc 0.9375\n",
      "2017-04-03T20:17:28.086110: step 16219, loss 0.0396035, acc 1\n",
      "2017-04-03T20:17:28.289513: step 16220, loss 0.24373, acc 0.921875\n",
      "2017-04-03T20:17:28.492977: step 16221, loss 0.155559, acc 0.9375\n",
      "2017-04-03T20:17:28.695604: step 16222, loss 0.0396875, acc 0.984375\n",
      "2017-04-03T20:17:28.901622: step 16223, loss 0.0646478, acc 0.96875\n",
      "2017-04-03T20:17:29.145997: step 16224, loss 0.105526, acc 0.96875\n",
      "2017-04-03T20:17:29.354059: step 16225, loss 0.126677, acc 0.96875\n",
      "2017-04-03T20:17:29.555021: step 16226, loss 0.14066, acc 0.96875\n",
      "2017-04-03T20:17:29.761633: step 16227, loss 0.311431, acc 0.9375\n",
      "2017-04-03T20:17:29.967332: step 16228, loss 0.227751, acc 0.921875\n",
      "2017-04-03T20:17:30.213073: step 16229, loss 0.137522, acc 0.96875\n",
      "2017-04-03T20:17:30.415969: step 16230, loss 0.226077, acc 0.90625\n",
      "2017-04-03T20:17:30.621858: step 16231, loss 0.0465822, acc 0.96875\n",
      "2017-04-03T20:17:30.821981: step 16232, loss 0.156385, acc 0.9375\n",
      "2017-04-03T20:17:31.035109: step 16233, loss 0.123185, acc 0.953125\n",
      "2017-04-03T20:17:31.244264: step 16234, loss 0.253922, acc 0.953125\n",
      "2017-04-03T20:17:31.463322: step 16235, loss 0.0333142, acc 0.984375\n",
      "2017-04-03T20:17:31.678520: step 16236, loss 0.0934903, acc 0.96875\n",
      "2017-04-03T20:17:31.878490: step 16237, loss 0.0956025, acc 0.953125\n",
      "2017-04-03T20:17:32.096166: step 16238, loss 0.156796, acc 0.953125\n",
      "2017-04-03T20:17:32.315742: step 16239, loss 0.157079, acc 0.9375\n",
      "2017-04-03T20:17:32.530646: step 16240, loss 0.158122, acc 0.9375\n",
      "2017-04-03T20:17:32.738514: step 16241, loss 0.0224352, acc 1\n",
      "2017-04-03T20:17:32.940422: step 16242, loss 0.11679, acc 0.953125\n",
      "2017-04-03T20:17:33.146511: step 16243, loss 0.145967, acc 0.921875\n",
      "2017-04-03T20:17:33.347493: step 16244, loss 0.151605, acc 0.953125\n",
      "2017-04-03T20:17:33.553902: step 16245, loss 0.121396, acc 0.96875\n",
      "2017-04-03T20:17:33.760851: step 16246, loss 0.168958, acc 0.9375\n",
      "2017-04-03T20:17:33.963984: step 16247, loss 0.0149115, acc 1\n",
      "2017-04-03T20:17:34.207028: step 16248, loss 0.0564927, acc 0.96875\n",
      "2017-04-03T20:17:34.415390: step 16249, loss 0.084308, acc 0.96875\n",
      "2017-04-03T20:17:34.618845: step 16250, loss 0.0596536, acc 0.984375\n",
      "2017-04-03T20:17:34.816806: step 16251, loss 0.10242, acc 0.96875\n",
      "2017-04-03T20:17:35.018443: step 16252, loss 0.0536456, acc 0.984375\n",
      "2017-04-03T20:17:35.227773: step 16253, loss 0.0906071, acc 0.96875\n",
      "2017-04-03T20:17:35.431775: step 16254, loss 0.199467, acc 0.921875\n",
      "2017-04-03T20:17:35.637446: step 16255, loss 0.0716353, acc 0.984375\n",
      "2017-04-03T20:17:35.876890: step 16256, loss 0.261524, acc 0.9375\n",
      "2017-04-03T20:17:36.079786: step 16257, loss 0.228619, acc 0.921875\n",
      "2017-04-03T20:17:36.325131: step 16258, loss 0.10302, acc 0.984375\n",
      "2017-04-03T20:17:36.528525: step 16259, loss 0.460509, acc 0.953125\n",
      "2017-04-03T20:17:36.734140: step 16260, loss 0.156048, acc 0.96875\n",
      "2017-04-03T20:17:36.976300: step 16261, loss 0.249588, acc 0.953125\n",
      "2017-04-03T20:17:37.182967: step 16262, loss 0.12738, acc 0.96875\n",
      "2017-04-03T20:17:37.387138: step 16263, loss 0.0654579, acc 0.96875\n",
      "2017-04-03T20:17:37.594780: step 16264, loss 0.123113, acc 0.953125\n",
      "2017-04-03T20:17:37.806144: step 16265, loss 0.113102, acc 0.984375\n",
      "2017-04-03T20:17:38.011099: step 16266, loss 0.0824607, acc 0.953125\n",
      "2017-04-03T20:17:38.258653: step 16267, loss 0.132424, acc 0.921875\n",
      "2017-04-03T20:17:38.465577: step 16268, loss 0.088077, acc 0.984375\n",
      "2017-04-03T20:17:38.671379: step 16269, loss 0.14559, acc 0.953125\n",
      "2017-04-03T20:17:38.920086: step 16270, loss 0.0372087, acc 0.984375\n",
      "2017-04-03T20:17:39.127819: step 16271, loss 0.141079, acc 0.921875\n",
      "2017-04-03T20:17:39.332517: step 16272, loss 0.0806182, acc 0.96875\n",
      "2017-04-03T20:17:39.547827: step 16273, loss 0.265583, acc 0.921875\n",
      "2017-04-03T20:17:39.747754: step 16274, loss 0.189149, acc 0.9375\n",
      "2017-04-03T20:17:39.952522: step 16275, loss 0.131292, acc 0.90625\n",
      "2017-04-03T20:17:40.197993: step 16276, loss 0.117691, acc 0.96875\n",
      "2017-04-03T20:17:40.403330: step 16277, loss 0.0986446, acc 0.96875\n",
      "2017-04-03T20:17:40.602786: step 16278, loss 0.1781, acc 0.921875\n",
      "2017-04-03T20:17:40.810341: step 16279, loss 0.169363, acc 0.9375\n",
      "2017-04-03T20:17:41.018413: step 16280, loss 0.14897, acc 0.921875\n",
      "2017-04-03T20:17:41.221266: step 16281, loss 0.127779, acc 0.96875\n",
      "2017-04-03T20:17:41.423579: step 16282, loss 0.198879, acc 0.921875\n",
      "2017-04-03T20:17:41.630142: step 16283, loss 0.578546, acc 0.9375\n",
      "2017-04-03T20:17:41.835586: step 16284, loss 0.150419, acc 0.9375\n",
      "2017-04-03T20:17:42.037543: step 16285, loss 0.151585, acc 0.9375\n",
      "2017-04-03T20:17:42.240271: step 16286, loss 0.0275274, acc 1\n",
      "2017-04-03T20:17:42.449557: step 16287, loss 0.259995, acc 0.9375\n",
      "2017-04-03T20:17:42.654481: step 16288, loss 0.173368, acc 0.9375\n",
      "2017-04-03T20:17:42.869742: step 16289, loss 0.0619757, acc 0.984375\n",
      "2017-04-03T20:17:43.071458: step 16290, loss 0.0510162, acc 0.984375\n",
      "2017-04-03T20:17:43.280302: step 16291, loss 0.112415, acc 0.953125\n",
      "2017-04-03T20:17:43.481600: step 16292, loss 0.0848109, acc 0.984375\n",
      "2017-04-03T20:17:43.729090: step 16293, loss 0.176888, acc 0.953125\n",
      "2017-04-03T20:17:43.932808: step 16294, loss 0.0542806, acc 1\n",
      "2017-04-03T20:17:44.145257: step 16295, loss 0.0609447, acc 0.96875\n",
      "2017-04-03T20:17:44.399786: step 16296, loss 0.0696151, acc 0.984375\n",
      "2017-04-03T20:17:44.607739: step 16297, loss 0.108812, acc 0.96875\n",
      "2017-04-03T20:17:44.848592: step 16298, loss 0.0932026, acc 0.96875\n",
      "2017-04-03T20:17:45.059671: step 16299, loss 0.0435124, acc 1\n",
      "2017-04-03T20:17:45.260860: step 16300, loss 0.240742, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:17:47.382414: step 16300, loss 6.37283, acc 0.288\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-16300\n",
      "\n",
      "2017-04-03T20:17:47.720387: step 16301, loss 0.0647531, acc 0.984375\n",
      "2017-04-03T20:17:47.922121: step 16302, loss 0.212034, acc 0.921875\n",
      "2017-04-03T20:17:48.124843: step 16303, loss 0.531411, acc 0.9375\n",
      "2017-04-03T20:17:48.326595: step 16304, loss 0.14003, acc 0.9375\n",
      "2017-04-03T20:17:48.572251: step 16305, loss 0.116297, acc 0.984375\n",
      "2017-04-03T20:17:48.784977: step 16306, loss 0.0713557, acc 0.984375\n",
      "2017-04-03T20:17:49.004254: step 16307, loss 0.220638, acc 0.953125\n",
      "2017-04-03T20:17:49.213806: step 16308, loss 0.294163, acc 0.921875\n",
      "2017-04-03T20:17:49.424445: step 16309, loss 0.0298715, acc 1\n",
      "2017-04-03T20:17:49.627365: step 16310, loss 0.121834, acc 0.953125\n",
      "2017-04-03T20:17:49.834973: step 16311, loss 0.126012, acc 0.9375\n",
      "2017-04-03T20:17:50.042223: step 16312, loss 0.233097, acc 0.96875\n",
      "2017-04-03T20:17:50.243176: step 16313, loss 0.181564, acc 0.9375\n",
      "2017-04-03T20:17:50.446974: step 16314, loss 0.373292, acc 0.9375\n",
      "2017-04-03T20:17:50.692706: step 16315, loss 0.301481, acc 0.9375\n",
      "2017-04-03T20:17:50.935946: step 16316, loss 0.132276, acc 0.96875\n",
      "2017-04-03T20:17:51.142933: step 16317, loss 0.0170459, acc 1\n",
      "2017-04-03T20:17:51.347216: step 16318, loss 0.270404, acc 0.9375\n",
      "2017-04-03T20:17:51.545266: step 16319, loss 0.0644919, acc 0.96875\n",
      "2017-04-03T20:17:51.757085: step 16320, loss 0.0829569, acc 0.96875\n",
      "2017-04-03T20:17:51.962763: step 16321, loss 0.223175, acc 0.921875\n",
      "2017-04-03T20:17:52.164973: step 16322, loss 0.0976032, acc 0.953125\n",
      "2017-04-03T20:17:52.404704: step 16323, loss 0.170875, acc 0.953125\n",
      "2017-04-03T20:17:52.605633: step 16324, loss 0.086464, acc 0.953125\n",
      "2017-04-03T20:17:52.857230: step 16325, loss 0.231752, acc 0.921875\n",
      "2017-04-03T20:17:53.060333: step 16326, loss 0.144573, acc 0.96875\n",
      "2017-04-03T20:17:53.208713: step 16327, loss 0.170816, acc 0.9375\n",
      "2017-04-03T20:17:53.461929: step 16328, loss 0.328607, acc 0.875\n",
      "2017-04-03T20:17:53.671830: step 16329, loss 0.0147001, acc 1\n",
      "2017-04-03T20:17:53.873211: step 16330, loss 0.184901, acc 0.953125\n",
      "2017-04-03T20:17:54.079356: step 16331, loss 0.0956713, acc 0.96875\n",
      "2017-04-03T20:17:54.285304: step 16332, loss 0.0592098, acc 0.984375\n",
      "2017-04-03T20:17:54.489606: step 16333, loss 0.0524943, acc 0.984375\n",
      "2017-04-03T20:17:54.695871: step 16334, loss 0.0305139, acc 1\n",
      "2017-04-03T20:17:54.901058: step 16335, loss 0.151725, acc 0.953125\n",
      "2017-04-03T20:17:55.106721: step 16336, loss 0.0511162, acc 0.984375\n",
      "2017-04-03T20:17:55.313185: step 16337, loss 0.198382, acc 0.9375\n",
      "2017-04-03T20:17:55.516237: step 16338, loss 0.0827512, acc 0.984375\n",
      "2017-04-03T20:17:55.715190: step 16339, loss 0.165988, acc 0.953125\n",
      "2017-04-03T20:17:55.919453: step 16340, loss 0.0953419, acc 0.953125\n",
      "2017-04-03T20:17:56.129501: step 16341, loss 0.0861214, acc 0.984375\n",
      "2017-04-03T20:17:56.332516: step 16342, loss 0.0902139, acc 0.96875\n",
      "2017-04-03T20:17:56.540721: step 16343, loss 0.142714, acc 0.953125\n",
      "2017-04-03T20:17:56.793183: step 16344, loss 0.0914791, acc 0.984375\n",
      "2017-04-03T20:17:57.007961: step 16345, loss 0.0795834, acc 0.984375\n",
      "2017-04-03T20:17:57.253957: step 16346, loss 0.0817905, acc 0.984375\n",
      "2017-04-03T20:17:57.464623: step 16347, loss 0.116342, acc 0.953125\n",
      "2017-04-03T20:17:57.668192: step 16348, loss 0.0437121, acc 0.984375\n",
      "2017-04-03T20:17:57.866901: step 16349, loss 0.0732591, acc 0.984375\n",
      "2017-04-03T20:17:58.070147: step 16350, loss 0.0652211, acc 0.984375\n",
      "2017-04-03T20:17:58.287001: step 16351, loss 0.0732111, acc 0.953125\n",
      "2017-04-03T20:17:58.506585: step 16352, loss 0.0886453, acc 0.953125\n",
      "2017-04-03T20:17:58.705217: step 16353, loss 0.0921027, acc 0.96875\n",
      "2017-04-03T20:17:58.914936: step 16354, loss 0.0427639, acc 1\n",
      "2017-04-03T20:17:59.167893: step 16355, loss 0.0605475, acc 0.984375\n",
      "2017-04-03T20:17:59.367711: step 16356, loss 0.0561152, acc 0.96875\n",
      "2017-04-03T20:17:59.572096: step 16357, loss 0.124288, acc 0.953125\n",
      "2017-04-03T20:17:59.780055: step 16358, loss 0.0131962, acc 1\n",
      "2017-04-03T20:17:59.982327: step 16359, loss 0.0425281, acc 1\n",
      "2017-04-03T20:18:00.188778: step 16360, loss 0.0998145, acc 0.984375\n",
      "2017-04-03T20:18:00.400267: step 16361, loss 0.0737491, acc 0.984375\n",
      "2017-04-03T20:18:00.603834: step 16362, loss 0.148767, acc 0.953125\n",
      "2017-04-03T20:18:00.807753: step 16363, loss 0.105357, acc 0.984375\n",
      "2017-04-03T20:18:01.012639: step 16364, loss 0.276924, acc 0.96875\n",
      "2017-04-03T20:18:01.210529: step 16365, loss 0.238303, acc 0.9375\n",
      "2017-04-03T20:18:01.457577: step 16366, loss 0.118676, acc 0.96875\n",
      "2017-04-03T20:18:01.670698: step 16367, loss 0.150652, acc 0.96875\n",
      "2017-04-03T20:18:01.874034: step 16368, loss 0.0965794, acc 0.96875\n",
      "2017-04-03T20:18:02.083797: step 16369, loss 0.0687123, acc 0.96875\n",
      "2017-04-03T20:18:02.284240: step 16370, loss 0.070461, acc 0.96875\n",
      "2017-04-03T20:18:02.488111: step 16371, loss 0.0513898, acc 0.984375\n",
      "2017-04-03T20:18:02.694616: step 16372, loss 0.0945482, acc 0.953125\n",
      "2017-04-03T20:18:02.899270: step 16373, loss 0.0475038, acc 1\n",
      "2017-04-03T20:18:03.137023: step 16374, loss 0.109859, acc 0.953125\n",
      "2017-04-03T20:18:03.345362: step 16375, loss 0.0520342, acc 0.984375\n",
      "2017-04-03T20:18:03.551227: step 16376, loss 0.076568, acc 1\n",
      "2017-04-03T20:18:03.756503: step 16377, loss 0.0453767, acc 0.984375\n",
      "2017-04-03T20:18:03.959689: step 16378, loss 0.0754379, acc 0.96875\n",
      "2017-04-03T20:18:04.159294: step 16379, loss 0.029096, acc 1\n",
      "2017-04-03T20:18:04.357878: step 16380, loss 0.188074, acc 0.9375\n",
      "2017-04-03T20:18:04.563882: step 16381, loss 0.210458, acc 0.953125\n",
      "2017-04-03T20:18:04.774052: step 16382, loss 0.201044, acc 0.984375\n",
      "2017-04-03T20:18:04.979248: step 16383, loss 0.0703175, acc 0.984375\n",
      "2017-04-03T20:18:05.192042: step 16384, loss 0.102734, acc 0.96875\n",
      "2017-04-03T20:18:05.393204: step 16385, loss 0.0852342, acc 0.96875\n",
      "2017-04-03T20:18:05.596249: step 16386, loss 0.0925322, acc 0.9375\n",
      "2017-04-03T20:18:05.799719: step 16387, loss 0.251112, acc 0.96875\n",
      "2017-04-03T20:18:06.017986: step 16388, loss 0.0512526, acc 0.984375\n",
      "2017-04-03T20:18:06.230280: step 16389, loss 0.175786, acc 0.953125\n",
      "2017-04-03T20:18:06.431419: step 16390, loss 0.0816402, acc 0.984375\n",
      "2017-04-03T20:18:06.630945: step 16391, loss 0.0838995, acc 0.984375\n",
      "2017-04-03T20:18:06.831957: step 16392, loss 0.0662102, acc 0.96875\n",
      "2017-04-03T20:18:07.033544: step 16393, loss 0.11898, acc 0.953125\n",
      "2017-04-03T20:18:07.233960: step 16394, loss 0.171371, acc 0.953125\n",
      "2017-04-03T20:18:07.436594: step 16395, loss 0.0955985, acc 0.984375\n",
      "2017-04-03T20:18:07.646934: step 16396, loss 0.114799, acc 0.984375\n",
      "2017-04-03T20:18:07.860320: step 16397, loss 0.120327, acc 0.96875\n",
      "2017-04-03T20:18:08.082734: step 16398, loss 0.0847714, acc 0.96875\n",
      "2017-04-03T20:18:08.303247: step 16399, loss 0.168848, acc 0.96875\n",
      "2017-04-03T20:18:08.506167: step 16400, loss 0.141217, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:18:10.618082: step 16400, loss 6.43838, acc 0.288\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-16400\n",
      "\n",
      "2017-04-03T20:18:10.994407: step 16401, loss 0.169456, acc 0.9375\n",
      "2017-04-03T20:18:11.201990: step 16402, loss 0.0927569, acc 0.984375\n",
      "2017-04-03T20:18:11.405458: step 16403, loss 0.143983, acc 0.96875\n",
      "2017-04-03T20:18:11.605018: step 16404, loss 0.150266, acc 0.9375\n",
      "2017-04-03T20:18:11.803680: step 16405, loss 0.114225, acc 0.953125\n",
      "2017-04-03T20:18:12.011442: step 16406, loss 0.0640795, acc 0.984375\n",
      "2017-04-03T20:18:12.217691: step 16407, loss 0.0457326, acc 1\n",
      "2017-04-03T20:18:12.423817: step 16408, loss 0.175562, acc 0.9375\n",
      "2017-04-03T20:18:12.628912: step 16409, loss 0.0992922, acc 0.96875\n",
      "2017-04-03T20:18:12.875889: step 16410, loss 0.12543, acc 0.96875\n",
      "2017-04-03T20:18:13.079165: step 16411, loss 0.124807, acc 0.953125\n",
      "2017-04-03T20:18:13.281879: step 16412, loss 0.345757, acc 0.9375\n",
      "2017-04-03T20:18:13.480626: step 16413, loss 0.106604, acc 0.953125\n",
      "2017-04-03T20:18:13.683538: step 16414, loss 0.0862266, acc 0.953125\n",
      "2017-04-03T20:18:13.882285: step 16415, loss 0.0468649, acc 0.984375\n",
      "2017-04-03T20:18:14.082223: step 16416, loss 0.0719999, acc 0.96875\n",
      "2017-04-03T20:18:14.279130: step 16417, loss 0.0453525, acc 0.96875\n",
      "2017-04-03T20:18:14.525463: step 16418, loss 0.0533377, acc 0.96875\n",
      "2017-04-03T20:18:14.729618: step 16419, loss 0.141892, acc 0.96875\n",
      "2017-04-03T20:18:14.931260: step 16420, loss 0.0936982, acc 0.953125\n",
      "2017-04-03T20:18:15.141643: step 16421, loss 0.0533668, acc 0.984375\n",
      "2017-04-03T20:18:15.347285: step 16422, loss 0.107916, acc 0.953125\n",
      "2017-04-03T20:18:15.556045: step 16423, loss 0.0712055, acc 0.984375\n",
      "2017-04-03T20:18:15.767085: step 16424, loss 0.0286198, acc 1\n",
      "2017-04-03T20:18:15.970642: step 16425, loss 0.232549, acc 0.921875\n",
      "2017-04-03T20:18:16.182045: step 16426, loss 0.0526991, acc 0.984375\n",
      "2017-04-03T20:18:16.387465: step 16427, loss 0.173778, acc 0.9375\n",
      "2017-04-03T20:18:16.587583: step 16428, loss 0.0251944, acc 1\n",
      "2017-04-03T20:18:16.795638: step 16429, loss 0.0169982, acc 1\n",
      "2017-04-03T20:18:16.999855: step 16430, loss 0.199153, acc 0.921875\n",
      "2017-04-03T20:18:17.202027: step 16431, loss 0.129217, acc 0.96875\n",
      "2017-04-03T20:18:17.408421: step 16432, loss 0.137605, acc 0.9375\n",
      "2017-04-03T20:18:17.613091: step 16433, loss 0.18212, acc 0.9375\n",
      "2017-04-03T20:18:17.835823: step 16434, loss 0.0741723, acc 0.96875\n",
      "2017-04-03T20:18:18.085404: step 16435, loss 0.183817, acc 0.921875\n",
      "2017-04-03T20:18:18.297635: step 16436, loss 0.0982646, acc 0.953125\n",
      "2017-04-03T20:18:18.544303: step 16437, loss 0.112269, acc 0.96875\n",
      "2017-04-03T20:18:18.746169: step 16438, loss 0.146706, acc 0.953125\n",
      "2017-04-03T20:18:18.953004: step 16439, loss 0.0535509, acc 1\n",
      "2017-04-03T20:18:19.148576: step 16440, loss 0.0784288, acc 0.96875\n",
      "2017-04-03T20:18:19.391766: step 16441, loss 0.101096, acc 0.96875\n",
      "2017-04-03T20:18:19.593272: step 16442, loss 0.0942184, acc 0.96875\n",
      "2017-04-03T20:18:19.795960: step 16443, loss 0.140816, acc 0.9375\n",
      "2017-04-03T20:18:20.035256: step 16444, loss 0.303917, acc 0.96875\n",
      "2017-04-03T20:18:20.234116: step 16445, loss 0.159702, acc 0.953125\n",
      "2017-04-03T20:18:20.438382: step 16446, loss 0.0868697, acc 0.96875\n",
      "2017-04-03T20:18:20.642456: step 16447, loss 0.0409498, acc 1\n",
      "2017-04-03T20:18:20.842939: step 16448, loss 0.159896, acc 0.96875\n",
      "2017-04-03T20:18:21.064094: step 16449, loss 0.147055, acc 0.953125\n",
      "2017-04-03T20:18:21.311886: step 16450, loss 0.168096, acc 0.921875\n",
      "2017-04-03T20:18:21.509370: step 16451, loss 0.146766, acc 0.9375\n",
      "2017-04-03T20:18:21.714448: step 16452, loss 0.115805, acc 0.984375\n",
      "2017-04-03T20:18:21.917051: step 16453, loss 0.151825, acc 0.953125\n",
      "2017-04-03T20:18:22.119761: step 16454, loss 0.100778, acc 0.953125\n",
      "2017-04-03T20:18:22.324019: step 16455, loss 0.0653275, acc 0.984375\n",
      "2017-04-03T20:18:22.523966: step 16456, loss 0.0452263, acc 0.984375\n",
      "2017-04-03T20:18:22.724273: step 16457, loss 0.128289, acc 0.953125\n",
      "2017-04-03T20:18:22.925920: step 16458, loss 0.0571983, acc 0.984375\n",
      "2017-04-03T20:18:23.123517: step 16459, loss 0.144081, acc 0.984375\n",
      "2017-04-03T20:18:23.333826: step 16460, loss 0.148585, acc 0.90625\n",
      "2017-04-03T20:18:23.538358: step 16461, loss 0.272417, acc 0.90625\n",
      "2017-04-03T20:18:23.737613: step 16462, loss 0.173497, acc 0.953125\n",
      "2017-04-03T20:18:23.936872: step 16463, loss 0.240458, acc 0.90625\n",
      "2017-04-03T20:18:24.138990: step 16464, loss 0.0309747, acc 1\n",
      "2017-04-03T20:18:24.339210: step 16465, loss 0.153288, acc 0.953125\n",
      "2017-04-03T20:18:24.540720: step 16466, loss 0.115806, acc 0.953125\n",
      "2017-04-03T20:18:24.741887: step 16467, loss 0.0447437, acc 1\n",
      "2017-04-03T20:18:24.944234: step 16468, loss 0.0743291, acc 0.96875\n",
      "2017-04-03T20:18:25.143627: step 16469, loss 0.140404, acc 0.9375\n",
      "2017-04-03T20:18:25.388649: step 16470, loss 0.0799289, acc 0.984375\n",
      "2017-04-03T20:18:25.596352: step 16471, loss 0.2008, acc 0.921875\n",
      "2017-04-03T20:18:25.850800: step 16472, loss 0.197715, acc 0.953125\n",
      "2017-04-03T20:18:26.052688: step 16473, loss 0.0610597, acc 1\n",
      "2017-04-03T20:18:26.268200: step 16474, loss 0.0958448, acc 0.953125\n",
      "2017-04-03T20:18:26.474985: step 16475, loss 0.0216654, acc 1\n",
      "2017-04-03T20:18:26.679676: step 16476, loss 0.0278402, acc 0.984375\n",
      "2017-04-03T20:18:26.884718: step 16477, loss 0.142796, acc 0.953125\n",
      "2017-04-03T20:18:27.085729: step 16478, loss 0.104212, acc 0.96875\n",
      "2017-04-03T20:18:27.293200: step 16479, loss 0.0249828, acc 1\n",
      "2017-04-03T20:18:27.496267: step 16480, loss 0.201205, acc 0.953125\n",
      "2017-04-03T20:18:27.712094: step 16481, loss 0.0372445, acc 1\n",
      "2017-04-03T20:18:27.919135: step 16482, loss 0.0757573, acc 0.96875\n",
      "2017-04-03T20:18:28.119431: step 16483, loss 0.200876, acc 0.890625\n",
      "2017-04-03T20:18:28.317823: step 16484, loss 0.111261, acc 0.96875\n",
      "2017-04-03T20:18:28.514634: step 16485, loss 0.0542461, acc 0.984375\n",
      "2017-04-03T20:18:28.719387: step 16486, loss 0.167144, acc 0.953125\n",
      "2017-04-03T20:18:28.924215: step 16487, loss 0.0957567, acc 0.96875\n",
      "2017-04-03T20:18:29.132997: step 16488, loss 0.0575049, acc 0.984375\n",
      "2017-04-03T20:18:29.376415: step 16489, loss 0.213164, acc 0.921875\n",
      "2017-04-03T20:18:29.585420: step 16490, loss 0.0619819, acc 0.984375\n",
      "2017-04-03T20:18:29.790239: step 16491, loss 0.113577, acc 0.96875\n",
      "2017-04-03T20:18:29.992802: step 16492, loss 0.0869456, acc 0.96875\n",
      "2017-04-03T20:18:30.207010: step 16493, loss 0.0569748, acc 0.96875\n",
      "2017-04-03T20:18:30.431623: step 16494, loss 0.0922107, acc 0.984375\n",
      "2017-04-03T20:18:30.640545: step 16495, loss 0.180922, acc 0.9375\n",
      "2017-04-03T20:18:30.847108: step 16496, loss 0.186811, acc 0.9375\n",
      "2017-04-03T20:18:31.052854: step 16497, loss 0.137063, acc 0.921875\n",
      "2017-04-03T20:18:31.254979: step 16498, loss 0.0366585, acc 0.984375\n",
      "2017-04-03T20:18:31.498224: step 16499, loss 0.0501099, acc 1\n",
      "2017-04-03T20:18:31.708574: step 16500, loss 0.0714204, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:18:33.864180: step 16500, loss 6.53894, acc 0.2835\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-16500\n",
      "\n",
      "2017-04-03T20:18:34.200372: step 16501, loss 0.075307, acc 0.96875\n",
      "2017-04-03T20:18:34.400919: step 16502, loss 0.42147, acc 0.875\n",
      "2017-04-03T20:18:34.607067: step 16503, loss 0.1092, acc 0.96875\n",
      "2017-04-03T20:18:34.808368: step 16504, loss 0.0399932, acc 0.984375\n",
      "2017-04-03T20:18:35.007783: step 16505, loss 0.0320453, acc 1\n",
      "2017-04-03T20:18:35.210940: step 16506, loss 0.0549158, acc 0.984375\n",
      "2017-04-03T20:18:35.416887: step 16507, loss 0.10247, acc 0.96875\n",
      "2017-04-03T20:18:35.662591: step 16508, loss 0.144368, acc 0.96875\n",
      "2017-04-03T20:18:35.870693: step 16509, loss 0.14549, acc 0.921875\n",
      "2017-04-03T20:18:36.068940: step 16510, loss 0.187905, acc 0.921875\n",
      "2017-04-03T20:18:36.274335: step 16511, loss 0.182163, acc 0.953125\n",
      "2017-04-03T20:18:36.475435: step 16512, loss 0.0785741, acc 0.984375\n",
      "2017-04-03T20:18:36.678028: step 16513, loss 0.0659485, acc 0.96875\n",
      "2017-04-03T20:18:36.886721: step 16514, loss 0.024934, acc 1\n",
      "2017-04-03T20:18:37.094660: step 16515, loss 0.0381904, acc 1\n",
      "2017-04-03T20:18:37.304980: step 16516, loss 0.0720534, acc 0.984375\n",
      "2017-04-03T20:18:37.510676: step 16517, loss 0.200786, acc 0.890625\n",
      "2017-04-03T20:18:37.711516: step 16518, loss 0.177873, acc 0.9375\n",
      "2017-04-03T20:18:37.911884: step 16519, loss 0.111787, acc 0.953125\n",
      "2017-04-03T20:18:38.115318: step 16520, loss 0.137706, acc 0.9375\n",
      "2017-04-03T20:18:38.315657: step 16521, loss 0.121596, acc 0.9375\n",
      "2017-04-03T20:18:38.515122: step 16522, loss 0.118094, acc 0.96875\n",
      "2017-04-03T20:18:38.719345: step 16523, loss 0.0618279, acc 0.984375\n",
      "2017-04-03T20:18:38.921739: step 16524, loss 0.061097, acc 0.984375\n",
      "2017-04-03T20:18:39.127700: step 16525, loss 0.0954618, acc 0.96875\n",
      "2017-04-03T20:18:39.330647: step 16526, loss 0.0783385, acc 0.953125\n",
      "2017-04-03T20:18:39.536055: step 16527, loss 0.213291, acc 0.953125\n",
      "2017-04-03T20:18:39.736253: step 16528, loss 0.223356, acc 0.90625\n",
      "2017-04-03T20:18:39.947695: step 16529, loss 0.0656024, acc 0.984375\n",
      "2017-04-03T20:18:40.153181: step 16530, loss 0.277221, acc 0.890625\n",
      "2017-04-03T20:18:40.357628: step 16531, loss 0.185589, acc 0.953125\n",
      "2017-04-03T20:18:40.558127: step 16532, loss 0.172177, acc 0.9375\n",
      "2017-04-03T20:18:40.752418: step 16533, loss 0.104713, acc 0.96875\n",
      "2017-04-03T20:18:40.952848: step 16534, loss 0.0248598, acc 1\n",
      "2017-04-03T20:18:41.154995: step 16535, loss 0.0937976, acc 0.96875\n",
      "2017-04-03T20:18:41.398188: step 16536, loss 0.237846, acc 0.984375\n",
      "2017-04-03T20:18:41.601293: step 16537, loss 0.108083, acc 0.96875\n",
      "2017-04-03T20:18:41.810839: step 16538, loss 0.0527225, acc 1\n",
      "2017-04-03T20:18:42.010229: step 16539, loss 0.0789194, acc 0.9375\n",
      "2017-04-03T20:18:42.219537: step 16540, loss 0.162151, acc 0.96875\n",
      "2017-04-03T20:18:42.463737: step 16541, loss 0.208827, acc 0.953125\n",
      "2017-04-03T20:18:42.684584: step 16542, loss 0.111086, acc 0.984375\n",
      "2017-04-03T20:18:42.885808: step 16543, loss 0.248378, acc 0.9375\n",
      "2017-04-03T20:18:43.087912: step 16544, loss 0.106934, acc 0.96875\n",
      "2017-04-03T20:18:43.296471: step 16545, loss 0.090828, acc 0.96875\n",
      "2017-04-03T20:18:43.499427: step 16546, loss 0.0428829, acc 0.984375\n",
      "2017-04-03T20:18:43.696471: step 16547, loss 0.133447, acc 0.953125\n",
      "2017-04-03T20:18:43.894933: step 16548, loss 0.0591934, acc 0.984375\n",
      "2017-04-03T20:18:44.096306: step 16549, loss 0.0753778, acc 1\n",
      "2017-04-03T20:18:44.301603: step 16550, loss 0.151189, acc 0.921875\n",
      "2017-04-03T20:18:44.505261: step 16551, loss 0.14171, acc 0.921875\n",
      "2017-04-03T20:18:44.702640: step 16552, loss 0.112039, acc 0.953125\n",
      "2017-04-03T20:18:44.906882: step 16553, loss 0.108869, acc 0.953125\n",
      "2017-04-03T20:18:45.110665: step 16554, loss 0.0984668, acc 0.96875\n",
      "2017-04-03T20:18:45.309597: step 16555, loss 0.0446103, acc 0.96875\n",
      "2017-04-03T20:18:45.512514: step 16556, loss 0.155987, acc 0.953125\n",
      "2017-04-03T20:18:45.714948: step 16557, loss 0.14745, acc 0.9375\n",
      "2017-04-03T20:18:45.920526: step 16558, loss 0.132634, acc 0.96875\n",
      "2017-04-03T20:18:46.124378: step 16559, loss 0.078075, acc 0.96875\n",
      "2017-04-03T20:18:46.326500: step 16560, loss 0.236327, acc 0.953125\n",
      "2017-04-03T20:18:46.535726: step 16561, loss 0.0653343, acc 0.96875\n",
      "2017-04-03T20:18:46.744005: step 16562, loss 0.0873002, acc 0.96875\n",
      "2017-04-03T20:18:46.945573: step 16563, loss 0.0493267, acc 0.984375\n",
      "2017-04-03T20:18:47.146344: step 16564, loss 0.142953, acc 0.953125\n",
      "2017-04-03T20:18:47.346465: step 16565, loss 0.0289562, acc 1\n",
      "2017-04-03T20:18:47.548076: step 16566, loss 0.0899929, acc 0.953125\n",
      "2017-04-03T20:18:47.749596: step 16567, loss 0.136042, acc 0.9375\n",
      "2017-04-03T20:18:47.975428: step 16568, loss 0.0771113, acc 0.96875\n",
      "2017-04-03T20:18:48.178471: step 16569, loss 0.108905, acc 0.953125\n",
      "2017-04-03T20:18:48.387877: step 16570, loss 0.164613, acc 0.9375\n",
      "2017-04-03T20:18:48.588651: step 16571, loss 0.145949, acc 0.96875\n",
      "2017-04-03T20:18:48.788750: step 16572, loss 0.159259, acc 0.9375\n",
      "2017-04-03T20:18:48.993723: step 16573, loss 0.0849924, acc 0.96875\n",
      "2017-04-03T20:18:49.199965: step 16574, loss 0.08835, acc 0.984375\n",
      "2017-04-03T20:18:49.402300: step 16575, loss 0.0889457, acc 0.96875\n",
      "2017-04-03T20:18:49.606029: step 16576, loss 0.106953, acc 0.953125\n",
      "2017-04-03T20:18:49.808922: step 16577, loss 0.0958997, acc 0.96875\n",
      "2017-04-03T20:18:50.009093: step 16578, loss 0.111651, acc 0.984375\n",
      "2017-04-03T20:18:50.211821: step 16579, loss 0.0669641, acc 0.984375\n",
      "2017-04-03T20:18:50.419392: step 16580, loss 0.100698, acc 0.96875\n",
      "2017-04-03T20:18:50.622671: step 16581, loss 0.1109, acc 0.96875\n",
      "2017-04-03T20:18:50.824285: step 16582, loss 0.261715, acc 0.890625\n",
      "2017-04-03T20:18:51.027081: step 16583, loss 0.236881, acc 0.9375\n",
      "2017-04-03T20:18:51.274102: step 16584, loss 0.104629, acc 0.9375\n",
      "2017-04-03T20:18:51.477371: step 16585, loss 0.0808848, acc 0.96875\n",
      "2017-04-03T20:18:51.683131: step 16586, loss 0.185708, acc 0.9375\n",
      "2017-04-03T20:18:51.883826: step 16587, loss 0.153766, acc 0.953125\n",
      "2017-04-03T20:18:52.089117: step 16588, loss 0.130309, acc 0.9375\n",
      "2017-04-03T20:18:52.286777: step 16589, loss 0.21653, acc 0.921875\n",
      "2017-04-03T20:18:52.490143: step 16590, loss 0.133805, acc 0.953125\n",
      "2017-04-03T20:18:52.689105: step 16591, loss 0.200818, acc 0.9375\n",
      "2017-04-03T20:18:52.938702: step 16592, loss 0.0500442, acc 1\n",
      "2017-04-03T20:18:53.182326: step 16593, loss 0.0701491, acc 0.96875\n",
      "2017-04-03T20:18:53.392022: step 16594, loss 0.205365, acc 0.9375\n",
      "2017-04-03T20:18:53.614968: step 16595, loss 0.174708, acc 0.9375\n",
      "2017-04-03T20:18:53.822237: step 16596, loss 0.0754746, acc 0.96875\n",
      "2017-04-03T20:18:54.024832: step 16597, loss 0.0421906, acc 0.984375\n",
      "2017-04-03T20:18:54.227137: step 16598, loss 0.0580421, acc 0.984375\n",
      "2017-04-03T20:18:54.429544: step 16599, loss 0.0518428, acc 1\n",
      "2017-04-03T20:18:54.630317: step 16600, loss 0.192987, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:18:56.815424: step 16600, loss 6.47203, acc 0.2885\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-16600\n",
      "\n",
      "2017-04-03T20:18:57.154815: step 16601, loss 0.0933893, acc 0.96875\n",
      "2017-04-03T20:18:57.358626: step 16602, loss 0.132475, acc 0.9375\n",
      "2017-04-03T20:18:57.558197: step 16603, loss 0.27854, acc 0.890625\n",
      "2017-04-03T20:18:57.758344: step 16604, loss 0.149092, acc 0.953125\n",
      "2017-04-03T20:18:57.960426: step 16605, loss 0.0807979, acc 0.96875\n",
      "2017-04-03T20:18:58.160876: step 16606, loss 0.113844, acc 0.953125\n",
      "2017-04-03T20:18:58.400215: step 16607, loss 0.0562354, acc 0.984375\n",
      "2017-04-03T20:18:58.607900: step 16608, loss 0.0653181, acc 0.96875\n",
      "2017-04-03T20:18:58.807314: step 16609, loss 0.127202, acc 0.9375\n",
      "2017-04-03T20:18:59.053012: step 16610, loss 0.0986864, acc 0.984375\n",
      "2017-04-03T20:18:59.259511: step 16611, loss 0.0391995, acc 1\n",
      "2017-04-03T20:18:59.503131: step 16612, loss 0.339504, acc 0.90625\n",
      "2017-04-03T20:18:59.710411: step 16613, loss 0.176664, acc 0.953125\n",
      "2017-04-03T20:18:59.917560: step 16614, loss 0.212669, acc 0.953125\n",
      "2017-04-03T20:19:00.158196: step 16615, loss 0.240617, acc 0.90625\n",
      "2017-04-03T20:19:00.407173: step 16616, loss 0.0888571, acc 0.96875\n",
      "2017-04-03T20:19:00.610567: step 16617, loss 0.0948146, acc 0.953125\n",
      "2017-04-03T20:19:00.808314: step 16618, loss 0.0626506, acc 0.984375\n",
      "2017-04-03T20:19:01.012712: step 16619, loss 0.0575594, acc 0.984375\n",
      "2017-04-03T20:19:01.219753: step 16620, loss 0.160017, acc 0.953125\n",
      "2017-04-03T20:19:01.430688: step 16621, loss 0.273345, acc 0.984375\n",
      "2017-04-03T20:19:01.640306: step 16622, loss 0.0937362, acc 0.96875\n",
      "2017-04-03T20:19:01.838652: step 16623, loss 0.175852, acc 0.9375\n",
      "2017-04-03T20:19:02.039285: step 16624, loss 0.0418635, acc 1\n",
      "2017-04-03T20:19:02.244192: step 16625, loss 0.0455822, acc 0.984375\n",
      "2017-04-03T20:19:02.447325: step 16626, loss 0.0763494, acc 0.984375\n",
      "2017-04-03T20:19:02.649587: step 16627, loss 0.210668, acc 0.890625\n",
      "2017-04-03T20:19:02.853679: step 16628, loss 0.0916277, acc 0.953125\n",
      "2017-04-03T20:19:03.051821: step 16629, loss 0.27488, acc 0.90625\n",
      "2017-04-03T20:19:03.250910: step 16630, loss 0.0629709, acc 0.96875\n",
      "2017-04-03T20:19:03.444163: step 16631, loss 0.173134, acc 0.984375\n",
      "2017-04-03T20:19:03.646644: step 16632, loss 0.111924, acc 0.953125\n",
      "2017-04-03T20:19:03.850684: step 16633, loss 0.0679663, acc 1\n",
      "2017-04-03T20:19:04.052315: step 16634, loss 0.0819747, acc 0.984375\n",
      "2017-04-03T20:19:04.255299: step 16635, loss 0.0536146, acc 0.984375\n",
      "2017-04-03T20:19:04.458654: step 16636, loss 0.0308929, acc 1\n",
      "2017-04-03T20:19:04.668108: step 16637, loss 0.125196, acc 0.984375\n",
      "2017-04-03T20:19:04.866413: step 16638, loss 0.0726047, acc 0.984375\n",
      "2017-04-03T20:19:05.073608: step 16639, loss 0.118421, acc 0.953125\n",
      "2017-04-03T20:19:05.298398: step 16640, loss 0.150874, acc 0.9375\n",
      "2017-04-03T20:19:05.513607: step 16641, loss 0.0783296, acc 0.984375\n",
      "2017-04-03T20:19:05.717677: step 16642, loss 0.0699048, acc 0.96875\n",
      "2017-04-03T20:19:05.922468: step 16643, loss 0.159524, acc 0.953125\n",
      "2017-04-03T20:19:06.124428: step 16644, loss 0.15338, acc 0.9375\n",
      "2017-04-03T20:19:06.324722: step 16645, loss 0.163235, acc 0.953125\n",
      "2017-04-03T20:19:06.526087: step 16646, loss 0.224953, acc 0.90625\n",
      "2017-04-03T20:19:06.726637: step 16647, loss 0.0247869, acc 1\n",
      "2017-04-03T20:19:06.930021: step 16648, loss 0.178674, acc 0.9375\n",
      "2017-04-03T20:19:07.129902: step 16649, loss 0.218326, acc 0.921875\n",
      "2017-04-03T20:19:07.331640: step 16650, loss 0.179741, acc 0.953125\n",
      "2017-04-03T20:19:07.532269: step 16651, loss 0.128966, acc 0.96875\n",
      "2017-04-03T20:19:07.734722: step 16652, loss 0.0951848, acc 0.96875\n",
      "2017-04-03T20:19:07.938381: step 16653, loss 0.120498, acc 0.953125\n",
      "2017-04-03T20:19:08.137422: step 16654, loss 0.109007, acc 0.96875\n",
      "2017-04-03T20:19:08.381237: step 16655, loss 0.251831, acc 0.921875\n",
      "2017-04-03T20:19:08.593646: step 16656, loss 0.276985, acc 0.921875\n",
      "2017-04-03T20:19:08.833391: step 16657, loss 0.0399834, acc 1\n",
      "2017-04-03T20:19:09.054923: step 16658, loss 0.173265, acc 0.96875\n",
      "2017-04-03T20:19:09.257658: step 16659, loss 0.328015, acc 0.875\n",
      "2017-04-03T20:19:09.454341: step 16660, loss 0.150673, acc 0.953125\n",
      "2017-04-03T20:19:09.654087: step 16661, loss 0.166943, acc 0.9375\n",
      "2017-04-03T20:19:09.852220: step 16662, loss 0.119581, acc 0.984375\n",
      "2017-04-03T20:19:10.056066: step 16663, loss 0.0889657, acc 0.953125\n",
      "2017-04-03T20:19:10.261077: step 16664, loss 0.038825, acc 0.984375\n",
      "2017-04-03T20:19:10.465277: step 16665, loss 0.0937703, acc 0.96875\n",
      "2017-04-03T20:19:10.669312: step 16666, loss 0.235946, acc 0.921875\n",
      "2017-04-03T20:19:10.887756: step 16667, loss 0.133129, acc 0.953125\n",
      "2017-04-03T20:19:11.095778: step 16668, loss 0.184714, acc 0.9375\n",
      "2017-04-03T20:19:11.300367: step 16669, loss 0.149752, acc 0.9375\n",
      "2017-04-03T20:19:11.502234: step 16670, loss 0.292075, acc 0.921875\n",
      "2017-04-03T20:19:11.712745: step 16671, loss 0.0701113, acc 0.984375\n",
      "2017-04-03T20:19:11.933530: step 16672, loss 0.0691271, acc 0.96875\n",
      "2017-04-03T20:19:12.148206: step 16673, loss 0.10763, acc 0.96875\n",
      "2017-04-03T20:19:12.346831: step 16674, loss 0.158065, acc 0.984375\n",
      "2017-04-03T20:19:12.547259: step 16675, loss 0.121215, acc 0.9375\n",
      "2017-04-03T20:19:12.757071: step 16676, loss 0.259221, acc 0.921875\n",
      "2017-04-03T20:19:12.958858: step 16677, loss 0.0734258, acc 0.96875\n",
      "2017-04-03T20:19:13.162758: step 16678, loss 0.082173, acc 0.984375\n",
      "2017-04-03T20:19:13.368400: step 16679, loss 0.209877, acc 0.890625\n",
      "2017-04-03T20:19:13.574883: step 16680, loss 0.0753664, acc 0.984375\n",
      "2017-04-03T20:19:13.819121: step 16681, loss 0.202055, acc 0.9375\n",
      "2017-04-03T20:19:14.033007: step 16682, loss 0.020681, acc 1\n",
      "2017-04-03T20:19:14.236201: step 16683, loss 0.0796973, acc 0.953125\n",
      "2017-04-03T20:19:14.435249: step 16684, loss 0.163425, acc 0.96875\n",
      "2017-04-03T20:19:14.634400: step 16685, loss 0.106073, acc 0.96875\n",
      "2017-04-03T20:19:14.850905: step 16686, loss 0.066904, acc 0.984375\n",
      "2017-04-03T20:19:15.057077: step 16687, loss 0.156526, acc 0.921875\n",
      "2017-04-03T20:19:15.266752: step 16688, loss 0.0556473, acc 0.984375\n",
      "2017-04-03T20:19:15.467187: step 16689, loss 0.176134, acc 0.921875\n",
      "2017-04-03T20:19:15.666121: step 16690, loss 0.0659695, acc 0.984375\n",
      "2017-04-03T20:19:15.869088: step 16691, loss 0.0981513, acc 0.953125\n",
      "2017-04-03T20:19:16.071387: step 16692, loss 0.332854, acc 0.890625\n",
      "2017-04-03T20:19:16.271635: step 16693, loss 0.166873, acc 0.9375\n",
      "2017-04-03T20:19:16.471272: step 16694, loss 0.14503, acc 0.96875\n",
      "2017-04-03T20:19:16.676127: step 16695, loss 0.113588, acc 0.953125\n",
      "2017-04-03T20:19:16.877155: step 16696, loss 0.35647, acc 0.9375\n",
      "2017-04-03T20:19:17.081310: step 16697, loss 0.131443, acc 0.953125\n",
      "2017-04-03T20:19:17.285135: step 16698, loss 0.152498, acc 0.921875\n",
      "2017-04-03T20:19:17.531810: step 16699, loss 0.244959, acc 0.9375\n",
      "2017-04-03T20:19:17.741791: step 16700, loss 0.109347, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:19:19.862449: step 16700, loss 6.52977, acc 0.28525\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-16700\n",
      "\n",
      "2017-04-03T20:19:20.204054: step 16701, loss 0.0549318, acc 0.984375\n",
      "2017-04-03T20:19:20.418523: step 16702, loss 0.0915694, acc 0.984375\n",
      "2017-04-03T20:19:20.621911: step 16703, loss 0.0447167, acc 0.984375\n",
      "2017-04-03T20:19:20.866334: step 16704, loss 0.382137, acc 0.921875\n",
      "2017-04-03T20:19:21.108117: step 16705, loss 0.0930551, acc 0.96875\n",
      "2017-04-03T20:19:21.363227: step 16706, loss 0.174904, acc 0.953125\n",
      "2017-04-03T20:19:21.568760: step 16707, loss 0.101976, acc 0.96875\n",
      "2017-04-03T20:19:21.772639: step 16708, loss 0.0424777, acc 0.984375\n",
      "2017-04-03T20:19:22.017986: step 16709, loss 0.123618, acc 0.953125\n",
      "2017-04-03T20:19:22.230247: step 16710, loss 0.122896, acc 0.9375\n",
      "2017-04-03T20:19:22.430702: step 16711, loss 0.187077, acc 0.9375\n",
      "2017-04-03T20:19:22.637897: step 16712, loss 0.134254, acc 0.953125\n",
      "2017-04-03T20:19:22.838871: step 16713, loss 0.153539, acc 0.953125\n",
      "2017-04-03T20:19:23.042388: step 16714, loss 0.0736829, acc 0.984375\n",
      "2017-04-03T20:19:23.252523: step 16715, loss 0.071738, acc 1\n",
      "2017-04-03T20:19:23.457475: step 16716, loss 0.347928, acc 0.890625\n",
      "2017-04-03T20:19:23.665253: step 16717, loss 0.0968803, acc 0.953125\n",
      "2017-04-03T20:19:23.871703: step 16718, loss 0.100782, acc 0.96875\n",
      "2017-04-03T20:19:24.071420: step 16719, loss 0.106995, acc 0.953125\n",
      "2017-04-03T20:19:24.273963: step 16720, loss 0.223349, acc 0.953125\n",
      "2017-04-03T20:19:24.475116: step 16721, loss 0.246022, acc 0.9375\n",
      "2017-04-03T20:19:24.680109: step 16722, loss 0.127412, acc 0.984375\n",
      "2017-04-03T20:19:24.883686: step 16723, loss 0.0476961, acc 0.984375\n",
      "2017-04-03T20:19:25.083025: step 16724, loss 0.0994216, acc 0.953125\n",
      "2017-04-03T20:19:25.290705: step 16725, loss 0.19375, acc 0.953125\n",
      "2017-04-03T20:19:25.497170: step 16726, loss 0.169971, acc 0.9375\n",
      "2017-04-03T20:19:25.697578: step 16727, loss 0.0950468, acc 0.96875\n",
      "2017-04-03T20:19:25.902249: step 16728, loss 0.188454, acc 0.921875\n",
      "2017-04-03T20:19:26.109797: step 16729, loss 0.0975548, acc 0.96875\n",
      "2017-04-03T20:19:26.310014: step 16730, loss 0.0905397, acc 0.96875\n",
      "2017-04-03T20:19:26.516703: step 16731, loss 0.247034, acc 0.9375\n",
      "2017-04-03T20:19:26.723046: step 16732, loss 0.220129, acc 0.953125\n",
      "2017-04-03T20:19:26.926128: step 16733, loss 0.0878248, acc 0.984375\n",
      "2017-04-03T20:19:27.147850: step 16734, loss 0.127103, acc 0.96875\n",
      "2017-04-03T20:19:27.352539: step 16735, loss 0.142885, acc 0.921875\n",
      "2017-04-03T20:19:27.552334: step 16736, loss 0.1499, acc 0.921875\n",
      "2017-04-03T20:19:27.798073: step 16737, loss 0.138976, acc 0.9375\n",
      "2017-04-03T20:19:28.003283: step 16738, loss 0.134486, acc 0.96875\n",
      "2017-04-03T20:19:28.199179: step 16739, loss 0.0909791, acc 0.96875\n",
      "2017-04-03T20:19:28.411478: step 16740, loss 0.212425, acc 0.953125\n",
      "2017-04-03T20:19:28.615151: step 16741, loss 0.182859, acc 0.953125\n",
      "2017-04-03T20:19:29.030702: step 16742, loss 0.137025, acc 0.953125\n",
      "2017-04-03T20:19:29.234105: step 16743, loss 0.121687, acc 0.921875\n",
      "2017-04-03T20:19:29.437250: step 16744, loss 0.110619, acc 0.9375\n",
      "2017-04-03T20:19:29.642549: step 16745, loss 0.15745, acc 0.984375\n",
      "2017-04-03T20:19:29.843574: step 16746, loss 0.163713, acc 0.953125\n",
      "2017-04-03T20:19:30.052626: step 16747, loss 0.0514049, acc 0.984375\n",
      "2017-04-03T20:19:30.255292: step 16748, loss 0.0274956, acc 1\n",
      "2017-04-03T20:19:30.469373: step 16749, loss 0.577216, acc 0.90625\n",
      "2017-04-03T20:19:30.685325: step 16750, loss 0.0919105, acc 0.984375\n",
      "2017-04-03T20:19:30.891628: step 16751, loss 0.160047, acc 0.9375\n",
      "2017-04-03T20:19:31.097389: step 16752, loss 0.103107, acc 0.953125\n",
      "2017-04-03T20:19:31.301836: step 16753, loss 0.0675541, acc 0.96875\n",
      "2017-04-03T20:19:31.535991: step 16754, loss 0.0447708, acc 1\n",
      "2017-04-03T20:19:31.745547: step 16755, loss 0.0493054, acc 0.984375\n",
      "2017-04-03T20:19:31.948696: step 16756, loss 0.0780703, acc 0.984375\n",
      "2017-04-03T20:19:32.155379: step 16757, loss 0.159545, acc 0.921875\n",
      "2017-04-03T20:19:32.365570: step 16758, loss 0.148891, acc 0.96875\n",
      "2017-04-03T20:19:32.571218: step 16759, loss 0.0301794, acc 1\n",
      "2017-04-03T20:19:32.771860: step 16760, loss 0.11755, acc 0.96875\n",
      "2017-04-03T20:19:32.978879: step 16761, loss 0.0527153, acc 0.96875\n",
      "2017-04-03T20:19:33.180089: step 16762, loss 0.162878, acc 0.953125\n",
      "2017-04-03T20:19:33.385458: step 16763, loss 0.120697, acc 0.953125\n",
      "2017-04-03T20:19:33.591194: step 16764, loss 0.214738, acc 0.96875\n",
      "2017-04-03T20:19:33.789296: step 16765, loss 0.172364, acc 0.953125\n",
      "2017-04-03T20:19:34.001700: step 16766, loss 0.0541021, acc 0.984375\n",
      "2017-04-03T20:19:34.203873: step 16767, loss 0.335351, acc 0.9375\n",
      "2017-04-03T20:19:34.416384: step 16768, loss 0.132139, acc 0.9375\n",
      "2017-04-03T20:19:34.624618: step 16769, loss 0.177154, acc 0.96875\n",
      "2017-04-03T20:19:34.830904: step 16770, loss 0.0532199, acc 0.96875\n",
      "2017-04-03T20:19:35.044638: step 16771, loss 0.188371, acc 0.921875\n",
      "2017-04-03T20:19:35.251578: step 16772, loss 0.108368, acc 0.953125\n",
      "2017-04-03T20:19:35.451752: step 16773, loss 0.0738911, acc 0.984375\n",
      "2017-04-03T20:19:35.693930: step 16774, loss 0.0746441, acc 0.984375\n",
      "2017-04-03T20:19:35.955885: step 16775, loss 0.0898464, acc 0.96875\n",
      "2017-04-03T20:19:36.151300: step 16776, loss 0.109572, acc 0.984375\n",
      "2017-04-03T20:19:36.395700: step 16777, loss 0.320367, acc 0.921875\n",
      "2017-04-03T20:19:36.649038: step 16778, loss 0.078963, acc 0.96875\n",
      "2017-04-03T20:19:36.899871: step 16779, loss 0.0887415, acc 0.953125\n",
      "2017-04-03T20:19:37.142213: step 16780, loss 0.054206, acc 0.96875\n",
      "2017-04-03T20:19:37.347277: step 16781, loss 0.131731, acc 0.9375\n",
      "2017-04-03T20:19:37.548190: step 16782, loss 0.248348, acc 0.953125\n",
      "2017-04-03T20:19:37.750097: step 16783, loss 0.0945242, acc 0.984375\n",
      "2017-04-03T20:19:37.951882: step 16784, loss 0.0957726, acc 0.96875\n",
      "2017-04-03T20:19:38.197762: step 16785, loss 0.0722038, acc 0.96875\n",
      "2017-04-03T20:19:38.402748: step 16786, loss 0.0338364, acc 1\n",
      "2017-04-03T20:19:38.601971: step 16787, loss 0.045696, acc 0.984375\n",
      "2017-04-03T20:19:38.801557: step 16788, loss 0.0473721, acc 0.984375\n",
      "2017-04-03T20:19:39.002082: step 16789, loss 0.290945, acc 0.890625\n",
      "2017-04-03T20:19:39.204771: step 16790, loss 0.166719, acc 0.9375\n",
      "2017-04-03T20:19:39.411122: step 16791, loss 0.21361, acc 0.953125\n",
      "2017-04-03T20:19:39.610136: step 16792, loss 0.0552697, acc 0.984375\n",
      "2017-04-03T20:19:39.816296: step 16793, loss 0.0594326, acc 1\n",
      "2017-04-03T20:19:40.020261: step 16794, loss 0.121848, acc 0.96875\n",
      "2017-04-03T20:19:40.223352: step 16795, loss 0.0370845, acc 0.984375\n",
      "2017-04-03T20:19:40.430829: step 16796, loss 0.208153, acc 0.90625\n",
      "2017-04-03T20:19:40.635246: step 16797, loss 0.112223, acc 0.9375\n",
      "2017-04-03T20:19:40.836442: step 16798, loss 0.105423, acc 0.96875\n",
      "2017-04-03T20:19:41.041487: step 16799, loss 0.11868, acc 0.9375\n",
      "2017-04-03T20:19:41.258779: step 16800, loss 0.0848154, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:19:43.385744: step 16800, loss 6.55843, acc 0.284\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-16800\n",
      "\n",
      "2017-04-03T20:19:43.742862: step 16801, loss 0.138423, acc 0.96875\n",
      "2017-04-03T20:19:43.960169: step 16802, loss 0.0822237, acc 0.953125\n",
      "2017-04-03T20:19:44.162873: step 16803, loss 0.191895, acc 0.890625\n",
      "2017-04-03T20:19:44.369620: step 16804, loss 0.117952, acc 0.953125\n",
      "2017-04-03T20:19:44.575215: step 16805, loss 0.198388, acc 0.921875\n",
      "2017-04-03T20:19:44.782129: step 16806, loss 0.0933252, acc 0.9375\n",
      "2017-04-03T20:19:44.986289: step 16807, loss 0.130235, acc 0.96875\n",
      "2017-04-03T20:19:45.188403: step 16808, loss 0.228092, acc 0.90625\n",
      "2017-04-03T20:19:45.396884: step 16809, loss 0.122562, acc 0.953125\n",
      "2017-04-03T20:19:45.613853: step 16810, loss 0.0986032, acc 0.96875\n",
      "2017-04-03T20:19:45.820602: step 16811, loss 0.124279, acc 0.9375\n",
      "2017-04-03T20:19:46.023934: step 16812, loss 0.0676823, acc 0.96875\n",
      "2017-04-03T20:19:46.228662: step 16813, loss 0.137431, acc 0.953125\n",
      "2017-04-03T20:19:46.472018: step 16814, loss 0.0591152, acc 0.984375\n",
      "2017-04-03T20:19:46.671791: step 16815, loss 0.204326, acc 0.9375\n",
      "2017-04-03T20:19:46.881455: step 16816, loss 0.119203, acc 0.953125\n",
      "2017-04-03T20:19:47.082271: step 16817, loss 0.142099, acc 0.953125\n",
      "2017-04-03T20:19:47.283818: step 16818, loss 0.0684049, acc 0.984375\n",
      "2017-04-03T20:19:47.530881: step 16819, loss 0.192706, acc 0.9375\n",
      "2017-04-03T20:19:47.780351: step 16820, loss 0.0999771, acc 0.96875\n",
      "2017-04-03T20:19:48.032455: step 16821, loss 0.131963, acc 0.9375\n",
      "2017-04-03T20:19:48.234305: step 16822, loss 0.130939, acc 0.9375\n",
      "2017-04-03T20:19:48.438098: step 16823, loss 0.114139, acc 0.953125\n",
      "2017-04-03T20:19:48.642518: step 16824, loss 0.137877, acc 0.96875\n",
      "2017-04-03T20:19:48.851058: step 16825, loss 0.325468, acc 0.90625\n",
      "2017-04-03T20:19:49.051033: step 16826, loss 0.120362, acc 0.9375\n",
      "2017-04-03T20:19:49.257207: step 16827, loss 0.0570054, acc 0.984375\n",
      "2017-04-03T20:19:49.465073: step 16828, loss 0.0618562, acc 0.984375\n",
      "2017-04-03T20:19:49.666133: step 16829, loss 0.148349, acc 0.96875\n",
      "2017-04-03T20:19:49.867460: step 16830, loss 0.0679099, acc 0.984375\n",
      "2017-04-03T20:19:50.073056: step 16831, loss 0.124087, acc 0.953125\n",
      "2017-04-03T20:19:50.279292: step 16832, loss 0.328894, acc 0.9375\n",
      "2017-04-03T20:19:50.509215: step 16833, loss 0.101771, acc 0.9375\n",
      "2017-04-03T20:19:50.728175: step 16834, loss 0.226423, acc 0.953125\n",
      "2017-04-03T20:19:50.933169: step 16835, loss 0.099266, acc 0.96875\n",
      "2017-04-03T20:19:51.133651: step 16836, loss 0.157619, acc 0.9375\n",
      "2017-04-03T20:19:51.338602: step 16837, loss 0.0742094, acc 0.9375\n",
      "2017-04-03T20:19:51.588028: step 16838, loss 0.152492, acc 0.96875\n",
      "2017-04-03T20:19:51.851341: step 16839, loss 0.0308533, acc 1\n",
      "2017-04-03T20:19:52.051380: step 16840, loss 0.0961377, acc 0.96875\n",
      "2017-04-03T20:19:52.295576: step 16841, loss 0.204414, acc 0.921875\n",
      "2017-04-03T20:19:52.513948: step 16842, loss 0.111792, acc 0.96875\n",
      "2017-04-03T20:19:52.717581: step 16843, loss 0.0530191, acc 0.984375\n",
      "2017-04-03T20:19:52.924723: step 16844, loss 0.25114, acc 0.890625\n",
      "2017-04-03T20:19:53.125873: step 16845, loss 0.159374, acc 0.953125\n",
      "2017-04-03T20:19:53.324031: step 16846, loss 0.103068, acc 0.953125\n",
      "2017-04-03T20:19:53.532052: step 16847, loss 0.0731174, acc 0.984375\n",
      "2017-04-03T20:19:53.734366: step 16848, loss 0.218032, acc 0.9375\n",
      "2017-04-03T20:19:53.938524: step 16849, loss 0.11324, acc 0.96875\n",
      "2017-04-03T20:19:54.145058: step 16850, loss 0.108784, acc 0.953125\n",
      "2017-04-03T20:19:54.340714: step 16851, loss 0.193352, acc 0.921875\n",
      "2017-04-03T20:19:54.555494: step 16852, loss 0.0929679, acc 0.953125\n",
      "2017-04-03T20:19:54.762837: step 16853, loss 0.143348, acc 0.953125\n",
      "2017-04-03T20:19:54.967107: step 16854, loss 0.166396, acc 0.921875\n",
      "2017-04-03T20:19:55.179311: step 16855, loss 0.260773, acc 0.90625\n",
      "2017-04-03T20:19:55.403366: step 16856, loss 0.149756, acc 0.953125\n",
      "2017-04-03T20:19:55.610318: step 16857, loss 0.0831594, acc 0.96875\n",
      "2017-04-03T20:19:55.815137: step 16858, loss 0.225828, acc 0.9375\n",
      "2017-04-03T20:19:56.019992: step 16859, loss 0.0622474, acc 0.984375\n",
      "2017-04-03T20:19:56.219378: step 16860, loss 0.205202, acc 0.9375\n",
      "2017-04-03T20:19:56.424948: step 16861, loss 0.106935, acc 0.953125\n",
      "2017-04-03T20:19:56.671456: step 16862, loss 0.292411, acc 0.921875\n",
      "2017-04-03T20:19:56.914929: step 16863, loss 0.388061, acc 0.921875\n",
      "2017-04-03T20:19:57.127646: step 16864, loss 0.198126, acc 0.953125\n",
      "2017-04-03T20:19:57.393822: step 16865, loss 0.167642, acc 0.953125\n",
      "2017-04-03T20:19:57.600773: step 16866, loss 0.14508, acc 0.953125\n",
      "2017-04-03T20:19:57.805539: step 16867, loss 0.140481, acc 0.953125\n",
      "2017-04-03T20:19:58.003478: step 16868, loss 0.151004, acc 0.9375\n",
      "2017-04-03T20:19:58.212414: step 16869, loss 0.0953962, acc 0.953125\n",
      "2017-04-03T20:19:58.422684: step 16870, loss 0.114506, acc 0.953125\n",
      "2017-04-03T20:19:58.623455: step 16871, loss 0.108034, acc 0.96875\n",
      "2017-04-03T20:19:58.823742: step 16872, loss 0.15962, acc 0.9375\n",
      "2017-04-03T20:19:59.070201: step 16873, loss 0.0657127, acc 0.96875\n",
      "2017-04-03T20:19:59.276663: step 16874, loss 0.081486, acc 0.953125\n",
      "2017-04-03T20:19:59.481775: step 16875, loss 0.0951587, acc 0.96875\n",
      "2017-04-03T20:19:59.690693: step 16876, loss 0.152333, acc 0.9375\n",
      "2017-04-03T20:19:59.895937: step 16877, loss 0.0951062, acc 0.96875\n",
      "2017-04-03T20:20:00.106773: step 16878, loss 0.0755141, acc 0.96875\n",
      "2017-04-03T20:20:00.350118: step 16879, loss 0.251805, acc 0.921875\n",
      "2017-04-03T20:20:00.560420: step 16880, loss 0.123191, acc 0.9375\n",
      "2017-04-03T20:20:00.806750: step 16881, loss 0.120293, acc 0.953125\n",
      "2017-04-03T20:20:01.012723: step 16882, loss 0.100308, acc 0.953125\n",
      "2017-04-03T20:20:01.218527: step 16883, loss 0.0423863, acc 1\n",
      "2017-04-03T20:20:01.419205: step 16884, loss 0.404323, acc 0.875\n",
      "2017-04-03T20:20:01.626675: step 16885, loss 0.0428737, acc 1\n",
      "2017-04-03T20:20:01.830239: step 16886, loss 0.0768586, acc 0.96875\n",
      "2017-04-03T20:20:02.034941: step 16887, loss 0.388529, acc 0.9375\n",
      "2017-04-03T20:20:02.236522: step 16888, loss 0.0874262, acc 0.96875\n",
      "2017-04-03T20:20:02.440380: step 16889, loss 0.0663948, acc 0.984375\n",
      "2017-04-03T20:20:02.592819: step 16890, loss 0.0840292, acc 0.9375\n",
      "2017-04-03T20:20:02.801486: step 16891, loss 0.0309831, acc 1\n",
      "2017-04-03T20:20:03.005242: step 16892, loss 0.0924211, acc 0.96875\n",
      "2017-04-03T20:20:03.208579: step 16893, loss 0.0899351, acc 0.9375\n",
      "2017-04-03T20:20:03.422016: step 16894, loss 0.0461752, acc 0.984375\n",
      "2017-04-03T20:20:03.630188: step 16895, loss 0.189424, acc 0.953125\n",
      "2017-04-03T20:20:03.839038: step 16896, loss 0.0887483, acc 0.96875\n",
      "2017-04-03T20:20:04.082393: step 16897, loss 0.145397, acc 0.984375\n",
      "2017-04-03T20:20:04.285098: step 16898, loss 0.132389, acc 0.953125\n",
      "2017-04-03T20:20:04.487334: step 16899, loss 0.080095, acc 0.984375\n",
      "2017-04-03T20:20:04.687876: step 16900, loss 0.0395461, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:20:06.806348: step 16900, loss 6.56208, acc 0.28825\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-16900\n",
      "\n",
      "2017-04-03T20:20:07.188070: step 16901, loss 0.190021, acc 0.953125\n",
      "2017-04-03T20:20:07.391719: step 16902, loss 0.118582, acc 0.953125\n",
      "2017-04-03T20:20:07.607315: step 16903, loss 0.201456, acc 0.9375\n",
      "2017-04-03T20:20:07.821642: step 16904, loss 0.0983766, acc 0.953125\n",
      "2017-04-03T20:20:08.024990: step 16905, loss 0.125306, acc 0.953125\n",
      "2017-04-03T20:20:08.227609: step 16906, loss 0.0909231, acc 0.984375\n",
      "2017-04-03T20:20:08.429969: step 16907, loss 0.305691, acc 0.953125\n",
      "2017-04-03T20:20:08.635643: step 16908, loss 0.135163, acc 0.96875\n",
      "2017-04-03T20:20:08.842751: step 16909, loss 0.226031, acc 0.90625\n",
      "2017-04-03T20:20:09.048884: step 16910, loss 0.124151, acc 0.984375\n",
      "2017-04-03T20:20:09.251839: step 16911, loss 0.0977687, acc 0.96875\n",
      "2017-04-03T20:20:09.458870: step 16912, loss 0.237164, acc 0.9375\n",
      "2017-04-03T20:20:09.661291: step 16913, loss 0.115093, acc 0.9375\n",
      "2017-04-03T20:20:09.867178: step 16914, loss 0.0387, acc 0.984375\n",
      "2017-04-03T20:20:10.069919: step 16915, loss 0.0812537, acc 0.96875\n",
      "2017-04-03T20:20:10.272768: step 16916, loss 0.120292, acc 0.9375\n",
      "2017-04-03T20:20:10.476126: step 16917, loss 0.0458766, acc 1\n",
      "2017-04-03T20:20:10.676183: step 16918, loss 0.103221, acc 0.96875\n",
      "2017-04-03T20:20:10.886894: step 16919, loss 0.0615832, acc 0.984375\n",
      "2017-04-03T20:20:11.119191: step 16920, loss 0.0551587, acc 1\n",
      "2017-04-03T20:20:11.324221: step 16921, loss 0.120411, acc 0.953125\n",
      "2017-04-03T20:20:11.528268: step 16922, loss 0.189628, acc 0.921875\n",
      "2017-04-03T20:20:11.728501: step 16923, loss 0.111141, acc 0.953125\n",
      "2017-04-03T20:20:11.927887: step 16924, loss 0.132941, acc 0.953125\n",
      "2017-04-03T20:20:12.137964: step 16925, loss 0.183037, acc 0.9375\n",
      "2017-04-03T20:20:12.337169: step 16926, loss 0.0820214, acc 0.984375\n",
      "2017-04-03T20:20:12.551821: step 16927, loss 0.0239003, acc 1\n",
      "2017-04-03T20:20:12.794278: step 16928, loss 0.119632, acc 0.96875\n",
      "2017-04-03T20:20:12.999200: step 16929, loss 0.171369, acc 0.953125\n",
      "2017-04-03T20:20:13.202983: step 16930, loss 0.0349057, acc 1\n",
      "2017-04-03T20:20:13.413938: step 16931, loss 0.0280357, acc 1\n",
      "2017-04-03T20:20:13.617962: step 16932, loss 0.0674586, acc 0.984375\n",
      "2017-04-03T20:20:13.865261: step 16933, loss 0.159991, acc 0.9375\n",
      "2017-04-03T20:20:14.071524: step 16934, loss 0.143545, acc 0.9375\n",
      "2017-04-03T20:20:14.275137: step 16935, loss 0.0592028, acc 0.984375\n",
      "2017-04-03T20:20:14.486348: step 16936, loss 0.11715, acc 0.953125\n",
      "2017-04-03T20:20:14.723002: step 16937, loss 0.168851, acc 0.953125\n",
      "2017-04-03T20:20:14.940812: step 16938, loss 0.0391573, acc 1\n",
      "2017-04-03T20:20:15.158357: step 16939, loss 0.146549, acc 0.921875\n",
      "2017-04-03T20:20:15.364518: step 16940, loss 0.169555, acc 0.9375\n",
      "2017-04-03T20:20:15.564494: step 16941, loss 0.0752368, acc 0.96875\n",
      "2017-04-03T20:20:15.812711: step 16942, loss 0.296215, acc 0.921875\n",
      "2017-04-03T20:20:16.059107: step 16943, loss 0.0762219, acc 0.984375\n",
      "2017-04-03T20:20:16.268959: step 16944, loss 0.219153, acc 0.96875\n",
      "2017-04-03T20:20:16.479285: step 16945, loss 0.0719071, acc 0.953125\n",
      "2017-04-03T20:20:16.681224: step 16946, loss 0.102038, acc 0.96875\n",
      "2017-04-03T20:20:16.890066: step 16947, loss 0.103751, acc 0.953125\n",
      "2017-04-03T20:20:17.099678: step 16948, loss 0.0910971, acc 0.953125\n",
      "2017-04-03T20:20:17.304836: step 16949, loss 0.101088, acc 0.96875\n",
      "2017-04-03T20:20:17.511356: step 16950, loss 0.0670103, acc 0.984375\n",
      "2017-04-03T20:20:17.717867: step 16951, loss 0.0281691, acc 0.984375\n",
      "2017-04-03T20:20:17.931508: step 16952, loss 0.0656454, acc 0.96875\n",
      "2017-04-03T20:20:18.137658: step 16953, loss 0.210701, acc 0.921875\n",
      "2017-04-03T20:20:18.341126: step 16954, loss 0.0309371, acc 0.984375\n",
      "2017-04-03T20:20:18.549689: step 16955, loss 0.148375, acc 0.984375\n",
      "2017-04-03T20:20:18.750801: step 16956, loss 0.0762427, acc 0.984375\n",
      "2017-04-03T20:20:18.961123: step 16957, loss 0.078244, acc 0.96875\n",
      "2017-04-03T20:20:19.163867: step 16958, loss 0.0213296, acc 1\n",
      "2017-04-03T20:20:19.377480: step 16959, loss 0.199774, acc 0.9375\n",
      "2017-04-03T20:20:19.588364: step 16960, loss 0.0166412, acc 1\n",
      "2017-04-03T20:20:19.788314: step 16961, loss 0.109971, acc 0.9375\n",
      "2017-04-03T20:20:19.994489: step 16962, loss 0.0683965, acc 0.984375\n",
      "2017-04-03T20:20:20.194395: step 16963, loss 0.0651564, acc 0.96875\n",
      "2017-04-03T20:20:20.404545: step 16964, loss 0.109652, acc 0.953125\n",
      "2017-04-03T20:20:20.605894: step 16965, loss 0.0441734, acc 0.984375\n",
      "2017-04-03T20:20:20.807649: step 16966, loss 0.0793269, acc 0.96875\n",
      "2017-04-03T20:20:21.048862: step 16967, loss 0.146864, acc 0.96875\n",
      "2017-04-03T20:20:21.249062: step 16968, loss 0.0643906, acc 0.96875\n",
      "2017-04-03T20:20:21.451547: step 16969, loss 0.101741, acc 0.96875\n",
      "2017-04-03T20:20:21.657998: step 16970, loss 0.193711, acc 0.953125\n",
      "2017-04-03T20:20:21.857102: step 16971, loss 0.0883423, acc 0.984375\n",
      "2017-04-03T20:20:22.062431: step 16972, loss 0.0629405, acc 0.984375\n",
      "2017-04-03T20:20:22.265289: step 16973, loss 0.0994905, acc 0.96875\n",
      "2017-04-03T20:20:22.468103: step 16974, loss 0.0299276, acc 1\n",
      "2017-04-03T20:20:22.719666: step 16975, loss 0.0943166, acc 0.984375\n",
      "2017-04-03T20:20:22.920136: step 16976, loss 0.0860075, acc 0.96875\n",
      "2017-04-03T20:20:23.126291: step 16977, loss 0.135481, acc 0.953125\n",
      "2017-04-03T20:20:23.329810: step 16978, loss 0.187301, acc 0.921875\n",
      "2017-04-03T20:20:23.530934: step 16979, loss 0.0423405, acc 0.984375\n",
      "2017-04-03T20:20:23.748379: step 16980, loss 0.0741982, acc 1\n",
      "2017-04-03T20:20:23.946403: step 16981, loss 0.11781, acc 0.96875\n",
      "2017-04-03T20:20:24.149412: step 16982, loss 0.0941143, acc 0.984375\n",
      "2017-04-03T20:20:24.348464: step 16983, loss 0.0541266, acc 0.96875\n",
      "2017-04-03T20:20:24.577365: step 16984, loss 0.143128, acc 0.953125\n",
      "2017-04-03T20:20:24.788422: step 16985, loss 0.0368937, acc 1\n",
      "2017-04-03T20:20:24.990888: step 16986, loss 0.0504026, acc 0.984375\n",
      "2017-04-03T20:20:25.192543: step 16987, loss 0.243411, acc 0.921875\n",
      "2017-04-03T20:20:25.396091: step 16988, loss 0.0689344, acc 0.96875\n",
      "2017-04-03T20:20:25.609394: step 16989, loss 0.140357, acc 0.953125\n",
      "2017-04-03T20:20:25.809058: step 16990, loss 0.0642893, acc 0.984375\n",
      "2017-04-03T20:20:26.016638: step 16991, loss 0.10606, acc 0.953125\n",
      "2017-04-03T20:20:26.222584: step 16992, loss 0.017448, acc 0.984375\n",
      "2017-04-03T20:20:26.426133: step 16993, loss 0.0797925, acc 0.96875\n",
      "2017-04-03T20:20:26.671050: step 16994, loss 0.182614, acc 0.953125\n",
      "2017-04-03T20:20:26.882393: step 16995, loss 0.0656888, acc 0.96875\n",
      "2017-04-03T20:20:27.084129: step 16996, loss 0.125774, acc 0.953125\n",
      "2017-04-03T20:20:27.292138: step 16997, loss 0.189116, acc 0.96875\n",
      "2017-04-03T20:20:27.494998: step 16998, loss 0.128472, acc 0.953125\n",
      "2017-04-03T20:20:27.697520: step 16999, loss 0.0272715, acc 1\n",
      "2017-04-03T20:20:27.900192: step 17000, loss 0.085895, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:20:30.047982: step 17000, loss 6.70423, acc 0.28575\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-17000\n",
      "\n",
      "2017-04-03T20:20:30.400870: step 17001, loss 0.232526, acc 0.953125\n",
      "2017-04-03T20:20:30.613808: step 17002, loss 0.0809622, acc 0.984375\n",
      "2017-04-03T20:20:30.820154: step 17003, loss 0.128853, acc 0.9375\n",
      "2017-04-03T20:20:31.020677: step 17004, loss 0.190798, acc 0.953125\n",
      "2017-04-03T20:20:31.269211: step 17005, loss 0.0824873, acc 0.953125\n",
      "2017-04-03T20:20:31.505785: step 17006, loss 0.0925846, acc 0.96875\n",
      "2017-04-03T20:20:31.710144: step 17007, loss 0.170617, acc 0.96875\n",
      "2017-04-03T20:20:31.912890: step 17008, loss 0.0812159, acc 0.96875\n",
      "2017-04-03T20:20:32.116182: step 17009, loss 0.0601273, acc 0.96875\n",
      "2017-04-03T20:20:32.314659: step 17010, loss 0.0765177, acc 0.984375\n",
      "2017-04-03T20:20:32.558363: step 17011, loss 0.110164, acc 0.9375\n",
      "2017-04-03T20:20:32.759877: step 17012, loss 0.0961055, acc 0.953125\n",
      "2017-04-03T20:20:32.959118: step 17013, loss 0.136288, acc 0.96875\n",
      "2017-04-03T20:20:33.165200: step 17014, loss 0.0563012, acc 0.984375\n",
      "2017-04-03T20:20:33.370660: step 17015, loss 0.0507368, acc 0.984375\n",
      "2017-04-03T20:20:33.583665: step 17016, loss 0.0371859, acc 1\n",
      "2017-04-03T20:20:33.785601: step 17017, loss 0.0620998, acc 0.984375\n",
      "2017-04-03T20:20:33.992375: step 17018, loss 0.144549, acc 0.953125\n",
      "2017-04-03T20:20:34.195724: step 17019, loss 0.0224882, acc 1\n",
      "2017-04-03T20:20:34.408971: step 17020, loss 0.123243, acc 0.953125\n",
      "2017-04-03T20:20:34.616881: step 17021, loss 0.139658, acc 0.9375\n",
      "2017-04-03T20:20:34.819136: step 17022, loss 0.0686923, acc 0.953125\n",
      "2017-04-03T20:20:35.020902: step 17023, loss 0.00737745, acc 1\n",
      "2017-04-03T20:20:35.223332: step 17024, loss 0.117481, acc 0.96875\n",
      "2017-04-03T20:20:35.430060: step 17025, loss 0.13649, acc 0.953125\n",
      "2017-04-03T20:20:35.645584: step 17026, loss 0.070836, acc 0.984375\n",
      "2017-04-03T20:20:35.853079: step 17027, loss 0.0421538, acc 0.984375\n",
      "2017-04-03T20:20:36.054111: step 17028, loss 0.150231, acc 0.9375\n",
      "2017-04-03T20:20:36.253354: step 17029, loss 0.147754, acc 0.921875\n",
      "2017-04-03T20:20:36.456668: step 17030, loss 0.0712392, acc 0.96875\n",
      "2017-04-03T20:20:36.705511: step 17031, loss 0.150101, acc 0.96875\n",
      "2017-04-03T20:20:36.907462: step 17032, loss 0.156167, acc 0.96875\n",
      "2017-04-03T20:20:37.107255: step 17033, loss 0.0520539, acc 0.96875\n",
      "2017-04-03T20:20:37.311666: step 17034, loss 0.0654774, acc 0.96875\n",
      "2017-04-03T20:20:37.513568: step 17035, loss 0.162476, acc 0.953125\n",
      "2017-04-03T20:20:37.717787: step 17036, loss 0.175425, acc 0.953125\n",
      "2017-04-03T20:20:37.916861: step 17037, loss 0.0989982, acc 0.96875\n",
      "2017-04-03T20:20:38.120439: step 17038, loss 0.0892056, acc 0.96875\n",
      "2017-04-03T20:20:38.329611: step 17039, loss 0.173452, acc 0.96875\n",
      "2017-04-03T20:20:38.540410: step 17040, loss 0.163896, acc 0.953125\n",
      "2017-04-03T20:20:38.762040: step 17041, loss 0.356294, acc 0.953125\n",
      "2017-04-03T20:20:38.981632: step 17042, loss 0.19087, acc 0.9375\n",
      "2017-04-03T20:20:39.184010: step 17043, loss 0.158101, acc 0.96875\n",
      "2017-04-03T20:20:39.391570: step 17044, loss 0.106543, acc 0.96875\n",
      "2017-04-03T20:20:39.593409: step 17045, loss 0.206378, acc 0.9375\n",
      "2017-04-03T20:20:39.799141: step 17046, loss 0.10462, acc 0.96875\n",
      "2017-04-03T20:20:40.041360: step 17047, loss 0.0507417, acc 1\n",
      "2017-04-03T20:20:40.248604: step 17048, loss 0.0967408, acc 0.96875\n",
      "2017-04-03T20:20:40.450220: step 17049, loss 0.0647621, acc 0.984375\n",
      "2017-04-03T20:20:40.651771: step 17050, loss 0.22495, acc 0.953125\n",
      "2017-04-03T20:20:40.853688: step 17051, loss 0.0507526, acc 1\n",
      "2017-04-03T20:20:41.052533: step 17052, loss 0.148583, acc 0.953125\n",
      "2017-04-03T20:20:41.254131: step 17053, loss 0.194778, acc 0.953125\n",
      "2017-04-03T20:20:41.468271: step 17054, loss 0.224626, acc 0.96875\n",
      "2017-04-03T20:20:41.668837: step 17055, loss 0.0683805, acc 0.96875\n",
      "2017-04-03T20:20:41.869700: step 17056, loss 0.197539, acc 0.9375\n",
      "2017-04-03T20:20:42.073351: step 17057, loss 0.0315296, acc 0.984375\n",
      "2017-04-03T20:20:42.289545: step 17058, loss 0.0725619, acc 0.96875\n",
      "2017-04-03T20:20:42.497323: step 17059, loss 0.0423103, acc 1\n",
      "2017-04-03T20:20:42.716627: step 17060, loss 0.0605734, acc 0.984375\n",
      "2017-04-03T20:20:42.922096: step 17061, loss 0.177454, acc 0.984375\n",
      "2017-04-03T20:20:43.127025: step 17062, loss 0.116164, acc 0.9375\n",
      "2017-04-03T20:20:43.371487: step 17063, loss 0.116143, acc 0.96875\n",
      "2017-04-03T20:20:43.574033: step 17064, loss 0.0852543, acc 0.984375\n",
      "2017-04-03T20:20:43.771633: step 17065, loss 0.0667626, acc 1\n",
      "2017-04-03T20:20:43.975029: step 17066, loss 0.217711, acc 0.921875\n",
      "2017-04-03T20:20:44.220900: step 17067, loss 0.142855, acc 0.953125\n",
      "2017-04-03T20:20:44.422166: step 17068, loss 0.421654, acc 0.875\n",
      "2017-04-03T20:20:44.623415: step 17069, loss 0.131281, acc 0.96875\n",
      "2017-04-03T20:20:44.822682: step 17070, loss 0.152614, acc 0.96875\n",
      "2017-04-03T20:20:45.042888: step 17071, loss 0.0983167, acc 0.9375\n",
      "2017-04-03T20:20:45.250681: step 17072, loss 0.0358076, acc 0.984375\n",
      "2017-04-03T20:20:45.461998: step 17073, loss 0.137231, acc 0.953125\n",
      "2017-04-03T20:20:45.672785: step 17074, loss 0.119348, acc 0.953125\n",
      "2017-04-03T20:20:45.875545: step 17075, loss 0.0524706, acc 0.984375\n",
      "2017-04-03T20:20:46.078272: step 17076, loss 0.112614, acc 0.9375\n",
      "2017-04-03T20:20:46.277182: step 17077, loss 0.0919163, acc 0.96875\n",
      "2017-04-03T20:20:46.480524: step 17078, loss 0.0519164, acc 0.984375\n",
      "2017-04-03T20:20:46.679845: step 17079, loss 0.224309, acc 0.953125\n",
      "2017-04-03T20:20:46.883865: step 17080, loss 0.0326078, acc 1\n",
      "2017-04-03T20:20:47.083647: step 17081, loss 0.157913, acc 0.953125\n",
      "2017-04-03T20:20:47.288889: step 17082, loss 0.161464, acc 0.9375\n",
      "2017-04-03T20:20:47.489980: step 17083, loss 0.109861, acc 0.96875\n",
      "2017-04-03T20:20:47.733480: step 17084, loss 0.0609972, acc 0.96875\n",
      "2017-04-03T20:20:47.933959: step 17085, loss 0.0471789, acc 0.984375\n",
      "2017-04-03T20:20:48.174991: step 17086, loss 0.153544, acc 0.953125\n",
      "2017-04-03T20:20:48.385652: step 17087, loss 0.200423, acc 0.90625\n",
      "2017-04-03T20:20:48.631368: step 17088, loss 0.053777, acc 1\n",
      "2017-04-03T20:20:48.836920: step 17089, loss 0.0345487, acc 0.984375\n",
      "2017-04-03T20:20:49.039266: step 17090, loss 0.107841, acc 0.96875\n",
      "2017-04-03T20:20:49.242156: step 17091, loss 0.305874, acc 0.9375\n",
      "2017-04-03T20:20:49.486026: step 17092, loss 0.084068, acc 0.96875\n",
      "2017-04-03T20:20:49.684576: step 17093, loss 0.119638, acc 0.96875\n",
      "2017-04-03T20:20:49.887679: step 17094, loss 0.109017, acc 0.96875\n",
      "2017-04-03T20:20:50.097463: step 17095, loss 0.121601, acc 0.96875\n",
      "2017-04-03T20:20:50.296997: step 17096, loss 0.10424, acc 0.96875\n",
      "2017-04-03T20:20:50.495005: step 17097, loss 0.165483, acc 0.96875\n",
      "2017-04-03T20:20:50.695642: step 17098, loss 0.108122, acc 0.9375\n",
      "2017-04-03T20:20:50.900413: step 17099, loss 0.115644, acc 0.953125\n",
      "2017-04-03T20:20:51.102025: step 17100, loss 0.107969, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:20:53.253287: step 17100, loss 6.67142, acc 0.28375\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-17100\n",
      "\n",
      "2017-04-03T20:20:53.588054: step 17101, loss 0.581428, acc 0.890625\n",
      "2017-04-03T20:20:53.797319: step 17102, loss 0.125241, acc 0.96875\n",
      "2017-04-03T20:20:54.011994: step 17103, loss 0.060323, acc 0.984375\n",
      "2017-04-03T20:20:54.220082: step 17104, loss 0.129616, acc 0.953125\n",
      "2017-04-03T20:20:54.458068: step 17105, loss 0.109336, acc 0.96875\n",
      "2017-04-03T20:20:54.660116: step 17106, loss 0.483428, acc 0.90625\n",
      "2017-04-03T20:20:54.901433: step 17107, loss 0.0250956, acc 1\n",
      "2017-04-03T20:20:55.104287: step 17108, loss 0.21151, acc 0.953125\n",
      "2017-04-03T20:20:55.302714: step 17109, loss 0.175864, acc 0.921875\n",
      "2017-04-03T20:20:55.552249: step 17110, loss 0.145236, acc 0.953125\n",
      "2017-04-03T20:20:55.755755: step 17111, loss 0.0587739, acc 0.984375\n",
      "2017-04-03T20:20:55.955950: step 17112, loss 0.171504, acc 0.90625\n",
      "2017-04-03T20:20:56.172779: step 17113, loss 0.0583729, acc 0.984375\n",
      "2017-04-03T20:20:56.380941: step 17114, loss 0.059225, acc 0.984375\n",
      "2017-04-03T20:20:56.633113: step 17115, loss 0.106487, acc 0.953125\n",
      "2017-04-03T20:20:56.832367: step 17116, loss 0.207156, acc 0.953125\n",
      "2017-04-03T20:20:57.068468: step 17117, loss 0.192433, acc 0.953125\n",
      "2017-04-03T20:20:57.282891: step 17118, loss 0.0869338, acc 0.96875\n",
      "2017-04-03T20:20:57.484931: step 17119, loss 0.0473015, acc 0.984375\n",
      "2017-04-03T20:20:57.685023: step 17120, loss 0.13098, acc 0.953125\n",
      "2017-04-03T20:20:57.886796: step 17121, loss 0.171187, acc 0.921875\n",
      "2017-04-03T20:20:58.095111: step 17122, loss 0.132809, acc 0.953125\n",
      "2017-04-03T20:20:58.298312: step 17123, loss 0.110759, acc 0.96875\n",
      "2017-04-03T20:20:58.502875: step 17124, loss 0.132235, acc 0.9375\n",
      "2017-04-03T20:20:58.705282: step 17125, loss 0.10319, acc 0.96875\n",
      "2017-04-03T20:20:58.911211: step 17126, loss 0.057508, acc 0.96875\n",
      "2017-04-03T20:20:59.115425: step 17127, loss 0.109652, acc 0.953125\n",
      "2017-04-03T20:20:59.321242: step 17128, loss 0.159676, acc 0.96875\n",
      "2017-04-03T20:20:59.523280: step 17129, loss 0.114762, acc 0.96875\n",
      "2017-04-03T20:20:59.726146: step 17130, loss 0.0532496, acc 0.984375\n",
      "2017-04-03T20:20:59.927974: step 17131, loss 0.115327, acc 0.953125\n",
      "2017-04-03T20:21:00.129875: step 17132, loss 0.107553, acc 0.96875\n",
      "2017-04-03T20:21:00.339013: step 17133, loss 0.0679616, acc 0.984375\n",
      "2017-04-03T20:21:00.544041: step 17134, loss 0.135081, acc 0.953125\n",
      "2017-04-03T20:21:00.743612: step 17135, loss 0.150272, acc 0.953125\n",
      "2017-04-03T20:21:00.991914: step 17136, loss 0.111546, acc 0.96875\n",
      "2017-04-03T20:21:01.243484: step 17137, loss 0.162808, acc 0.921875\n",
      "2017-04-03T20:21:01.451816: step 17138, loss 0.0784754, acc 0.96875\n",
      "2017-04-03T20:21:01.656834: step 17139, loss 0.0604763, acc 1\n",
      "2017-04-03T20:21:01.857351: step 17140, loss 0.103903, acc 0.96875\n",
      "2017-04-03T20:21:02.064133: step 17141, loss 0.170591, acc 0.9375\n",
      "2017-04-03T20:21:02.325848: step 17142, loss 0.156878, acc 0.953125\n",
      "2017-04-03T20:21:02.523845: step 17143, loss 0.0255571, acc 1\n",
      "2017-04-03T20:21:02.732360: step 17144, loss 0.16894, acc 0.9375\n",
      "2017-04-03T20:21:02.935085: step 17145, loss 0.122816, acc 0.953125\n",
      "2017-04-03T20:21:03.188502: step 17146, loss 0.133455, acc 0.9375\n",
      "2017-04-03T20:21:03.389464: step 17147, loss 0.0467288, acc 1\n",
      "2017-04-03T20:21:03.595065: step 17148, loss 0.12055, acc 0.96875\n",
      "2017-04-03T20:21:03.798041: step 17149, loss 0.08955, acc 0.953125\n",
      "2017-04-03T20:21:04.051432: step 17150, loss 0.154803, acc 0.9375\n",
      "2017-04-03T20:21:04.254651: step 17151, loss 0.154424, acc 0.9375\n",
      "2017-04-03T20:21:04.454166: step 17152, loss 0.142918, acc 0.96875\n",
      "2017-04-03T20:21:04.657571: step 17153, loss 0.0667084, acc 0.984375\n",
      "2017-04-03T20:21:04.901548: step 17154, loss 0.118175, acc 0.953125\n",
      "2017-04-03T20:21:05.144176: step 17155, loss 0.205592, acc 0.921875\n",
      "2017-04-03T20:21:05.342101: step 17156, loss 0.129522, acc 0.96875\n",
      "2017-04-03T20:21:05.555991: step 17157, loss 0.0611781, acc 1\n",
      "2017-04-03T20:21:05.762554: step 17158, loss 0.0817703, acc 0.984375\n",
      "2017-04-03T20:21:05.968356: step 17159, loss 0.0360973, acc 0.984375\n",
      "2017-04-03T20:21:06.175925: step 17160, loss 0.170087, acc 0.921875\n",
      "2017-04-03T20:21:06.381209: step 17161, loss 0.162041, acc 0.9375\n",
      "2017-04-03T20:21:06.585059: step 17162, loss 0.163413, acc 0.9375\n",
      "2017-04-03T20:21:06.782186: step 17163, loss 0.168023, acc 0.96875\n",
      "2017-04-03T20:21:06.980866: step 17164, loss 0.179699, acc 0.96875\n",
      "2017-04-03T20:21:07.190704: step 17165, loss 0.119032, acc 0.96875\n",
      "2017-04-03T20:21:07.391655: step 17166, loss 0.0925912, acc 0.953125\n",
      "2017-04-03T20:21:07.596000: step 17167, loss 0.143104, acc 0.9375\n",
      "2017-04-03T20:21:07.798213: step 17168, loss 0.301229, acc 0.90625\n",
      "2017-04-03T20:21:08.004288: step 17169, loss 0.146695, acc 0.953125\n",
      "2017-04-03T20:21:08.210527: step 17170, loss 0.137437, acc 0.96875\n",
      "2017-04-03T20:21:08.411164: step 17171, loss 0.0931368, acc 0.953125\n",
      "2017-04-03T20:21:08.615216: step 17172, loss 0.0917089, acc 0.984375\n",
      "2017-04-03T20:21:08.810699: step 17173, loss 0.198612, acc 0.890625\n",
      "2017-04-03T20:21:09.015007: step 17174, loss 0.141733, acc 0.9375\n",
      "2017-04-03T20:21:09.216747: step 17175, loss 0.130863, acc 0.953125\n",
      "2017-04-03T20:21:09.414846: step 17176, loss 0.0625943, acc 0.984375\n",
      "2017-04-03T20:21:09.660596: step 17177, loss 0.0658484, acc 0.96875\n",
      "2017-04-03T20:21:09.861232: step 17178, loss 0.0702303, acc 0.984375\n",
      "2017-04-03T20:21:10.065787: step 17179, loss 0.0404338, acc 1\n",
      "2017-04-03T20:21:10.267022: step 17180, loss 0.1181, acc 0.953125\n",
      "2017-04-03T20:21:10.466461: step 17181, loss 0.0172897, acc 1\n",
      "2017-04-03T20:21:10.669606: step 17182, loss 0.0613954, acc 1\n",
      "2017-04-03T20:21:10.912896: step 17183, loss 0.0715656, acc 0.96875\n",
      "2017-04-03T20:21:11.156361: step 17184, loss 0.0733425, acc 0.984375\n",
      "2017-04-03T20:21:11.356461: step 17185, loss 0.0570191, acc 1\n",
      "2017-04-03T20:21:11.560219: step 17186, loss 0.192299, acc 0.9375\n",
      "2017-04-03T20:21:11.770251: step 17187, loss 0.0509986, acc 1\n",
      "2017-04-03T20:21:11.971785: step 17188, loss 0.0337674, acc 0.984375\n",
      "2017-04-03T20:21:12.171967: step 17189, loss 0.0720254, acc 0.984375\n",
      "2017-04-03T20:21:12.374665: step 17190, loss 0.156259, acc 0.921875\n",
      "2017-04-03T20:21:12.579212: step 17191, loss 0.0441128, acc 0.984375\n",
      "2017-04-03T20:21:12.828991: step 17192, loss 0.135276, acc 0.96875\n",
      "2017-04-03T20:21:13.029989: step 17193, loss 0.12121, acc 0.9375\n",
      "2017-04-03T20:21:13.235502: step 17194, loss 0.063405, acc 0.96875\n",
      "2017-04-03T20:21:13.440189: step 17195, loss 0.196294, acc 0.90625\n",
      "2017-04-03T20:21:13.646350: step 17196, loss 0.101642, acc 0.96875\n",
      "2017-04-03T20:21:13.844493: step 17197, loss 0.0858733, acc 0.953125\n",
      "2017-04-03T20:21:14.055088: step 17198, loss 0.107178, acc 0.953125\n",
      "2017-04-03T20:21:14.259139: step 17199, loss 0.163264, acc 0.953125\n",
      "2017-04-03T20:21:14.462805: step 17200, loss 0.0541638, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:21:16.590411: step 17200, loss 6.74196, acc 0.283\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-17200\n",
      "\n",
      "2017-04-03T20:21:16.930008: step 17201, loss 0.0715265, acc 0.96875\n",
      "2017-04-03T20:21:17.134864: step 17202, loss 0.284786, acc 0.921875\n",
      "2017-04-03T20:21:17.341315: step 17203, loss 0.312476, acc 0.90625\n",
      "2017-04-03T20:21:17.542475: step 17204, loss 0.0945034, acc 0.953125\n",
      "2017-04-03T20:21:17.784065: step 17205, loss 0.0661019, acc 0.96875\n",
      "2017-04-03T20:21:17.986909: step 17206, loss 0.150321, acc 0.921875\n",
      "2017-04-03T20:21:18.186693: step 17207, loss 0.151233, acc 0.90625\n",
      "2017-04-03T20:21:18.389212: step 17208, loss 0.255271, acc 0.953125\n",
      "2017-04-03T20:21:18.590731: step 17209, loss 0.204663, acc 0.953125\n",
      "2017-04-03T20:21:18.794682: step 17210, loss 0.0835736, acc 0.984375\n",
      "2017-04-03T20:21:18.994552: step 17211, loss 0.097377, acc 0.984375\n",
      "2017-04-03T20:21:19.200728: step 17212, loss 0.341844, acc 0.9375\n",
      "2017-04-03T20:21:19.451156: step 17213, loss 0.0649285, acc 1\n",
      "2017-04-03T20:21:19.655517: step 17214, loss 0.0453769, acc 1\n",
      "2017-04-03T20:21:19.863992: step 17215, loss 0.0892111, acc 0.984375\n",
      "2017-04-03T20:21:20.064964: step 17216, loss 0.0938476, acc 0.953125\n",
      "2017-04-03T20:21:20.267744: step 17217, loss 0.116238, acc 0.96875\n",
      "2017-04-03T20:21:20.471282: step 17218, loss 0.110351, acc 0.96875\n",
      "2017-04-03T20:21:20.670610: step 17219, loss 0.172295, acc 0.9375\n",
      "2017-04-03T20:21:20.869781: step 17220, loss 0.0727121, acc 0.96875\n",
      "2017-04-03T20:21:21.075644: step 17221, loss 0.295625, acc 0.953125\n",
      "2017-04-03T20:21:21.297826: step 17222, loss 0.0995505, acc 0.96875\n",
      "2017-04-03T20:21:21.519552: step 17223, loss 0.0811905, acc 0.96875\n",
      "2017-04-03T20:21:21.738884: step 17224, loss 0.0743509, acc 0.96875\n",
      "2017-04-03T20:21:21.942687: step 17225, loss 0.0631198, acc 0.984375\n",
      "2017-04-03T20:21:22.148211: step 17226, loss 0.126711, acc 0.96875\n",
      "2017-04-03T20:21:22.350438: step 17227, loss 0.257879, acc 0.9375\n",
      "2017-04-03T20:21:22.550721: step 17228, loss 0.13473, acc 0.953125\n",
      "2017-04-03T20:21:22.756697: step 17229, loss 0.181457, acc 0.9375\n",
      "2017-04-03T20:21:22.967514: step 17230, loss 0.0658255, acc 1\n",
      "2017-04-03T20:21:23.180335: step 17231, loss 0.144426, acc 0.96875\n",
      "2017-04-03T20:21:23.385679: step 17232, loss 0.0574962, acc 0.96875\n",
      "2017-04-03T20:21:23.590628: step 17233, loss 0.0504099, acc 0.984375\n",
      "2017-04-03T20:21:23.792226: step 17234, loss 0.231995, acc 0.9375\n",
      "2017-04-03T20:21:23.994483: step 17235, loss 0.106401, acc 0.96875\n",
      "2017-04-03T20:21:24.240068: step 17236, loss 0.0813743, acc 0.96875\n",
      "2017-04-03T20:21:24.443323: step 17237, loss 0.111971, acc 0.953125\n",
      "2017-04-03T20:21:24.646592: step 17238, loss 0.103377, acc 0.96875\n",
      "2017-04-03T20:21:24.854942: step 17239, loss 0.160875, acc 0.953125\n",
      "2017-04-03T20:21:25.071190: step 17240, loss 0.197439, acc 0.9375\n",
      "2017-04-03T20:21:25.275397: step 17241, loss 0.109849, acc 0.96875\n",
      "2017-04-03T20:21:25.480240: step 17242, loss 0.14832, acc 0.953125\n",
      "2017-04-03T20:21:25.678155: step 17243, loss 0.215218, acc 0.9375\n",
      "2017-04-03T20:21:25.887588: step 17244, loss 0.16004, acc 0.921875\n",
      "2017-04-03T20:21:26.097250: step 17245, loss 0.0141673, acc 1\n",
      "2017-04-03T20:21:26.303090: step 17246, loss 0.101281, acc 0.96875\n",
      "2017-04-03T20:21:26.504554: step 17247, loss 0.0928622, acc 0.953125\n",
      "2017-04-03T20:21:26.720364: step 17248, loss 0.0277283, acc 1\n",
      "2017-04-03T20:21:26.928859: step 17249, loss 0.226628, acc 0.921875\n",
      "2017-04-03T20:21:27.172695: step 17250, loss 0.0534272, acc 1\n",
      "2017-04-03T20:21:27.377097: step 17251, loss 0.0599631, acc 0.96875\n",
      "2017-04-03T20:21:27.577923: step 17252, loss 0.305583, acc 0.921875\n",
      "2017-04-03T20:21:27.784215: step 17253, loss 0.107133, acc 0.953125\n",
      "2017-04-03T20:21:27.994275: step 17254, loss 0.151539, acc 0.953125\n",
      "2017-04-03T20:21:28.212446: step 17255, loss 0.139554, acc 0.953125\n",
      "2017-04-03T20:21:28.428320: step 17256, loss 0.0786471, acc 0.96875\n",
      "2017-04-03T20:21:28.631451: step 17257, loss 0.118219, acc 0.96875\n",
      "2017-04-03T20:21:28.831785: step 17258, loss 0.0377105, acc 0.96875\n",
      "2017-04-03T20:21:29.035811: step 17259, loss 0.111827, acc 0.96875\n",
      "2017-04-03T20:21:29.246583: step 17260, loss 0.0842976, acc 0.96875\n",
      "2017-04-03T20:21:29.452531: step 17261, loss 0.0754311, acc 0.96875\n",
      "2017-04-03T20:21:29.658320: step 17262, loss 0.160885, acc 0.96875\n",
      "2017-04-03T20:21:29.858904: step 17263, loss 0.258392, acc 0.953125\n",
      "2017-04-03T20:21:30.072078: step 17264, loss 0.26205, acc 0.921875\n",
      "2017-04-03T20:21:30.292524: step 17265, loss 0.0998128, acc 0.96875\n",
      "2017-04-03T20:21:30.491427: step 17266, loss 0.0787173, acc 0.953125\n",
      "2017-04-03T20:21:30.692141: step 17267, loss 0.118734, acc 0.96875\n",
      "2017-04-03T20:21:30.894652: step 17268, loss 0.221963, acc 0.921875\n",
      "2017-04-03T20:21:31.095928: step 17269, loss 0.148823, acc 0.90625\n",
      "2017-04-03T20:21:31.300060: step 17270, loss 0.143795, acc 0.953125\n",
      "2017-04-03T20:21:31.499433: step 17271, loss 0.0631886, acc 0.96875\n",
      "2017-04-03T20:21:31.701345: step 17272, loss 0.069679, acc 0.984375\n",
      "2017-04-03T20:21:31.905139: step 17273, loss 0.0363246, acc 1\n",
      "2017-04-03T20:21:32.103657: step 17274, loss 0.326285, acc 0.90625\n",
      "2017-04-03T20:21:32.307124: step 17275, loss 0.0816764, acc 0.96875\n",
      "2017-04-03T20:21:32.503527: step 17276, loss 0.0644264, acc 0.96875\n",
      "2017-04-03T20:21:32.706252: step 17277, loss 0.133525, acc 0.9375\n",
      "2017-04-03T20:21:32.908307: step 17278, loss 0.246245, acc 0.921875\n",
      "2017-04-03T20:21:33.116161: step 17279, loss 0.205247, acc 0.921875\n",
      "2017-04-03T20:21:33.320750: step 17280, loss 0.138344, acc 0.9375\n",
      "2017-04-03T20:21:33.523353: step 17281, loss 0.103811, acc 0.984375\n",
      "2017-04-03T20:21:33.766189: step 17282, loss 0.224054, acc 0.921875\n",
      "2017-04-03T20:21:33.972777: step 17283, loss 0.159762, acc 0.9375\n",
      "2017-04-03T20:21:34.173739: step 17284, loss 0.133215, acc 0.953125\n",
      "2017-04-03T20:21:34.377969: step 17285, loss 0.162473, acc 0.984375\n",
      "2017-04-03T20:21:34.581341: step 17286, loss 0.113359, acc 0.953125\n",
      "2017-04-03T20:21:34.781694: step 17287, loss 0.0787846, acc 0.96875\n",
      "2017-04-03T20:21:34.988004: step 17288, loss 0.0895784, acc 0.984375\n",
      "2017-04-03T20:21:35.192493: step 17289, loss 0.118739, acc 0.96875\n",
      "2017-04-03T20:21:35.396141: step 17290, loss 0.121071, acc 0.96875\n",
      "2017-04-03T20:21:35.599257: step 17291, loss 0.194578, acc 0.953125\n",
      "2017-04-03T20:21:35.849580: step 17292, loss 0.0345116, acc 1\n",
      "2017-04-03T20:21:36.052801: step 17293, loss 0.124466, acc 0.953125\n",
      "2017-04-03T20:21:36.266721: step 17294, loss 0.146083, acc 0.953125\n",
      "2017-04-03T20:21:36.485697: step 17295, loss 0.219534, acc 0.921875\n",
      "2017-04-03T20:21:36.699313: step 17296, loss 0.108699, acc 0.953125\n",
      "2017-04-03T20:21:36.902897: step 17297, loss 0.0922651, acc 0.953125\n",
      "2017-04-03T20:21:37.120158: step 17298, loss 0.122503, acc 0.953125\n",
      "2017-04-03T20:21:37.321509: step 17299, loss 0.144506, acc 0.953125\n",
      "2017-04-03T20:21:37.519931: step 17300, loss 0.228838, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:21:39.698762: step 17300, loss 6.71406, acc 0.27575\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-17300\n",
      "\n",
      "2017-04-03T20:21:40.076627: step 17301, loss 0.172646, acc 0.953125\n",
      "2017-04-03T20:21:40.281566: step 17302, loss 0.211825, acc 0.921875\n",
      "2017-04-03T20:21:40.492605: step 17303, loss 0.147999, acc 0.96875\n",
      "2017-04-03T20:21:40.696770: step 17304, loss 0.0695168, acc 0.984375\n",
      "2017-04-03T20:21:40.905289: step 17305, loss 0.0594007, acc 0.96875\n",
      "2017-04-03T20:21:41.146558: step 17306, loss 0.0822456, acc 0.96875\n",
      "2017-04-03T20:21:41.359930: step 17307, loss 0.0545227, acc 1\n",
      "2017-04-03T20:21:41.570900: step 17308, loss 0.0624398, acc 0.96875\n",
      "2017-04-03T20:21:41.785800: step 17309, loss 0.149255, acc 0.953125\n",
      "2017-04-03T20:21:42.006078: step 17310, loss 0.103478, acc 0.96875\n",
      "2017-04-03T20:21:42.216886: step 17311, loss 0.105346, acc 0.953125\n",
      "2017-04-03T20:21:42.416457: step 17312, loss 0.141428, acc 0.953125\n",
      "2017-04-03T20:21:42.622414: step 17313, loss 0.0256443, acc 1\n",
      "2017-04-03T20:21:42.829635: step 17314, loss 0.405157, acc 0.890625\n",
      "2017-04-03T20:21:43.036432: step 17315, loss 0.0737204, acc 0.96875\n",
      "2017-04-03T20:21:43.243866: step 17316, loss 0.0951217, acc 0.984375\n",
      "2017-04-03T20:21:43.448290: step 17317, loss 0.152482, acc 0.953125\n",
      "2017-04-03T20:21:43.649754: step 17318, loss 0.0613062, acc 0.984375\n",
      "2017-04-03T20:21:43.856472: step 17319, loss 0.517382, acc 0.875\n",
      "2017-04-03T20:21:44.058585: step 17320, loss 0.0749729, acc 0.96875\n",
      "2017-04-03T20:21:44.258680: step 17321, loss 0.130777, acc 0.96875\n",
      "2017-04-03T20:21:44.462552: step 17322, loss 0.40684, acc 0.9375\n",
      "2017-04-03T20:21:44.668439: step 17323, loss 0.15972, acc 0.9375\n",
      "2017-04-03T20:21:44.872076: step 17324, loss 0.0405109, acc 0.984375\n",
      "2017-04-03T20:21:45.074600: step 17325, loss 0.0697016, acc 0.984375\n",
      "2017-04-03T20:21:45.277893: step 17326, loss 0.269946, acc 0.921875\n",
      "2017-04-03T20:21:45.480457: step 17327, loss 0.048906, acc 0.984375\n",
      "2017-04-03T20:21:45.682056: step 17328, loss 0.199223, acc 0.921875\n",
      "2017-04-03T20:21:45.885915: step 17329, loss 0.173189, acc 0.953125\n",
      "2017-04-03T20:21:46.084355: step 17330, loss 0.146491, acc 0.90625\n",
      "2017-04-03T20:21:46.322869: step 17331, loss 0.135842, acc 0.953125\n",
      "2017-04-03T20:21:46.525176: step 17332, loss 0.399266, acc 0.90625\n",
      "2017-04-03T20:21:46.771144: step 17333, loss 0.328953, acc 0.953125\n",
      "2017-04-03T20:21:46.978501: step 17334, loss 0.0969025, acc 0.984375\n",
      "2017-04-03T20:21:47.182351: step 17335, loss 0.246941, acc 0.90625\n",
      "2017-04-03T20:21:47.397756: step 17336, loss 0.179777, acc 0.921875\n",
      "2017-04-03T20:21:47.604114: step 17337, loss 0.0461198, acc 1\n",
      "2017-04-03T20:21:47.806390: step 17338, loss 0.162764, acc 0.96875\n",
      "2017-04-03T20:21:48.011377: step 17339, loss 0.122387, acc 0.953125\n",
      "2017-04-03T20:21:48.213105: step 17340, loss 0.102692, acc 0.984375\n",
      "2017-04-03T20:21:48.417124: step 17341, loss 0.174981, acc 0.921875\n",
      "2017-04-03T20:21:48.621718: step 17342, loss 0.139869, acc 0.953125\n",
      "2017-04-03T20:21:48.826302: step 17343, loss 0.106564, acc 0.96875\n",
      "2017-04-03T20:21:49.045942: step 17344, loss 0.194648, acc 0.9375\n",
      "2017-04-03T20:21:49.268737: step 17345, loss 0.166554, acc 0.90625\n",
      "2017-04-03T20:21:49.486652: step 17346, loss 0.0404362, acc 1\n",
      "2017-04-03T20:21:49.687276: step 17347, loss 0.0725671, acc 0.984375\n",
      "2017-04-03T20:21:49.888675: step 17348, loss 0.0547361, acc 0.96875\n",
      "2017-04-03T20:21:50.098155: step 17349, loss 0.118638, acc 0.96875\n",
      "2017-04-03T20:21:50.299720: step 17350, loss 0.0739276, acc 0.984375\n",
      "2017-04-03T20:21:50.502802: step 17351, loss 0.0602505, acc 0.984375\n",
      "2017-04-03T20:21:50.707271: step 17352, loss 0.0764062, acc 0.96875\n",
      "2017-04-03T20:21:50.907483: step 17353, loss 0.0853513, acc 0.96875\n",
      "2017-04-03T20:21:51.109199: step 17354, loss 0.124836, acc 0.96875\n",
      "2017-04-03T20:21:51.315161: step 17355, loss 0.0409685, acc 0.984375\n",
      "2017-04-03T20:21:51.525372: step 17356, loss 0.124768, acc 0.984375\n",
      "2017-04-03T20:21:51.729248: step 17357, loss 0.204013, acc 0.90625\n",
      "2017-04-03T20:21:51.928367: step 17358, loss 0.0525264, acc 0.984375\n",
      "2017-04-03T20:21:52.132160: step 17359, loss 0.133443, acc 0.96875\n",
      "2017-04-03T20:21:52.350524: step 17360, loss 0.115885, acc 0.953125\n",
      "2017-04-03T20:21:52.564935: step 17361, loss 0.245397, acc 0.90625\n",
      "2017-04-03T20:21:52.782385: step 17362, loss 0.0583235, acc 0.984375\n",
      "2017-04-03T20:21:52.988650: step 17363, loss 0.2174, acc 0.90625\n",
      "2017-04-03T20:21:53.201129: step 17364, loss 0.139874, acc 0.953125\n",
      "2017-04-03T20:21:53.422189: step 17365, loss 0.237477, acc 0.90625\n",
      "2017-04-03T20:21:53.633757: step 17366, loss 0.127684, acc 0.96875\n",
      "2017-04-03T20:21:53.840649: step 17367, loss 0.0833189, acc 0.984375\n",
      "2017-04-03T20:21:54.039820: step 17368, loss 0.0647756, acc 0.984375\n",
      "2017-04-03T20:21:54.245441: step 17369, loss 0.0959689, acc 0.984375\n",
      "2017-04-03T20:21:54.448406: step 17370, loss 0.167436, acc 0.953125\n",
      "2017-04-03T20:21:54.692422: step 17371, loss 0.0512709, acc 1\n",
      "2017-04-03T20:21:54.897860: step 17372, loss 0.250454, acc 0.953125\n",
      "2017-04-03T20:21:55.101242: step 17373, loss 0.0371344, acc 1\n",
      "2017-04-03T20:21:55.309289: step 17374, loss 0.221964, acc 0.953125\n",
      "2017-04-03T20:21:55.514397: step 17375, loss 0.109985, acc 0.96875\n",
      "2017-04-03T20:21:55.768907: step 17376, loss 0.0588881, acc 0.984375\n",
      "2017-04-03T20:21:55.968114: step 17377, loss 0.0817618, acc 0.984375\n",
      "2017-04-03T20:21:56.180664: step 17378, loss 0.122311, acc 0.96875\n",
      "2017-04-03T20:21:56.381618: step 17379, loss 0.103865, acc 0.96875\n",
      "2017-04-03T20:21:56.623564: step 17380, loss 0.101595, acc 0.96875\n",
      "2017-04-03T20:21:56.839835: step 17381, loss 0.21667, acc 0.921875\n",
      "2017-04-03T20:21:57.052996: step 17382, loss 0.0381172, acc 0.984375\n",
      "2017-04-03T20:21:57.255514: step 17383, loss 0.103119, acc 0.953125\n",
      "2017-04-03T20:21:57.467881: step 17384, loss 0.229089, acc 0.890625\n",
      "2017-04-03T20:21:57.670817: step 17385, loss 0.174141, acc 0.953125\n",
      "2017-04-03T20:21:57.877176: step 17386, loss 0.212599, acc 0.953125\n",
      "2017-04-03T20:21:58.080242: step 17387, loss 0.0852835, acc 0.984375\n",
      "2017-04-03T20:21:58.287817: step 17388, loss 0.184731, acc 0.953125\n",
      "2017-04-03T20:21:58.489606: step 17389, loss 0.102387, acc 0.953125\n",
      "2017-04-03T20:21:58.696890: step 17390, loss 0.1993, acc 0.953125\n",
      "2017-04-03T20:21:58.940309: step 17391, loss 0.139322, acc 0.984375\n",
      "2017-04-03T20:21:59.153253: step 17392, loss 0.1086, acc 0.9375\n",
      "2017-04-03T20:21:59.370579: step 17393, loss 0.252199, acc 0.921875\n",
      "2017-04-03T20:21:59.578918: step 17394, loss 0.0806353, acc 0.96875\n",
      "2017-04-03T20:21:59.785610: step 17395, loss 0.0342458, acc 1\n",
      "2017-04-03T20:21:59.995566: step 17396, loss 0.119336, acc 0.984375\n",
      "2017-04-03T20:22:00.213959: step 17397, loss 0.222301, acc 0.953125\n",
      "2017-04-03T20:22:00.415191: step 17398, loss 0.118249, acc 0.953125\n",
      "2017-04-03T20:22:00.620473: step 17399, loss 0.180508, acc 0.9375\n",
      "2017-04-03T20:22:00.827523: step 17400, loss 0.101679, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:22:02.989103: step 17400, loss 6.76115, acc 0.284\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-17400\n",
      "\n",
      "2017-04-03T20:22:03.324160: step 17401, loss 0.161389, acc 0.9375\n",
      "2017-04-03T20:22:03.524835: step 17402, loss 0.100423, acc 0.96875\n",
      "2017-04-03T20:22:03.726275: step 17403, loss 0.0559666, acc 0.984375\n",
      "2017-04-03T20:22:03.926038: step 17404, loss 0.0609471, acc 0.96875\n",
      "2017-04-03T20:22:04.134106: step 17405, loss 0.0633755, acc 0.96875\n",
      "2017-04-03T20:22:04.336746: step 17406, loss 0.150223, acc 0.953125\n",
      "2017-04-03T20:22:04.542434: step 17407, loss 0.133329, acc 0.9375\n",
      "2017-04-03T20:22:04.743495: step 17408, loss 0.127383, acc 0.953125\n",
      "2017-04-03T20:22:04.944633: step 17409, loss 0.0788591, acc 0.96875\n",
      "2017-04-03T20:22:05.145957: step 17410, loss 0.104192, acc 0.984375\n",
      "2017-04-03T20:22:05.352356: step 17411, loss 0.0968057, acc 0.96875\n",
      "2017-04-03T20:22:05.553305: step 17412, loss 0.373631, acc 0.90625\n",
      "2017-04-03T20:22:05.750905: step 17413, loss 0.267791, acc 0.953125\n",
      "2017-04-03T20:22:05.963284: step 17414, loss 0.21094, acc 0.953125\n",
      "2017-04-03T20:22:06.169197: step 17415, loss 0.159637, acc 0.953125\n",
      "2017-04-03T20:22:06.374566: step 17416, loss 0.0518742, acc 1\n",
      "2017-04-03T20:22:06.573328: step 17417, loss 0.0806852, acc 0.984375\n",
      "2017-04-03T20:22:06.782371: step 17418, loss 0.133392, acc 0.953125\n",
      "2017-04-03T20:22:06.988974: step 17419, loss 0.396997, acc 0.9375\n",
      "2017-04-03T20:22:07.196773: step 17420, loss 0.345279, acc 0.953125\n",
      "2017-04-03T20:22:07.413142: step 17421, loss 0.0350385, acc 1\n",
      "2017-04-03T20:22:07.616761: step 17422, loss 0.226737, acc 0.9375\n",
      "2017-04-03T20:22:07.822173: step 17423, loss 0.232974, acc 0.953125\n",
      "2017-04-03T20:22:08.022699: step 17424, loss 0.243145, acc 0.921875\n",
      "2017-04-03T20:22:08.228117: step 17425, loss 0.126957, acc 0.9375\n",
      "2017-04-03T20:22:08.429169: step 17426, loss 0.124041, acc 0.96875\n",
      "2017-04-03T20:22:08.681318: step 17427, loss 0.079593, acc 0.96875\n",
      "2017-04-03T20:22:08.883802: step 17428, loss 0.176203, acc 0.953125\n",
      "2017-04-03T20:22:09.089683: step 17429, loss 0.176885, acc 0.96875\n",
      "2017-04-03T20:22:09.333079: step 17430, loss 0.0868252, acc 0.953125\n",
      "2017-04-03T20:22:09.541658: step 17431, loss 0.0425516, acc 0.984375\n",
      "2017-04-03T20:22:09.742511: step 17432, loss 0.226921, acc 0.890625\n",
      "2017-04-03T20:22:09.950540: step 17433, loss 0.0798441, acc 0.953125\n",
      "2017-04-03T20:22:10.194684: step 17434, loss 0.185527, acc 0.9375\n",
      "2017-04-03T20:22:10.401159: step 17435, loss 0.207693, acc 0.9375\n",
      "2017-04-03T20:22:10.601534: step 17436, loss 0.206121, acc 0.921875\n",
      "2017-04-03T20:22:10.805334: step 17437, loss 0.0960865, acc 0.953125\n",
      "2017-04-03T20:22:11.012516: step 17438, loss 0.152264, acc 0.953125\n",
      "2017-04-03T20:22:11.222322: step 17439, loss 0.0699889, acc 0.96875\n",
      "2017-04-03T20:22:11.428047: step 17440, loss 0.149892, acc 0.9375\n",
      "2017-04-03T20:22:11.627945: step 17441, loss 0.168941, acc 0.9375\n",
      "2017-04-03T20:22:11.832112: step 17442, loss 0.0867697, acc 0.96875\n",
      "2017-04-03T20:22:12.038801: step 17443, loss 0.0944052, acc 0.953125\n",
      "2017-04-03T20:22:12.253355: step 17444, loss 0.108673, acc 0.953125\n",
      "2017-04-03T20:22:12.461683: step 17445, loss 0.0771524, acc 0.984375\n",
      "2017-04-03T20:22:12.663320: step 17446, loss 0.115468, acc 0.921875\n",
      "2017-04-03T20:22:12.907588: step 17447, loss 0.0507243, acc 0.984375\n",
      "2017-04-03T20:22:13.113551: step 17448, loss 0.0943279, acc 0.96875\n",
      "2017-04-03T20:22:13.314682: step 17449, loss 0.357296, acc 0.890625\n",
      "2017-04-03T20:22:13.553637: step 17450, loss 0.0572464, acc 0.984375\n",
      "2017-04-03T20:22:13.755818: step 17451, loss 0.425202, acc 0.90625\n",
      "2017-04-03T20:22:13.958937: step 17452, loss 0.137745, acc 0.984375\n",
      "2017-04-03T20:22:14.104412: step 17453, loss 0.0956179, acc 0.96875\n",
      "2017-04-03T20:22:14.313549: step 17454, loss 0.165694, acc 0.921875\n",
      "2017-04-03T20:22:14.519523: step 17455, loss 0.0479277, acc 0.984375\n",
      "2017-04-03T20:22:14.725189: step 17456, loss 0.0875963, acc 0.96875\n",
      "2017-04-03T20:22:14.930938: step 17457, loss 0.11641, acc 0.953125\n",
      "2017-04-03T20:22:15.133888: step 17458, loss 0.153293, acc 0.96875\n",
      "2017-04-03T20:22:15.343237: step 17459, loss 0.133447, acc 0.953125\n",
      "2017-04-03T20:22:15.550429: step 17460, loss 0.0345389, acc 0.984375\n",
      "2017-04-03T20:22:15.756667: step 17461, loss 0.090919, acc 0.953125\n",
      "2017-04-03T20:22:15.954703: step 17462, loss 0.1075, acc 0.96875\n",
      "2017-04-03T20:22:16.161606: step 17463, loss 0.0421235, acc 1\n",
      "2017-04-03T20:22:16.369873: step 17464, loss 0.0858273, acc 0.953125\n",
      "2017-04-03T20:22:16.573582: step 17465, loss 0.205497, acc 0.9375\n",
      "2017-04-03T20:22:16.780122: step 17466, loss 0.0424433, acc 1\n",
      "2017-04-03T20:22:16.978574: step 17467, loss 0.0836702, acc 0.96875\n",
      "2017-04-03T20:22:17.186247: step 17468, loss 0.119082, acc 0.9375\n",
      "2017-04-03T20:22:17.391275: step 17469, loss 0.0529269, acc 0.984375\n",
      "2017-04-03T20:22:17.601872: step 17470, loss 0.167058, acc 0.9375\n",
      "2017-04-03T20:22:17.803082: step 17471, loss 0.119809, acc 0.96875\n",
      "2017-04-03T20:22:18.011194: step 17472, loss 0.214781, acc 0.953125\n",
      "2017-04-03T20:22:18.216105: step 17473, loss 0.210522, acc 0.921875\n",
      "2017-04-03T20:22:18.435379: step 17474, loss 0.116751, acc 0.953125\n",
      "2017-04-03T20:22:18.639166: step 17475, loss 0.108024, acc 0.96875\n",
      "2017-04-03T20:22:18.844039: step 17476, loss 0.042216, acc 0.984375\n",
      "2017-04-03T20:22:19.050755: step 17477, loss 0.02349, acc 1\n",
      "2017-04-03T20:22:19.254965: step 17478, loss 0.0448836, acc 0.984375\n",
      "2017-04-03T20:22:19.461808: step 17479, loss 0.236266, acc 0.953125\n",
      "2017-04-03T20:22:19.664826: step 17480, loss 0.118122, acc 0.96875\n",
      "2017-04-03T20:22:19.867099: step 17481, loss 0.057016, acc 0.984375\n",
      "2017-04-03T20:22:20.078640: step 17482, loss 0.0766736, acc 0.984375\n",
      "2017-04-03T20:22:20.280848: step 17483, loss 0.102816, acc 0.96875\n",
      "2017-04-03T20:22:20.487422: step 17484, loss 0.228032, acc 0.9375\n",
      "2017-04-03T20:22:20.731482: step 17485, loss 0.257734, acc 0.96875\n",
      "2017-04-03T20:22:20.936518: step 17486, loss 0.0617801, acc 0.96875\n",
      "2017-04-03T20:22:21.148584: step 17487, loss 0.151425, acc 0.953125\n",
      "2017-04-03T20:22:21.365016: step 17488, loss 0.185333, acc 0.9375\n",
      "2017-04-03T20:22:21.567072: step 17489, loss 0.0854404, acc 0.9375\n",
      "2017-04-03T20:22:21.776785: step 17490, loss 0.104714, acc 0.96875\n",
      "2017-04-03T20:22:21.996889: step 17491, loss 0.0966024, acc 0.96875\n",
      "2017-04-03T20:22:22.213236: step 17492, loss 0.148385, acc 0.953125\n",
      "2017-04-03T20:22:22.430467: step 17493, loss 0.322537, acc 0.953125\n",
      "2017-04-03T20:22:22.639727: step 17494, loss 0.183353, acc 0.953125\n",
      "2017-04-03T20:22:22.856464: step 17495, loss 0.086419, acc 0.96875\n",
      "2017-04-03T20:22:23.112114: step 17496, loss 0.142018, acc 0.953125\n",
      "2017-04-03T20:22:23.316370: step 17497, loss 0.187646, acc 0.90625\n",
      "2017-04-03T20:22:23.519117: step 17498, loss 0.0823344, acc 0.984375\n",
      "2017-04-03T20:22:23.721675: step 17499, loss 0.0769908, acc 0.984375\n",
      "2017-04-03T20:22:23.923463: step 17500, loss 0.067241, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:22:26.040582: step 17500, loss 6.71432, acc 0.27875\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-17500\n",
      "\n",
      "2017-04-03T20:22:26.385056: step 17501, loss 0.0389586, acc 0.984375\n",
      "2017-04-03T20:22:26.592162: step 17502, loss 0.15877, acc 0.953125\n",
      "2017-04-03T20:22:26.800351: step 17503, loss 0.0833351, acc 0.984375\n",
      "2017-04-03T20:22:26.997774: step 17504, loss 0.037454, acc 0.984375\n",
      "2017-04-03T20:22:27.213105: step 17505, loss 0.0271318, acc 1\n",
      "2017-04-03T20:22:27.420095: step 17506, loss 0.0653559, acc 0.984375\n",
      "2017-04-03T20:22:27.621683: step 17507, loss 0.199723, acc 0.90625\n",
      "2017-04-03T20:22:27.824370: step 17508, loss 0.0968244, acc 0.953125\n",
      "2017-04-03T20:22:28.024426: step 17509, loss 0.145798, acc 0.96875\n",
      "2017-04-03T20:22:28.227059: step 17510, loss 0.0191105, acc 1\n",
      "2017-04-03T20:22:28.431818: step 17511, loss 0.0419049, acc 1\n",
      "2017-04-03T20:22:28.638186: step 17512, loss 0.0701281, acc 0.984375\n",
      "2017-04-03T20:22:28.844135: step 17513, loss 0.114801, acc 0.96875\n",
      "2017-04-03T20:22:29.056681: step 17514, loss 0.0529569, acc 0.984375\n",
      "2017-04-03T20:22:29.269699: step 17515, loss 0.105519, acc 0.96875\n",
      "2017-04-03T20:22:29.471772: step 17516, loss 0.0906084, acc 0.96875\n",
      "2017-04-03T20:22:29.677612: step 17517, loss 0.094118, acc 0.96875\n",
      "2017-04-03T20:22:29.888657: step 17518, loss 0.161954, acc 0.9375\n",
      "2017-04-03T20:22:30.096195: step 17519, loss 0.120467, acc 0.953125\n",
      "2017-04-03T20:22:30.304919: step 17520, loss 0.432871, acc 0.9375\n",
      "2017-04-03T20:22:30.535347: step 17521, loss 0.246181, acc 0.953125\n",
      "2017-04-03T20:22:30.750420: step 17522, loss 0.0566992, acc 0.984375\n",
      "2017-04-03T20:22:30.950092: step 17523, loss 0.276836, acc 0.9375\n",
      "2017-04-03T20:22:31.173536: step 17524, loss 0.0924514, acc 0.96875\n",
      "2017-04-03T20:22:31.377860: step 17525, loss 0.195003, acc 0.96875\n",
      "2017-04-03T20:22:31.584237: step 17526, loss 0.129569, acc 0.953125\n",
      "2017-04-03T20:22:31.790735: step 17527, loss 0.235989, acc 0.96875\n",
      "2017-04-03T20:22:31.994349: step 17528, loss 0.215969, acc 0.9375\n",
      "2017-04-03T20:22:32.193681: step 17529, loss 0.32897, acc 0.9375\n",
      "2017-04-03T20:22:32.437106: step 17530, loss 0.128537, acc 0.9375\n",
      "2017-04-03T20:22:32.643881: step 17531, loss 0.0729233, acc 0.984375\n",
      "2017-04-03T20:22:32.849778: step 17532, loss 0.159508, acc 0.953125\n",
      "2017-04-03T20:22:33.056812: step 17533, loss 0.0464206, acc 0.984375\n",
      "2017-04-03T20:22:33.261201: step 17534, loss 0.0665385, acc 0.96875\n",
      "2017-04-03T20:22:33.504174: step 17535, loss 0.0879348, acc 0.984375\n",
      "2017-04-03T20:22:33.704880: step 17536, loss 0.109319, acc 0.953125\n",
      "2017-04-03T20:22:33.952775: step 17537, loss 0.216714, acc 0.9375\n",
      "2017-04-03T20:22:34.160518: step 17538, loss 0.118976, acc 0.96875\n",
      "2017-04-03T20:22:34.361932: step 17539, loss 0.0707686, acc 0.984375\n",
      "2017-04-03T20:22:34.569746: step 17540, loss 0.15884, acc 0.9375\n",
      "2017-04-03T20:22:34.775938: step 17541, loss 0.0637322, acc 0.984375\n",
      "2017-04-03T20:22:34.981617: step 17542, loss 0.0226248, acc 1\n",
      "2017-04-03T20:22:35.183265: step 17543, loss 0.149934, acc 0.953125\n",
      "2017-04-03T20:22:35.380691: step 17544, loss 0.0655989, acc 0.984375\n",
      "2017-04-03T20:22:35.622776: step 17545, loss 0.0483371, acc 0.984375\n",
      "2017-04-03T20:22:35.827565: step 17546, loss 0.0445127, acc 0.984375\n",
      "2017-04-03T20:22:36.031587: step 17547, loss 0.154889, acc 0.921875\n",
      "2017-04-03T20:22:36.236802: step 17548, loss 0.07988, acc 0.96875\n",
      "2017-04-03T20:22:36.436769: step 17549, loss 0.0160258, acc 1\n",
      "2017-04-03T20:22:36.682887: step 17550, loss 0.0530963, acc 0.984375\n",
      "2017-04-03T20:22:36.894714: step 17551, loss 0.0874355, acc 0.984375\n",
      "2017-04-03T20:22:37.097136: step 17552, loss 0.0818372, acc 0.96875\n",
      "2017-04-03T20:22:37.297701: step 17553, loss 0.109874, acc 0.96875\n",
      "2017-04-03T20:22:37.509896: step 17554, loss 0.252609, acc 0.921875\n",
      "2017-04-03T20:22:37.708872: step 17555, loss 0.0247746, acc 1\n",
      "2017-04-03T20:22:37.911671: step 17556, loss 0.201004, acc 0.921875\n",
      "2017-04-03T20:22:38.154766: step 17557, loss 0.0667125, acc 0.984375\n",
      "2017-04-03T20:22:38.355612: step 17558, loss 0.147294, acc 0.9375\n",
      "2017-04-03T20:22:38.562307: step 17559, loss 0.0468422, acc 0.984375\n",
      "2017-04-03T20:22:38.770330: step 17560, loss 0.2444, acc 0.9375\n",
      "2017-04-03T20:22:38.969511: step 17561, loss 0.043876, acc 1\n",
      "2017-04-03T20:22:39.174555: step 17562, loss 0.0745282, acc 0.96875\n",
      "2017-04-03T20:22:39.379658: step 17563, loss 0.123207, acc 0.984375\n",
      "2017-04-03T20:22:39.577716: step 17564, loss 0.321262, acc 0.921875\n",
      "2017-04-03T20:22:39.780199: step 17565, loss 0.119992, acc 0.953125\n",
      "2017-04-03T20:22:39.981995: step 17566, loss 0.0969157, acc 0.984375\n",
      "2017-04-03T20:22:40.186285: step 17567, loss 0.108612, acc 0.984375\n",
      "2017-04-03T20:22:40.392048: step 17568, loss 0.141243, acc 0.953125\n",
      "2017-04-03T20:22:40.593541: step 17569, loss 0.0984051, acc 0.96875\n",
      "2017-04-03T20:22:40.799041: step 17570, loss 0.178471, acc 0.921875\n",
      "2017-04-03T20:22:41.005059: step 17571, loss 0.085058, acc 0.984375\n",
      "2017-04-03T20:22:41.205060: step 17572, loss 0.038302, acc 0.984375\n",
      "2017-04-03T20:22:41.407341: step 17573, loss 0.144776, acc 0.953125\n",
      "2017-04-03T20:22:41.607223: step 17574, loss 0.0809166, acc 0.984375\n",
      "2017-04-03T20:22:41.811341: step 17575, loss 0.220863, acc 0.90625\n",
      "2017-04-03T20:22:42.022532: step 17576, loss 0.101075, acc 0.96875\n",
      "2017-04-03T20:22:42.233794: step 17577, loss 0.107587, acc 0.953125\n",
      "2017-04-03T20:22:42.446935: step 17578, loss 0.0513981, acc 1\n",
      "2017-04-03T20:22:42.648390: step 17579, loss 0.0624614, acc 0.96875\n",
      "2017-04-03T20:22:42.848077: step 17580, loss 0.0939369, acc 0.96875\n",
      "2017-04-03T20:22:43.049164: step 17581, loss 0.0730922, acc 0.96875\n",
      "2017-04-03T20:22:43.253581: step 17582, loss 0.134887, acc 0.96875\n",
      "2017-04-03T20:22:43.453731: step 17583, loss 0.216869, acc 0.90625\n",
      "2017-04-03T20:22:43.666216: step 17584, loss 0.095914, acc 0.984375\n",
      "2017-04-03T20:22:43.882545: step 17585, loss 0.0849794, acc 0.984375\n",
      "2017-04-03T20:22:44.101806: step 17586, loss 0.124379, acc 0.953125\n",
      "2017-04-03T20:22:44.309756: step 17587, loss 0.114531, acc 0.96875\n",
      "2017-04-03T20:22:44.557317: step 17588, loss 0.266397, acc 0.90625\n",
      "2017-04-03T20:22:44.800784: step 17589, loss 0.12319, acc 0.96875\n",
      "2017-04-03T20:22:44.999163: step 17590, loss 0.103921, acc 0.953125\n",
      "2017-04-03T20:22:45.205017: step 17591, loss 0.147971, acc 0.9375\n",
      "2017-04-03T20:22:45.408862: step 17592, loss 0.0818278, acc 0.96875\n",
      "2017-04-03T20:22:45.606074: step 17593, loss 0.0884498, acc 0.953125\n",
      "2017-04-03T20:22:45.811350: step 17594, loss 0.0570972, acc 0.984375\n",
      "2017-04-03T20:22:46.018414: step 17595, loss 0.167429, acc 0.9375\n",
      "2017-04-03T20:22:46.229412: step 17596, loss 0.123867, acc 0.953125\n",
      "2017-04-03T20:22:46.433852: step 17597, loss 0.0326597, acc 1\n",
      "2017-04-03T20:22:46.675536: step 17598, loss 0.0836159, acc 0.984375\n",
      "2017-04-03T20:22:46.885675: step 17599, loss 0.0934156, acc 0.984375\n",
      "2017-04-03T20:22:47.087240: step 17600, loss 0.294289, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:22:49.204704: step 17600, loss 6.77729, acc 0.279\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-17600\n",
      "\n",
      "2017-04-03T20:22:49.557591: step 17601, loss 0.0541155, acc 0.984375\n",
      "2017-04-03T20:22:49.807528: step 17602, loss 0.107734, acc 0.96875\n",
      "2017-04-03T20:22:50.010537: step 17603, loss 0.133358, acc 0.9375\n",
      "2017-04-03T20:22:50.214481: step 17604, loss 0.0840384, acc 0.96875\n",
      "2017-04-03T20:22:50.419616: step 17605, loss 0.177755, acc 0.921875\n",
      "2017-04-03T20:22:50.623608: step 17606, loss 0.10665, acc 0.953125\n",
      "2017-04-03T20:22:50.825218: step 17607, loss 0.0752393, acc 0.96875\n",
      "2017-04-03T20:22:51.036503: step 17608, loss 0.1092, acc 0.96875\n",
      "2017-04-03T20:22:51.280882: step 17609, loss 0.0614441, acc 0.96875\n",
      "2017-04-03T20:22:51.482743: step 17610, loss 0.0369442, acc 1\n",
      "2017-04-03T20:22:51.692342: step 17611, loss 0.0977288, acc 0.984375\n",
      "2017-04-03T20:22:51.908091: step 17612, loss 0.117766, acc 0.96875\n",
      "2017-04-03T20:22:52.107389: step 17613, loss 0.124314, acc 0.953125\n",
      "2017-04-03T20:22:52.316141: step 17614, loss 0.0520384, acc 0.96875\n",
      "2017-04-03T20:22:52.533446: step 17615, loss 0.0295293, acc 1\n",
      "2017-04-03T20:22:52.737804: step 17616, loss 0.163326, acc 0.96875\n",
      "2017-04-03T20:22:52.940072: step 17617, loss 0.0984498, acc 0.96875\n",
      "2017-04-03T20:22:53.146001: step 17618, loss 0.290317, acc 0.890625\n",
      "2017-04-03T20:22:53.348371: step 17619, loss 0.0505289, acc 1\n",
      "2017-04-03T20:22:53.552261: step 17620, loss 0.124669, acc 0.9375\n",
      "2017-04-03T20:22:53.750719: step 17621, loss 0.0954547, acc 0.96875\n",
      "2017-04-03T20:22:53.951425: step 17622, loss 0.0617713, acc 0.96875\n",
      "2017-04-03T20:22:54.154849: step 17623, loss 0.10876, acc 0.96875\n",
      "2017-04-03T20:22:54.358939: step 17624, loss 0.167406, acc 0.96875\n",
      "2017-04-03T20:22:54.558585: step 17625, loss 0.148816, acc 0.953125\n",
      "2017-04-03T20:22:54.759756: step 17626, loss 0.0391433, acc 1\n",
      "2017-04-03T20:22:54.960134: step 17627, loss 0.0476675, acc 0.984375\n",
      "2017-04-03T20:22:55.165347: step 17628, loss 0.148316, acc 0.9375\n",
      "2017-04-03T20:22:55.369880: step 17629, loss 0.0578725, acc 0.984375\n",
      "2017-04-03T20:22:55.573169: step 17630, loss 0.0552756, acc 0.984375\n",
      "2017-04-03T20:22:55.777787: step 17631, loss 0.0733066, acc 0.984375\n",
      "2017-04-03T20:22:55.982422: step 17632, loss 0.118923, acc 0.96875\n",
      "2017-04-03T20:22:56.183674: step 17633, loss 0.132792, acc 0.953125\n",
      "2017-04-03T20:22:56.390418: step 17634, loss 0.0640112, acc 0.953125\n",
      "2017-04-03T20:22:56.633366: step 17635, loss 0.158093, acc 0.984375\n",
      "2017-04-03T20:22:56.833573: step 17636, loss 0.121301, acc 0.96875\n",
      "2017-04-03T20:22:57.033226: step 17637, loss 0.0410658, acc 1\n",
      "2017-04-03T20:22:57.232433: step 17638, loss 0.134795, acc 0.96875\n",
      "2017-04-03T20:22:57.432866: step 17639, loss 0.219149, acc 0.9375\n",
      "2017-04-03T20:22:57.634151: step 17640, loss 0.164093, acc 0.9375\n",
      "2017-04-03T20:22:57.833327: step 17641, loss 0.0902363, acc 0.96875\n",
      "2017-04-03T20:22:58.041317: step 17642, loss 0.112318, acc 0.921875\n",
      "2017-04-03T20:22:58.241993: step 17643, loss 0.0763289, acc 0.984375\n",
      "2017-04-03T20:22:58.442352: step 17644, loss 0.105946, acc 0.96875\n",
      "2017-04-03T20:22:58.658463: step 17645, loss 0.057126, acc 0.984375\n",
      "2017-04-03T20:22:58.861185: step 17646, loss 0.209299, acc 0.9375\n",
      "2017-04-03T20:22:59.062285: step 17647, loss 0.078339, acc 0.984375\n",
      "2017-04-03T20:22:59.266683: step 17648, loss 0.153765, acc 0.9375\n",
      "2017-04-03T20:22:59.474539: step 17649, loss 0.108608, acc 0.953125\n",
      "2017-04-03T20:22:59.672172: step 17650, loss 0.105325, acc 0.953125\n",
      "2017-04-03T20:22:59.918216: step 17651, loss 0.129414, acc 0.953125\n",
      "2017-04-03T20:23:00.133762: step 17652, loss 0.0955043, acc 0.984375\n",
      "2017-04-03T20:23:00.335742: step 17653, loss 0.265379, acc 0.921875\n",
      "2017-04-03T20:23:00.539447: step 17654, loss 0.070707, acc 0.984375\n",
      "2017-04-03T20:23:00.750265: step 17655, loss 0.0817419, acc 0.984375\n",
      "2017-04-03T20:23:00.957617: step 17656, loss 0.192828, acc 0.953125\n",
      "2017-04-03T20:23:01.157856: step 17657, loss 0.0782837, acc 0.953125\n",
      "2017-04-03T20:23:01.358264: step 17658, loss 0.144977, acc 0.921875\n",
      "2017-04-03T20:23:01.559074: step 17659, loss 0.13905, acc 0.984375\n",
      "2017-04-03T20:23:01.763732: step 17660, loss 0.0655837, acc 0.984375\n",
      "2017-04-03T20:23:01.966641: step 17661, loss 0.045311, acc 0.96875\n",
      "2017-04-03T20:23:02.168470: step 17662, loss 0.0578863, acc 1\n",
      "2017-04-03T20:23:02.371844: step 17663, loss 0.163619, acc 0.9375\n",
      "2017-04-03T20:23:02.568945: step 17664, loss 0.028791, acc 1\n",
      "2017-04-03T20:23:02.772449: step 17665, loss 0.0885902, acc 0.984375\n",
      "2017-04-03T20:23:02.976764: step 17666, loss 0.173588, acc 0.921875\n",
      "2017-04-03T20:23:03.179207: step 17667, loss 0.0613085, acc 0.984375\n",
      "2017-04-03T20:23:03.380313: step 17668, loss 0.15725, acc 0.90625\n",
      "2017-04-03T20:23:03.584352: step 17669, loss 0.0699639, acc 0.984375\n",
      "2017-04-03T20:23:03.792082: step 17670, loss 0.241978, acc 0.9375\n",
      "2017-04-03T20:23:04.002042: step 17671, loss 0.12622, acc 0.953125\n",
      "2017-04-03T20:23:04.203951: step 17672, loss 0.0328653, acc 1\n",
      "2017-04-03T20:23:04.405986: step 17673, loss 0.159131, acc 0.921875\n",
      "2017-04-03T20:23:04.611435: step 17674, loss 0.0911506, acc 0.96875\n",
      "2017-04-03T20:23:04.815720: step 17675, loss 0.0635587, acc 0.984375\n",
      "2017-04-03T20:23:05.022899: step 17676, loss 0.118363, acc 0.9375\n",
      "2017-04-03T20:23:05.225651: step 17677, loss 0.0442771, acc 0.984375\n",
      "2017-04-03T20:23:05.425875: step 17678, loss 0.0794212, acc 0.984375\n",
      "2017-04-03T20:23:05.629328: step 17679, loss 0.0618721, acc 1\n",
      "2017-04-03T20:23:05.828328: step 17680, loss 0.0435818, acc 0.96875\n",
      "2017-04-03T20:23:06.028769: step 17681, loss 0.0353971, acc 0.984375\n",
      "2017-04-03T20:23:06.227425: step 17682, loss 0.0635363, acc 0.96875\n",
      "2017-04-03T20:23:06.429165: step 17683, loss 0.0984152, acc 0.96875\n",
      "2017-04-03T20:23:06.634793: step 17684, loss 0.0698222, acc 0.984375\n",
      "2017-04-03T20:23:06.835366: step 17685, loss 0.340455, acc 0.9375\n",
      "2017-04-03T20:23:07.040562: step 17686, loss 0.0920755, acc 0.96875\n",
      "2017-04-03T20:23:07.242216: step 17687, loss 0.233281, acc 0.96875\n",
      "2017-04-03T20:23:07.484377: step 17688, loss 0.160422, acc 0.9375\n",
      "2017-04-03T20:23:07.704261: step 17689, loss 0.0461657, acc 1\n",
      "2017-04-03T20:23:07.922816: step 17690, loss 0.0392459, acc 1\n",
      "2017-04-03T20:23:08.124804: step 17691, loss 0.110646, acc 0.96875\n",
      "2017-04-03T20:23:08.325870: step 17692, loss 0.0931392, acc 0.984375\n",
      "2017-04-03T20:23:08.530144: step 17693, loss 0.093126, acc 0.96875\n",
      "2017-04-03T20:23:08.730308: step 17694, loss 0.173804, acc 0.953125\n",
      "2017-04-03T20:23:08.932407: step 17695, loss 0.139962, acc 0.953125\n",
      "2017-04-03T20:23:09.146265: step 17696, loss 0.0793684, acc 0.96875\n",
      "2017-04-03T20:23:09.351546: step 17697, loss 0.0944013, acc 0.96875\n",
      "2017-04-03T20:23:09.549452: step 17698, loss 0.203123, acc 0.921875\n",
      "2017-04-03T20:23:09.752485: step 17699, loss 0.149408, acc 0.96875\n",
      "2017-04-03T20:23:09.976063: step 17700, loss 0.197905, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:23:12.096697: step 17700, loss 6.86224, acc 0.277\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-17700\n",
      "\n",
      "2017-04-03T20:23:12.426778: step 17701, loss 0.116532, acc 0.984375\n",
      "2017-04-03T20:23:12.632980: step 17702, loss 0.0545036, acc 0.984375\n",
      "2017-04-03T20:23:12.838622: step 17703, loss 0.113254, acc 0.96875\n",
      "2017-04-03T20:23:13.055632: step 17704, loss 0.0820566, acc 0.984375\n",
      "2017-04-03T20:23:13.263001: step 17705, loss 0.196885, acc 0.9375\n",
      "2017-04-03T20:23:13.468221: step 17706, loss 0.0782304, acc 0.96875\n",
      "2017-04-03T20:23:13.676263: step 17707, loss 0.130066, acc 0.953125\n",
      "2017-04-03T20:23:13.918191: step 17708, loss 0.150462, acc 0.921875\n",
      "2017-04-03T20:23:14.137080: step 17709, loss 0.0340394, acc 0.984375\n",
      "2017-04-03T20:23:14.356116: step 17710, loss 0.153225, acc 0.96875\n",
      "2017-04-03T20:23:14.562575: step 17711, loss 0.0433567, acc 1\n",
      "2017-04-03T20:23:14.802198: step 17712, loss 0.136769, acc 0.921875\n",
      "2017-04-03T20:23:15.012610: step 17713, loss 0.2543, acc 0.921875\n",
      "2017-04-03T20:23:15.234895: step 17714, loss 0.318053, acc 0.90625\n",
      "2017-04-03T20:23:15.453918: step 17715, loss 0.10812, acc 0.953125\n",
      "2017-04-03T20:23:15.664016: step 17716, loss 0.129395, acc 0.953125\n",
      "2017-04-03T20:23:15.862050: step 17717, loss 0.161158, acc 0.953125\n",
      "2017-04-03T20:23:16.068983: step 17718, loss 0.128052, acc 0.9375\n",
      "2017-04-03T20:23:16.274125: step 17719, loss 0.112785, acc 0.96875\n",
      "2017-04-03T20:23:16.486186: step 17720, loss 0.0326416, acc 0.984375\n",
      "2017-04-03T20:23:16.712121: step 17721, loss 0.107058, acc 0.984375\n",
      "2017-04-03T20:23:16.926550: step 17722, loss 0.112295, acc 0.953125\n",
      "2017-04-03T20:23:17.129811: step 17723, loss 0.214115, acc 0.921875\n",
      "2017-04-03T20:23:17.332273: step 17724, loss 0.0897835, acc 0.96875\n",
      "2017-04-03T20:23:17.538426: step 17725, loss 0.0585954, acc 1\n",
      "2017-04-03T20:23:17.741180: step 17726, loss 0.125547, acc 0.953125\n",
      "2017-04-03T20:23:17.942867: step 17727, loss 0.0481951, acc 0.984375\n",
      "2017-04-03T20:23:18.145763: step 17728, loss 0.144785, acc 0.953125\n",
      "2017-04-03T20:23:18.352208: step 17729, loss 0.213971, acc 0.890625\n",
      "2017-04-03T20:23:18.557717: step 17730, loss 0.114994, acc 0.96875\n",
      "2017-04-03T20:23:18.759625: step 17731, loss 0.210743, acc 0.9375\n",
      "2017-04-03T20:23:18.960033: step 17732, loss 0.215161, acc 0.9375\n",
      "2017-04-03T20:23:19.161039: step 17733, loss 0.132688, acc 0.953125\n",
      "2017-04-03T20:23:19.366421: step 17734, loss 0.126578, acc 0.96875\n",
      "2017-04-03T20:23:19.572341: step 17735, loss 0.10452, acc 0.984375\n",
      "2017-04-03T20:23:19.799798: step 17736, loss 0.03469, acc 1\n",
      "2017-04-03T20:23:20.000453: step 17737, loss 0.10318, acc 0.953125\n",
      "2017-04-03T20:23:20.240748: step 17738, loss 0.106203, acc 0.96875\n",
      "2017-04-03T20:23:20.443499: step 17739, loss 0.128016, acc 0.953125\n",
      "2017-04-03T20:23:20.685125: step 17740, loss 0.0766643, acc 0.984375\n",
      "2017-04-03T20:23:20.931295: step 17741, loss 0.0925282, acc 0.953125\n",
      "2017-04-03T20:23:21.134906: step 17742, loss 0.128094, acc 0.953125\n",
      "2017-04-03T20:23:21.337095: step 17743, loss 0.0678993, acc 0.984375\n",
      "2017-04-03T20:23:21.543164: step 17744, loss 0.245388, acc 0.96875\n",
      "2017-04-03T20:23:21.741213: step 17745, loss 0.031617, acc 0.984375\n",
      "2017-04-03T20:23:21.947398: step 17746, loss 0.12109, acc 0.96875\n",
      "2017-04-03T20:23:22.147549: step 17747, loss 0.119102, acc 0.953125\n",
      "2017-04-03T20:23:22.355075: step 17748, loss 0.155608, acc 0.96875\n",
      "2017-04-03T20:23:22.554495: step 17749, loss 0.140006, acc 0.953125\n",
      "2017-04-03T20:23:22.757298: step 17750, loss 0.0429788, acc 1\n",
      "2017-04-03T20:23:22.999918: step 17751, loss 0.124036, acc 0.953125\n",
      "2017-04-03T20:23:23.208247: step 17752, loss 0.31148, acc 0.890625\n",
      "2017-04-03T20:23:23.407949: step 17753, loss 0.154656, acc 0.96875\n",
      "2017-04-03T20:23:23.611408: step 17754, loss 0.083043, acc 0.984375\n",
      "2017-04-03T20:23:23.820313: step 17755, loss 0.0595332, acc 0.96875\n",
      "2017-04-03T20:23:24.038432: step 17756, loss 0.131784, acc 0.9375\n",
      "2017-04-03T20:23:24.254048: step 17757, loss 0.161958, acc 0.9375\n",
      "2017-04-03T20:23:24.466531: step 17758, loss 0.0419363, acc 1\n",
      "2017-04-03T20:23:24.663702: step 17759, loss 0.111346, acc 0.921875\n",
      "2017-04-03T20:23:24.862935: step 17760, loss 0.163995, acc 0.921875\n",
      "2017-04-03T20:23:25.067740: step 17761, loss 0.119407, acc 0.96875\n",
      "2017-04-03T20:23:25.310132: step 17762, loss 0.0811913, acc 0.984375\n",
      "2017-04-03T20:23:25.524769: step 17763, loss 0.0466934, acc 1\n",
      "2017-04-03T20:23:25.724681: step 17764, loss 0.0543415, acc 0.984375\n",
      "2017-04-03T20:23:25.928119: step 17765, loss 0.146486, acc 0.96875\n",
      "2017-04-03T20:23:26.129343: step 17766, loss 0.0552391, acc 0.984375\n",
      "2017-04-03T20:23:26.338075: step 17767, loss 0.093801, acc 0.96875\n",
      "2017-04-03T20:23:26.545182: step 17768, loss 0.186374, acc 0.921875\n",
      "2017-04-03T20:23:26.745213: step 17769, loss 0.122355, acc 0.9375\n",
      "2017-04-03T20:23:26.960466: step 17770, loss 0.133531, acc 0.953125\n",
      "2017-04-03T20:23:27.162533: step 17771, loss 0.299139, acc 0.9375\n",
      "2017-04-03T20:23:27.360638: step 17772, loss 0.145911, acc 0.921875\n",
      "2017-04-03T20:23:27.573902: step 17773, loss 0.0892612, acc 0.96875\n",
      "2017-04-03T20:23:27.786241: step 17774, loss 0.0988741, acc 0.96875\n",
      "2017-04-03T20:23:27.996708: step 17775, loss 0.199986, acc 0.953125\n",
      "2017-04-03T20:23:28.196240: step 17776, loss 0.0848833, acc 0.96875\n",
      "2017-04-03T20:23:28.396863: step 17777, loss 0.158864, acc 0.953125\n",
      "2017-04-03T20:23:28.601452: step 17778, loss 0.348881, acc 0.921875\n",
      "2017-04-03T20:23:28.846712: step 17779, loss 0.176247, acc 0.921875\n",
      "2017-04-03T20:23:29.054337: step 17780, loss 0.0733019, acc 0.96875\n",
      "2017-04-03T20:23:29.256613: step 17781, loss 0.0354527, acc 0.96875\n",
      "2017-04-03T20:23:29.461958: step 17782, loss 0.194269, acc 0.953125\n",
      "2017-04-03T20:23:29.665130: step 17783, loss 0.119017, acc 0.953125\n",
      "2017-04-03T20:23:29.881712: step 17784, loss 0.0917841, acc 0.96875\n",
      "2017-04-03T20:23:30.102917: step 17785, loss 0.103861, acc 0.984375\n",
      "2017-04-03T20:23:30.305822: step 17786, loss 0.121915, acc 0.96875\n",
      "2017-04-03T20:23:30.549767: step 17787, loss 0.0880218, acc 0.953125\n",
      "2017-04-03T20:23:30.753541: step 17788, loss 0.108413, acc 0.953125\n",
      "2017-04-03T20:23:30.957243: step 17789, loss 0.0343692, acc 1\n",
      "2017-04-03T20:23:31.164540: step 17790, loss 0.035906, acc 0.984375\n",
      "2017-04-03T20:23:31.375361: step 17791, loss 0.105994, acc 0.953125\n",
      "2017-04-03T20:23:31.586480: step 17792, loss 0.124157, acc 0.984375\n",
      "2017-04-03T20:23:31.793328: step 17793, loss 0.288152, acc 0.90625\n",
      "2017-04-03T20:23:31.995818: step 17794, loss 0.0450927, acc 0.984375\n",
      "2017-04-03T20:23:32.197861: step 17795, loss 0.107171, acc 0.953125\n",
      "2017-04-03T20:23:32.398016: step 17796, loss 0.107078, acc 0.953125\n",
      "2017-04-03T20:23:32.607144: step 17797, loss 0.0262268, acc 1\n",
      "2017-04-03T20:23:32.813263: step 17798, loss 0.0809419, acc 0.96875\n",
      "2017-04-03T20:23:33.015082: step 17799, loss 0.0319634, acc 0.984375\n",
      "2017-04-03T20:23:33.213464: step 17800, loss 0.0125301, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:23:35.359280: step 17800, loss 6.90254, acc 0.28725\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-17800\n",
      "\n",
      "2017-04-03T20:23:35.688118: step 17801, loss 0.0567648, acc 0.984375\n",
      "2017-04-03T20:23:35.930532: step 17802, loss 0.156458, acc 0.9375\n",
      "2017-04-03T20:23:36.145897: step 17803, loss 0.0823964, acc 0.96875\n",
      "2017-04-03T20:23:36.347823: step 17804, loss 0.171668, acc 0.9375\n",
      "2017-04-03T20:23:36.550785: step 17805, loss 0.111727, acc 0.984375\n",
      "2017-04-03T20:23:36.757089: step 17806, loss 0.148953, acc 0.953125\n",
      "2017-04-03T20:23:36.966580: step 17807, loss 0.143467, acc 0.9375\n",
      "2017-04-03T20:23:37.214576: step 17808, loss 0.292691, acc 0.953125\n",
      "2017-04-03T20:23:37.417482: step 17809, loss 0.111191, acc 0.953125\n",
      "2017-04-03T20:23:37.620713: step 17810, loss 0.0700311, acc 0.984375\n",
      "2017-04-03T20:23:37.822047: step 17811, loss 0.217994, acc 0.96875\n",
      "2017-04-03T20:23:38.067036: step 17812, loss 0.0491366, acc 0.984375\n",
      "2017-04-03T20:23:38.290346: step 17813, loss 0.137134, acc 0.953125\n",
      "2017-04-03T20:23:38.492269: step 17814, loss 0.0990111, acc 0.96875\n",
      "2017-04-03T20:23:38.701239: step 17815, loss 0.213133, acc 0.9375\n",
      "2017-04-03T20:23:38.899924: step 17816, loss 0.0930507, acc 0.96875\n",
      "2017-04-03T20:23:39.102425: step 17817, loss 0.160648, acc 0.96875\n",
      "2017-04-03T20:23:39.311659: step 17818, loss 0.0578589, acc 0.96875\n",
      "2017-04-03T20:23:39.515519: step 17819, loss 0.0614216, acc 1\n",
      "2017-04-03T20:23:39.714247: step 17820, loss 0.175901, acc 0.921875\n",
      "2017-04-03T20:23:39.916918: step 17821, loss 0.160418, acc 0.953125\n",
      "2017-04-03T20:23:40.117335: step 17822, loss 0.213498, acc 0.921875\n",
      "2017-04-03T20:23:40.325666: step 17823, loss 0.115116, acc 0.953125\n",
      "2017-04-03T20:23:40.528610: step 17824, loss 0.104555, acc 0.9375\n",
      "2017-04-03T20:23:40.733812: step 17825, loss 0.0553916, acc 1\n",
      "2017-04-03T20:23:40.934810: step 17826, loss 0.0751664, acc 0.96875\n",
      "2017-04-03T20:23:41.139218: step 17827, loss 0.0795016, acc 0.96875\n",
      "2017-04-03T20:23:41.350083: step 17828, loss 0.142462, acc 0.953125\n",
      "2017-04-03T20:23:41.549061: step 17829, loss 0.0609623, acc 0.984375\n",
      "2017-04-03T20:23:41.754090: step 17830, loss 0.233894, acc 0.921875\n",
      "2017-04-03T20:23:41.955541: step 17831, loss 0.052057, acc 0.984375\n",
      "2017-04-03T20:23:42.154749: step 17832, loss 0.186696, acc 0.9375\n",
      "2017-04-03T20:23:42.357263: step 17833, loss 0.0423074, acc 0.984375\n",
      "2017-04-03T20:23:42.557637: step 17834, loss 0.127987, acc 0.9375\n",
      "2017-04-03T20:23:42.758225: step 17835, loss 0.11045, acc 0.96875\n",
      "2017-04-03T20:23:42.963448: step 17836, loss 0.0972361, acc 0.984375\n",
      "2017-04-03T20:23:43.162975: step 17837, loss 0.0782735, acc 0.984375\n",
      "2017-04-03T20:23:43.370322: step 17838, loss 0.129582, acc 0.9375\n",
      "2017-04-03T20:23:43.576812: step 17839, loss 0.110042, acc 0.96875\n",
      "2017-04-03T20:23:43.835165: step 17840, loss 0.0793032, acc 0.984375\n",
      "2017-04-03T20:23:44.041378: step 17841, loss 0.115974, acc 0.96875\n",
      "2017-04-03T20:23:44.242428: step 17842, loss 0.0659513, acc 0.96875\n",
      "2017-04-03T20:23:44.446670: step 17843, loss 0.173027, acc 0.921875\n",
      "2017-04-03T20:23:44.649717: step 17844, loss 0.110873, acc 0.953125\n",
      "2017-04-03T20:23:44.859938: step 17845, loss 0.110458, acc 0.953125\n",
      "2017-04-03T20:23:45.078469: step 17846, loss 0.0675103, acc 0.984375\n",
      "2017-04-03T20:23:45.322943: step 17847, loss 0.12493, acc 0.953125\n",
      "2017-04-03T20:23:45.529826: step 17848, loss 0.340721, acc 0.953125\n",
      "2017-04-03T20:23:45.729516: step 17849, loss 0.119555, acc 0.921875\n",
      "2017-04-03T20:23:45.931836: step 17850, loss 0.0647984, acc 0.984375\n",
      "2017-04-03T20:23:46.133935: step 17851, loss 0.0196329, acc 1\n",
      "2017-04-03T20:23:46.342630: step 17852, loss 0.184175, acc 0.9375\n",
      "2017-04-03T20:23:46.544399: step 17853, loss 0.159421, acc 0.953125\n",
      "2017-04-03T20:23:46.745937: step 17854, loss 0.235017, acc 0.9375\n",
      "2017-04-03T20:23:46.992668: step 17855, loss 0.0245975, acc 1\n",
      "2017-04-03T20:23:47.193413: step 17856, loss 0.130942, acc 0.984375\n",
      "2017-04-03T20:23:47.398763: step 17857, loss 0.0372557, acc 1\n",
      "2017-04-03T20:23:47.598903: step 17858, loss 0.0902516, acc 0.953125\n",
      "2017-04-03T20:23:47.803207: step 17859, loss 0.135077, acc 0.953125\n",
      "2017-04-03T20:23:48.008549: step 17860, loss 0.233666, acc 0.90625\n",
      "2017-04-03T20:23:48.216183: step 17861, loss 0.262904, acc 0.953125\n",
      "2017-04-03T20:23:48.415239: step 17862, loss 0.123129, acc 0.953125\n",
      "2017-04-03T20:23:48.614997: step 17863, loss 0.117216, acc 0.953125\n",
      "2017-04-03T20:23:48.829263: step 17864, loss 0.0650073, acc 0.984375\n",
      "2017-04-03T20:23:49.033079: step 17865, loss 0.152403, acc 0.9375\n",
      "2017-04-03T20:23:49.237389: step 17866, loss 0.159872, acc 0.9375\n",
      "2017-04-03T20:23:49.438991: step 17867, loss 0.0380023, acc 0.984375\n",
      "2017-04-03T20:23:49.640440: step 17868, loss 0.164089, acc 0.9375\n",
      "2017-04-03T20:23:49.842008: step 17869, loss 0.0538391, acc 0.984375\n",
      "2017-04-03T20:23:50.045387: step 17870, loss 0.147867, acc 0.9375\n",
      "2017-04-03T20:23:50.248115: step 17871, loss 0.0725598, acc 0.984375\n",
      "2017-04-03T20:23:50.447974: step 17872, loss 0.0887079, acc 0.984375\n",
      "2017-04-03T20:23:50.653460: step 17873, loss 0.0963846, acc 0.96875\n",
      "2017-04-03T20:23:50.865762: step 17874, loss 0.158047, acc 0.96875\n",
      "2017-04-03T20:23:51.070048: step 17875, loss 0.16302, acc 0.9375\n",
      "2017-04-03T20:23:51.272093: step 17876, loss 0.108286, acc 0.96875\n",
      "2017-04-03T20:23:51.471623: step 17877, loss 0.077216, acc 0.96875\n",
      "2017-04-03T20:23:51.684812: step 17878, loss 0.0827521, acc 0.953125\n",
      "2017-04-03T20:23:51.896570: step 17879, loss 0.13295, acc 0.953125\n",
      "2017-04-03T20:23:52.110007: step 17880, loss 0.253204, acc 0.96875\n",
      "2017-04-03T20:23:52.325629: step 17881, loss 0.0541048, acc 0.96875\n",
      "2017-04-03T20:23:52.533509: step 17882, loss 0.190507, acc 0.953125\n",
      "2017-04-03T20:23:52.751277: step 17883, loss 0.102229, acc 0.96875\n",
      "2017-04-03T20:23:52.994496: step 17884, loss 0.223484, acc 0.953125\n",
      "2017-04-03T20:23:53.201242: step 17885, loss 0.11015, acc 0.96875\n",
      "2017-04-03T20:23:53.404163: step 17886, loss 0.103883, acc 0.9375\n",
      "2017-04-03T20:23:53.612249: step 17887, loss 0.164189, acc 0.921875\n",
      "2017-04-03T20:23:53.814476: step 17888, loss 0.180667, acc 0.96875\n",
      "2017-04-03T20:23:54.014959: step 17889, loss 0.0391448, acc 1\n",
      "2017-04-03T20:23:54.214626: step 17890, loss 0.0385903, acc 1\n",
      "2017-04-03T20:23:54.420630: step 17891, loss 0.324575, acc 0.9375\n",
      "2017-04-03T20:23:54.621204: step 17892, loss 0.14958, acc 0.953125\n",
      "2017-04-03T20:23:54.826450: step 17893, loss 0.0632735, acc 0.984375\n",
      "2017-04-03T20:23:55.031814: step 17894, loss 0.154788, acc 0.921875\n",
      "2017-04-03T20:23:55.238919: step 17895, loss 0.0847506, acc 0.953125\n",
      "2017-04-03T20:23:55.438144: step 17896, loss 0.222546, acc 0.96875\n",
      "2017-04-03T20:23:55.640064: step 17897, loss 0.0798825, acc 0.953125\n",
      "2017-04-03T20:23:55.840655: step 17898, loss 0.28362, acc 0.921875\n",
      "2017-04-03T20:23:56.086507: step 17899, loss 0.100515, acc 0.96875\n",
      "2017-04-03T20:23:56.302992: step 17900, loss 0.110597, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:23:58.498528: step 17900, loss 6.91888, acc 0.279\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-17900\n",
      "\n",
      "2017-04-03T20:23:58.876161: step 17901, loss 0.095682, acc 0.96875\n",
      "2017-04-03T20:23:59.081262: step 17902, loss 0.100462, acc 0.96875\n",
      "2017-04-03T20:23:59.284826: step 17903, loss 0.156909, acc 0.953125\n",
      "2017-04-03T20:23:59.486889: step 17904, loss 0.145879, acc 0.953125\n",
      "2017-04-03T20:23:59.686327: step 17905, loss 0.156798, acc 0.9375\n",
      "2017-04-03T20:23:59.887285: step 17906, loss 0.157388, acc 0.9375\n",
      "2017-04-03T20:24:00.087263: step 17907, loss 0.140493, acc 0.953125\n",
      "2017-04-03T20:24:00.337039: step 17908, loss 0.106027, acc 0.96875\n",
      "2017-04-03T20:24:00.538126: step 17909, loss 0.150819, acc 0.953125\n",
      "2017-04-03T20:24:00.740374: step 17910, loss 0.0904785, acc 0.953125\n",
      "2017-04-03T20:24:00.944041: step 17911, loss 0.138182, acc 0.953125\n",
      "2017-04-03T20:24:01.150637: step 17912, loss 0.12908, acc 0.953125\n",
      "2017-04-03T20:24:01.356042: step 17913, loss 0.205273, acc 0.90625\n",
      "2017-04-03T20:24:01.556321: step 17914, loss 0.186065, acc 0.953125\n",
      "2017-04-03T20:24:01.758666: step 17915, loss 0.147364, acc 0.953125\n",
      "2017-04-03T20:24:01.965242: step 17916, loss 0.099776, acc 0.953125\n",
      "2017-04-03T20:24:02.167987: step 17917, loss 0.113756, acc 0.96875\n",
      "2017-04-03T20:24:02.376655: step 17918, loss 0.168489, acc 0.921875\n",
      "2017-04-03T20:24:02.580981: step 17919, loss 0.147072, acc 0.96875\n",
      "2017-04-03T20:24:02.783402: step 17920, loss 0.143766, acc 0.953125\n",
      "2017-04-03T20:24:02.986331: step 17921, loss 0.183725, acc 0.96875\n",
      "2017-04-03T20:24:03.193845: step 17922, loss 0.205749, acc 0.921875\n",
      "2017-04-03T20:24:03.393089: step 17923, loss 0.0375775, acc 0.984375\n",
      "2017-04-03T20:24:03.605110: step 17924, loss 0.129823, acc 0.953125\n",
      "2017-04-03T20:24:03.812803: step 17925, loss 0.0739249, acc 0.96875\n",
      "2017-04-03T20:24:04.021449: step 17926, loss 0.0666759, acc 0.984375\n",
      "2017-04-03T20:24:04.227078: step 17927, loss 0.0661949, acc 0.96875\n",
      "2017-04-03T20:24:04.435920: step 17928, loss 0.250126, acc 0.953125\n",
      "2017-04-03T20:24:04.638973: step 17929, loss 0.235183, acc 0.921875\n",
      "2017-04-03T20:24:04.853189: step 17930, loss 0.0613241, acc 0.96875\n",
      "2017-04-03T20:24:05.052576: step 17931, loss 0.121841, acc 0.953125\n",
      "2017-04-03T20:24:05.258616: step 17932, loss 0.157232, acc 0.953125\n",
      "2017-04-03T20:24:05.462900: step 17933, loss 0.0394116, acc 0.984375\n",
      "2017-04-03T20:24:05.668504: step 17934, loss 0.0877085, acc 0.96875\n",
      "2017-04-03T20:24:05.871998: step 17935, loss 0.0469009, acc 1\n",
      "2017-04-03T20:24:06.074072: step 17936, loss 0.224791, acc 0.953125\n",
      "2017-04-03T20:24:06.322177: step 17937, loss 0.0898069, acc 0.96875\n",
      "2017-04-03T20:24:06.528174: step 17938, loss 0.248011, acc 0.921875\n",
      "2017-04-03T20:24:06.736912: step 17939, loss 0.136904, acc 0.953125\n",
      "2017-04-03T20:24:06.946183: step 17940, loss 0.0401672, acc 1\n",
      "2017-04-03T20:24:07.148286: step 17941, loss 0.0373179, acc 0.984375\n",
      "2017-04-03T20:24:07.356611: step 17942, loss 0.184701, acc 0.9375\n",
      "2017-04-03T20:24:07.564856: step 17943, loss 0.0827935, acc 0.96875\n",
      "2017-04-03T20:24:07.771838: step 17944, loss 0.0993299, acc 0.96875\n",
      "2017-04-03T20:24:07.973456: step 17945, loss 0.023052, acc 0.984375\n",
      "2017-04-03T20:24:08.180102: step 17946, loss 0.110555, acc 0.953125\n",
      "2017-04-03T20:24:08.385017: step 17947, loss 0.0913609, acc 0.96875\n",
      "2017-04-03T20:24:08.589933: step 17948, loss 0.110639, acc 0.953125\n",
      "2017-04-03T20:24:08.818519: step 17949, loss 0.0638553, acc 1\n",
      "2017-04-03T20:24:09.029785: step 17950, loss 0.113549, acc 0.96875\n",
      "2017-04-03T20:24:09.240524: step 17951, loss 0.0458798, acc 0.984375\n",
      "2017-04-03T20:24:09.444833: step 17952, loss 0.089863, acc 0.9375\n",
      "2017-04-03T20:24:09.657835: step 17953, loss 0.180115, acc 0.9375\n",
      "2017-04-03T20:24:09.863966: step 17954, loss 0.121327, acc 0.9375\n",
      "2017-04-03T20:24:10.112644: step 17955, loss 0.116759, acc 0.953125\n",
      "2017-04-03T20:24:10.322250: step 17956, loss 0.137391, acc 0.9375\n",
      "2017-04-03T20:24:10.524636: step 17957, loss 0.176904, acc 0.953125\n",
      "2017-04-03T20:24:10.732240: step 17958, loss 0.0864704, acc 0.96875\n",
      "2017-04-03T20:24:10.936588: step 17959, loss 0.185454, acc 0.96875\n",
      "2017-04-03T20:24:11.143028: step 17960, loss 0.130182, acc 0.953125\n",
      "2017-04-03T20:24:11.357465: step 17961, loss 0.106093, acc 0.953125\n",
      "2017-04-03T20:24:11.574687: step 17962, loss 0.156901, acc 0.953125\n",
      "2017-04-03T20:24:11.824028: step 17963, loss 0.117936, acc 0.953125\n",
      "2017-04-03T20:24:12.047603: step 17964, loss 0.0830057, acc 0.96875\n",
      "2017-04-03T20:24:12.266993: step 17965, loss 0.0970608, acc 0.96875\n",
      "2017-04-03T20:24:12.486767: step 17966, loss 0.0741401, acc 0.96875\n",
      "2017-04-03T20:24:12.688909: step 17967, loss 0.024108, acc 1\n",
      "2017-04-03T20:24:12.893527: step 17968, loss 0.141815, acc 0.9375\n",
      "2017-04-03T20:24:13.109704: step 17969, loss 0.212713, acc 0.9375\n",
      "2017-04-03T20:24:13.315168: step 17970, loss 0.208498, acc 0.9375\n",
      "2017-04-03T20:24:13.519508: step 17971, loss 0.166839, acc 0.9375\n",
      "2017-04-03T20:24:13.725789: step 17972, loss 0.0880286, acc 0.953125\n",
      "2017-04-03T20:24:13.929665: step 17973, loss 0.0822103, acc 0.984375\n",
      "2017-04-03T20:24:14.133797: step 17974, loss 0.135007, acc 0.953125\n",
      "2017-04-03T20:24:14.343003: step 17975, loss 0.0811607, acc 0.96875\n",
      "2017-04-03T20:24:14.543311: step 17976, loss 0.0613018, acc 0.96875\n",
      "2017-04-03T20:24:14.749421: step 17977, loss 0.0360599, acc 1\n",
      "2017-04-03T20:24:14.966656: step 17978, loss 0.137903, acc 0.96875\n",
      "2017-04-03T20:24:15.174108: step 17979, loss 0.12595, acc 0.953125\n",
      "2017-04-03T20:24:15.373977: step 17980, loss 0.369122, acc 0.9375\n",
      "2017-04-03T20:24:15.580338: step 17981, loss 0.0657184, acc 0.984375\n",
      "2017-04-03T20:24:15.786879: step 17982, loss 0.193151, acc 0.9375\n",
      "2017-04-03T20:24:16.030806: step 17983, loss 0.0780228, acc 0.96875\n",
      "2017-04-03T20:24:16.233566: step 17984, loss 0.188182, acc 0.9375\n",
      "2017-04-03T20:24:16.435411: step 17985, loss 0.106667, acc 0.96875\n",
      "2017-04-03T20:24:16.639335: step 17986, loss 0.0858696, acc 0.96875\n",
      "2017-04-03T20:24:16.844502: step 17987, loss 0.168509, acc 0.921875\n",
      "2017-04-03T20:24:17.050935: step 17988, loss 0.0739069, acc 0.96875\n",
      "2017-04-03T20:24:17.265681: step 17989, loss 0.197238, acc 0.953125\n",
      "2017-04-03T20:24:17.469998: step 17990, loss 0.205503, acc 0.890625\n",
      "2017-04-03T20:24:17.675176: step 17991, loss 0.179793, acc 0.921875\n",
      "2017-04-03T20:24:17.887366: step 17992, loss 0.072785, acc 0.96875\n",
      "2017-04-03T20:24:18.101991: step 17993, loss 0.126807, acc 0.96875\n",
      "2017-04-03T20:24:18.304234: step 17994, loss 0.119896, acc 0.96875\n",
      "2017-04-03T20:24:18.512990: step 17995, loss 0.0636943, acc 0.984375\n",
      "2017-04-03T20:24:18.716291: step 17996, loss 0.0800928, acc 0.984375\n",
      "2017-04-03T20:24:18.948038: step 17997, loss 0.114543, acc 0.96875\n",
      "2017-04-03T20:24:19.166640: step 17998, loss 0.147581, acc 0.953125\n",
      "2017-04-03T20:24:19.383198: step 17999, loss 0.0807753, acc 0.984375\n",
      "2017-04-03T20:24:19.602152: step 18000, loss 0.247082, acc 0.890625\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:24:21.748744: step 18000, loss 6.9038, acc 0.27775\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-18000\n",
      "\n",
      "2017-04-03T20:24:22.087853: step 18001, loss 0.118937, acc 0.96875\n",
      "2017-04-03T20:24:22.287513: step 18002, loss 0.116588, acc 0.96875\n",
      "2017-04-03T20:24:22.490450: step 18003, loss 0.0750587, acc 0.96875\n",
      "2017-04-03T20:24:22.692562: step 18004, loss 0.211963, acc 0.9375\n",
      "2017-04-03T20:24:22.890361: step 18005, loss 0.157791, acc 0.96875\n",
      "2017-04-03T20:24:23.094839: step 18006, loss 0.143221, acc 0.953125\n",
      "2017-04-03T20:24:23.300472: step 18007, loss 0.0937666, acc 0.96875\n",
      "2017-04-03T20:24:23.506712: step 18008, loss 0.0438053, acc 1\n",
      "2017-04-03T20:24:23.754198: step 18009, loss 0.136959, acc 0.9375\n",
      "2017-04-03T20:24:23.964194: step 18010, loss 0.12611, acc 0.96875\n",
      "2017-04-03T20:24:24.171577: step 18011, loss 0.291468, acc 0.96875\n",
      "2017-04-03T20:24:24.396694: step 18012, loss 0.123341, acc 0.953125\n",
      "2017-04-03T20:24:24.601670: step 18013, loss 0.117194, acc 0.96875\n",
      "2017-04-03T20:24:24.801047: step 18014, loss 0.0651791, acc 0.984375\n",
      "2017-04-03T20:24:25.005775: step 18015, loss 0.0725772, acc 0.984375\n",
      "2017-04-03T20:24:25.156608: step 18016, loss 0.0310877, acc 1\n",
      "2017-04-03T20:24:25.363362: step 18017, loss 0.167437, acc 0.953125\n",
      "2017-04-03T20:24:25.566115: step 18018, loss 0.105749, acc 0.953125\n",
      "2017-04-03T20:24:25.806969: step 18019, loss 0.0386724, acc 0.984375\n",
      "2017-04-03T20:24:26.013559: step 18020, loss 0.131219, acc 0.9375\n",
      "2017-04-03T20:24:26.221469: step 18021, loss 0.143917, acc 0.953125\n",
      "2017-04-03T20:24:26.422765: step 18022, loss 0.157362, acc 0.9375\n",
      "2017-04-03T20:24:26.625830: step 18023, loss 0.021651, acc 1\n",
      "2017-04-03T20:24:26.825533: step 18024, loss 0.0475362, acc 0.984375\n",
      "2017-04-03T20:24:27.029066: step 18025, loss 0.091468, acc 0.96875\n",
      "2017-04-03T20:24:27.228880: step 18026, loss 0.088931, acc 0.984375\n",
      "2017-04-03T20:24:27.429899: step 18027, loss 0.114324, acc 0.984375\n",
      "2017-04-03T20:24:27.672696: step 18028, loss 0.323696, acc 0.90625\n",
      "2017-04-03T20:24:27.880421: step 18029, loss 0.0903299, acc 0.96875\n",
      "2017-04-03T20:24:28.085536: step 18030, loss 0.115033, acc 0.96875\n",
      "2017-04-03T20:24:28.287661: step 18031, loss 0.086199, acc 0.984375\n",
      "2017-04-03T20:24:28.491584: step 18032, loss 0.0406013, acc 0.984375\n",
      "2017-04-03T20:24:28.698415: step 18033, loss 0.044379, acc 0.984375\n",
      "2017-04-03T20:24:28.904269: step 18034, loss 0.121998, acc 0.9375\n",
      "2017-04-03T20:24:29.108357: step 18035, loss 0.0989597, acc 0.953125\n",
      "2017-04-03T20:24:29.321606: step 18036, loss 0.0492491, acc 0.984375\n",
      "2017-04-03T20:24:29.526663: step 18037, loss 0.125404, acc 0.953125\n",
      "2017-04-03T20:24:29.734172: step 18038, loss 0.0427701, acc 0.984375\n",
      "2017-04-03T20:24:29.935636: step 18039, loss 0.0189394, acc 0.984375\n",
      "2017-04-03T20:24:30.136265: step 18040, loss 0.283505, acc 0.9375\n",
      "2017-04-03T20:24:30.336484: step 18041, loss 0.0320542, acc 1\n",
      "2017-04-03T20:24:30.582453: step 18042, loss 0.242984, acc 0.90625\n",
      "2017-04-03T20:24:30.781801: step 18043, loss 0.106632, acc 0.984375\n",
      "2017-04-03T20:24:30.983008: step 18044, loss 0.120157, acc 0.921875\n",
      "2017-04-03T20:24:31.187548: step 18045, loss 0.108173, acc 0.9375\n",
      "2017-04-03T20:24:31.395823: step 18046, loss 0.0212326, acc 1\n",
      "2017-04-03T20:24:31.596080: step 18047, loss 0.129956, acc 0.953125\n",
      "2017-04-03T20:24:31.805320: step 18048, loss 0.109433, acc 0.96875\n",
      "2017-04-03T20:24:32.010627: step 18049, loss 0.0550502, acc 1\n",
      "2017-04-03T20:24:32.221709: step 18050, loss 0.136518, acc 0.953125\n",
      "2017-04-03T20:24:32.426449: step 18051, loss 0.114021, acc 0.984375\n",
      "2017-04-03T20:24:32.631059: step 18052, loss 0.0883189, acc 0.984375\n",
      "2017-04-03T20:24:32.833685: step 18053, loss 0.090284, acc 0.96875\n",
      "2017-04-03T20:24:33.034589: step 18054, loss 0.112919, acc 0.96875\n",
      "2017-04-03T20:24:33.242905: step 18055, loss 0.0841804, acc 0.984375\n",
      "2017-04-03T20:24:33.450981: step 18056, loss 0.082744, acc 0.984375\n",
      "2017-04-03T20:24:33.662861: step 18057, loss 0.0581114, acc 0.984375\n",
      "2017-04-03T20:24:33.866041: step 18058, loss 0.115802, acc 0.9375\n",
      "2017-04-03T20:24:34.116736: step 18059, loss 0.0842943, acc 0.984375\n",
      "2017-04-03T20:24:34.327206: step 18060, loss 0.0640003, acc 0.984375\n",
      "2017-04-03T20:24:34.536339: step 18061, loss 0.139874, acc 0.953125\n",
      "2017-04-03T20:24:34.781484: step 18062, loss 0.112649, acc 0.953125\n",
      "2017-04-03T20:24:34.983043: step 18063, loss 0.0349973, acc 0.984375\n",
      "2017-04-03T20:24:35.184368: step 18064, loss 0.0339359, acc 0.984375\n",
      "2017-04-03T20:24:35.393866: step 18065, loss 0.0650618, acc 0.96875\n",
      "2017-04-03T20:24:35.650259: step 18066, loss 0.157203, acc 0.953125\n",
      "2017-04-03T20:24:35.858920: step 18067, loss 0.0905479, acc 0.984375\n",
      "2017-04-03T20:24:36.058094: step 18068, loss 0.115394, acc 0.96875\n",
      "2017-04-03T20:24:36.304788: step 18069, loss 0.0727784, acc 0.96875\n",
      "2017-04-03T20:24:36.510328: step 18070, loss 0.0948597, acc 0.96875\n",
      "2017-04-03T20:24:36.715492: step 18071, loss 0.0757467, acc 0.96875\n",
      "2017-04-03T20:24:36.922156: step 18072, loss 0.203641, acc 0.96875\n",
      "2017-04-03T20:24:37.123881: step 18073, loss 0.0399355, acc 1\n",
      "2017-04-03T20:24:37.320598: step 18074, loss 0.104764, acc 0.953125\n",
      "2017-04-03T20:24:37.569223: step 18075, loss 0.165544, acc 0.984375\n",
      "2017-04-03T20:24:37.775413: step 18076, loss 0.118499, acc 0.96875\n",
      "2017-04-03T20:24:37.978010: step 18077, loss 0.180908, acc 0.9375\n",
      "2017-04-03T20:24:38.199460: step 18078, loss 0.060801, acc 0.96875\n",
      "2017-04-03T20:24:38.417580: step 18079, loss 0.0323473, acc 1\n",
      "2017-04-03T20:24:38.619837: step 18080, loss 0.0540464, acc 0.984375\n",
      "2017-04-03T20:24:38.822716: step 18081, loss 0.0677441, acc 0.96875\n",
      "2017-04-03T20:24:39.025319: step 18082, loss 0.0568392, acc 1\n",
      "2017-04-03T20:24:39.269312: step 18083, loss 0.0372252, acc 0.984375\n",
      "2017-04-03T20:24:39.475277: step 18084, loss 0.104518, acc 0.96875\n",
      "2017-04-03T20:24:39.676717: step 18085, loss 0.124069, acc 0.953125\n",
      "2017-04-03T20:24:39.876312: step 18086, loss 0.107558, acc 0.96875\n",
      "2017-04-03T20:24:40.078041: step 18087, loss 0.222583, acc 0.953125\n",
      "2017-04-03T20:24:40.283330: step 18088, loss 0.169602, acc 0.984375\n",
      "2017-04-03T20:24:40.486781: step 18089, loss 0.018248, acc 1\n",
      "2017-04-03T20:24:40.691176: step 18090, loss 0.123272, acc 0.9375\n",
      "2017-04-03T20:24:40.900019: step 18091, loss 0.169485, acc 0.953125\n",
      "2017-04-03T20:24:41.110617: step 18092, loss 0.102251, acc 0.953125\n",
      "2017-04-03T20:24:41.326356: step 18093, loss 0.0256695, acc 1\n",
      "2017-04-03T20:24:41.543980: step 18094, loss 0.107252, acc 0.96875\n",
      "2017-04-03T20:24:41.797120: step 18095, loss 0.0706197, acc 0.96875\n",
      "2017-04-03T20:24:41.997584: step 18096, loss 0.103533, acc 0.953125\n",
      "2017-04-03T20:24:42.196370: step 18097, loss 0.0537305, acc 0.96875\n",
      "2017-04-03T20:24:42.391807: step 18098, loss 0.0923788, acc 0.984375\n",
      "2017-04-03T20:24:42.591906: step 18099, loss 0.170686, acc 0.953125\n",
      "2017-04-03T20:24:42.792502: step 18100, loss 0.159183, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:24:44.889040: step 18100, loss 6.95521, acc 0.28175\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-18100\n",
      "\n",
      "2017-04-03T20:24:45.226634: step 18101, loss 0.107845, acc 0.953125\n",
      "2017-04-03T20:24:45.433942: step 18102, loss 0.111533, acc 0.96875\n",
      "2017-04-03T20:24:45.635097: step 18103, loss 0.118797, acc 0.96875\n",
      "2017-04-03T20:24:45.837842: step 18104, loss 0.209173, acc 0.953125\n",
      "2017-04-03T20:24:46.038761: step 18105, loss 0.0742208, acc 0.96875\n",
      "2017-04-03T20:24:46.241468: step 18106, loss 0.0650105, acc 0.96875\n",
      "2017-04-03T20:24:46.487812: step 18107, loss 0.117588, acc 0.953125\n",
      "2017-04-03T20:24:46.706780: step 18108, loss 0.0746967, acc 0.96875\n",
      "2017-04-03T20:24:46.909805: step 18109, loss 0.0761896, acc 0.96875\n",
      "2017-04-03T20:24:47.112009: step 18110, loss 0.102105, acc 0.96875\n",
      "2017-04-03T20:24:47.327578: step 18111, loss 0.1978, acc 0.921875\n",
      "2017-04-03T20:24:47.540311: step 18112, loss 0.0407704, acc 0.984375\n",
      "2017-04-03T20:24:47.742243: step 18113, loss 0.0330755, acc 1\n",
      "2017-04-03T20:24:47.947681: step 18114, loss 0.183155, acc 0.9375\n",
      "2017-04-03T20:24:48.152456: step 18115, loss 0.0714977, acc 0.984375\n",
      "2017-04-03T20:24:48.396808: step 18116, loss 0.0760237, acc 0.96875\n",
      "2017-04-03T20:24:48.607910: step 18117, loss 0.0494417, acc 1\n",
      "2017-04-03T20:24:48.814554: step 18118, loss 0.0725012, acc 0.984375\n",
      "2017-04-03T20:24:49.019772: step 18119, loss 0.0800391, acc 0.96875\n",
      "2017-04-03T20:24:49.266333: step 18120, loss 0.0814671, acc 0.984375\n",
      "2017-04-03T20:24:49.476438: step 18121, loss 0.0555424, acc 1\n",
      "2017-04-03T20:24:49.678447: step 18122, loss 0.158662, acc 0.953125\n",
      "2017-04-03T20:24:49.879396: step 18123, loss 0.0505388, acc 0.984375\n",
      "2017-04-03T20:24:50.123438: step 18124, loss 0.150179, acc 0.953125\n",
      "2017-04-03T20:24:50.325296: step 18125, loss 0.180246, acc 0.953125\n",
      "2017-04-03T20:24:50.530346: step 18126, loss 0.0369423, acc 1\n",
      "2017-04-03T20:24:50.734404: step 18127, loss 0.145154, acc 0.953125\n",
      "2017-04-03T20:24:50.934723: step 18128, loss 0.0590437, acc 0.984375\n",
      "2017-04-03T20:24:51.132795: step 18129, loss 0.0724692, acc 0.984375\n",
      "2017-04-03T20:24:51.334080: step 18130, loss 0.157701, acc 0.953125\n",
      "2017-04-03T20:24:51.582759: step 18131, loss 0.0196303, acc 1\n",
      "2017-04-03T20:24:51.796456: step 18132, loss 0.154012, acc 0.96875\n",
      "2017-04-03T20:24:52.040199: step 18133, loss 0.497711, acc 0.953125\n",
      "2017-04-03T20:24:52.252909: step 18134, loss 0.252858, acc 0.953125\n",
      "2017-04-03T20:24:52.457285: step 18135, loss 0.0823637, acc 0.953125\n",
      "2017-04-03T20:24:52.671002: step 18136, loss 0.0668952, acc 0.984375\n",
      "2017-04-03T20:24:52.871501: step 18137, loss 0.0470789, acc 0.984375\n",
      "2017-04-03T20:24:53.071585: step 18138, loss 0.0744851, acc 0.984375\n",
      "2017-04-03T20:24:53.276455: step 18139, loss 0.162111, acc 0.9375\n",
      "2017-04-03T20:24:53.518207: step 18140, loss 0.181278, acc 0.921875\n",
      "2017-04-03T20:24:53.724102: step 18141, loss 0.098139, acc 0.96875\n",
      "2017-04-03T20:24:53.923030: step 18142, loss 0.0445161, acc 0.984375\n",
      "2017-04-03T20:24:54.125663: step 18143, loss 0.0577997, acc 0.984375\n",
      "2017-04-03T20:24:54.374101: step 18144, loss 0.045689, acc 1\n",
      "2017-04-03T20:24:54.577500: step 18145, loss 0.291169, acc 0.953125\n",
      "2017-04-03T20:24:54.777474: step 18146, loss 0.216298, acc 0.921875\n",
      "2017-04-03T20:24:54.978865: step 18147, loss 0.138158, acc 0.953125\n",
      "2017-04-03T20:24:55.184811: step 18148, loss 0.155102, acc 0.96875\n",
      "2017-04-03T20:24:55.388930: step 18149, loss 0.0700777, acc 0.984375\n",
      "2017-04-03T20:24:55.589936: step 18150, loss 0.125462, acc 0.96875\n",
      "2017-04-03T20:24:55.795369: step 18151, loss 0.0792774, acc 0.984375\n",
      "2017-04-03T20:24:55.999576: step 18152, loss 0.163107, acc 0.953125\n",
      "2017-04-03T20:24:56.201523: step 18153, loss 0.100702, acc 0.953125\n",
      "2017-04-03T20:24:56.399839: step 18154, loss 0.0358486, acc 0.984375\n",
      "2017-04-03T20:24:56.605389: step 18155, loss 0.0204836, acc 1\n",
      "2017-04-03T20:24:56.808579: step 18156, loss 0.163636, acc 0.953125\n",
      "2017-04-03T20:24:57.013855: step 18157, loss 0.118015, acc 0.9375\n",
      "2017-04-03T20:24:57.257525: step 18158, loss 0.134912, acc 0.953125\n",
      "2017-04-03T20:24:57.466030: step 18159, loss 0.0933272, acc 0.953125\n",
      "2017-04-03T20:24:57.668741: step 18160, loss 0.218518, acc 0.984375\n",
      "2017-04-03T20:24:57.870159: step 18161, loss 0.131287, acc 0.953125\n",
      "2017-04-03T20:24:58.070603: step 18162, loss 0.0956097, acc 0.953125\n",
      "2017-04-03T20:24:58.273896: step 18163, loss 0.0418385, acc 1\n",
      "2017-04-03T20:24:58.514935: step 18164, loss 0.183125, acc 0.96875\n",
      "2017-04-03T20:24:58.724668: step 18165, loss 0.0610719, acc 0.984375\n",
      "2017-04-03T20:24:58.926899: step 18166, loss 0.274449, acc 0.921875\n",
      "2017-04-03T20:24:59.129007: step 18167, loss 0.0332317, acc 0.984375\n",
      "2017-04-03T20:24:59.348314: step 18168, loss 0.198659, acc 0.9375\n",
      "2017-04-03T20:24:59.600591: step 18169, loss 0.25763, acc 0.96875\n",
      "2017-04-03T20:24:59.808212: step 18170, loss 0.0604968, acc 0.96875\n",
      "2017-04-03T20:25:00.011993: step 18171, loss 0.0940476, acc 0.953125\n",
      "2017-04-03T20:25:00.214860: step 18172, loss 0.0476274, acc 0.984375\n",
      "2017-04-03T20:25:00.458865: step 18173, loss 0.124869, acc 0.96875\n",
      "2017-04-03T20:25:00.661719: step 18174, loss 0.0579789, acc 0.984375\n",
      "2017-04-03T20:25:00.861268: step 18175, loss 0.559556, acc 0.96875\n",
      "2017-04-03T20:25:01.062513: step 18176, loss 0.219418, acc 0.953125\n",
      "2017-04-03T20:25:01.261705: step 18177, loss 0.141296, acc 0.953125\n",
      "2017-04-03T20:25:01.463089: step 18178, loss 0.229454, acc 0.9375\n",
      "2017-04-03T20:25:01.662251: step 18179, loss 0.0956266, acc 0.953125\n",
      "2017-04-03T20:25:01.865915: step 18180, loss 0.115383, acc 0.96875\n",
      "2017-04-03T20:25:02.111221: step 18181, loss 0.083985, acc 0.96875\n",
      "2017-04-03T20:25:02.314753: step 18182, loss 0.0867705, acc 0.96875\n",
      "2017-04-03T20:25:02.563817: step 18183, loss 0.108161, acc 0.96875\n",
      "2017-04-03T20:25:02.764030: step 18184, loss 0.043849, acc 0.96875\n",
      "2017-04-03T20:25:02.971650: step 18185, loss 0.121886, acc 0.953125\n",
      "2017-04-03T20:25:03.188519: step 18186, loss 0.0560111, acc 0.984375\n",
      "2017-04-03T20:25:03.403355: step 18187, loss 0.0700506, acc 0.984375\n",
      "2017-04-03T20:25:03.603733: step 18188, loss 0.14038, acc 0.9375\n",
      "2017-04-03T20:25:03.810634: step 18189, loss 0.120492, acc 0.984375\n",
      "2017-04-03T20:25:04.012456: step 18190, loss 0.285073, acc 0.921875\n",
      "2017-04-03T20:25:04.221870: step 18191, loss 0.106166, acc 0.96875\n",
      "2017-04-03T20:25:04.420386: step 18192, loss 0.175281, acc 0.953125\n",
      "2017-04-03T20:25:04.626867: step 18193, loss 0.130907, acc 0.953125\n",
      "2017-04-03T20:25:04.828138: step 18194, loss 0.0855915, acc 0.96875\n",
      "2017-04-03T20:25:05.027386: step 18195, loss 0.0744475, acc 0.96875\n",
      "2017-04-03T20:25:05.230236: step 18196, loss 0.211417, acc 0.96875\n",
      "2017-04-03T20:25:05.427269: step 18197, loss 0.087792, acc 0.953125\n",
      "2017-04-03T20:25:05.629367: step 18198, loss 0.123548, acc 0.9375\n",
      "2017-04-03T20:25:05.836084: step 18199, loss 0.275168, acc 0.9375\n",
      "2017-04-03T20:25:06.040078: step 18200, loss 0.0200966, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:25:08.151117: step 18200, loss 6.98954, acc 0.285\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-18200\n",
      "\n",
      "2017-04-03T20:25:08.498485: step 18201, loss 0.0783768, acc 0.96875\n",
      "2017-04-03T20:25:08.701621: step 18202, loss 0.0942386, acc 0.96875\n",
      "2017-04-03T20:25:08.900506: step 18203, loss 0.016508, acc 1\n",
      "2017-04-03T20:25:09.101377: step 18204, loss 0.0878081, acc 0.9375\n",
      "2017-04-03T20:25:09.305133: step 18205, loss 0.0942467, acc 0.984375\n",
      "2017-04-03T20:25:09.504035: step 18206, loss 0.132525, acc 0.9375\n",
      "2017-04-03T20:25:09.704981: step 18207, loss 0.114875, acc 0.96875\n",
      "2017-04-03T20:25:09.919257: step 18208, loss 0.172098, acc 0.953125\n",
      "2017-04-03T20:25:10.118458: step 18209, loss 0.128937, acc 0.9375\n",
      "2017-04-03T20:25:10.362015: step 18210, loss 0.0514739, acc 0.984375\n",
      "2017-04-03T20:25:10.558410: step 18211, loss 0.134836, acc 0.96875\n",
      "2017-04-03T20:25:10.758923: step 18212, loss 0.124975, acc 0.984375\n",
      "2017-04-03T20:25:10.975121: step 18213, loss 0.0328294, acc 0.984375\n",
      "2017-04-03T20:25:11.213553: step 18214, loss 0.13654, acc 0.953125\n",
      "2017-04-03T20:25:11.427132: step 18215, loss 0.120407, acc 0.953125\n",
      "2017-04-03T20:25:11.626027: step 18216, loss 0.0678978, acc 0.984375\n",
      "2017-04-03T20:25:11.832687: step 18217, loss 0.0788989, acc 0.953125\n",
      "2017-04-03T20:25:12.061517: step 18218, loss 0.121545, acc 0.953125\n",
      "2017-04-03T20:25:12.267382: step 18219, loss 0.114243, acc 0.953125\n",
      "2017-04-03T20:25:12.465851: step 18220, loss 0.20933, acc 0.953125\n",
      "2017-04-03T20:25:12.671386: step 18221, loss 0.0404178, acc 0.984375\n",
      "2017-04-03T20:25:12.871291: step 18222, loss 0.10321, acc 0.96875\n",
      "2017-04-03T20:25:13.077447: step 18223, loss 0.116983, acc 0.96875\n",
      "2017-04-03T20:25:13.281715: step 18224, loss 0.0673863, acc 0.984375\n",
      "2017-04-03T20:25:13.490353: step 18225, loss 0.106085, acc 0.96875\n",
      "2017-04-03T20:25:13.691186: step 18226, loss 0.177922, acc 0.984375\n",
      "2017-04-03T20:25:13.892215: step 18227, loss 0.0756857, acc 0.953125\n",
      "2017-04-03T20:25:14.104051: step 18228, loss 0.10584, acc 0.96875\n",
      "2017-04-03T20:25:14.304084: step 18229, loss 0.165449, acc 0.953125\n",
      "2017-04-03T20:25:14.507140: step 18230, loss 0.0530384, acc 0.984375\n",
      "2017-04-03T20:25:14.723908: step 18231, loss 0.16575, acc 0.953125\n",
      "2017-04-03T20:25:14.939430: step 18232, loss 0.103347, acc 0.96875\n",
      "2017-04-03T20:25:15.142198: step 18233, loss 0.082927, acc 0.984375\n",
      "2017-04-03T20:25:15.344859: step 18234, loss 0.103752, acc 0.96875\n",
      "2017-04-03T20:25:15.554806: step 18235, loss 0.190106, acc 0.9375\n",
      "2017-04-03T20:25:15.755638: step 18236, loss 0.0413135, acc 1\n",
      "2017-04-03T20:25:15.982074: step 18237, loss 0.0364035, acc 0.984375\n",
      "2017-04-03T20:25:16.190793: step 18238, loss 0.103065, acc 0.984375\n",
      "2017-04-03T20:25:16.422617: step 18239, loss 0.123742, acc 0.953125\n",
      "2017-04-03T20:25:16.628513: step 18240, loss 0.0439867, acc 0.984375\n",
      "2017-04-03T20:25:16.827943: step 18241, loss 0.0555213, acc 0.984375\n",
      "2017-04-03T20:25:17.028335: step 18242, loss 0.0581295, acc 0.984375\n",
      "2017-04-03T20:25:17.230439: step 18243, loss 0.146934, acc 0.9375\n",
      "2017-04-03T20:25:17.434322: step 18244, loss 0.0502952, acc 0.984375\n",
      "2017-04-03T20:25:17.656070: step 18245, loss 0.0688643, acc 1\n",
      "2017-04-03T20:25:17.874772: step 18246, loss 0.196971, acc 0.953125\n",
      "2017-04-03T20:25:18.127549: step 18247, loss 0.0543518, acc 0.984375\n",
      "2017-04-03T20:25:18.331028: step 18248, loss 0.175674, acc 0.984375\n",
      "2017-04-03T20:25:18.531516: step 18249, loss 0.205838, acc 0.921875\n",
      "2017-04-03T20:25:18.733653: step 18250, loss 0.217755, acc 0.953125\n",
      "2017-04-03T20:25:18.937266: step 18251, loss 0.0216959, acc 1\n",
      "2017-04-03T20:25:19.138797: step 18252, loss 0.179771, acc 0.9375\n",
      "2017-04-03T20:25:19.348236: step 18253, loss 0.194366, acc 0.953125\n",
      "2017-04-03T20:25:19.589326: step 18254, loss 0.167782, acc 0.9375\n",
      "2017-04-03T20:25:19.791946: step 18255, loss 0.338355, acc 0.90625\n",
      "2017-04-03T20:25:19.996458: step 18256, loss 0.0327261, acc 1\n",
      "2017-04-03T20:25:20.198623: step 18257, loss 0.0823892, acc 0.96875\n",
      "2017-04-03T20:25:20.398652: step 18258, loss 0.0662235, acc 0.984375\n",
      "2017-04-03T20:25:20.599289: step 18259, loss 0.0641363, acc 0.984375\n",
      "2017-04-03T20:25:20.802403: step 18260, loss 0.0388332, acc 0.984375\n",
      "2017-04-03T20:25:21.005518: step 18261, loss 0.0799717, acc 0.96875\n",
      "2017-04-03T20:25:21.213525: step 18262, loss 0.099804, acc 0.953125\n",
      "2017-04-03T20:25:21.419547: step 18263, loss 0.138783, acc 0.96875\n",
      "2017-04-03T20:25:21.621756: step 18264, loss 0.153754, acc 0.9375\n",
      "2017-04-03T20:25:21.824580: step 18265, loss 0.163551, acc 0.96875\n",
      "2017-04-03T20:25:22.069381: step 18266, loss 0.309742, acc 0.921875\n",
      "2017-04-03T20:25:22.269884: step 18267, loss 0.0642692, acc 0.984375\n",
      "2017-04-03T20:25:22.476788: step 18268, loss 0.258689, acc 0.90625\n",
      "2017-04-03T20:25:22.680302: step 18269, loss 0.145151, acc 0.953125\n",
      "2017-04-03T20:25:22.885422: step 18270, loss 0.159559, acc 0.953125\n",
      "2017-04-03T20:25:23.093608: step 18271, loss 0.06575, acc 0.984375\n",
      "2017-04-03T20:25:23.296334: step 18272, loss 0.11701, acc 0.96875\n",
      "2017-04-03T20:25:23.504058: step 18273, loss 0.0228996, acc 1\n",
      "2017-04-03T20:25:23.703335: step 18274, loss 0.0454279, acc 0.984375\n",
      "2017-04-03T20:25:23.907833: step 18275, loss 0.0689999, acc 0.984375\n",
      "2017-04-03T20:25:24.108325: step 18276, loss 0.102858, acc 0.984375\n",
      "2017-04-03T20:25:24.335851: step 18277, loss 0.225551, acc 0.984375\n",
      "2017-04-03T20:25:24.555367: step 18278, loss 0.0321897, acc 0.984375\n",
      "2017-04-03T20:25:24.762956: step 18279, loss 0.0655838, acc 1\n",
      "2017-04-03T20:25:24.968290: step 18280, loss 0.0852211, acc 0.96875\n",
      "2017-04-03T20:25:25.172581: step 18281, loss 0.126626, acc 0.953125\n",
      "2017-04-03T20:25:25.374436: step 18282, loss 0.0928303, acc 0.96875\n",
      "2017-04-03T20:25:25.579204: step 18283, loss 0.093711, acc 0.96875\n",
      "2017-04-03T20:25:25.817839: step 18284, loss 0.120173, acc 0.984375\n",
      "2017-04-03T20:25:26.023912: step 18285, loss 0.130517, acc 0.953125\n",
      "2017-04-03T20:25:26.228002: step 18286, loss 0.0156974, acc 1\n",
      "2017-04-03T20:25:26.428449: step 18287, loss 0.0950152, acc 0.96875\n",
      "2017-04-03T20:25:26.674486: step 18288, loss 0.0778768, acc 0.96875\n",
      "2017-04-03T20:25:26.875185: step 18289, loss 0.0846205, acc 0.984375\n",
      "2017-04-03T20:25:27.076917: step 18290, loss 0.0381491, acc 1\n",
      "2017-04-03T20:25:27.278284: step 18291, loss 0.236869, acc 0.921875\n",
      "2017-04-03T20:25:27.476054: step 18292, loss 0.13761, acc 0.96875\n",
      "2017-04-03T20:25:27.675081: step 18293, loss 0.125722, acc 0.984375\n",
      "2017-04-03T20:25:27.877068: step 18294, loss 0.0224177, acc 1\n",
      "2017-04-03T20:25:28.079442: step 18295, loss 0.069636, acc 0.984375\n",
      "2017-04-03T20:25:28.283998: step 18296, loss 0.110665, acc 0.953125\n",
      "2017-04-03T20:25:28.485034: step 18297, loss 0.067071, acc 0.984375\n",
      "2017-04-03T20:25:28.684356: step 18298, loss 0.14014, acc 0.984375\n",
      "2017-04-03T20:25:28.882047: step 18299, loss 0.135487, acc 0.9375\n",
      "2017-04-03T20:25:29.132599: step 18300, loss 0.0934122, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:25:31.263104: step 18300, loss 6.98212, acc 0.28275\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-18300\n",
      "\n",
      "2017-04-03T20:25:31.605808: step 18301, loss 0.110985, acc 0.953125\n",
      "2017-04-03T20:25:31.808040: step 18302, loss 0.0964518, acc 0.96875\n",
      "2017-04-03T20:25:32.008279: step 18303, loss 0.200135, acc 0.90625\n",
      "2017-04-03T20:25:32.211125: step 18304, loss 0.0591923, acc 0.96875\n",
      "2017-04-03T20:25:32.416716: step 18305, loss 0.137681, acc 0.953125\n",
      "2017-04-03T20:25:32.623756: step 18306, loss 0.180819, acc 0.9375\n",
      "2017-04-03T20:25:32.824953: step 18307, loss 0.0713918, acc 0.953125\n",
      "2017-04-03T20:25:33.030732: step 18308, loss 0.0566282, acc 0.984375\n",
      "2017-04-03T20:25:33.249961: step 18309, loss 0.232887, acc 0.9375\n",
      "2017-04-03T20:25:33.454541: step 18310, loss 0.262348, acc 0.9375\n",
      "2017-04-03T20:25:33.663589: step 18311, loss 0.124875, acc 0.953125\n",
      "2017-04-03T20:25:33.864686: step 18312, loss 0.260738, acc 0.921875\n",
      "2017-04-03T20:25:34.067690: step 18313, loss 0.222241, acc 0.953125\n",
      "2017-04-03T20:25:34.270085: step 18314, loss 0.247244, acc 0.9375\n",
      "2017-04-03T20:25:34.471112: step 18315, loss 0.17121, acc 0.953125\n",
      "2017-04-03T20:25:34.679598: step 18316, loss 0.125749, acc 0.953125\n",
      "2017-04-03T20:25:34.879510: step 18317, loss 0.121051, acc 0.953125\n",
      "2017-04-03T20:25:35.082773: step 18318, loss 0.059221, acc 0.984375\n",
      "2017-04-03T20:25:35.280799: step 18319, loss 0.122251, acc 0.984375\n",
      "2017-04-03T20:25:35.479928: step 18320, loss 0.113722, acc 0.96875\n",
      "2017-04-03T20:25:35.683414: step 18321, loss 0.0678605, acc 0.96875\n",
      "2017-04-03T20:25:35.892654: step 18322, loss 0.144288, acc 0.96875\n",
      "2017-04-03T20:25:36.139640: step 18323, loss 0.15167, acc 0.953125\n",
      "2017-04-03T20:25:36.383915: step 18324, loss 0.142774, acc 0.953125\n",
      "2017-04-03T20:25:36.584162: step 18325, loss 0.091899, acc 0.96875\n",
      "2017-04-03T20:25:36.836057: step 18326, loss 0.138306, acc 0.953125\n",
      "2017-04-03T20:25:37.035755: step 18327, loss 0.161982, acc 0.96875\n",
      "2017-04-03T20:25:37.238634: step 18328, loss 0.107376, acc 0.96875\n",
      "2017-04-03T20:25:37.446773: step 18329, loss 0.108279, acc 0.96875\n",
      "2017-04-03T20:25:37.649239: step 18330, loss 0.0651602, acc 0.984375\n",
      "2017-04-03T20:25:37.849463: step 18331, loss 0.16062, acc 0.90625\n",
      "2017-04-03T20:25:38.049073: step 18332, loss 0.121991, acc 0.953125\n",
      "2017-04-03T20:25:38.251587: step 18333, loss 0.0534767, acc 0.984375\n",
      "2017-04-03T20:25:38.456334: step 18334, loss 0.0764807, acc 0.96875\n",
      "2017-04-03T20:25:38.671186: step 18335, loss 0.117691, acc 0.953125\n",
      "2017-04-03T20:25:38.874579: step 18336, loss 0.115969, acc 0.96875\n",
      "2017-04-03T20:25:39.080299: step 18337, loss 0.0373964, acc 1\n",
      "2017-04-03T20:25:39.284412: step 18338, loss 0.0906404, acc 0.953125\n",
      "2017-04-03T20:25:39.486604: step 18339, loss 0.0935822, acc 0.9375\n",
      "2017-04-03T20:25:39.690358: step 18340, loss 0.140524, acc 0.953125\n",
      "2017-04-03T20:25:39.886767: step 18341, loss 0.145601, acc 0.921875\n",
      "2017-04-03T20:25:40.087555: step 18342, loss 0.0690971, acc 0.953125\n",
      "2017-04-03T20:25:40.290373: step 18343, loss 0.0670802, acc 0.984375\n",
      "2017-04-03T20:25:40.538292: step 18344, loss 0.0678526, acc 0.984375\n",
      "2017-04-03T20:25:40.761063: step 18345, loss 0.0569526, acc 0.984375\n",
      "2017-04-03T20:25:40.978193: step 18346, loss 0.159912, acc 0.921875\n",
      "2017-04-03T20:25:41.188121: step 18347, loss 0.0967715, acc 0.9375\n",
      "2017-04-03T20:25:41.388590: step 18348, loss 0.109919, acc 0.9375\n",
      "2017-04-03T20:25:41.635444: step 18349, loss 0.132368, acc 0.953125\n",
      "2017-04-03T20:25:41.834354: step 18350, loss 0.147329, acc 0.96875\n",
      "2017-04-03T20:25:42.042495: step 18351, loss 0.111718, acc 0.9375\n",
      "2017-04-03T20:25:42.287219: step 18352, loss 0.151178, acc 0.953125\n",
      "2017-04-03T20:25:42.484966: step 18353, loss 0.156784, acc 0.953125\n",
      "2017-04-03T20:25:42.700750: step 18354, loss 0.0877445, acc 0.953125\n",
      "2017-04-03T20:25:42.913832: step 18355, loss 0.0755463, acc 0.984375\n",
      "2017-04-03T20:25:43.156272: step 18356, loss 0.19309, acc 0.9375\n",
      "2017-04-03T20:25:43.365473: step 18357, loss 0.0229957, acc 1\n",
      "2017-04-03T20:25:43.566012: step 18358, loss 0.248922, acc 0.921875\n",
      "2017-04-03T20:25:43.764483: step 18359, loss 0.156134, acc 0.9375\n",
      "2017-04-03T20:25:43.970251: step 18360, loss 0.107566, acc 0.96875\n",
      "2017-04-03T20:25:44.170738: step 18361, loss 0.0856505, acc 0.96875\n",
      "2017-04-03T20:25:44.379285: step 18362, loss 0.0259773, acc 0.984375\n",
      "2017-04-03T20:25:44.624558: step 18363, loss 0.156193, acc 0.96875\n",
      "2017-04-03T20:25:44.828731: step 18364, loss 0.190353, acc 0.953125\n",
      "2017-04-03T20:25:45.027341: step 18365, loss 0.134955, acc 0.921875\n",
      "2017-04-03T20:25:45.225706: step 18366, loss 0.160377, acc 0.96875\n",
      "2017-04-03T20:25:45.428192: step 18367, loss 0.0768294, acc 0.984375\n",
      "2017-04-03T20:25:45.636581: step 18368, loss 0.226783, acc 0.953125\n",
      "2017-04-03T20:25:45.841095: step 18369, loss 0.0502567, acc 0.984375\n",
      "2017-04-03T20:25:46.046696: step 18370, loss 0.0449564, acc 0.984375\n",
      "2017-04-03T20:25:46.246614: step 18371, loss 0.0716224, acc 0.9375\n",
      "2017-04-03T20:25:46.446125: step 18372, loss 0.246599, acc 0.9375\n",
      "2017-04-03T20:25:46.649593: step 18373, loss 0.124096, acc 0.96875\n",
      "2017-04-03T20:25:46.857181: step 18374, loss 0.0761722, acc 0.984375\n",
      "2017-04-03T20:25:47.055627: step 18375, loss 0.128149, acc 0.9375\n",
      "2017-04-03T20:25:47.256971: step 18376, loss 0.115426, acc 0.96875\n",
      "2017-04-03T20:25:47.460054: step 18377, loss 0.0723862, acc 0.96875\n",
      "2017-04-03T20:25:47.659553: step 18378, loss 0.10974, acc 0.984375\n",
      "2017-04-03T20:25:47.862802: step 18379, loss 0.0979177, acc 0.96875\n",
      "2017-04-03T20:25:48.106207: step 18380, loss 0.195616, acc 0.9375\n",
      "2017-04-03T20:25:48.316290: step 18381, loss 0.0820445, acc 0.96875\n",
      "2017-04-03T20:25:48.518005: step 18382, loss 0.22981, acc 0.90625\n",
      "2017-04-03T20:25:48.724387: step 18383, loss 0.0872373, acc 0.96875\n",
      "2017-04-03T20:25:48.931905: step 18384, loss 0.131517, acc 0.953125\n",
      "2017-04-03T20:25:49.131199: step 18385, loss 0.0954352, acc 0.9375\n",
      "2017-04-03T20:25:49.383038: step 18386, loss 0.133288, acc 0.96875\n",
      "2017-04-03T20:25:49.589176: step 18387, loss 0.104943, acc 0.96875\n",
      "2017-04-03T20:25:49.790865: step 18388, loss 0.0557973, acc 0.96875\n",
      "2017-04-03T20:25:49.991689: step 18389, loss 0.130043, acc 0.953125\n",
      "2017-04-03T20:25:50.213564: step 18390, loss 0.0220552, acc 1\n",
      "2017-04-03T20:25:50.416749: step 18391, loss 0.118208, acc 0.953125\n",
      "2017-04-03T20:25:50.618923: step 18392, loss 0.113372, acc 0.96875\n",
      "2017-04-03T20:25:50.817577: step 18393, loss 0.14751, acc 0.953125\n",
      "2017-04-03T20:25:51.019136: step 18394, loss 0.0691863, acc 0.96875\n",
      "2017-04-03T20:25:51.225774: step 18395, loss 0.0802222, acc 0.984375\n",
      "2017-04-03T20:25:51.438325: step 18396, loss 0.0516962, acc 1\n",
      "2017-04-03T20:25:51.639554: step 18397, loss 0.126716, acc 0.96875\n",
      "2017-04-03T20:25:51.836916: step 18398, loss 0.1478, acc 0.9375\n",
      "2017-04-03T20:25:52.053843: step 18399, loss 0.132343, acc 0.96875\n",
      "2017-04-03T20:25:52.259273: step 18400, loss 0.0680277, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:25:54.404574: step 18400, loss 7.01023, acc 0.2835\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-18400\n",
      "\n",
      "2017-04-03T20:25:54.739559: step 18401, loss 0.0949685, acc 0.953125\n",
      "2017-04-03T20:25:54.949931: step 18402, loss 0.138325, acc 0.96875\n",
      "2017-04-03T20:25:55.149468: step 18403, loss 0.331736, acc 0.90625\n",
      "2017-04-03T20:25:55.352708: step 18404, loss 0.041328, acc 0.984375\n",
      "2017-04-03T20:25:55.558109: step 18405, loss 0.119193, acc 0.9375\n",
      "2017-04-03T20:25:55.757146: step 18406, loss 0.0761722, acc 0.953125\n",
      "2017-04-03T20:25:55.959285: step 18407, loss 0.0839647, acc 0.984375\n",
      "2017-04-03T20:25:56.160797: step 18408, loss 0.12222, acc 0.9375\n",
      "2017-04-03T20:25:56.362233: step 18409, loss 0.109149, acc 0.9375\n",
      "2017-04-03T20:25:56.566798: step 18410, loss 0.0332523, acc 0.984375\n",
      "2017-04-03T20:25:56.774262: step 18411, loss 0.0852719, acc 0.984375\n",
      "2017-04-03T20:25:56.989925: step 18412, loss 0.0404044, acc 1\n",
      "2017-04-03T20:25:57.190640: step 18413, loss 0.0526088, acc 0.96875\n",
      "2017-04-03T20:25:57.396244: step 18414, loss 0.0637802, acc 0.984375\n",
      "2017-04-03T20:25:57.601891: step 18415, loss 0.0324908, acc 0.984375\n",
      "2017-04-03T20:25:57.800971: step 18416, loss 0.155642, acc 0.953125\n",
      "2017-04-03T20:25:58.001026: step 18417, loss 0.256298, acc 0.890625\n",
      "2017-04-03T20:25:58.200053: step 18418, loss 0.0335116, acc 1\n",
      "2017-04-03T20:25:58.408699: step 18419, loss 0.139454, acc 0.953125\n",
      "2017-04-03T20:25:58.613771: step 18420, loss 0.118405, acc 0.984375\n",
      "2017-04-03T20:25:58.813541: step 18421, loss 0.140223, acc 0.9375\n",
      "2017-04-03T20:25:59.017423: step 18422, loss 0.0633196, acc 0.96875\n",
      "2017-04-03T20:25:59.221181: step 18423, loss 0.265993, acc 0.921875\n",
      "2017-04-03T20:25:59.419604: step 18424, loss 0.246644, acc 0.953125\n",
      "2017-04-03T20:25:59.623975: step 18425, loss 0.107983, acc 0.953125\n",
      "2017-04-03T20:25:59.822922: step 18426, loss 0.0482078, acc 0.984375\n",
      "2017-04-03T20:26:00.027508: step 18427, loss 0.0621016, acc 0.96875\n",
      "2017-04-03T20:26:00.232367: step 18428, loss 0.111217, acc 0.96875\n",
      "2017-04-03T20:26:00.434747: step 18429, loss 0.0937563, acc 0.984375\n",
      "2017-04-03T20:26:00.638893: step 18430, loss 0.109905, acc 0.96875\n",
      "2017-04-03T20:26:00.846080: step 18431, loss 0.0867817, acc 0.96875\n",
      "2017-04-03T20:26:01.057785: step 18432, loss 0.112307, acc 0.96875\n",
      "2017-04-03T20:26:01.308287: step 18433, loss 0.109696, acc 0.96875\n",
      "2017-04-03T20:26:01.515471: step 18434, loss 0.121763, acc 0.953125\n",
      "2017-04-03T20:26:01.721672: step 18435, loss 0.265803, acc 0.96875\n",
      "2017-04-03T20:26:01.925169: step 18436, loss 0.131827, acc 0.96875\n",
      "2017-04-03T20:26:02.129282: step 18437, loss 0.0492689, acc 0.984375\n",
      "2017-04-03T20:26:02.330382: step 18438, loss 0.0934776, acc 0.953125\n",
      "2017-04-03T20:26:02.531272: step 18439, loss 0.0810655, acc 0.984375\n",
      "2017-04-03T20:26:02.732484: step 18440, loss 0.180365, acc 0.953125\n",
      "2017-04-03T20:26:02.936422: step 18441, loss 0.132305, acc 0.921875\n",
      "2017-04-03T20:26:03.133873: step 18442, loss 0.0707051, acc 0.96875\n",
      "2017-04-03T20:26:03.338233: step 18443, loss 0.178662, acc 0.921875\n",
      "2017-04-03T20:26:03.537546: step 18444, loss 0.168949, acc 0.953125\n",
      "2017-04-03T20:26:03.735965: step 18445, loss 0.161543, acc 0.9375\n",
      "2017-04-03T20:26:03.944306: step 18446, loss 0.11413, acc 0.96875\n",
      "2017-04-03T20:26:04.146735: step 18447, loss 0.236563, acc 0.921875\n",
      "2017-04-03T20:26:04.346184: step 18448, loss 0.0595657, acc 0.984375\n",
      "2017-04-03T20:26:04.556155: step 18449, loss 0.0810268, acc 0.96875\n",
      "2017-04-03T20:26:04.764566: step 18450, loss 0.126076, acc 0.96875\n",
      "2017-04-03T20:26:04.963853: step 18451, loss 0.0763162, acc 0.96875\n",
      "2017-04-03T20:26:05.166876: step 18452, loss 0.0605893, acc 0.984375\n",
      "2017-04-03T20:26:05.369928: step 18453, loss 0.0505452, acc 0.984375\n",
      "2017-04-03T20:26:05.572669: step 18454, loss 0.0291347, acc 0.984375\n",
      "2017-04-03T20:26:05.773795: step 18455, loss 0.167631, acc 0.9375\n",
      "2017-04-03T20:26:05.977491: step 18456, loss 0.120789, acc 0.96875\n",
      "2017-04-03T20:26:06.180645: step 18457, loss 0.120144, acc 0.953125\n",
      "2017-04-03T20:26:06.383356: step 18458, loss 0.0642164, acc 0.96875\n",
      "2017-04-03T20:26:06.586341: step 18459, loss 0.237373, acc 0.921875\n",
      "2017-04-03T20:26:06.793734: step 18460, loss 0.174226, acc 0.9375\n",
      "2017-04-03T20:26:06.994513: step 18461, loss 0.105746, acc 0.953125\n",
      "2017-04-03T20:26:07.197566: step 18462, loss 0.0755792, acc 0.96875\n",
      "2017-04-03T20:26:07.400164: step 18463, loss 0.0906861, acc 0.96875\n",
      "2017-04-03T20:26:07.610467: step 18464, loss 0.196915, acc 0.9375\n",
      "2017-04-03T20:26:07.816334: step 18465, loss 0.0432406, acc 1\n",
      "2017-04-03T20:26:08.022305: step 18466, loss 0.048444, acc 0.984375\n",
      "2017-04-03T20:26:08.226926: step 18467, loss 0.0262797, acc 1\n",
      "2017-04-03T20:26:08.470285: step 18468, loss 0.171645, acc 0.890625\n",
      "2017-04-03T20:26:08.673493: step 18469, loss 0.0921293, acc 0.953125\n",
      "2017-04-03T20:26:08.878363: step 18470, loss 0.0314276, acc 1\n",
      "2017-04-03T20:26:09.082602: step 18471, loss 0.137284, acc 0.953125\n",
      "2017-04-03T20:26:09.286201: step 18472, loss 0.258918, acc 0.921875\n",
      "2017-04-03T20:26:09.487558: step 18473, loss 0.118993, acc 0.984375\n",
      "2017-04-03T20:26:09.693310: step 18474, loss 0.0672848, acc 0.953125\n",
      "2017-04-03T20:26:09.897960: step 18475, loss 0.114484, acc 0.9375\n",
      "2017-04-03T20:26:10.100869: step 18476, loss 0.0860777, acc 0.96875\n",
      "2017-04-03T20:26:10.301288: step 18477, loss 0.134286, acc 0.9375\n",
      "2017-04-03T20:26:10.507032: step 18478, loss 0.200919, acc 0.921875\n",
      "2017-04-03T20:26:10.710623: step 18479, loss 0.100929, acc 0.953125\n",
      "2017-04-03T20:26:10.914716: step 18480, loss 0.152803, acc 0.96875\n",
      "2017-04-03T20:26:11.122424: step 18481, loss 0.196084, acc 0.953125\n",
      "2017-04-03T20:26:11.339843: step 18482, loss 0.110097, acc 0.984375\n",
      "2017-04-03T20:26:11.545587: step 18483, loss 0.156537, acc 0.96875\n",
      "2017-04-03T20:26:11.742535: step 18484, loss 0.221562, acc 0.9375\n",
      "2017-04-03T20:26:11.953958: step 18485, loss 0.0741157, acc 0.96875\n",
      "2017-04-03T20:26:12.153388: step 18486, loss 0.148422, acc 0.9375\n",
      "2017-04-03T20:26:12.356083: step 18487, loss 0.22921, acc 0.921875\n",
      "2017-04-03T20:26:12.562456: step 18488, loss 0.0823329, acc 0.953125\n",
      "2017-04-03T20:26:12.769051: step 18489, loss 0.157205, acc 0.9375\n",
      "2017-04-03T20:26:12.970578: step 18490, loss 0.0446102, acc 0.984375\n",
      "2017-04-03T20:26:13.172937: step 18491, loss 0.124989, acc 0.953125\n",
      "2017-04-03T20:26:13.390093: step 18492, loss 0.0501402, acc 0.984375\n",
      "2017-04-03T20:26:13.590296: step 18493, loss 0.0586833, acc 0.984375\n",
      "2017-04-03T20:26:13.791135: step 18494, loss 0.0522119, acc 0.984375\n",
      "2017-04-03T20:26:13.994936: step 18495, loss 0.292265, acc 0.9375\n",
      "2017-04-03T20:26:14.193661: step 18496, loss 0.0923097, acc 0.96875\n",
      "2017-04-03T20:26:14.394267: step 18497, loss 0.0417324, acc 0.984375\n",
      "2017-04-03T20:26:14.593126: step 18498, loss 0.234608, acc 0.953125\n",
      "2017-04-03T20:26:14.798754: step 18499, loss 0.0885514, acc 0.96875\n",
      "2017-04-03T20:26:14.998336: step 18500, loss 0.118544, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:26:17.108633: step 18500, loss 7.04117, acc 0.28075\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-18500\n",
      "\n",
      "2017-04-03T20:26:17.444125: step 18501, loss 0.175445, acc 0.953125\n",
      "2017-04-03T20:26:17.643403: step 18502, loss 0.0456917, acc 1\n",
      "2017-04-03T20:26:17.870166: step 18503, loss 0.190049, acc 0.9375\n",
      "2017-04-03T20:26:18.092003: step 18504, loss 0.167116, acc 0.953125\n",
      "2017-04-03T20:26:18.306310: step 18505, loss 0.160763, acc 0.953125\n",
      "2017-04-03T20:26:18.511655: step 18506, loss 0.152751, acc 0.953125\n",
      "2017-04-03T20:26:18.711780: step 18507, loss 0.0656166, acc 1\n",
      "2017-04-03T20:26:18.919165: step 18508, loss 0.104525, acc 0.984375\n",
      "2017-04-03T20:26:19.120952: step 18509, loss 0.0898754, acc 0.96875\n",
      "2017-04-03T20:26:19.326534: step 18510, loss 0.203147, acc 0.96875\n",
      "2017-04-03T20:26:19.529126: step 18511, loss 0.114009, acc 0.953125\n",
      "2017-04-03T20:26:19.769786: step 18512, loss 0.103704, acc 0.96875\n",
      "2017-04-03T20:26:19.974434: step 18513, loss 0.0421837, acc 0.984375\n",
      "2017-04-03T20:26:20.191542: step 18514, loss 0.161988, acc 0.9375\n",
      "2017-04-03T20:26:20.396265: step 18515, loss 0.170082, acc 0.953125\n",
      "2017-04-03T20:26:20.595614: step 18516, loss 0.11027, acc 0.953125\n",
      "2017-04-03T20:26:20.841567: step 18517, loss 0.125968, acc 0.953125\n",
      "2017-04-03T20:26:21.057354: step 18518, loss 0.244677, acc 0.9375\n",
      "2017-04-03T20:26:21.270299: step 18519, loss 0.11067, acc 0.953125\n",
      "2017-04-03T20:26:21.475106: step 18520, loss 0.109085, acc 0.953125\n",
      "2017-04-03T20:26:21.727799: step 18521, loss 0.114111, acc 0.96875\n",
      "2017-04-03T20:26:21.932150: step 18522, loss 0.110651, acc 0.953125\n",
      "2017-04-03T20:26:22.135132: step 18523, loss 0.0418029, acc 0.984375\n",
      "2017-04-03T20:26:22.344517: step 18524, loss 0.228059, acc 0.96875\n",
      "2017-04-03T20:26:22.546739: step 18525, loss 0.0534624, acc 0.984375\n",
      "2017-04-03T20:26:22.748437: step 18526, loss 0.0485669, acc 1\n",
      "2017-04-03T20:26:22.951459: step 18527, loss 0.213264, acc 0.96875\n",
      "2017-04-03T20:26:23.157451: step 18528, loss 0.352861, acc 0.890625\n",
      "2017-04-03T20:26:23.366251: step 18529, loss 0.614966, acc 0.96875\n",
      "2017-04-03T20:26:23.567633: step 18530, loss 0.179981, acc 0.9375\n",
      "2017-04-03T20:26:23.771602: step 18531, loss 0.153019, acc 0.9375\n",
      "2017-04-03T20:26:23.985499: step 18532, loss 0.117486, acc 0.953125\n",
      "2017-04-03T20:26:24.191761: step 18533, loss 0.103454, acc 0.984375\n",
      "2017-04-03T20:26:24.396822: step 18534, loss 0.216184, acc 0.96875\n",
      "2017-04-03T20:26:24.600177: step 18535, loss 0.127113, acc 0.96875\n",
      "2017-04-03T20:26:24.807706: step 18536, loss 0.0980783, acc 0.984375\n",
      "2017-04-03T20:26:25.014710: step 18537, loss 0.0695209, acc 0.984375\n",
      "2017-04-03T20:26:25.219862: step 18538, loss 0.136196, acc 0.9375\n",
      "2017-04-03T20:26:25.463825: step 18539, loss 0.0315086, acc 0.984375\n",
      "2017-04-03T20:26:25.676117: step 18540, loss 0.182019, acc 0.9375\n",
      "2017-04-03T20:26:25.887455: step 18541, loss 0.127741, acc 0.921875\n",
      "2017-04-03T20:26:26.093481: step 18542, loss 0.0286818, acc 1\n",
      "2017-04-03T20:26:26.340718: step 18543, loss 0.116892, acc 0.9375\n",
      "2017-04-03T20:26:26.543354: step 18544, loss 0.131085, acc 0.953125\n",
      "2017-04-03T20:26:26.756672: step 18545, loss 0.0749507, acc 0.96875\n",
      "2017-04-03T20:26:26.962571: step 18546, loss 0.137662, acc 0.953125\n",
      "2017-04-03T20:26:27.169527: step 18547, loss 0.1314, acc 0.984375\n",
      "2017-04-03T20:26:27.370715: step 18548, loss 0.0712006, acc 0.96875\n",
      "2017-04-03T20:26:27.570646: step 18549, loss 0.0278521, acc 0.984375\n",
      "2017-04-03T20:26:27.773392: step 18550, loss 0.0869588, acc 0.984375\n",
      "2017-04-03T20:26:27.984469: step 18551, loss 0.0853771, acc 0.96875\n",
      "2017-04-03T20:26:28.188540: step 18552, loss 0.0911936, acc 0.984375\n",
      "2017-04-03T20:26:28.397828: step 18553, loss 0.0862962, acc 0.984375\n",
      "2017-04-03T20:26:28.599969: step 18554, loss 0.138228, acc 0.953125\n",
      "2017-04-03T20:26:28.803792: step 18555, loss 0.118837, acc 0.9375\n",
      "2017-04-03T20:26:29.008944: step 18556, loss 0.312487, acc 0.921875\n",
      "2017-04-03T20:26:29.229372: step 18557, loss 0.0538615, acc 0.984375\n",
      "2017-04-03T20:26:29.426670: step 18558, loss 0.294869, acc 0.921875\n",
      "2017-04-03T20:26:29.679022: step 18559, loss 0.0468214, acc 1\n",
      "2017-04-03T20:26:29.878194: step 18560, loss 0.0325051, acc 1\n",
      "2017-04-03T20:26:30.080491: step 18561, loss 0.0420754, acc 1\n",
      "2017-04-03T20:26:30.281555: step 18562, loss 0.0951269, acc 0.96875\n",
      "2017-04-03T20:26:30.483117: step 18563, loss 0.0750063, acc 0.984375\n",
      "2017-04-03T20:26:30.698417: step 18564, loss 0.0538797, acc 0.984375\n",
      "2017-04-03T20:26:30.902519: step 18565, loss 0.0611714, acc 0.984375\n",
      "2017-04-03T20:26:31.109243: step 18566, loss 0.0348261, acc 1\n",
      "2017-04-03T20:26:31.312696: step 18567, loss 0.101141, acc 0.9375\n",
      "2017-04-03T20:26:31.562739: step 18568, loss 0.0450812, acc 0.96875\n",
      "2017-04-03T20:26:31.804456: step 18569, loss 0.0724697, acc 0.984375\n",
      "2017-04-03T20:26:32.014998: step 18570, loss 0.121029, acc 0.953125\n",
      "2017-04-03T20:26:32.231382: step 18571, loss 0.0947981, acc 0.953125\n",
      "2017-04-03T20:26:32.439617: step 18572, loss 0.0723496, acc 0.96875\n",
      "2017-04-03T20:26:32.650682: step 18573, loss 0.053121, acc 0.96875\n",
      "2017-04-03T20:26:32.872002: step 18574, loss 0.139819, acc 0.953125\n",
      "2017-04-03T20:26:33.091164: step 18575, loss 0.0842067, acc 0.96875\n",
      "2017-04-03T20:26:33.292151: step 18576, loss 0.146552, acc 0.953125\n",
      "2017-04-03T20:26:33.491748: step 18577, loss 0.0906169, acc 0.96875\n",
      "2017-04-03T20:26:33.691342: step 18578, loss 0.0451177, acc 0.984375\n",
      "2017-04-03T20:26:33.839735: step 18579, loss 0.114009, acc 0.9375\n",
      "2017-04-03T20:26:34.046985: step 18580, loss 0.0929644, acc 0.96875\n",
      "2017-04-03T20:26:34.253980: step 18581, loss 0.145357, acc 0.953125\n",
      "2017-04-03T20:26:34.463821: step 18582, loss 0.124314, acc 0.953125\n",
      "2017-04-03T20:26:34.669286: step 18583, loss 0.0478835, acc 1\n",
      "2017-04-03T20:26:34.869939: step 18584, loss 0.0564941, acc 0.984375\n",
      "2017-04-03T20:26:35.071268: step 18585, loss 0.0610759, acc 0.96875\n",
      "2017-04-03T20:26:35.279407: step 18586, loss 0.120163, acc 0.9375\n",
      "2017-04-03T20:26:35.484459: step 18587, loss 0.0820364, acc 0.984375\n",
      "2017-04-03T20:26:35.685911: step 18588, loss 0.202804, acc 0.953125\n",
      "2017-04-03T20:26:35.893804: step 18589, loss 0.112937, acc 0.96875\n",
      "2017-04-03T20:26:36.140445: step 18590, loss 0.0272079, acc 1\n",
      "2017-04-03T20:26:36.356916: step 18591, loss 0.055412, acc 0.984375\n",
      "2017-04-03T20:26:36.567217: step 18592, loss 0.11513, acc 0.96875\n",
      "2017-04-03T20:26:36.769398: step 18593, loss 0.0503427, acc 0.96875\n",
      "2017-04-03T20:26:36.977233: step 18594, loss 0.16529, acc 0.9375\n",
      "2017-04-03T20:26:37.180493: step 18595, loss 0.10575, acc 0.953125\n",
      "2017-04-03T20:26:37.377054: step 18596, loss 0.121592, acc 0.953125\n",
      "2017-04-03T20:26:37.576638: step 18597, loss 0.0289747, acc 1\n",
      "2017-04-03T20:26:37.792282: step 18598, loss 0.0917228, acc 0.984375\n",
      "2017-04-03T20:26:37.997409: step 18599, loss 0.0710531, acc 0.96875\n",
      "2017-04-03T20:26:38.241461: step 18600, loss 0.0513417, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:26:40.363667: step 18600, loss 7.04407, acc 0.2835\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-18600\n",
      "\n",
      "2017-04-03T20:26:40.715213: step 18601, loss 0.0623963, acc 0.953125\n",
      "2017-04-03T20:26:40.927478: step 18602, loss 0.0564256, acc 0.96875\n",
      "2017-04-03T20:26:41.130996: step 18603, loss 0.0492569, acc 0.984375\n",
      "2017-04-03T20:26:41.332623: step 18604, loss 0.117448, acc 0.984375\n",
      "2017-04-03T20:26:41.536264: step 18605, loss 0.048058, acc 1\n",
      "2017-04-03T20:26:41.765212: step 18606, loss 0.0567849, acc 0.984375\n",
      "2017-04-03T20:26:41.987338: step 18607, loss 0.18411, acc 0.9375\n",
      "2017-04-03T20:26:42.206204: step 18608, loss 0.0698311, acc 0.96875\n",
      "2017-04-03T20:26:42.409330: step 18609, loss 0.0543475, acc 0.984375\n",
      "2017-04-03T20:26:42.607868: step 18610, loss 0.122122, acc 0.953125\n",
      "2017-04-03T20:26:42.822524: step 18611, loss 0.175607, acc 0.96875\n",
      "2017-04-03T20:26:43.024237: step 18612, loss 0.0276114, acc 1\n",
      "2017-04-03T20:26:43.223052: step 18613, loss 0.0652606, acc 0.96875\n",
      "2017-04-03T20:26:43.432203: step 18614, loss 0.117965, acc 0.984375\n",
      "2017-04-03T20:26:43.636342: step 18615, loss 0.0337078, acc 0.984375\n",
      "2017-04-03T20:26:43.837806: step 18616, loss 0.0542218, acc 1\n",
      "2017-04-03T20:26:44.044341: step 18617, loss 0.140239, acc 0.984375\n",
      "2017-04-03T20:26:44.247325: step 18618, loss 0.114987, acc 0.96875\n",
      "2017-04-03T20:26:44.448676: step 18619, loss 0.230158, acc 0.953125\n",
      "2017-04-03T20:26:44.654026: step 18620, loss 0.10338, acc 0.984375\n",
      "2017-04-03T20:26:44.855339: step 18621, loss 0.0716612, acc 0.953125\n",
      "2017-04-03T20:26:45.056474: step 18622, loss 0.131041, acc 0.9375\n",
      "2017-04-03T20:26:45.296888: step 18623, loss 0.117196, acc 0.96875\n",
      "2017-04-03T20:26:45.507009: step 18624, loss 0.134309, acc 0.953125\n",
      "2017-04-03T20:26:45.753042: step 18625, loss 0.0759131, acc 0.96875\n",
      "2017-04-03T20:26:45.954639: step 18626, loss 0.128936, acc 0.96875\n",
      "2017-04-03T20:26:46.169167: step 18627, loss 0.0254767, acc 0.984375\n",
      "2017-04-03T20:26:46.368974: step 18628, loss 0.0763296, acc 0.96875\n",
      "2017-04-03T20:26:46.610031: step 18629, loss 0.0472107, acc 0.984375\n",
      "2017-04-03T20:26:46.811487: step 18630, loss 0.0365479, acc 1\n",
      "2017-04-03T20:26:47.014552: step 18631, loss 0.182936, acc 0.953125\n",
      "2017-04-03T20:26:47.261575: step 18632, loss 0.0869894, acc 0.96875\n",
      "2017-04-03T20:26:47.473589: step 18633, loss 0.0721733, acc 0.984375\n",
      "2017-04-03T20:26:47.687531: step 18634, loss 0.0943169, acc 0.984375\n",
      "2017-04-03T20:26:47.905144: step 18635, loss 0.154188, acc 0.9375\n",
      "2017-04-03T20:26:48.106630: step 18636, loss 0.0633116, acc 0.96875\n",
      "2017-04-03T20:26:48.311821: step 18637, loss 0.164548, acc 0.96875\n",
      "2017-04-03T20:26:48.512397: step 18638, loss 0.108818, acc 0.953125\n",
      "2017-04-03T20:26:48.712520: step 18639, loss 0.0465573, acc 1\n",
      "2017-04-03T20:26:48.912112: step 18640, loss 0.0812828, acc 0.953125\n",
      "2017-04-03T20:26:49.112151: step 18641, loss 0.0721181, acc 0.984375\n",
      "2017-04-03T20:26:49.312207: step 18642, loss 0.0809817, acc 0.96875\n",
      "2017-04-03T20:26:49.520791: step 18643, loss 0.0941885, acc 0.96875\n",
      "2017-04-03T20:26:49.721530: step 18644, loss 0.253066, acc 0.96875\n",
      "2017-04-03T20:26:49.921610: step 18645, loss 0.129057, acc 0.984375\n",
      "2017-04-03T20:26:50.126304: step 18646, loss 0.189221, acc 0.9375\n",
      "2017-04-03T20:26:50.330471: step 18647, loss 0.160993, acc 0.9375\n",
      "2017-04-03T20:26:50.535039: step 18648, loss 0.11318, acc 0.984375\n",
      "2017-04-03T20:26:50.733447: step 18649, loss 0.0899017, acc 0.96875\n",
      "2017-04-03T20:26:50.935674: step 18650, loss 0.0762499, acc 0.984375\n",
      "2017-04-03T20:26:51.147276: step 18651, loss 0.0872948, acc 0.96875\n",
      "2017-04-03T20:26:51.347335: step 18652, loss 0.0364911, acc 1\n",
      "2017-04-03T20:26:51.547445: step 18653, loss 0.0775799, acc 0.953125\n",
      "2017-04-03T20:26:51.752189: step 18654, loss 0.0180078, acc 1\n",
      "2017-04-03T20:26:52.001125: step 18655, loss 0.04768, acc 0.984375\n",
      "2017-04-03T20:26:52.209533: step 18656, loss 0.306509, acc 0.921875\n",
      "2017-04-03T20:26:52.456532: step 18657, loss 0.0680861, acc 0.984375\n",
      "2017-04-03T20:26:52.662144: step 18658, loss 0.181902, acc 0.9375\n",
      "2017-04-03T20:26:52.861805: step 18659, loss 0.137011, acc 0.96875\n",
      "2017-04-03T20:26:53.066994: step 18660, loss 0.142951, acc 0.953125\n",
      "2017-04-03T20:26:53.315739: step 18661, loss 0.257906, acc 0.890625\n",
      "2017-04-03T20:26:53.564904: step 18662, loss 0.0381504, acc 0.984375\n",
      "2017-04-03T20:26:53.781237: step 18663, loss 0.0675325, acc 0.984375\n",
      "2017-04-03T20:26:53.986181: step 18664, loss 0.104862, acc 0.953125\n",
      "2017-04-03T20:26:54.190990: step 18665, loss 0.0985594, acc 0.96875\n",
      "2017-04-03T20:26:54.397092: step 18666, loss 0.0715437, acc 0.984375\n",
      "2017-04-03T20:26:54.599816: step 18667, loss 0.0801287, acc 0.96875\n",
      "2017-04-03T20:26:54.801091: step 18668, loss 0.0429082, acc 0.984375\n",
      "2017-04-03T20:26:55.000378: step 18669, loss 0.0831629, acc 0.984375\n",
      "2017-04-03T20:26:55.215544: step 18670, loss 0.0156215, acc 1\n",
      "2017-04-03T20:26:55.426736: step 18671, loss 0.066624, acc 0.96875\n",
      "2017-04-03T20:26:55.631194: step 18672, loss 0.0514866, acc 0.984375\n",
      "2017-04-03T20:26:55.857432: step 18673, loss 0.0970148, acc 0.96875\n",
      "2017-04-03T20:26:56.059778: step 18674, loss 0.0670754, acc 0.984375\n",
      "2017-04-03T20:26:56.270978: step 18675, loss 0.176359, acc 0.921875\n",
      "2017-04-03T20:26:56.473354: step 18676, loss 0.0630249, acc 0.96875\n",
      "2017-04-03T20:26:56.671468: step 18677, loss 0.0422442, acc 0.96875\n",
      "2017-04-03T20:26:56.874187: step 18678, loss 0.17148, acc 0.953125\n",
      "2017-04-03T20:26:57.081883: step 18679, loss 0.038125, acc 1\n",
      "2017-04-03T20:26:57.287270: step 18680, loss 0.115822, acc 0.953125\n",
      "2017-04-03T20:26:57.499168: step 18681, loss 0.0633921, acc 1\n",
      "2017-04-03T20:26:57.717776: step 18682, loss 0.0667703, acc 1\n",
      "2017-04-03T20:26:57.921588: step 18683, loss 0.0270886, acc 1\n",
      "2017-04-03T20:26:58.122129: step 18684, loss 0.110608, acc 0.96875\n",
      "2017-04-03T20:26:58.321339: step 18685, loss 0.0541258, acc 0.984375\n",
      "2017-04-03T20:26:58.525359: step 18686, loss 0.0263139, acc 1\n",
      "2017-04-03T20:26:58.733335: step 18687, loss 0.240737, acc 0.953125\n",
      "2017-04-03T20:26:58.938231: step 18688, loss 0.0524174, acc 0.984375\n",
      "2017-04-03T20:26:59.140975: step 18689, loss 0.183864, acc 0.90625\n",
      "2017-04-03T20:26:59.338553: step 18690, loss 0.0741888, acc 0.984375\n",
      "2017-04-03T20:26:59.543011: step 18691, loss 0.040615, acc 1\n",
      "2017-04-03T20:26:59.743727: step 18692, loss 0.0712774, acc 0.984375\n",
      "2017-04-03T20:26:59.944529: step 18693, loss 0.082018, acc 0.953125\n",
      "2017-04-03T20:27:00.144825: step 18694, loss 0.117555, acc 0.96875\n",
      "2017-04-03T20:27:00.343071: step 18695, loss 0.111039, acc 0.953125\n",
      "2017-04-03T20:27:00.545434: step 18696, loss 0.0431335, acc 0.984375\n",
      "2017-04-03T20:27:00.753696: step 18697, loss 0.174074, acc 0.9375\n",
      "2017-04-03T20:27:00.952502: step 18698, loss 0.0312633, acc 1\n",
      "2017-04-03T20:27:01.154757: step 18699, loss 0.280787, acc 0.953125\n",
      "2017-04-03T20:27:01.356595: step 18700, loss 0.0423475, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:27:03.492413: step 18700, loss 7.13927, acc 0.28575\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-18700\n",
      "\n",
      "2017-04-03T20:27:03.872140: step 18701, loss 0.238562, acc 0.953125\n",
      "2017-04-03T20:27:04.073167: step 18702, loss 0.00641406, acc 1\n",
      "2017-04-03T20:27:04.271668: step 18703, loss 0.0541452, acc 0.984375\n",
      "2017-04-03T20:27:04.479163: step 18704, loss 0.128573, acc 0.96875\n",
      "2017-04-03T20:27:04.683407: step 18705, loss 0.117441, acc 0.953125\n",
      "2017-04-03T20:27:04.883381: step 18706, loss 0.0761387, acc 0.96875\n",
      "2017-04-03T20:27:05.091016: step 18707, loss 0.180311, acc 0.921875\n",
      "2017-04-03T20:27:05.309366: step 18708, loss 0.136093, acc 0.921875\n",
      "2017-04-03T20:27:05.533999: step 18709, loss 0.0623065, acc 0.984375\n",
      "2017-04-03T20:27:05.735953: step 18710, loss 0.189527, acc 0.921875\n",
      "2017-04-03T20:27:05.935968: step 18711, loss 0.0450898, acc 0.984375\n",
      "2017-04-03T20:27:06.145685: step 18712, loss 0.120795, acc 0.96875\n",
      "2017-04-03T20:27:06.341287: step 18713, loss 0.13075, acc 0.96875\n",
      "2017-04-03T20:27:06.542963: step 18714, loss 0.11782, acc 0.96875\n",
      "2017-04-03T20:27:06.741923: step 18715, loss 0.343093, acc 0.96875\n",
      "2017-04-03T20:27:06.946449: step 18716, loss 0.158178, acc 0.953125\n",
      "2017-04-03T20:27:07.148624: step 18717, loss 0.0779109, acc 1\n",
      "2017-04-03T20:27:07.344468: step 18718, loss 0.0464142, acc 0.984375\n",
      "2017-04-03T20:27:07.550025: step 18719, loss 0.0590073, acc 0.96875\n",
      "2017-04-03T20:27:07.752443: step 18720, loss 0.0555987, acc 0.96875\n",
      "2017-04-03T20:27:07.955893: step 18721, loss 0.126611, acc 0.953125\n",
      "2017-04-03T20:27:08.155230: step 18722, loss 0.0679299, acc 0.984375\n",
      "2017-04-03T20:27:08.378233: step 18723, loss 0.0893999, acc 0.96875\n",
      "2017-04-03T20:27:08.582704: step 18724, loss 0.125476, acc 0.953125\n",
      "2017-04-03T20:27:08.779805: step 18725, loss 0.0112115, acc 1\n",
      "2017-04-03T20:27:08.983885: step 18726, loss 0.246669, acc 0.9375\n",
      "2017-04-03T20:27:09.183353: step 18727, loss 0.0266691, acc 1\n",
      "2017-04-03T20:27:09.397316: step 18728, loss 0.268885, acc 0.953125\n",
      "2017-04-03T20:27:09.593680: step 18729, loss 0.113117, acc 0.9375\n",
      "2017-04-03T20:27:09.841094: step 18730, loss 0.0412421, acc 0.984375\n",
      "2017-04-03T20:27:10.047693: step 18731, loss 0.140932, acc 0.953125\n",
      "2017-04-03T20:27:10.252495: step 18732, loss 0.0428446, acc 0.984375\n",
      "2017-04-03T20:27:10.455996: step 18733, loss 0.115171, acc 0.953125\n",
      "2017-04-03T20:27:10.656868: step 18734, loss 0.0390868, acc 0.984375\n",
      "2017-04-03T20:27:10.856984: step 18735, loss 0.173234, acc 0.921875\n",
      "2017-04-03T20:27:11.059340: step 18736, loss 0.0313326, acc 1\n",
      "2017-04-03T20:27:11.266631: step 18737, loss 0.123444, acc 0.953125\n",
      "2017-04-03T20:27:11.468270: step 18738, loss 0.0823238, acc 0.96875\n",
      "2017-04-03T20:27:11.669989: step 18739, loss 0.0910395, acc 0.96875\n",
      "2017-04-03T20:27:11.874755: step 18740, loss 0.0597594, acc 0.96875\n",
      "2017-04-03T20:27:12.116616: step 18741, loss 0.267106, acc 0.9375\n",
      "2017-04-03T20:27:12.371452: step 18742, loss 0.0459481, acc 0.984375\n",
      "2017-04-03T20:27:12.571641: step 18743, loss 0.0440167, acc 0.984375\n",
      "2017-04-03T20:27:12.789548: step 18744, loss 0.0459706, acc 0.984375\n",
      "2017-04-03T20:27:13.003751: step 18745, loss 0.147489, acc 0.96875\n",
      "2017-04-03T20:27:13.212966: step 18746, loss 0.362183, acc 0.953125\n",
      "2017-04-03T20:27:13.415360: step 18747, loss 0.169012, acc 0.953125\n",
      "2017-04-03T20:27:13.612701: step 18748, loss 0.0774927, acc 0.96875\n",
      "2017-04-03T20:27:13.810564: step 18749, loss 0.172201, acc 0.953125\n",
      "2017-04-03T20:27:14.013835: step 18750, loss 0.0864089, acc 0.953125\n",
      "2017-04-03T20:27:14.224696: step 18751, loss 0.0693303, acc 0.984375\n",
      "2017-04-03T20:27:14.444776: step 18752, loss 0.0487284, acc 0.984375\n",
      "2017-04-03T20:27:14.659977: step 18753, loss 0.101701, acc 0.984375\n",
      "2017-04-03T20:27:14.872133: step 18754, loss 0.0423829, acc 0.984375\n",
      "2017-04-03T20:27:15.078484: step 18755, loss 0.0928861, acc 0.96875\n",
      "2017-04-03T20:27:15.285181: step 18756, loss 0.119036, acc 0.953125\n",
      "2017-04-03T20:27:15.485906: step 18757, loss 0.0683258, acc 0.984375\n",
      "2017-04-03T20:27:15.689730: step 18758, loss 0.183068, acc 0.96875\n",
      "2017-04-03T20:27:15.903143: step 18759, loss 0.130917, acc 0.953125\n",
      "2017-04-03T20:27:16.105421: step 18760, loss 0.0819208, acc 0.984375\n",
      "2017-04-03T20:27:16.312972: step 18761, loss 0.0753257, acc 0.96875\n",
      "2017-04-03T20:27:16.557753: step 18762, loss 0.174277, acc 0.921875\n",
      "2017-04-03T20:27:16.762334: step 18763, loss 0.0857519, acc 0.96875\n",
      "2017-04-03T20:27:16.964632: step 18764, loss 0.0944963, acc 0.984375\n",
      "2017-04-03T20:27:17.191040: step 18765, loss 0.169872, acc 0.96875\n",
      "2017-04-03T20:27:17.406356: step 18766, loss 0.0870255, acc 0.96875\n",
      "2017-04-03T20:27:17.621788: step 18767, loss 0.0723478, acc 1\n",
      "2017-04-03T20:27:17.825073: step 18768, loss 0.0887033, acc 0.984375\n",
      "2017-04-03T20:27:18.026567: step 18769, loss 0.0539007, acc 0.984375\n",
      "2017-04-03T20:27:18.228479: step 18770, loss 0.178093, acc 0.96875\n",
      "2017-04-03T20:27:18.426622: step 18771, loss 0.0746327, acc 0.96875\n",
      "2017-04-03T20:27:18.626739: step 18772, loss 0.165694, acc 0.953125\n",
      "2017-04-03T20:27:18.865609: step 18773, loss 0.0424666, acc 0.984375\n",
      "2017-04-03T20:27:19.065878: step 18774, loss 0.0495038, acc 0.984375\n",
      "2017-04-03T20:27:19.268418: step 18775, loss 0.300572, acc 0.921875\n",
      "2017-04-03T20:27:19.472697: step 18776, loss 0.181712, acc 0.921875\n",
      "2017-04-03T20:27:19.677250: step 18777, loss 0.0450912, acc 0.984375\n",
      "2017-04-03T20:27:19.879714: step 18778, loss 0.0279434, acc 1\n",
      "2017-04-03T20:27:20.078447: step 18779, loss 0.056251, acc 0.984375\n",
      "2017-04-03T20:27:20.280969: step 18780, loss 0.108342, acc 0.96875\n",
      "2017-04-03T20:27:20.487972: step 18781, loss 0.0446043, acc 0.984375\n",
      "2017-04-03T20:27:20.688585: step 18782, loss 0.0446294, acc 0.984375\n",
      "2017-04-03T20:27:20.885999: step 18783, loss 0.0417898, acc 0.984375\n",
      "2017-04-03T20:27:21.085603: step 18784, loss 0.0916212, acc 0.96875\n",
      "2017-04-03T20:27:21.287501: step 18785, loss 0.0959754, acc 0.953125\n",
      "2017-04-03T20:27:21.485487: step 18786, loss 0.0354908, acc 0.984375\n",
      "2017-04-03T20:27:21.729279: step 18787, loss 0.117966, acc 0.953125\n",
      "2017-04-03T20:27:21.932526: step 18788, loss 0.0270351, acc 1\n",
      "2017-04-03T20:27:22.136673: step 18789, loss 0.239338, acc 0.984375\n",
      "2017-04-03T20:27:22.354354: step 18790, loss 0.0782771, acc 0.96875\n",
      "2017-04-03T20:27:22.553918: step 18791, loss 0.137072, acc 0.953125\n",
      "2017-04-03T20:27:22.762576: step 18792, loss 0.042338, acc 0.984375\n",
      "2017-04-03T20:27:22.963704: step 18793, loss 0.0599203, acc 0.96875\n",
      "2017-04-03T20:27:23.169112: step 18794, loss 0.131037, acc 0.96875\n",
      "2017-04-03T20:27:23.373684: step 18795, loss 0.0546026, acc 0.984375\n",
      "2017-04-03T20:27:23.574328: step 18796, loss 0.048341, acc 0.984375\n",
      "2017-04-03T20:27:23.774595: step 18797, loss 0.0692324, acc 0.984375\n",
      "2017-04-03T20:27:23.974838: step 18798, loss 0.121845, acc 0.96875\n",
      "2017-04-03T20:27:24.176625: step 18799, loss 0.0789794, acc 0.96875\n",
      "2017-04-03T20:27:24.383220: step 18800, loss 0.0426425, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:27:26.518331: step 18800, loss 7.17815, acc 0.278\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-18800\n",
      "\n",
      "2017-04-03T20:27:26.856375: step 18801, loss 0.0880738, acc 0.96875\n",
      "2017-04-03T20:27:27.064019: step 18802, loss 0.109868, acc 0.96875\n",
      "2017-04-03T20:27:27.267159: step 18803, loss 0.0995225, acc 0.96875\n",
      "2017-04-03T20:27:27.471078: step 18804, loss 0.162876, acc 0.9375\n",
      "2017-04-03T20:27:27.695645: step 18805, loss 0.10916, acc 0.96875\n",
      "2017-04-03T20:27:27.909632: step 18806, loss 0.0831506, acc 0.96875\n",
      "2017-04-03T20:27:28.128461: step 18807, loss 0.137755, acc 0.96875\n",
      "2017-04-03T20:27:28.334929: step 18808, loss 0.12336, acc 0.984375\n",
      "2017-04-03T20:27:28.538522: step 18809, loss 0.0725906, acc 0.984375\n",
      "2017-04-03T20:27:28.739572: step 18810, loss 0.141053, acc 0.953125\n",
      "2017-04-03T20:27:28.941495: step 18811, loss 0.0191383, acc 1\n",
      "2017-04-03T20:27:29.181934: step 18812, loss 0.204635, acc 0.9375\n",
      "2017-04-03T20:27:29.388539: step 18813, loss 0.0416881, acc 1\n",
      "2017-04-03T20:27:29.588944: step 18814, loss 0.127143, acc 0.96875\n",
      "2017-04-03T20:27:29.831414: step 18815, loss 0.15764, acc 0.9375\n",
      "2017-04-03T20:27:30.048253: step 18816, loss 0.0256097, acc 0.984375\n",
      "2017-04-03T20:27:30.262777: step 18817, loss 0.12798, acc 0.953125\n",
      "2017-04-03T20:27:30.464549: step 18818, loss 0.0526693, acc 0.984375\n",
      "2017-04-03T20:27:30.666995: step 18819, loss 0.0580793, acc 0.984375\n",
      "2017-04-03T20:27:30.910976: step 18820, loss 0.128441, acc 0.9375\n",
      "2017-04-03T20:27:31.116667: step 18821, loss 0.135945, acc 0.953125\n",
      "2017-04-03T20:27:31.315855: step 18822, loss 0.269428, acc 0.921875\n",
      "2017-04-03T20:27:31.518449: step 18823, loss 0.154268, acc 0.96875\n",
      "2017-04-03T20:27:31.721434: step 18824, loss 0.235494, acc 0.9375\n",
      "2017-04-03T20:27:31.931222: step 18825, loss 0.0868679, acc 0.96875\n",
      "2017-04-03T20:27:32.142983: step 18826, loss 0.0295168, acc 1\n",
      "2017-04-03T20:27:32.368795: step 18827, loss 0.0891069, acc 0.96875\n",
      "2017-04-03T20:27:32.619488: step 18828, loss 0.0603992, acc 0.984375\n",
      "2017-04-03T20:27:32.836714: step 18829, loss 0.187502, acc 0.953125\n",
      "2017-04-03T20:27:33.036446: step 18830, loss 0.0609184, acc 0.984375\n",
      "2017-04-03T20:27:33.237567: step 18831, loss 0.0635917, acc 0.984375\n",
      "2017-04-03T20:27:33.482034: step 18832, loss 0.0555171, acc 0.96875\n",
      "2017-04-03T20:27:33.683991: step 18833, loss 0.121132, acc 0.953125\n",
      "2017-04-03T20:27:33.886832: step 18834, loss 0.139688, acc 0.953125\n",
      "2017-04-03T20:27:34.089870: step 18835, loss 0.0982464, acc 0.96875\n",
      "2017-04-03T20:27:34.336224: step 18836, loss 0.104252, acc 0.96875\n",
      "2017-04-03T20:27:34.553182: step 18837, loss 0.0800752, acc 0.96875\n",
      "2017-04-03T20:27:34.765765: step 18838, loss 0.0793865, acc 0.96875\n",
      "2017-04-03T20:27:34.971488: step 18839, loss 0.0263151, acc 1\n",
      "2017-04-03T20:27:35.218284: step 18840, loss 0.0909231, acc 0.96875\n",
      "2017-04-03T20:27:35.422328: step 18841, loss 0.142307, acc 0.953125\n",
      "2017-04-03T20:27:35.627034: step 18842, loss 0.0906217, acc 0.984375\n",
      "2017-04-03T20:27:35.834590: step 18843, loss 0.0281272, acc 0.984375\n",
      "2017-04-03T20:27:36.039877: step 18844, loss 0.0863664, acc 0.96875\n",
      "2017-04-03T20:27:36.240294: step 18845, loss 0.0147585, acc 1\n",
      "2017-04-03T20:27:36.440075: step 18846, loss 0.158706, acc 0.96875\n",
      "2017-04-03T20:27:36.637569: step 18847, loss 0.117465, acc 0.953125\n",
      "2017-04-03T20:27:36.881746: step 18848, loss 0.109461, acc 0.96875\n",
      "2017-04-03T20:27:37.089336: step 18849, loss 0.116818, acc 0.9375\n",
      "2017-04-03T20:27:37.295309: step 18850, loss 0.144624, acc 0.953125\n",
      "2017-04-03T20:27:37.538287: step 18851, loss 0.176741, acc 0.9375\n",
      "2017-04-03T20:27:37.747275: step 18852, loss 0.21451, acc 0.953125\n",
      "2017-04-03T20:27:37.945160: step 18853, loss 0.123647, acc 0.953125\n",
      "2017-04-03T20:27:38.159358: step 18854, loss 0.310435, acc 0.890625\n",
      "2017-04-03T20:27:38.357907: step 18855, loss 0.0901872, acc 0.96875\n",
      "2017-04-03T20:27:38.561024: step 18856, loss 0.0844263, acc 0.96875\n",
      "2017-04-03T20:27:38.768180: step 18857, loss 0.215696, acc 0.953125\n",
      "2017-04-03T20:27:38.969156: step 18858, loss 0.0746432, acc 0.96875\n",
      "2017-04-03T20:27:39.214520: step 18859, loss 0.0651432, acc 0.984375\n",
      "2017-04-03T20:27:39.423691: step 18860, loss 0.196351, acc 0.9375\n",
      "2017-04-03T20:27:39.624135: step 18861, loss 0.0849881, acc 0.96875\n",
      "2017-04-03T20:27:39.824135: step 18862, loss 0.0679616, acc 0.984375\n",
      "2017-04-03T20:27:40.028356: step 18863, loss 0.0835193, acc 0.96875\n",
      "2017-04-03T20:27:40.226429: step 18864, loss 0.14028, acc 0.953125\n",
      "2017-04-03T20:27:40.428337: step 18865, loss 0.0788032, acc 0.96875\n",
      "2017-04-03T20:27:40.630388: step 18866, loss 0.0923201, acc 0.984375\n",
      "2017-04-03T20:27:40.830031: step 18867, loss 0.163452, acc 0.9375\n",
      "2017-04-03T20:27:41.032524: step 18868, loss 0.0277357, acc 1\n",
      "2017-04-03T20:27:41.230782: step 18869, loss 0.112685, acc 0.96875\n",
      "2017-04-03T20:27:41.438087: step 18870, loss 0.099675, acc 0.984375\n",
      "2017-04-03T20:27:41.687748: step 18871, loss 0.17772, acc 0.921875\n",
      "2017-04-03T20:27:41.892934: step 18872, loss 0.137751, acc 0.9375\n",
      "2017-04-03T20:27:42.099818: step 18873, loss 0.0800373, acc 0.984375\n",
      "2017-04-03T20:27:42.301424: step 18874, loss 0.139754, acc 0.9375\n",
      "2017-04-03T20:27:42.499932: step 18875, loss 0.0967123, acc 0.953125\n",
      "2017-04-03T20:27:42.704011: step 18876, loss 0.260385, acc 0.953125\n",
      "2017-04-03T20:27:42.901508: step 18877, loss 0.0597385, acc 1\n",
      "2017-04-03T20:27:43.107466: step 18878, loss 0.105815, acc 0.96875\n",
      "2017-04-03T20:27:43.307196: step 18879, loss 0.0701787, acc 0.984375\n",
      "2017-04-03T20:27:43.506407: step 18880, loss 0.144505, acc 0.921875\n",
      "2017-04-03T20:27:43.704864: step 18881, loss 0.197334, acc 0.9375\n",
      "2017-04-03T20:27:43.905859: step 18882, loss 0.0582175, acc 1\n",
      "2017-04-03T20:27:44.116685: step 18883, loss 0.179036, acc 0.953125\n",
      "2017-04-03T20:27:44.357807: step 18884, loss 0.199652, acc 0.9375\n",
      "2017-04-03T20:27:44.566744: step 18885, loss 0.268005, acc 0.984375\n",
      "2017-04-03T20:27:44.767189: step 18886, loss 0.112537, acc 0.9375\n",
      "2017-04-03T20:27:44.968621: step 18887, loss 0.16016, acc 0.921875\n",
      "2017-04-03T20:27:45.171936: step 18888, loss 0.0587526, acc 0.984375\n",
      "2017-04-03T20:27:45.416399: step 18889, loss 0.262176, acc 0.921875\n",
      "2017-04-03T20:27:45.618675: step 18890, loss 0.0447689, acc 1\n",
      "2017-04-03T20:27:45.819361: step 18891, loss 0.446601, acc 0.953125\n",
      "2017-04-03T20:27:46.020155: step 18892, loss 0.110731, acc 0.96875\n",
      "2017-04-03T20:27:46.260170: step 18893, loss 0.0716475, acc 0.96875\n",
      "2017-04-03T20:27:46.473370: step 18894, loss 0.0678627, acc 0.96875\n",
      "2017-04-03T20:27:46.679853: step 18895, loss 0.141741, acc 0.953125\n",
      "2017-04-03T20:27:46.891135: step 18896, loss 0.103719, acc 0.96875\n",
      "2017-04-03T20:27:47.096147: step 18897, loss 0.0984666, acc 0.953125\n",
      "2017-04-03T20:27:47.299142: step 18898, loss 0.113335, acc 0.9375\n",
      "2017-04-03T20:27:47.500396: step 18899, loss 0.137747, acc 0.953125\n",
      "2017-04-03T20:27:47.707141: step 18900, loss 0.0598431, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:27:49.805894: step 18900, loss 7.1368, acc 0.27875\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-18900\n",
      "\n",
      "2017-04-03T20:27:50.138735: step 18901, loss 0.0525753, acc 1\n",
      "2017-04-03T20:27:50.383044: step 18902, loss 0.13328, acc 0.984375\n",
      "2017-04-03T20:27:50.587984: step 18903, loss 0.0384865, acc 1\n",
      "2017-04-03T20:27:50.798999: step 18904, loss 0.825107, acc 0.90625\n",
      "2017-04-03T20:27:51.006877: step 18905, loss 0.0723799, acc 0.96875\n",
      "2017-04-03T20:27:51.206764: step 18906, loss 0.325523, acc 0.921875\n",
      "2017-04-03T20:27:51.410935: step 18907, loss 0.104049, acc 0.96875\n",
      "2017-04-03T20:27:51.656174: step 18908, loss 0.0564306, acc 0.984375\n",
      "2017-04-03T20:27:51.862996: step 18909, loss 0.0274828, acc 0.984375\n",
      "2017-04-03T20:27:52.066941: step 18910, loss 0.0774437, acc 0.953125\n",
      "2017-04-03T20:27:52.275420: step 18911, loss 0.00385746, acc 1\n",
      "2017-04-03T20:27:52.472297: step 18912, loss 0.0300069, acc 1\n",
      "2017-04-03T20:27:52.675823: step 18913, loss 0.0859577, acc 0.984375\n",
      "2017-04-03T20:27:52.901156: step 18914, loss 0.084591, acc 0.984375\n",
      "2017-04-03T20:27:53.122764: step 18915, loss 0.22424, acc 0.953125\n",
      "2017-04-03T20:27:53.324424: step 18916, loss 0.0471924, acc 0.984375\n",
      "2017-04-03T20:27:53.569848: step 18917, loss 0.0427612, acc 0.96875\n",
      "2017-04-03T20:27:53.775530: step 18918, loss 0.0986896, acc 0.96875\n",
      "2017-04-03T20:27:53.975978: step 18919, loss 0.0239327, acc 1\n",
      "2017-04-03T20:27:54.179466: step 18920, loss 0.180473, acc 0.890625\n",
      "2017-04-03T20:27:54.388719: step 18921, loss 0.108983, acc 0.96875\n",
      "2017-04-03T20:27:54.590288: step 18922, loss 0.0733355, acc 0.953125\n",
      "2017-04-03T20:27:54.794333: step 18923, loss 0.0430919, acc 1\n",
      "2017-04-03T20:27:54.993537: step 18924, loss 0.288017, acc 0.953125\n",
      "2017-04-03T20:27:55.199824: step 18925, loss 0.175752, acc 0.953125\n",
      "2017-04-03T20:27:55.422132: step 18926, loss 0.238124, acc 0.90625\n",
      "2017-04-03T20:27:55.673461: step 18927, loss 0.0799795, acc 0.984375\n",
      "2017-04-03T20:27:55.875265: step 18928, loss 0.15331, acc 0.9375\n",
      "2017-04-03T20:27:56.074864: step 18929, loss 0.0864696, acc 0.96875\n",
      "2017-04-03T20:27:56.277715: step 18930, loss 0.0548927, acc 0.984375\n",
      "2017-04-03T20:27:56.479157: step 18931, loss 0.243437, acc 0.921875\n",
      "2017-04-03T20:27:56.683787: step 18932, loss 0.0428273, acc 1\n",
      "2017-04-03T20:27:56.888178: step 18933, loss 0.0432421, acc 0.984375\n",
      "2017-04-03T20:27:57.091024: step 18934, loss 0.178754, acc 0.9375\n",
      "2017-04-03T20:27:57.298274: step 18935, loss 0.163328, acc 0.953125\n",
      "2017-04-03T20:27:57.500403: step 18936, loss 0.0811769, acc 0.96875\n",
      "2017-04-03T20:27:57.705628: step 18937, loss 0.114573, acc 0.953125\n",
      "2017-04-03T20:27:57.911415: step 18938, loss 0.103024, acc 0.984375\n",
      "2017-04-03T20:27:58.160814: step 18939, loss 0.169795, acc 0.921875\n",
      "2017-04-03T20:27:58.359796: step 18940, loss 0.0694285, acc 0.984375\n",
      "2017-04-03T20:27:58.567514: step 18941, loss 0.117722, acc 0.96875\n",
      "2017-04-03T20:27:58.770907: step 18942, loss 0.0424172, acc 1\n",
      "2017-04-03T20:27:58.975959: step 18943, loss 0.173175, acc 0.921875\n",
      "2017-04-03T20:27:59.184044: step 18944, loss 0.081479, acc 0.984375\n",
      "2017-04-03T20:27:59.396547: step 18945, loss 0.118852, acc 0.96875\n",
      "2017-04-03T20:27:59.598320: step 18946, loss 0.0909219, acc 0.953125\n",
      "2017-04-03T20:27:59.801009: step 18947, loss 0.0940914, acc 0.953125\n",
      "2017-04-03T20:28:00.005512: step 18948, loss 0.123235, acc 0.96875\n",
      "2017-04-03T20:28:00.376116: step 18949, loss 0.182449, acc 0.96875\n",
      "2017-04-03T20:28:00.579100: step 18950, loss 0.106711, acc 0.96875\n",
      "2017-04-03T20:28:00.779253: step 18951, loss 0.16543, acc 0.953125\n",
      "2017-04-03T20:28:00.984845: step 18952, loss 0.13383, acc 0.953125\n",
      "2017-04-03T20:28:01.190243: step 18953, loss 0.112411, acc 0.96875\n",
      "2017-04-03T20:28:01.404167: step 18954, loss 0.160177, acc 0.9375\n",
      "2017-04-03T20:28:01.617507: step 18955, loss 0.0763643, acc 0.96875\n",
      "2017-04-03T20:28:01.820722: step 18956, loss 0.221224, acc 0.921875\n",
      "2017-04-03T20:28:02.043897: step 18957, loss 0.0938754, acc 0.96875\n",
      "2017-04-03T20:28:02.248573: step 18958, loss 0.0213658, acc 1\n",
      "2017-04-03T20:28:02.489947: step 18959, loss 0.0925531, acc 0.96875\n",
      "2017-04-03T20:28:02.708539: step 18960, loss 0.0827996, acc 0.96875\n",
      "2017-04-03T20:28:02.926622: step 18961, loss 0.136652, acc 0.953125\n",
      "2017-04-03T20:28:03.149395: step 18962, loss 0.168315, acc 0.953125\n",
      "2017-04-03T20:28:03.354083: step 18963, loss 0.0466441, acc 1\n",
      "2017-04-03T20:28:03.554252: step 18964, loss 0.234275, acc 0.96875\n",
      "2017-04-03T20:28:03.753305: step 18965, loss 0.158144, acc 0.9375\n",
      "2017-04-03T20:28:03.957281: step 18966, loss 0.0821724, acc 0.984375\n",
      "2017-04-03T20:28:04.159895: step 18967, loss 0.0654921, acc 0.96875\n",
      "2017-04-03T20:28:04.359680: step 18968, loss 0.23845, acc 0.9375\n",
      "2017-04-03T20:28:04.558926: step 18969, loss 0.233483, acc 0.9375\n",
      "2017-04-03T20:28:04.768936: step 18970, loss 0.0822447, acc 0.984375\n",
      "2017-04-03T20:28:04.977718: step 18971, loss 0.0489808, acc 0.984375\n",
      "2017-04-03T20:28:05.185498: step 18972, loss 0.190254, acc 0.921875\n",
      "2017-04-03T20:28:05.428510: step 18973, loss 0.161146, acc 0.921875\n",
      "2017-04-03T20:28:05.628032: step 18974, loss 0.0658203, acc 0.96875\n",
      "2017-04-03T20:28:05.833073: step 18975, loss 0.226511, acc 0.90625\n",
      "2017-04-03T20:28:06.038108: step 18976, loss 0.0722454, acc 0.984375\n",
      "2017-04-03T20:28:06.241951: step 18977, loss 0.0958121, acc 0.984375\n",
      "2017-04-03T20:28:06.491237: step 18978, loss 0.162546, acc 0.9375\n",
      "2017-04-03T20:28:06.692374: step 18979, loss 0.0747995, acc 0.96875\n",
      "2017-04-03T20:28:06.938804: step 18980, loss 0.20439, acc 0.921875\n",
      "2017-04-03T20:28:07.141305: step 18981, loss 0.115227, acc 0.953125\n",
      "2017-04-03T20:28:07.343001: step 18982, loss 0.0902411, acc 0.96875\n",
      "2017-04-03T20:28:07.584771: step 18983, loss 0.100019, acc 0.984375\n",
      "2017-04-03T20:28:07.803649: step 18984, loss 0.0683907, acc 1\n",
      "2017-04-03T20:28:08.005667: step 18985, loss 0.103199, acc 0.96875\n",
      "2017-04-03T20:28:08.205006: step 18986, loss 0.181697, acc 0.96875\n",
      "2017-04-03T20:28:08.407199: step 18987, loss 0.0944459, acc 0.984375\n",
      "2017-04-03T20:28:08.656403: step 18988, loss 0.226986, acc 0.90625\n",
      "2017-04-03T20:28:08.859592: step 18989, loss 0.0798397, acc 0.96875\n",
      "2017-04-03T20:28:09.066236: step 18990, loss 0.440257, acc 0.90625\n",
      "2017-04-03T20:28:09.268926: step 18991, loss 0.156179, acc 0.96875\n",
      "2017-04-03T20:28:09.469000: step 18992, loss 0.34481, acc 0.9375\n",
      "2017-04-03T20:28:09.669394: step 18993, loss 0.095141, acc 0.984375\n",
      "2017-04-03T20:28:09.911781: step 18994, loss 0.149141, acc 0.953125\n",
      "2017-04-03T20:28:10.118478: step 18995, loss 0.0796687, acc 0.984375\n",
      "2017-04-03T20:28:10.318460: step 18996, loss 0.0973702, acc 0.96875\n",
      "2017-04-03T20:28:10.535039: step 18997, loss 0.051687, acc 0.984375\n",
      "2017-04-03T20:28:10.737549: step 18998, loss 0.541355, acc 0.9375\n",
      "2017-04-03T20:28:10.935207: step 18999, loss 0.156698, acc 0.9375\n",
      "2017-04-03T20:28:11.141199: step 19000, loss 0.0528223, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:28:13.249189: step 19000, loss 7.17048, acc 0.278\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-19000\n",
      "\n",
      "2017-04-03T20:28:13.593141: step 19001, loss 0.146801, acc 0.9375\n",
      "2017-04-03T20:28:13.805530: step 19002, loss 0.0725736, acc 0.984375\n",
      "2017-04-03T20:28:14.009487: step 19003, loss 0.0498178, acc 0.984375\n",
      "2017-04-03T20:28:14.214457: step 19004, loss 0.103678, acc 0.96875\n",
      "2017-04-03T20:28:14.425226: step 19005, loss 0.136104, acc 0.984375\n",
      "2017-04-03T20:28:14.632524: step 19006, loss 0.0446387, acc 1\n",
      "2017-04-03T20:28:14.844399: step 19007, loss 0.104117, acc 0.96875\n",
      "2017-04-03T20:28:15.048602: step 19008, loss 0.184872, acc 0.921875\n",
      "2017-04-03T20:28:15.261585: step 19009, loss 0.0481555, acc 0.984375\n",
      "2017-04-03T20:28:15.482963: step 19010, loss 0.192783, acc 0.90625\n",
      "2017-04-03T20:28:15.701068: step 19011, loss 0.0578874, acc 0.984375\n",
      "2017-04-03T20:28:15.912866: step 19012, loss 0.0572077, acc 0.984375\n",
      "2017-04-03T20:28:16.115191: step 19013, loss 0.0292515, acc 1\n",
      "2017-04-03T20:28:16.321015: step 19014, loss 0.191202, acc 0.9375\n",
      "2017-04-03T20:28:16.526454: step 19015, loss 0.251346, acc 0.9375\n",
      "2017-04-03T20:28:16.730258: step 19016, loss 0.122517, acc 0.953125\n",
      "2017-04-03T20:28:16.940520: step 19017, loss 0.158797, acc 0.953125\n",
      "2017-04-03T20:28:17.155131: step 19018, loss 0.293414, acc 0.921875\n",
      "2017-04-03T20:28:17.370583: step 19019, loss 0.0733071, acc 0.984375\n",
      "2017-04-03T20:28:17.625090: step 19020, loss 0.103599, acc 0.984375\n",
      "2017-04-03T20:28:17.835283: step 19021, loss 0.111549, acc 0.953125\n",
      "2017-04-03T20:28:18.042712: step 19022, loss 0.0917249, acc 0.96875\n",
      "2017-04-03T20:28:18.248344: step 19023, loss 0.06444, acc 0.984375\n",
      "2017-04-03T20:28:18.456322: step 19024, loss 0.0748883, acc 0.984375\n",
      "2017-04-03T20:28:18.659474: step 19025, loss 0.11596, acc 0.921875\n",
      "2017-04-03T20:28:18.861202: step 19026, loss 0.116176, acc 0.96875\n",
      "2017-04-03T20:28:19.065521: step 19027, loss 0.0623366, acc 0.984375\n",
      "2017-04-03T20:28:19.264203: step 19028, loss 0.0253799, acc 1\n",
      "2017-04-03T20:28:19.470495: step 19029, loss 0.166466, acc 0.9375\n",
      "2017-04-03T20:28:19.678001: step 19030, loss 0.0797876, acc 0.96875\n",
      "2017-04-03T20:28:19.881009: step 19031, loss 0.121039, acc 0.9375\n",
      "2017-04-03T20:28:20.085876: step 19032, loss 0.114719, acc 0.984375\n",
      "2017-04-03T20:28:20.294128: step 19033, loss 0.135582, acc 0.96875\n",
      "2017-04-03T20:28:20.495981: step 19034, loss 0.0959956, acc 0.984375\n",
      "2017-04-03T20:28:20.700378: step 19035, loss 0.17077, acc 0.9375\n",
      "2017-04-03T20:28:20.903509: step 19036, loss 0.102883, acc 0.96875\n",
      "2017-04-03T20:28:21.105346: step 19037, loss 0.19289, acc 0.921875\n",
      "2017-04-03T20:28:21.309507: step 19038, loss 0.165792, acc 0.953125\n",
      "2017-04-03T20:28:21.556083: step 19039, loss 0.123866, acc 0.9375\n",
      "2017-04-03T20:28:21.774319: step 19040, loss 0.15344, acc 0.953125\n",
      "2017-04-03T20:28:21.996679: step 19041, loss 0.0766585, acc 0.96875\n",
      "2017-04-03T20:28:22.209964: step 19042, loss 0.160311, acc 0.9375\n",
      "2017-04-03T20:28:22.420959: step 19043, loss 0.0333237, acc 0.984375\n",
      "2017-04-03T20:28:22.623901: step 19044, loss 0.0368732, acc 1\n",
      "2017-04-03T20:28:22.823658: step 19045, loss 0.0942645, acc 0.96875\n",
      "2017-04-03T20:28:23.027695: step 19046, loss 0.0624402, acc 0.984375\n",
      "2017-04-03T20:28:23.228479: step 19047, loss 0.0326369, acc 1\n",
      "2017-04-03T20:28:23.431062: step 19048, loss 0.0189441, acc 1\n",
      "2017-04-03T20:28:23.633944: step 19049, loss 0.0701167, acc 0.96875\n",
      "2017-04-03T20:28:23.834779: step 19050, loss 0.0681266, acc 0.96875\n",
      "2017-04-03T20:28:24.075277: step 19051, loss 0.103187, acc 0.984375\n",
      "2017-04-03T20:28:24.279815: step 19052, loss 0.0238306, acc 1\n",
      "2017-04-03T20:28:24.481252: step 19053, loss 0.0526744, acc 1\n",
      "2017-04-03T20:28:24.679299: step 19054, loss 0.0924074, acc 0.96875\n",
      "2017-04-03T20:28:24.894760: step 19055, loss 0.0999811, acc 0.96875\n",
      "2017-04-03T20:28:25.097555: step 19056, loss 0.0309676, acc 1\n",
      "2017-04-03T20:28:25.299452: step 19057, loss 0.0980662, acc 0.96875\n",
      "2017-04-03T20:28:25.504343: step 19058, loss 0.162037, acc 0.953125\n",
      "2017-04-03T20:28:25.705426: step 19059, loss 0.0899702, acc 0.96875\n",
      "2017-04-03T20:28:25.905865: step 19060, loss 0.187936, acc 0.953125\n",
      "2017-04-03T20:28:26.110115: step 19061, loss 0.0745494, acc 1\n",
      "2017-04-03T20:28:26.312433: step 19062, loss 0.16667, acc 0.953125\n",
      "2017-04-03T20:28:26.518953: step 19063, loss 0.154741, acc 0.9375\n",
      "2017-04-03T20:28:26.734970: step 19064, loss 0.0633761, acc 0.984375\n",
      "2017-04-03T20:28:26.949791: step 19065, loss 0.111019, acc 0.96875\n",
      "2017-04-03T20:28:27.156119: step 19066, loss 0.0656455, acc 0.96875\n",
      "2017-04-03T20:28:27.406080: step 19067, loss 0.29522, acc 0.953125\n",
      "2017-04-03T20:28:27.605405: step 19068, loss 0.0747011, acc 0.984375\n",
      "2017-04-03T20:28:27.810021: step 19069, loss 0.209445, acc 0.953125\n",
      "2017-04-03T20:28:28.034411: step 19070, loss 0.11574, acc 0.96875\n",
      "2017-04-03T20:28:28.237282: step 19071, loss 0.0771389, acc 0.984375\n",
      "2017-04-03T20:28:28.440496: step 19072, loss 0.156322, acc 0.953125\n",
      "2017-04-03T20:28:28.694861: step 19073, loss 0.0573398, acc 0.984375\n",
      "2017-04-03T20:28:28.897465: step 19074, loss 0.0851458, acc 0.984375\n",
      "2017-04-03T20:28:29.101428: step 19075, loss 0.0995305, acc 0.96875\n",
      "2017-04-03T20:28:29.307021: step 19076, loss 0.072231, acc 0.96875\n",
      "2017-04-03T20:28:29.552594: step 19077, loss 0.0443693, acc 1\n",
      "2017-04-03T20:28:29.781708: step 19078, loss 0.165057, acc 0.9375\n",
      "2017-04-03T20:28:29.991892: step 19079, loss 0.284081, acc 0.953125\n",
      "2017-04-03T20:28:30.200325: step 19080, loss 0.325082, acc 0.953125\n",
      "2017-04-03T20:28:30.406500: step 19081, loss 0.302641, acc 0.921875\n",
      "2017-04-03T20:28:30.606198: step 19082, loss 0.404809, acc 0.9375\n",
      "2017-04-03T20:28:30.808075: step 19083, loss 0.0833268, acc 0.96875\n",
      "2017-04-03T20:28:31.013970: step 19084, loss 0.0563565, acc 0.96875\n",
      "2017-04-03T20:28:31.255926: step 19085, loss 0.0584503, acc 0.984375\n",
      "2017-04-03T20:28:31.464038: step 19086, loss 0.0780176, acc 0.984375\n",
      "2017-04-03T20:28:31.665791: step 19087, loss 0.145666, acc 0.953125\n",
      "2017-04-03T20:28:31.867292: step 19088, loss 0.0339714, acc 0.984375\n",
      "2017-04-03T20:28:32.068789: step 19089, loss 0.0275593, acc 1\n",
      "2017-04-03T20:28:32.272253: step 19090, loss 0.0494417, acc 1\n",
      "2017-04-03T20:28:32.473255: step 19091, loss 0.0904821, acc 0.984375\n",
      "2017-04-03T20:28:32.682387: step 19092, loss 0.0906848, acc 0.984375\n",
      "2017-04-03T20:28:32.888675: step 19093, loss 0.238758, acc 0.90625\n",
      "2017-04-03T20:28:33.088515: step 19094, loss 0.154183, acc 0.953125\n",
      "2017-04-03T20:28:33.336252: step 19095, loss 0.301814, acc 0.9375\n",
      "2017-04-03T20:28:33.566679: step 19096, loss 0.113018, acc 0.953125\n",
      "2017-04-03T20:28:33.816431: step 19097, loss 0.147487, acc 0.9375\n",
      "2017-04-03T20:28:34.024233: step 19098, loss 0.0814584, acc 0.953125\n",
      "2017-04-03T20:28:34.225086: step 19099, loss 0.184153, acc 0.953125\n",
      "2017-04-03T20:28:34.431001: step 19100, loss 0.15525, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:28:36.566211: step 19100, loss 7.2075, acc 0.27825\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-19100\n",
      "\n",
      "2017-04-03T20:28:36.913350: step 19101, loss 0.136275, acc 0.953125\n",
      "2017-04-03T20:28:37.130239: step 19102, loss 0.119359, acc 0.96875\n",
      "2017-04-03T20:28:37.339188: step 19103, loss 0.13082, acc 0.9375\n",
      "2017-04-03T20:28:37.540812: step 19104, loss 0.0626155, acc 0.984375\n",
      "2017-04-03T20:28:37.742628: step 19105, loss 0.0924335, acc 0.96875\n",
      "2017-04-03T20:28:37.944570: step 19106, loss 0.0843486, acc 0.96875\n",
      "2017-04-03T20:28:38.145174: step 19107, loss 0.143416, acc 0.953125\n",
      "2017-04-03T20:28:38.350202: step 19108, loss 0.145414, acc 0.953125\n",
      "2017-04-03T20:28:38.557734: step 19109, loss 0.223286, acc 0.96875\n",
      "2017-04-03T20:28:38.762042: step 19110, loss 0.0447522, acc 1\n",
      "2017-04-03T20:28:38.964501: step 19111, loss 0.0760938, acc 0.984375\n",
      "2017-04-03T20:28:39.163756: step 19112, loss 0.0273405, acc 0.984375\n",
      "2017-04-03T20:28:39.364703: step 19113, loss 0.165368, acc 0.9375\n",
      "2017-04-03T20:28:39.581159: step 19114, loss 0.0592744, acc 0.984375\n",
      "2017-04-03T20:28:39.798892: step 19115, loss 0.0732707, acc 0.984375\n",
      "2017-04-03T20:28:39.999061: step 19116, loss 0.0620564, acc 0.953125\n",
      "2017-04-03T20:28:40.202060: step 19117, loss 0.182523, acc 0.9375\n",
      "2017-04-03T20:28:40.404580: step 19118, loss 0.0582764, acc 0.984375\n",
      "2017-04-03T20:28:40.612123: step 19119, loss 0.123205, acc 0.984375\n",
      "2017-04-03T20:28:40.815418: step 19120, loss 0.0724113, acc 0.984375\n",
      "2017-04-03T20:28:41.016619: step 19121, loss 0.0673357, acc 0.984375\n",
      "2017-04-03T20:28:41.260617: step 19122, loss 0.148174, acc 0.953125\n",
      "2017-04-03T20:28:41.470741: step 19123, loss 0.0945311, acc 0.984375\n",
      "2017-04-03T20:28:41.676143: step 19124, loss 0.117366, acc 0.9375\n",
      "2017-04-03T20:28:41.878888: step 19125, loss 0.268928, acc 0.9375\n",
      "2017-04-03T20:28:42.079951: step 19126, loss 0.164781, acc 0.953125\n",
      "2017-04-03T20:28:42.287073: step 19127, loss 0.107416, acc 0.96875\n",
      "2017-04-03T20:28:42.488231: step 19128, loss 0.0826699, acc 0.96875\n",
      "2017-04-03T20:28:42.690675: step 19129, loss 0.0841591, acc 0.96875\n",
      "2017-04-03T20:28:42.890950: step 19130, loss 0.0533657, acc 0.984375\n",
      "2017-04-03T20:28:43.092244: step 19131, loss 0.038952, acc 1\n",
      "2017-04-03T20:28:43.293859: step 19132, loss 0.0649712, acc 0.96875\n",
      "2017-04-03T20:28:43.542347: step 19133, loss 0.165877, acc 0.890625\n",
      "2017-04-03T20:28:43.756933: step 19134, loss 0.0414846, acc 1\n",
      "2017-04-03T20:28:43.967747: step 19135, loss 0.10018, acc 0.953125\n",
      "2017-04-03T20:28:44.174205: step 19136, loss 0.152186, acc 0.96875\n",
      "2017-04-03T20:28:44.385983: step 19137, loss 0.0827995, acc 0.96875\n",
      "2017-04-03T20:28:44.594964: step 19138, loss 0.0609625, acc 0.96875\n",
      "2017-04-03T20:28:44.793427: step 19139, loss 0.106383, acc 0.96875\n",
      "2017-04-03T20:28:45.012991: step 19140, loss 0.0344302, acc 1\n",
      "2017-04-03T20:28:45.224293: step 19141, loss 0.0575782, acc 0.96875\n",
      "2017-04-03T20:28:45.369368: step 19142, loss 0.299408, acc 0.96875\n",
      "2017-04-03T20:28:45.575440: step 19143, loss 0.0611356, acc 0.984375\n",
      "2017-04-03T20:28:45.777748: step 19144, loss 0.0482777, acc 0.984375\n",
      "2017-04-03T20:28:45.981906: step 19145, loss 0.0356541, acc 1\n",
      "2017-04-03T20:28:46.187136: step 19146, loss 0.0540326, acc 0.984375\n",
      "2017-04-03T20:28:46.386272: step 19147, loss 0.0294062, acc 1\n",
      "2017-04-03T20:28:46.629638: step 19148, loss 0.0743617, acc 0.9375\n",
      "2017-04-03T20:28:46.831196: step 19149, loss 0.12642, acc 0.96875\n",
      "2017-04-03T20:28:47.063020: step 19150, loss 0.0802999, acc 0.96875\n",
      "2017-04-03T20:28:47.280821: step 19151, loss 0.0305893, acc 0.984375\n",
      "2017-04-03T20:28:47.501081: step 19152, loss 0.0467689, acc 0.984375\n",
      "2017-04-03T20:28:47.699683: step 19153, loss 0.103014, acc 0.953125\n",
      "2017-04-03T20:28:47.905825: step 19154, loss 0.0333243, acc 1\n",
      "2017-04-03T20:28:48.109582: step 19155, loss 0.0152576, acc 1\n",
      "2017-04-03T20:28:48.317167: step 19156, loss 0.070287, acc 0.984375\n",
      "2017-04-03T20:28:48.518847: step 19157, loss 0.0503636, acc 0.984375\n",
      "2017-04-03T20:28:48.765434: step 19158, loss 0.0240042, acc 1\n",
      "2017-04-03T20:28:48.974175: step 19159, loss 0.0385704, acc 0.984375\n",
      "2017-04-03T20:28:49.218912: step 19160, loss 0.210178, acc 0.921875\n",
      "2017-04-03T20:28:49.429695: step 19161, loss 0.0599614, acc 0.96875\n",
      "2017-04-03T20:28:49.632626: step 19162, loss 0.108032, acc 0.96875\n",
      "2017-04-03T20:28:49.836006: step 19163, loss 0.051227, acc 0.96875\n",
      "2017-04-03T20:28:50.045024: step 19164, loss 0.126058, acc 0.96875\n",
      "2017-04-03T20:28:50.248130: step 19165, loss 0.0264745, acc 0.984375\n",
      "2017-04-03T20:28:50.451980: step 19166, loss 0.144689, acc 0.953125\n",
      "2017-04-03T20:28:50.650469: step 19167, loss 0.134617, acc 0.96875\n",
      "2017-04-03T20:28:50.851579: step 19168, loss 0.119033, acc 0.96875\n",
      "2017-04-03T20:28:51.054916: step 19169, loss 0.0854698, acc 0.984375\n",
      "2017-04-03T20:28:51.260440: step 19170, loss 0.0851541, acc 0.984375\n",
      "2017-04-03T20:28:51.461712: step 19171, loss 0.103268, acc 0.953125\n",
      "2017-04-03T20:28:51.662137: step 19172, loss 0.0236179, acc 1\n",
      "2017-04-03T20:28:51.878807: step 19173, loss 0.0367793, acc 0.984375\n",
      "2017-04-03T20:28:52.132540: step 19174, loss 0.0272025, acc 1\n",
      "2017-04-03T20:28:52.334285: step 19175, loss 0.0531993, acc 0.96875\n",
      "2017-04-03T20:28:52.535275: step 19176, loss 0.100482, acc 0.96875\n",
      "2017-04-03T20:28:52.734948: step 19177, loss 0.13625, acc 0.953125\n",
      "2017-04-03T20:28:52.940837: step 19178, loss 0.0756002, acc 0.984375\n",
      "2017-04-03T20:28:53.182984: step 19179, loss 0.028899, acc 1\n",
      "2017-04-03T20:28:53.429884: step 19180, loss 0.0390727, acc 1\n",
      "2017-04-03T20:28:53.634647: step 19181, loss 0.0834698, acc 0.984375\n",
      "2017-04-03T20:28:53.832928: step 19182, loss 0.13398, acc 0.96875\n",
      "2017-04-03T20:28:54.037696: step 19183, loss 0.253492, acc 0.96875\n",
      "2017-04-03T20:28:54.240242: step 19184, loss 0.0620037, acc 0.984375\n",
      "2017-04-03T20:28:54.443229: step 19185, loss 0.0658809, acc 0.984375\n",
      "2017-04-03T20:28:54.685585: step 19186, loss 0.0835673, acc 0.96875\n",
      "2017-04-03T20:28:54.896465: step 19187, loss 0.0164398, acc 1\n",
      "2017-04-03T20:28:55.114287: step 19188, loss 0.103985, acc 0.96875\n",
      "2017-04-03T20:28:55.319317: step 19189, loss 0.208883, acc 0.9375\n",
      "2017-04-03T20:28:55.539832: step 19190, loss 0.0992193, acc 0.9375\n",
      "2017-04-03T20:28:55.753476: step 19191, loss 0.0337567, acc 1\n",
      "2017-04-03T20:28:55.977972: step 19192, loss 0.0948495, acc 0.96875\n",
      "2017-04-03T20:28:56.190248: step 19193, loss 0.166522, acc 0.953125\n",
      "2017-04-03T20:28:56.406857: step 19194, loss 0.0663729, acc 0.984375\n",
      "2017-04-03T20:28:56.611684: step 19195, loss 0.292108, acc 0.90625\n",
      "2017-04-03T20:28:56.812563: step 19196, loss 0.084651, acc 0.96875\n",
      "2017-04-03T20:28:57.027158: step 19197, loss 0.0836235, acc 0.953125\n",
      "2017-04-03T20:28:57.265392: step 19198, loss 0.0748811, acc 0.96875\n",
      "2017-04-03T20:28:57.481774: step 19199, loss 0.110007, acc 0.984375\n",
      "2017-04-03T20:28:57.683194: step 19200, loss 0.0706332, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:28:59.822152: step 19200, loss 7.22864, acc 0.27275\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-19200\n",
      "\n",
      "2017-04-03T20:29:00.151706: step 19201, loss 0.0410229, acc 1\n",
      "2017-04-03T20:29:00.358549: step 19202, loss 0.0964176, acc 0.96875\n",
      "2017-04-03T20:29:00.563775: step 19203, loss 0.0213134, acc 1\n",
      "2017-04-03T20:29:00.774144: step 19204, loss 0.055251, acc 0.984375\n",
      "2017-04-03T20:29:00.979050: step 19205, loss 0.0704874, acc 0.96875\n",
      "2017-04-03T20:29:01.188133: step 19206, loss 0.128641, acc 0.953125\n",
      "2017-04-03T20:29:01.397656: step 19207, loss 0.0620844, acc 0.984375\n",
      "2017-04-03T20:29:01.599468: step 19208, loss 0.0435403, acc 0.984375\n",
      "2017-04-03T20:29:01.803043: step 19209, loss 0.124327, acc 0.96875\n",
      "2017-04-03T20:29:02.045803: step 19210, loss 0.17222, acc 0.953125\n",
      "2017-04-03T20:29:02.288535: step 19211, loss 0.0958613, acc 0.953125\n",
      "2017-04-03T20:29:02.490625: step 19212, loss 0.133008, acc 0.921875\n",
      "2017-04-03T20:29:02.699507: step 19213, loss 0.032162, acc 1\n",
      "2017-04-03T20:29:02.905786: step 19214, loss 0.142408, acc 0.953125\n",
      "2017-04-03T20:29:03.108834: step 19215, loss 0.224394, acc 0.953125\n",
      "2017-04-03T20:29:03.350776: step 19216, loss 0.0940756, acc 0.96875\n",
      "2017-04-03T20:29:03.577528: step 19217, loss 0.0473212, acc 1\n",
      "2017-04-03T20:29:03.796780: step 19218, loss 0.081539, acc 0.96875\n",
      "2017-04-03T20:29:03.998620: step 19219, loss 0.0338835, acc 1\n",
      "2017-04-03T20:29:04.203046: step 19220, loss 0.0749129, acc 0.984375\n",
      "2017-04-03T20:29:04.403406: step 19221, loss 0.0812169, acc 0.96875\n",
      "2017-04-03T20:29:04.640081: step 19222, loss 0.059065, acc 0.96875\n",
      "2017-04-03T20:29:04.883286: step 19223, loss 0.0889752, acc 0.96875\n",
      "2017-04-03T20:29:05.095880: step 19224, loss 0.123441, acc 0.9375\n",
      "2017-04-03T20:29:05.294108: step 19225, loss 0.109995, acc 0.953125\n",
      "2017-04-03T20:29:05.502216: step 19226, loss 0.0944549, acc 0.953125\n",
      "2017-04-03T20:29:05.703294: step 19227, loss 0.121807, acc 0.96875\n",
      "2017-04-03T20:29:05.904572: step 19228, loss 0.109416, acc 0.953125\n",
      "2017-04-03T20:29:06.150925: step 19229, loss 0.131937, acc 0.953125\n",
      "2017-04-03T20:29:06.353108: step 19230, loss 0.138967, acc 0.984375\n",
      "2017-04-03T20:29:06.554115: step 19231, loss 0.0181493, acc 1\n",
      "2017-04-03T20:29:06.751715: step 19232, loss 0.165433, acc 0.953125\n",
      "2017-04-03T20:29:06.960203: step 19233, loss 0.0691284, acc 1\n",
      "2017-04-03T20:29:07.161765: step 19234, loss 0.091616, acc 0.96875\n",
      "2017-04-03T20:29:07.367019: step 19235, loss 0.176014, acc 0.9375\n",
      "2017-04-03T20:29:07.567162: step 19236, loss 0.065568, acc 0.984375\n",
      "2017-04-03T20:29:07.764360: step 19237, loss 0.0824805, acc 1\n",
      "2017-04-03T20:29:07.968636: step 19238, loss 0.233713, acc 0.9375\n",
      "2017-04-03T20:29:08.173090: step 19239, loss 0.0477397, acc 0.984375\n",
      "2017-04-03T20:29:08.395877: step 19240, loss 0.0619354, acc 0.96875\n",
      "2017-04-03T20:29:08.612056: step 19241, loss 0.0217946, acc 1\n",
      "2017-04-03T20:29:08.819746: step 19242, loss 0.228216, acc 0.9375\n",
      "2017-04-03T20:29:09.024719: step 19243, loss 0.0662148, acc 0.984375\n",
      "2017-04-03T20:29:09.228077: step 19244, loss 0.0361575, acc 1\n",
      "2017-04-03T20:29:09.447323: step 19245, loss 0.0131867, acc 1\n",
      "2017-04-03T20:29:09.663134: step 19246, loss 0.0152121, acc 1\n",
      "2017-04-03T20:29:09.862069: step 19247, loss 0.148714, acc 0.953125\n",
      "2017-04-03T20:29:10.061733: step 19248, loss 0.0187404, acc 1\n",
      "2017-04-03T20:29:10.264824: step 19249, loss 0.109657, acc 0.984375\n",
      "2017-04-03T20:29:10.461872: step 19250, loss 0.0490815, acc 1\n",
      "2017-04-03T20:29:10.666983: step 19251, loss 0.177703, acc 0.9375\n",
      "2017-04-03T20:29:10.869349: step 19252, loss 0.0863595, acc 0.984375\n",
      "2017-04-03T20:29:11.072954: step 19253, loss 0.0314269, acc 1\n",
      "2017-04-03T20:29:11.279458: step 19254, loss 0.100248, acc 0.96875\n",
      "2017-04-03T20:29:11.478036: step 19255, loss 0.112181, acc 0.953125\n",
      "2017-04-03T20:29:11.684030: step 19256, loss 0.0271323, acc 1\n",
      "2017-04-03T20:29:11.935765: step 19257, loss 0.0511642, acc 0.984375\n",
      "2017-04-03T20:29:12.143760: step 19258, loss 0.142235, acc 0.96875\n",
      "2017-04-03T20:29:12.366744: step 19259, loss 0.0505914, acc 0.984375\n",
      "2017-04-03T20:29:12.574865: step 19260, loss 0.109397, acc 0.953125\n",
      "2017-04-03T20:29:12.778947: step 19261, loss 0.221662, acc 0.921875\n",
      "2017-04-03T20:29:13.020738: step 19262, loss 0.074077, acc 0.96875\n",
      "2017-04-03T20:29:13.220929: step 19263, loss 0.197348, acc 0.9375\n",
      "2017-04-03T20:29:13.427984: step 19264, loss 0.18351, acc 0.9375\n",
      "2017-04-03T20:29:13.647919: step 19265, loss 0.255976, acc 0.90625\n",
      "2017-04-03T20:29:13.869230: step 19266, loss 0.100245, acc 0.96875\n",
      "2017-04-03T20:29:14.086081: step 19267, loss 0.0532838, acc 0.96875\n",
      "2017-04-03T20:29:14.301884: step 19268, loss 0.110448, acc 0.953125\n",
      "2017-04-03T20:29:14.521134: step 19269, loss 0.122324, acc 0.96875\n",
      "2017-04-03T20:29:14.737519: step 19270, loss 0.0876226, acc 0.96875\n",
      "2017-04-03T20:29:14.955165: step 19271, loss 0.0665807, acc 0.984375\n",
      "2017-04-03T20:29:15.171083: step 19272, loss 0.0267968, acc 0.984375\n",
      "2017-04-03T20:29:15.413595: step 19273, loss 0.110148, acc 0.953125\n",
      "2017-04-03T20:29:15.618640: step 19274, loss 0.0498847, acc 0.984375\n",
      "2017-04-03T20:29:15.823256: step 19275, loss 0.0627374, acc 0.984375\n",
      "2017-04-03T20:29:16.033241: step 19276, loss 0.0389315, acc 0.984375\n",
      "2017-04-03T20:29:16.270106: step 19277, loss 0.041219, acc 1\n",
      "2017-04-03T20:29:16.471727: step 19278, loss 0.100903, acc 0.953125\n",
      "2017-04-03T20:29:16.671019: step 19279, loss 0.0618248, acc 0.984375\n",
      "2017-04-03T20:29:16.871055: step 19280, loss 0.0736638, acc 0.984375\n",
      "2017-04-03T20:29:17.076193: step 19281, loss 0.0242585, acc 1\n",
      "2017-04-03T20:29:17.318220: step 19282, loss 0.0652305, acc 0.984375\n",
      "2017-04-03T20:29:17.520928: step 19283, loss 0.0873308, acc 0.984375\n",
      "2017-04-03T20:29:17.721938: step 19284, loss 0.0553493, acc 0.984375\n",
      "2017-04-03T20:29:17.933179: step 19285, loss 0.0869727, acc 0.984375\n",
      "2017-04-03T20:29:18.153550: step 19286, loss 0.091204, acc 0.96875\n",
      "2017-04-03T20:29:18.371479: step 19287, loss 0.0164418, acc 1\n",
      "2017-04-03T20:29:18.588973: step 19288, loss 0.109832, acc 0.96875\n",
      "2017-04-03T20:29:18.798181: step 19289, loss 0.113886, acc 0.96875\n",
      "2017-04-03T20:29:19.004695: step 19290, loss 0.0807988, acc 1\n",
      "2017-04-03T20:29:19.207701: step 19291, loss 0.0400154, acc 1\n",
      "2017-04-03T20:29:19.410970: step 19292, loss 0.162959, acc 0.953125\n",
      "2017-04-03T20:29:19.671408: step 19293, loss 0.10427, acc 0.984375\n",
      "2017-04-03T20:29:19.875603: step 19294, loss 0.016731, acc 1\n",
      "2017-04-03T20:29:20.077246: step 19295, loss 0.240872, acc 0.890625\n",
      "2017-04-03T20:29:20.273047: step 19296, loss 0.0345522, acc 1\n",
      "2017-04-03T20:29:20.489308: step 19297, loss 0.139795, acc 0.96875\n",
      "2017-04-03T20:29:20.708583: step 19298, loss 0.143046, acc 0.96875\n",
      "2017-04-03T20:29:20.908198: step 19299, loss 0.161847, acc 0.96875\n",
      "2017-04-03T20:29:21.108837: step 19300, loss 0.129218, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:29:23.272848: step 19300, loss 7.30844, acc 0.2785\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-19300\n",
      "\n",
      "2017-04-03T20:29:23.635347: step 19301, loss 0.0784303, acc 0.96875\n",
      "2017-04-03T20:29:23.835063: step 19302, loss 0.112899, acc 0.96875\n",
      "2017-04-03T20:29:24.035054: step 19303, loss 0.0551831, acc 0.984375\n",
      "2017-04-03T20:29:24.236682: step 19304, loss 0.115085, acc 0.953125\n",
      "2017-04-03T20:29:24.437751: step 19305, loss 0.0338827, acc 1\n",
      "2017-04-03T20:29:24.638641: step 19306, loss 0.0308675, acc 1\n",
      "2017-04-03T20:29:24.879685: step 19307, loss 0.0803212, acc 0.96875\n",
      "2017-04-03T20:29:25.089336: step 19308, loss 0.159067, acc 0.90625\n",
      "2017-04-03T20:29:25.291517: step 19309, loss 0.107688, acc 0.953125\n",
      "2017-04-03T20:29:25.498237: step 19310, loss 0.0936023, acc 0.96875\n",
      "2017-04-03T20:29:25.700474: step 19311, loss 0.104033, acc 0.96875\n",
      "2017-04-03T20:29:25.907552: step 19312, loss 0.087034, acc 0.953125\n",
      "2017-04-03T20:29:26.107874: step 19313, loss 0.0259324, acc 0.984375\n",
      "2017-04-03T20:29:26.309454: step 19314, loss 0.180707, acc 0.96875\n",
      "2017-04-03T20:29:26.510156: step 19315, loss 0.2234, acc 0.9375\n",
      "2017-04-03T20:29:26.711031: step 19316, loss 0.066949, acc 0.96875\n",
      "2017-04-03T20:29:26.915130: step 19317, loss 0.0576249, acc 1\n",
      "2017-04-03T20:29:27.114328: step 19318, loss 0.0570495, acc 0.984375\n",
      "2017-04-03T20:29:27.355693: step 19319, loss 0.0408587, acc 0.96875\n",
      "2017-04-03T20:29:27.557244: step 19320, loss 0.319146, acc 0.90625\n",
      "2017-04-03T20:29:27.766091: step 19321, loss 0.046094, acc 1\n",
      "2017-04-03T20:29:27.981168: step 19322, loss 0.239564, acc 0.90625\n",
      "2017-04-03T20:29:28.184664: step 19323, loss 0.0303551, acc 1\n",
      "2017-04-03T20:29:28.382424: step 19324, loss 0.0336361, acc 1\n",
      "2017-04-03T20:29:28.584027: step 19325, loss 0.330121, acc 0.9375\n",
      "2017-04-03T20:29:28.783324: step 19326, loss 0.136687, acc 0.953125\n",
      "2017-04-03T20:29:28.986116: step 19327, loss 0.207157, acc 0.921875\n",
      "2017-04-03T20:29:29.234309: step 19328, loss 0.0282392, acc 1\n",
      "2017-04-03T20:29:29.435707: step 19329, loss 0.0297973, acc 1\n",
      "2017-04-03T20:29:29.633250: step 19330, loss 0.244348, acc 0.953125\n",
      "2017-04-03T20:29:29.843163: step 19331, loss 0.0451074, acc 0.984375\n",
      "2017-04-03T20:29:30.046660: step 19332, loss 0.0706696, acc 0.984375\n",
      "2017-04-03T20:29:30.250480: step 19333, loss 0.0182537, acc 0.984375\n",
      "2017-04-03T20:29:30.474400: step 19334, loss 0.155371, acc 0.953125\n",
      "2017-04-03T20:29:30.688772: step 19335, loss 0.0357329, acc 0.984375\n",
      "2017-04-03T20:29:30.912240: step 19336, loss 0.0859855, acc 0.984375\n",
      "2017-04-03T20:29:31.129681: step 19337, loss 0.0721578, acc 0.953125\n",
      "2017-04-03T20:29:31.344562: step 19338, loss 0.0170049, acc 1\n",
      "2017-04-03T20:29:31.547254: step 19339, loss 0.0850376, acc 0.984375\n",
      "2017-04-03T20:29:31.752931: step 19340, loss 0.021581, acc 1\n",
      "2017-04-03T20:29:31.952853: step 19341, loss 0.0241567, acc 1\n",
      "2017-04-03T20:29:32.159232: step 19342, loss 0.0845716, acc 0.96875\n",
      "2017-04-03T20:29:32.373508: step 19343, loss 0.125949, acc 0.9375\n",
      "2017-04-03T20:29:32.587726: step 19344, loss 0.0723965, acc 0.96875\n",
      "2017-04-03T20:29:32.796779: step 19345, loss 0.0435912, acc 1\n",
      "2017-04-03T20:29:33.014153: step 19346, loss 0.0302242, acc 1\n",
      "2017-04-03T20:29:33.231526: step 19347, loss 0.267616, acc 0.90625\n",
      "2017-04-03T20:29:33.428667: step 19348, loss 0.057073, acc 0.96875\n",
      "2017-04-03T20:29:33.627834: step 19349, loss 0.0475064, acc 0.984375\n",
      "2017-04-03T20:29:33.826350: step 19350, loss 0.139256, acc 0.9375\n",
      "2017-04-03T20:29:34.026339: step 19351, loss 0.0642042, acc 0.96875\n",
      "2017-04-03T20:29:34.267332: step 19352, loss 0.0726779, acc 0.984375\n",
      "2017-04-03T20:29:34.507332: step 19353, loss 0.161379, acc 0.953125\n",
      "2017-04-03T20:29:34.734069: step 19354, loss 0.123577, acc 0.96875\n",
      "2017-04-03T20:29:34.952213: step 19355, loss 0.0377714, acc 1\n",
      "2017-04-03T20:29:35.170951: step 19356, loss 0.107529, acc 0.984375\n",
      "2017-04-03T20:29:35.372326: step 19357, loss 0.0803281, acc 0.984375\n",
      "2017-04-03T20:29:35.570579: step 19358, loss 0.108152, acc 0.984375\n",
      "2017-04-03T20:29:35.770336: step 19359, loss 0.0845482, acc 0.9375\n",
      "2017-04-03T20:29:35.970385: step 19360, loss 0.0647889, acc 0.953125\n",
      "2017-04-03T20:29:36.172640: step 19361, loss 0.0946494, acc 0.96875\n",
      "2017-04-03T20:29:36.375492: step 19362, loss 0.0162646, acc 1\n",
      "2017-04-03T20:29:36.574243: step 19363, loss 0.18714, acc 0.9375\n",
      "2017-04-03T20:29:36.775277: step 19364, loss 0.141426, acc 0.984375\n",
      "2017-04-03T20:29:36.977046: step 19365, loss 0.0766701, acc 0.96875\n",
      "2017-04-03T20:29:37.179067: step 19366, loss 0.0921023, acc 0.96875\n",
      "2017-04-03T20:29:37.383212: step 19367, loss 0.18724, acc 0.953125\n",
      "2017-04-03T20:29:37.583903: step 19368, loss 0.244749, acc 0.953125\n",
      "2017-04-03T20:29:37.781136: step 19369, loss 0.028227, acc 1\n",
      "2017-04-03T20:29:37.992226: step 19370, loss 0.0536378, acc 0.984375\n",
      "2017-04-03T20:29:38.198687: step 19371, loss 0.175444, acc 0.9375\n",
      "2017-04-03T20:29:38.394747: step 19372, loss 0.0979095, acc 0.984375\n",
      "2017-04-03T20:29:38.595820: step 19373, loss 0.106675, acc 0.96875\n",
      "2017-04-03T20:29:38.799281: step 19374, loss 0.169615, acc 0.921875\n",
      "2017-04-03T20:29:39.028175: step 19375, loss 0.0769272, acc 0.96875\n",
      "2017-04-03T20:29:39.249307: step 19376, loss 0.243826, acc 0.9375\n",
      "2017-04-03T20:29:39.493387: step 19377, loss 0.197658, acc 0.953125\n",
      "2017-04-03T20:29:39.705375: step 19378, loss 0.0644595, acc 0.984375\n",
      "2017-04-03T20:29:39.955098: step 19379, loss 0.047379, acc 0.96875\n",
      "2017-04-03T20:29:40.151749: step 19380, loss 0.056089, acc 0.96875\n",
      "2017-04-03T20:29:40.352349: step 19381, loss 0.140777, acc 0.953125\n",
      "2017-04-03T20:29:40.554375: step 19382, loss 0.0198201, acc 1\n",
      "2017-04-03T20:29:40.751172: step 19383, loss 0.0254222, acc 1\n",
      "2017-04-03T20:29:40.956830: step 19384, loss 0.0780732, acc 0.984375\n",
      "2017-04-03T20:29:41.164209: step 19385, loss 0.115147, acc 0.96875\n",
      "2017-04-03T20:29:41.368023: step 19386, loss 0.218447, acc 0.9375\n",
      "2017-04-03T20:29:41.568684: step 19387, loss 0.044987, acc 0.96875\n",
      "2017-04-03T20:29:41.766611: step 19388, loss 0.0948687, acc 0.96875\n",
      "2017-04-03T20:29:42.010690: step 19389, loss 0.0712669, acc 0.953125\n",
      "2017-04-03T20:29:42.220524: step 19390, loss 0.0797507, acc 1\n",
      "2017-04-03T20:29:42.421269: step 19391, loss 0.145461, acc 0.96875\n",
      "2017-04-03T20:29:42.633027: step 19392, loss 0.0427183, acc 1\n",
      "2017-04-03T20:29:42.838643: step 19393, loss 0.240425, acc 0.9375\n",
      "2017-04-03T20:29:43.039497: step 19394, loss 0.0184671, acc 1\n",
      "2017-04-03T20:29:43.247397: step 19395, loss 0.139881, acc 0.9375\n",
      "2017-04-03T20:29:43.450167: step 19396, loss 0.0975972, acc 0.9375\n",
      "2017-04-03T20:29:43.650147: step 19397, loss 0.0209033, acc 1\n",
      "2017-04-03T20:29:43.852133: step 19398, loss 0.0745758, acc 0.984375\n",
      "2017-04-03T20:29:44.058148: step 19399, loss 0.281269, acc 0.921875\n",
      "2017-04-03T20:29:44.264952: step 19400, loss 0.0879751, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:29:46.575436: step 19400, loss 7.4001, acc 0.28225\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-19400\n",
      "\n",
      "2017-04-03T20:29:46.912419: step 19401, loss 0.168065, acc 0.953125\n",
      "2017-04-03T20:29:47.133776: step 19402, loss 0.0403804, acc 1\n",
      "2017-04-03T20:29:47.330480: step 19403, loss 0.104286, acc 0.96875\n",
      "2017-04-03T20:29:47.537282: step 19404, loss 0.128461, acc 0.953125\n",
      "2017-04-03T20:29:47.744201: step 19405, loss 0.0768292, acc 0.96875\n",
      "2017-04-03T20:29:47.945594: step 19406, loss 0.185204, acc 0.953125\n",
      "2017-04-03T20:29:48.148304: step 19407, loss 0.104304, acc 0.953125\n",
      "2017-04-03T20:29:48.392197: step 19408, loss 0.121032, acc 0.953125\n",
      "2017-04-03T20:29:48.591768: step 19409, loss 0.036104, acc 0.984375\n",
      "2017-04-03T20:29:48.791690: step 19410, loss 0.0716377, acc 0.984375\n",
      "2017-04-03T20:29:48.995318: step 19411, loss 0.0590326, acc 0.984375\n",
      "2017-04-03T20:29:49.199674: step 19412, loss 0.183272, acc 0.921875\n",
      "2017-04-03T20:29:49.402554: step 19413, loss 0.231728, acc 0.96875\n",
      "2017-04-03T20:29:49.607782: step 19414, loss 0.160797, acc 0.9375\n",
      "2017-04-03T20:29:49.810133: step 19415, loss 0.0509448, acc 1\n",
      "2017-04-03T20:29:50.008496: step 19416, loss 0.109439, acc 0.96875\n",
      "2017-04-03T20:29:50.209897: step 19417, loss 0.0639359, acc 0.984375\n",
      "2017-04-03T20:29:50.410137: step 19418, loss 0.0755363, acc 0.984375\n",
      "2017-04-03T20:29:50.616014: step 19419, loss 0.0723556, acc 0.984375\n",
      "2017-04-03T20:29:50.823882: step 19420, loss 0.0560887, acc 0.984375\n",
      "2017-04-03T20:29:51.024676: step 19421, loss 0.174644, acc 0.953125\n",
      "2017-04-03T20:29:51.224194: step 19422, loss 0.0891226, acc 0.953125\n",
      "2017-04-03T20:29:51.424548: step 19423, loss 0.165061, acc 0.9375\n",
      "2017-04-03T20:29:51.627565: step 19424, loss 0.0699571, acc 0.96875\n",
      "2017-04-03T20:29:51.832350: step 19425, loss 0.0547375, acc 0.96875\n",
      "2017-04-03T20:29:52.035999: step 19426, loss 0.0278687, acc 1\n",
      "2017-04-03T20:29:52.235734: step 19427, loss 0.033915, acc 0.984375\n",
      "2017-04-03T20:29:52.470587: step 19428, loss 0.0963822, acc 0.96875\n",
      "2017-04-03T20:29:52.666836: step 19429, loss 0.0963069, acc 0.953125\n",
      "2017-04-03T20:29:52.869835: step 19430, loss 0.0991555, acc 0.9375\n",
      "2017-04-03T20:29:53.066860: step 19431, loss 0.130339, acc 0.9375\n",
      "2017-04-03T20:29:53.264944: step 19432, loss 0.082566, acc 0.96875\n",
      "2017-04-03T20:29:53.462920: step 19433, loss 0.0783197, acc 0.984375\n",
      "2017-04-03T20:29:53.662678: step 19434, loss 0.0326406, acc 1\n",
      "2017-04-03T20:29:53.873503: step 19435, loss 0.100155, acc 0.984375\n",
      "2017-04-03T20:29:54.091089: step 19436, loss 0.0354142, acc 1\n",
      "2017-04-03T20:29:54.311432: step 19437, loss 0.193911, acc 0.96875\n",
      "2017-04-03T20:29:54.517196: step 19438, loss 0.203021, acc 0.921875\n",
      "2017-04-03T20:29:54.725247: step 19439, loss 0.0756895, acc 0.984375\n",
      "2017-04-03T20:29:54.926211: step 19440, loss 0.152503, acc 0.953125\n",
      "2017-04-03T20:29:55.128254: step 19441, loss 0.136689, acc 0.953125\n",
      "2017-04-03T20:29:55.340967: step 19442, loss 0.0722342, acc 0.984375\n",
      "2017-04-03T20:29:55.551898: step 19443, loss 0.113806, acc 0.984375\n",
      "2017-04-03T20:29:55.757233: step 19444, loss 0.163012, acc 0.96875\n",
      "2017-04-03T20:29:55.961819: step 19445, loss 0.0529701, acc 0.984375\n",
      "2017-04-03T20:29:56.170484: step 19446, loss 0.125967, acc 0.984375\n",
      "2017-04-03T20:29:56.380323: step 19447, loss 0.0649783, acc 0.984375\n",
      "2017-04-03T20:29:56.597990: step 19448, loss 0.0812514, acc 0.9375\n",
      "2017-04-03T20:29:56.799500: step 19449, loss 0.0613064, acc 0.96875\n",
      "2017-04-03T20:29:56.997370: step 19450, loss 0.122037, acc 0.96875\n",
      "2017-04-03T20:29:57.243206: step 19451, loss 0.035185, acc 1\n",
      "2017-04-03T20:29:57.445474: step 19452, loss 0.0894633, acc 0.96875\n",
      "2017-04-03T20:29:57.646644: step 19453, loss 0.0570568, acc 0.984375\n",
      "2017-04-03T20:29:57.847733: step 19454, loss 0.0935326, acc 0.953125\n",
      "2017-04-03T20:29:58.049396: step 19455, loss 0.102992, acc 0.96875\n",
      "2017-04-03T20:29:58.253507: step 19456, loss 0.0624385, acc 0.984375\n",
      "2017-04-03T20:29:58.490178: step 19457, loss 0.0518568, acc 0.96875\n",
      "2017-04-03T20:29:58.706761: step 19458, loss 0.17655, acc 0.953125\n",
      "2017-04-03T20:29:58.920609: step 19459, loss 0.0424534, acc 0.984375\n",
      "2017-04-03T20:29:59.142164: step 19460, loss 0.101312, acc 0.96875\n",
      "2017-04-03T20:29:59.361686: step 19461, loss 0.0668035, acc 0.984375\n",
      "2017-04-03T20:29:59.571728: step 19462, loss 0.241298, acc 0.953125\n",
      "2017-04-03T20:29:59.771610: step 19463, loss 0.140981, acc 0.953125\n",
      "2017-04-03T20:29:59.971421: step 19464, loss 0.0943888, acc 1\n",
      "2017-04-03T20:30:00.179243: step 19465, loss 0.127684, acc 0.9375\n",
      "2017-04-03T20:30:00.380596: step 19466, loss 0.0185049, acc 0.984375\n",
      "2017-04-03T20:30:00.583213: step 19467, loss 0.157694, acc 0.953125\n",
      "2017-04-03T20:30:00.792067: step 19468, loss 0.191636, acc 0.96875\n",
      "2017-04-03T20:30:00.997988: step 19469, loss 0.0524895, acc 0.984375\n",
      "2017-04-03T20:30:01.198519: step 19470, loss 0.0843515, acc 0.953125\n",
      "2017-04-03T20:30:01.400605: step 19471, loss 0.171023, acc 0.9375\n",
      "2017-04-03T20:30:01.603096: step 19472, loss 0.156701, acc 0.953125\n",
      "2017-04-03T20:30:01.804078: step 19473, loss 0.036869, acc 1\n",
      "2017-04-03T20:30:02.006883: step 19474, loss 0.114488, acc 0.953125\n",
      "2017-04-03T20:30:02.208706: step 19475, loss 0.0739008, acc 0.96875\n",
      "2017-04-03T20:30:02.410321: step 19476, loss 0.167152, acc 0.953125\n",
      "2017-04-03T20:30:02.625377: step 19477, loss 0.0944166, acc 0.96875\n",
      "2017-04-03T20:30:02.839381: step 19478, loss 0.129974, acc 0.96875\n",
      "2017-04-03T20:30:03.058231: step 19479, loss 0.166693, acc 0.9375\n",
      "2017-04-03T20:30:03.275880: step 19480, loss 0.108819, acc 0.96875\n",
      "2017-04-03T20:30:03.477231: step 19481, loss 0.273185, acc 0.90625\n",
      "2017-04-03T20:30:03.683533: step 19482, loss 0.132034, acc 0.953125\n",
      "2017-04-03T20:30:03.884041: step 19483, loss 0.0227782, acc 1\n",
      "2017-04-03T20:30:04.090933: step 19484, loss 0.0427328, acc 0.984375\n",
      "2017-04-03T20:30:04.339223: step 19485, loss 0.0880956, acc 0.96875\n",
      "2017-04-03T20:30:04.547587: step 19486, loss 0.0792334, acc 0.953125\n",
      "2017-04-03T20:30:04.789866: step 19487, loss 0.0148118, acc 1\n",
      "2017-04-03T20:30:04.992417: step 19488, loss 0.0961898, acc 0.984375\n",
      "2017-04-03T20:30:05.211727: step 19489, loss 0.0225996, acc 1\n",
      "2017-04-03T20:30:05.420301: step 19490, loss 0.104072, acc 0.953125\n",
      "2017-04-03T20:30:05.663181: step 19491, loss 0.098874, acc 0.96875\n",
      "2017-04-03T20:30:05.867919: step 19492, loss 0.0249449, acc 0.984375\n",
      "2017-04-03T20:30:06.069270: step 19493, loss 0.0501927, acc 0.984375\n",
      "2017-04-03T20:30:06.273573: step 19494, loss 0.0496664, acc 0.984375\n",
      "2017-04-03T20:30:06.473019: step 19495, loss 0.0522549, acc 0.96875\n",
      "2017-04-03T20:30:06.672698: step 19496, loss 0.0215695, acc 1\n",
      "2017-04-03T20:30:06.911364: step 19497, loss 0.0274943, acc 1\n",
      "2017-04-03T20:30:07.158423: step 19498, loss 0.114746, acc 0.96875\n",
      "2017-04-03T20:30:07.374258: step 19499, loss 0.0643095, acc 1\n",
      "2017-04-03T20:30:07.586541: step 19500, loss 0.0664815, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:30:09.707999: step 19500, loss 7.30427, acc 0.28375\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-19500\n",
      "\n",
      "2017-04-03T20:30:10.040177: step 19501, loss 0.223645, acc 0.953125\n",
      "2017-04-03T20:30:10.239685: step 19502, loss 0.104393, acc 0.96875\n",
      "2017-04-03T20:30:10.444733: step 19503, loss 0.194609, acc 0.9375\n",
      "2017-04-03T20:30:10.649709: step 19504, loss 0.0724267, acc 0.984375\n",
      "2017-04-03T20:30:10.850682: step 19505, loss 0.0771853, acc 0.96875\n",
      "2017-04-03T20:30:11.053522: step 19506, loss 0.0922193, acc 0.953125\n",
      "2017-04-03T20:30:11.255662: step 19507, loss 0.282717, acc 0.890625\n",
      "2017-04-03T20:30:11.454859: step 19508, loss 0.128806, acc 0.953125\n",
      "2017-04-03T20:30:11.656185: step 19509, loss 0.0486427, acc 0.984375\n",
      "2017-04-03T20:30:11.864053: step 19510, loss 0.0785733, acc 0.96875\n",
      "2017-04-03T20:30:12.077769: step 19511, loss 0.215404, acc 0.90625\n",
      "2017-04-03T20:30:12.280743: step 19512, loss 0.0685852, acc 0.96875\n",
      "2017-04-03T20:30:12.486612: step 19513, loss 0.125089, acc 0.953125\n",
      "2017-04-03T20:30:12.702160: step 19514, loss 0.157471, acc 0.96875\n",
      "2017-04-03T20:30:12.906529: step 19515, loss 0.139409, acc 0.953125\n",
      "2017-04-03T20:30:13.108669: step 19516, loss 0.0444764, acc 0.984375\n",
      "2017-04-03T20:30:13.309800: step 19517, loss 0.0831674, acc 0.96875\n",
      "2017-04-03T20:30:13.514143: step 19518, loss 0.157115, acc 0.96875\n",
      "2017-04-03T20:30:13.716531: step 19519, loss 0.0788829, acc 0.96875\n",
      "2017-04-03T20:30:13.918892: step 19520, loss 0.0814226, acc 0.984375\n",
      "2017-04-03T20:30:14.120223: step 19521, loss 0.148267, acc 0.953125\n",
      "2017-04-03T20:30:14.322189: step 19522, loss 0.0847223, acc 0.984375\n",
      "2017-04-03T20:30:14.524696: step 19523, loss 0.113177, acc 0.984375\n",
      "2017-04-03T20:30:14.731542: step 19524, loss 0.0424173, acc 0.984375\n",
      "2017-04-03T20:30:14.932043: step 19525, loss 0.121606, acc 0.953125\n",
      "2017-04-03T20:30:15.132259: step 19526, loss 0.0591062, acc 0.96875\n",
      "2017-04-03T20:30:15.377101: step 19527, loss 0.112824, acc 0.953125\n",
      "2017-04-03T20:30:15.583158: step 19528, loss 0.0339837, acc 0.984375\n",
      "2017-04-03T20:30:15.784961: step 19529, loss 0.0400952, acc 0.984375\n",
      "2017-04-03T20:30:15.989082: step 19530, loss 0.080156, acc 0.984375\n",
      "2017-04-03T20:30:16.240894: step 19531, loss 0.0574147, acc 0.984375\n",
      "2017-04-03T20:30:16.452879: step 19532, loss 0.0941411, acc 0.96875\n",
      "2017-04-03T20:30:16.651300: step 19533, loss 0.0637518, acc 0.96875\n",
      "2017-04-03T20:30:16.856127: step 19534, loss 0.0130853, acc 1\n",
      "2017-04-03T20:30:17.054960: step 19535, loss 0.0355994, acc 1\n",
      "2017-04-03T20:30:17.260690: step 19536, loss 0.0853088, acc 0.984375\n",
      "2017-04-03T20:30:17.461969: step 19537, loss 0.138128, acc 0.96875\n",
      "2017-04-03T20:30:17.665026: step 19538, loss 0.0326443, acc 1\n",
      "2017-04-03T20:30:17.866035: step 19539, loss 0.125885, acc 0.953125\n",
      "2017-04-03T20:30:18.078335: step 19540, loss 0.114882, acc 0.953125\n",
      "2017-04-03T20:30:18.287911: step 19541, loss 0.167211, acc 0.953125\n",
      "2017-04-03T20:30:18.531847: step 19542, loss 0.0397422, acc 0.984375\n",
      "2017-04-03T20:30:18.775012: step 19543, loss 0.0844409, acc 0.953125\n",
      "2017-04-03T20:30:18.974525: step 19544, loss 0.019073, acc 0.984375\n",
      "2017-04-03T20:30:19.176492: step 19545, loss 0.153677, acc 0.9375\n",
      "2017-04-03T20:30:19.387155: step 19546, loss 0.104731, acc 0.96875\n",
      "2017-04-03T20:30:19.584978: step 19547, loss 0.159728, acc 0.96875\n",
      "2017-04-03T20:30:19.787998: step 19548, loss 0.0726898, acc 0.984375\n",
      "2017-04-03T20:30:19.988627: step 19549, loss 0.0516963, acc 0.984375\n",
      "2017-04-03T20:30:20.192773: step 19550, loss 0.187408, acc 0.96875\n",
      "2017-04-03T20:30:20.412133: step 19551, loss 0.095229, acc 0.96875\n",
      "2017-04-03T20:30:20.636179: step 19552, loss 0.0427824, acc 0.984375\n",
      "2017-04-03T20:30:20.853680: step 19553, loss 0.154008, acc 0.953125\n",
      "2017-04-03T20:30:21.069309: step 19554, loss 0.0567095, acc 0.953125\n",
      "2017-04-03T20:30:21.289834: step 19555, loss 0.0608547, acc 0.984375\n",
      "2017-04-03T20:30:21.506762: step 19556, loss 0.0793197, acc 0.96875\n",
      "2017-04-03T20:30:21.727449: step 19557, loss 0.144256, acc 0.984375\n",
      "2017-04-03T20:30:21.954405: step 19558, loss 0.0152777, acc 1\n",
      "2017-04-03T20:30:22.172332: step 19559, loss 0.0650822, acc 0.984375\n",
      "2017-04-03T20:30:22.394515: step 19560, loss 0.124325, acc 0.953125\n",
      "2017-04-03T20:30:22.611497: step 19561, loss 0.242398, acc 0.921875\n",
      "2017-04-03T20:30:22.815137: step 19562, loss 0.0314305, acc 1\n",
      "2017-04-03T20:30:23.018547: step 19563, loss 0.0487302, acc 0.984375\n",
      "2017-04-03T20:30:23.222744: step 19564, loss 0.140366, acc 0.953125\n",
      "2017-04-03T20:30:23.421991: step 19565, loss 0.24311, acc 0.921875\n",
      "2017-04-03T20:30:23.623021: step 19566, loss 0.184422, acc 0.96875\n",
      "2017-04-03T20:30:23.824546: step 19567, loss 0.295429, acc 0.96875\n",
      "2017-04-03T20:30:24.029201: step 19568, loss 0.142926, acc 0.953125\n",
      "2017-04-03T20:30:24.229295: step 19569, loss 0.18305, acc 0.96875\n",
      "2017-04-03T20:30:24.426367: step 19570, loss 0.0983405, acc 0.953125\n",
      "2017-04-03T20:30:24.630513: step 19571, loss 0.0910208, acc 0.96875\n",
      "2017-04-03T20:30:24.833390: step 19572, loss 0.143061, acc 0.953125\n",
      "2017-04-03T20:30:25.035792: step 19573, loss 0.152591, acc 0.9375\n",
      "2017-04-03T20:30:25.245432: step 19574, loss 0.0556329, acc 0.984375\n",
      "2017-04-03T20:30:25.489865: step 19575, loss 0.130667, acc 0.9375\n",
      "2017-04-03T20:30:25.742157: step 19576, loss 0.0751851, acc 0.96875\n",
      "2017-04-03T20:30:25.967847: step 19577, loss 0.137187, acc 0.953125\n",
      "2017-04-03T20:30:26.168242: step 19578, loss 0.0572849, acc 0.984375\n",
      "2017-04-03T20:30:26.367031: step 19579, loss 0.176714, acc 0.9375\n",
      "2017-04-03T20:30:26.566563: step 19580, loss 0.0400809, acc 0.984375\n",
      "2017-04-03T20:30:26.765870: step 19581, loss 0.094877, acc 0.96875\n",
      "2017-04-03T20:30:26.969123: step 19582, loss 0.121718, acc 0.96875\n",
      "2017-04-03T20:30:27.185430: step 19583, loss 0.0458711, acc 0.984375\n",
      "2017-04-03T20:30:27.400418: step 19584, loss 0.0168799, acc 1\n",
      "2017-04-03T20:30:27.608075: step 19585, loss 0.0633886, acc 0.984375\n",
      "2017-04-03T20:30:27.808324: step 19586, loss 0.0603338, acc 1\n",
      "2017-04-03T20:30:28.017449: step 19587, loss 0.0557134, acc 0.984375\n",
      "2017-04-03T20:30:28.220326: step 19588, loss 0.126236, acc 0.984375\n",
      "2017-04-03T20:30:28.420659: step 19589, loss 0.0713532, acc 0.96875\n",
      "2017-04-03T20:30:28.621948: step 19590, loss 0.0792749, acc 0.96875\n",
      "2017-04-03T20:30:28.823225: step 19591, loss 0.0584595, acc 1\n",
      "2017-04-03T20:30:29.021870: step 19592, loss 0.515955, acc 0.953125\n",
      "2017-04-03T20:30:29.266728: step 19593, loss 0.148709, acc 0.9375\n",
      "2017-04-03T20:30:29.471412: step 19594, loss 0.141975, acc 0.953125\n",
      "2017-04-03T20:30:29.672202: step 19595, loss 0.107928, acc 0.96875\n",
      "2017-04-03T20:30:29.875806: step 19596, loss 0.117238, acc 0.9375\n",
      "2017-04-03T20:30:30.077732: step 19597, loss 0.3363, acc 0.90625\n",
      "2017-04-03T20:30:30.280654: step 19598, loss 0.11134, acc 0.96875\n",
      "2017-04-03T20:30:30.486811: step 19599, loss 0.0922552, acc 0.96875\n",
      "2017-04-03T20:30:30.696187: step 19600, loss 0.107161, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:30:32.837308: step 19600, loss 7.38119, acc 0.27725\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-19600\n",
      "\n",
      "2017-04-03T20:30:33.174987: step 19601, loss 0.137577, acc 0.96875\n",
      "2017-04-03T20:30:33.376255: step 19602, loss 0.102153, acc 0.96875\n",
      "2017-04-03T20:30:33.581678: step 19603, loss 0.1446, acc 0.96875\n",
      "2017-04-03T20:30:33.782781: step 19604, loss 0.125317, acc 0.953125\n",
      "2017-04-03T20:30:33.993280: step 19605, loss 0.108303, acc 0.953125\n",
      "2017-04-03T20:30:34.200342: step 19606, loss 0.0749636, acc 0.984375\n",
      "2017-04-03T20:30:34.404969: step 19607, loss 0.560738, acc 0.953125\n",
      "2017-04-03T20:30:34.612047: step 19608, loss 0.161925, acc 0.9375\n",
      "2017-04-03T20:30:34.810711: step 19609, loss 0.611402, acc 0.953125\n",
      "2017-04-03T20:30:35.012459: step 19610, loss 0.0604238, acc 0.984375\n",
      "2017-04-03T20:30:35.226112: step 19611, loss 0.081347, acc 0.984375\n",
      "2017-04-03T20:30:35.427324: step 19612, loss 0.183332, acc 0.921875\n",
      "2017-04-03T20:30:35.628334: step 19613, loss 0.03153, acc 0.984375\n",
      "2017-04-03T20:30:35.827098: step 19614, loss 0.131996, acc 0.9375\n",
      "2017-04-03T20:30:36.037823: step 19615, loss 0.18136, acc 0.9375\n",
      "2017-04-03T20:30:36.240282: step 19616, loss 0.11157, acc 0.96875\n",
      "2017-04-03T20:30:36.446790: step 19617, loss 0.0871679, acc 0.984375\n",
      "2017-04-03T20:30:36.699253: step 19618, loss 0.0845084, acc 0.96875\n",
      "2017-04-03T20:30:36.902835: step 19619, loss 0.140576, acc 0.953125\n",
      "2017-04-03T20:30:37.104889: step 19620, loss 0.0586262, acc 0.984375\n",
      "2017-04-03T20:30:37.312404: step 19621, loss 0.10265, acc 0.96875\n",
      "2017-04-03T20:30:37.519982: step 19622, loss 0.189443, acc 0.90625\n",
      "2017-04-03T20:30:37.764576: step 19623, loss 0.0680543, acc 0.984375\n",
      "2017-04-03T20:30:37.991698: step 19624, loss 0.0991473, acc 0.984375\n",
      "2017-04-03T20:30:38.208288: step 19625, loss 0.15311, acc 0.96875\n",
      "2017-04-03T20:30:38.429132: step 19626, loss 0.129978, acc 0.953125\n",
      "2017-04-03T20:30:38.636829: step 19627, loss 0.0675952, acc 0.984375\n",
      "2017-04-03T20:30:38.876071: step 19628, loss 0.159816, acc 0.9375\n",
      "2017-04-03T20:30:39.087739: step 19629, loss 0.0934393, acc 0.953125\n",
      "2017-04-03T20:30:39.329445: step 19630, loss 0.041828, acc 0.984375\n",
      "2017-04-03T20:30:39.576725: step 19631, loss 0.106262, acc 0.96875\n",
      "2017-04-03T20:30:39.792613: step 19632, loss 0.118348, acc 0.953125\n",
      "2017-04-03T20:30:40.001329: step 19633, loss 0.128015, acc 0.9375\n",
      "2017-04-03T20:30:40.202549: step 19634, loss 0.0626423, acc 0.984375\n",
      "2017-04-03T20:30:40.411526: step 19635, loss 0.10683, acc 0.96875\n",
      "2017-04-03T20:30:40.658894: step 19636, loss 0.191903, acc 0.96875\n",
      "2017-04-03T20:30:40.904393: step 19637, loss 0.150847, acc 0.953125\n",
      "2017-04-03T20:30:41.110161: step 19638, loss 0.107583, acc 0.9375\n",
      "2017-04-03T20:30:41.312007: step 19639, loss 0.0671353, acc 0.96875\n",
      "2017-04-03T20:30:41.515078: step 19640, loss 0.132345, acc 0.9375\n",
      "2017-04-03T20:30:41.718290: step 19641, loss 0.0831326, acc 0.984375\n",
      "2017-04-03T20:30:41.919655: step 19642, loss 0.0604936, acc 0.96875\n",
      "2017-04-03T20:30:42.122765: step 19643, loss 0.120116, acc 0.953125\n",
      "2017-04-03T20:30:42.335710: step 19644, loss 0.100003, acc 0.984375\n",
      "2017-04-03T20:30:42.543300: step 19645, loss 0.0324718, acc 0.984375\n",
      "2017-04-03T20:30:42.745969: step 19646, loss 0.113184, acc 0.953125\n",
      "2017-04-03T20:30:42.951467: step 19647, loss 0.00636601, acc 1\n",
      "2017-04-03T20:30:43.156937: step 19648, loss 0.0397093, acc 1\n",
      "2017-04-03T20:30:43.381347: step 19649, loss 0.147581, acc 0.953125\n",
      "2017-04-03T20:30:43.591307: step 19650, loss 0.100553, acc 0.953125\n",
      "2017-04-03T20:30:43.793908: step 19651, loss 0.0854714, acc 0.984375\n",
      "2017-04-03T20:30:43.997996: step 19652, loss 0.128427, acc 0.96875\n",
      "2017-04-03T20:30:44.213849: step 19653, loss 0.208158, acc 0.921875\n",
      "2017-04-03T20:30:44.413911: step 19654, loss 0.214152, acc 0.9375\n",
      "2017-04-03T20:30:44.615957: step 19655, loss 0.0626676, acc 0.984375\n",
      "2017-04-03T20:30:44.818808: step 19656, loss 0.123043, acc 0.96875\n",
      "2017-04-03T20:30:45.021670: step 19657, loss 0.178947, acc 0.953125\n",
      "2017-04-03T20:30:45.265426: step 19658, loss 0.182345, acc 0.9375\n",
      "2017-04-03T20:30:45.469273: step 19659, loss 0.118209, acc 0.96875\n",
      "2017-04-03T20:30:45.671417: step 19660, loss 0.125512, acc 0.953125\n",
      "2017-04-03T20:30:45.918837: step 19661, loss 0.156941, acc 0.953125\n",
      "2017-04-03T20:30:46.124884: step 19662, loss 0.193974, acc 0.9375\n",
      "2017-04-03T20:30:46.335241: step 19663, loss 0.104578, acc 0.96875\n",
      "2017-04-03T20:30:46.544498: step 19664, loss 0.0948653, acc 0.984375\n",
      "2017-04-03T20:30:46.746166: step 19665, loss 0.0949665, acc 0.96875\n",
      "2017-04-03T20:30:46.949765: step 19666, loss 0.168844, acc 0.9375\n",
      "2017-04-03T20:30:47.154703: step 19667, loss 0.221505, acc 0.921875\n",
      "2017-04-03T20:30:47.353226: step 19668, loss 0.118579, acc 0.984375\n",
      "2017-04-03T20:30:47.565312: step 19669, loss 0.213262, acc 0.90625\n",
      "2017-04-03T20:30:47.766604: step 19670, loss 0.0982566, acc 0.96875\n",
      "2017-04-03T20:30:47.972321: step 19671, loss 0.0550057, acc 0.984375\n",
      "2017-04-03T20:30:48.180677: step 19672, loss 0.237571, acc 0.921875\n",
      "2017-04-03T20:30:48.385729: step 19673, loss 0.325649, acc 0.921875\n",
      "2017-04-03T20:30:48.585633: step 19674, loss 0.102597, acc 0.953125\n",
      "2017-04-03T20:30:48.800989: step 19675, loss 0.182335, acc 0.921875\n",
      "2017-04-03T20:30:49.023196: step 19676, loss 0.134556, acc 0.96875\n",
      "2017-04-03T20:30:49.242344: step 19677, loss 0.116494, acc 0.984375\n",
      "2017-04-03T20:30:49.458728: step 19678, loss 0.0674901, acc 1\n",
      "2017-04-03T20:30:49.680341: step 19679, loss 0.145092, acc 0.96875\n",
      "2017-04-03T20:30:49.884628: step 19680, loss 0.0622174, acc 0.96875\n",
      "2017-04-03T20:30:50.083445: step 19681, loss 0.276392, acc 0.9375\n",
      "2017-04-03T20:30:50.286708: step 19682, loss 0.0643547, acc 0.96875\n",
      "2017-04-03T20:30:50.491117: step 19683, loss 0.0647242, acc 0.984375\n",
      "2017-04-03T20:30:50.697836: step 19684, loss 0.123173, acc 0.953125\n",
      "2017-04-03T20:30:50.904689: step 19685, loss 0.300351, acc 0.921875\n",
      "2017-04-03T20:30:51.156871: step 19686, loss 0.159996, acc 0.953125\n",
      "2017-04-03T20:30:51.381714: step 19687, loss 0.347033, acc 0.90625\n",
      "2017-04-03T20:30:51.596653: step 19688, loss 0.0780636, acc 0.984375\n",
      "2017-04-03T20:30:51.819100: step 19689, loss 0.0753236, acc 0.96875\n",
      "2017-04-03T20:30:52.026712: step 19690, loss 0.126904, acc 0.953125\n",
      "2017-04-03T20:30:52.241951: step 19691, loss 0.116236, acc 0.953125\n",
      "2017-04-03T20:30:52.445014: step 19692, loss 0.0437955, acc 0.984375\n",
      "2017-04-03T20:30:52.697434: step 19693, loss 0.183195, acc 0.953125\n",
      "2017-04-03T20:30:52.900008: step 19694, loss 0.131499, acc 0.96875\n",
      "2017-04-03T20:30:53.107788: step 19695, loss 0.145397, acc 0.984375\n",
      "2017-04-03T20:30:53.308738: step 19696, loss 0.0817682, acc 0.984375\n",
      "2017-04-03T20:30:53.553349: step 19697, loss 0.0739345, acc 0.984375\n",
      "2017-04-03T20:30:53.762954: step 19698, loss 0.160154, acc 0.96875\n",
      "2017-04-03T20:30:53.967621: step 19699, loss 0.0343115, acc 1\n",
      "2017-04-03T20:30:54.167181: step 19700, loss 0.115884, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:30:56.289529: step 19700, loss 7.42563, acc 0.27575\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-19700\n",
      "\n",
      "2017-04-03T20:30:56.631953: step 19701, loss 0.0781866, acc 0.984375\n",
      "2017-04-03T20:30:56.833192: step 19702, loss 0.0691338, acc 0.984375\n",
      "2017-04-03T20:30:57.041896: step 19703, loss 0.0447848, acc 0.984375\n",
      "2017-04-03T20:30:57.261295: step 19704, loss 0.0684121, acc 0.984375\n",
      "2017-04-03T20:30:57.407354: step 19705, loss 0.0576621, acc 0.96875\n",
      "2017-04-03T20:30:57.616358: step 19706, loss 0.0692277, acc 0.96875\n",
      "2017-04-03T20:30:57.858521: step 19707, loss 0.0710968, acc 0.953125\n",
      "2017-04-03T20:30:58.068660: step 19708, loss 0.12633, acc 0.953125\n",
      "2017-04-03T20:30:58.271587: step 19709, loss 0.0360083, acc 1\n",
      "2017-04-03T20:30:58.472627: step 19710, loss 0.156997, acc 0.9375\n",
      "2017-04-03T20:30:58.670552: step 19711, loss 0.142336, acc 0.921875\n",
      "2017-04-03T20:30:58.871989: step 19712, loss 0.113698, acc 0.96875\n",
      "2017-04-03T20:30:59.069668: step 19713, loss 0.053768, acc 0.984375\n",
      "2017-04-03T20:30:59.273811: step 19714, loss 0.0575874, acc 1\n",
      "2017-04-03T20:30:59.472448: step 19715, loss 0.165984, acc 0.9375\n",
      "2017-04-03T20:30:59.680901: step 19716, loss 0.172767, acc 0.9375\n",
      "2017-04-03T20:30:59.880962: step 19717, loss 0.101663, acc 0.96875\n",
      "2017-04-03T20:31:00.081319: step 19718, loss 0.104932, acc 0.96875\n",
      "2017-04-03T20:31:00.286715: step 19719, loss 0.0398814, acc 0.984375\n",
      "2017-04-03T20:31:00.536821: step 19720, loss 0.0405477, acc 1\n",
      "2017-04-03T20:31:00.734038: step 19721, loss 0.0773197, acc 0.984375\n",
      "2017-04-03T20:31:00.933892: step 19722, loss 0.0398291, acc 0.984375\n",
      "2017-04-03T20:31:01.139132: step 19723, loss 0.243895, acc 0.9375\n",
      "2017-04-03T20:31:01.384569: step 19724, loss 0.143397, acc 0.96875\n",
      "2017-04-03T20:31:01.630974: step 19725, loss 0.0291253, acc 1\n",
      "2017-04-03T20:31:01.834911: step 19726, loss 0.142906, acc 0.953125\n",
      "2017-04-03T20:31:02.037138: step 19727, loss 0.0447051, acc 1\n",
      "2017-04-03T20:31:02.239329: step 19728, loss 0.0931292, acc 0.96875\n",
      "2017-04-03T20:31:02.440638: step 19729, loss 0.124562, acc 0.9375\n",
      "2017-04-03T20:31:02.641094: step 19730, loss 0.183977, acc 0.953125\n",
      "2017-04-03T20:31:02.841556: step 19731, loss 0.186338, acc 0.9375\n",
      "2017-04-03T20:31:03.081170: step 19732, loss 0.185348, acc 0.953125\n",
      "2017-04-03T20:31:03.283314: step 19733, loss 0.269931, acc 0.90625\n",
      "2017-04-03T20:31:03.486797: step 19734, loss 0.0721636, acc 0.96875\n",
      "2017-04-03T20:31:03.736513: step 19735, loss 0.087336, acc 0.953125\n",
      "2017-04-03T20:31:03.943863: step 19736, loss 0.075732, acc 0.984375\n",
      "2017-04-03T20:31:04.146104: step 19737, loss 0.0529683, acc 0.984375\n",
      "2017-04-03T20:31:04.347343: step 19738, loss 0.113536, acc 0.9375\n",
      "2017-04-03T20:31:04.548153: step 19739, loss 0.0798565, acc 0.984375\n",
      "2017-04-03T20:31:04.750398: step 19740, loss 0.103426, acc 0.96875\n",
      "2017-04-03T20:31:04.952486: step 19741, loss 0.0874748, acc 0.96875\n",
      "2017-04-03T20:31:05.164763: step 19742, loss 0.0433115, acc 1\n",
      "2017-04-03T20:31:05.372990: step 19743, loss 0.0265123, acc 1\n",
      "2017-04-03T20:31:05.572222: step 19744, loss 0.0691119, acc 0.984375\n",
      "2017-04-03T20:31:05.774859: step 19745, loss 0.170769, acc 0.953125\n",
      "2017-04-03T20:31:05.988777: step 19746, loss 0.120974, acc 0.96875\n",
      "2017-04-03T20:31:06.211768: step 19747, loss 0.195963, acc 0.9375\n",
      "2017-04-03T20:31:06.429685: step 19748, loss 0.127882, acc 0.96875\n",
      "2017-04-03T20:31:06.646205: step 19749, loss 0.093563, acc 0.96875\n",
      "2017-04-03T20:31:06.875482: step 19750, loss 0.0804327, acc 0.984375\n",
      "2017-04-03T20:31:07.135306: step 19751, loss 0.138274, acc 0.921875\n",
      "2017-04-03T20:31:07.338020: step 19752, loss 0.0707273, acc 0.96875\n",
      "2017-04-03T20:31:07.541449: step 19753, loss 0.0625334, acc 0.984375\n",
      "2017-04-03T20:31:07.735978: step 19754, loss 0.0794298, acc 0.984375\n",
      "2017-04-03T20:31:07.935614: step 19755, loss 0.252233, acc 0.953125\n",
      "2017-04-03T20:31:08.176387: step 19756, loss 0.249727, acc 0.921875\n",
      "2017-04-03T20:31:08.419295: step 19757, loss 0.0772661, acc 0.96875\n",
      "2017-04-03T20:31:08.665853: step 19758, loss 0.232147, acc 0.9375\n",
      "2017-04-03T20:31:08.882156: step 19759, loss 0.044551, acc 0.984375\n",
      "2017-04-03T20:31:09.080665: step 19760, loss 0.0974579, acc 0.984375\n",
      "2017-04-03T20:31:09.285640: step 19761, loss 0.0819826, acc 0.96875\n",
      "2017-04-03T20:31:09.498929: step 19762, loss 0.0668292, acc 0.984375\n",
      "2017-04-03T20:31:09.707154: step 19763, loss 0.119695, acc 0.9375\n",
      "2017-04-03T20:31:09.910319: step 19764, loss 0.0454871, acc 1\n",
      "2017-04-03T20:31:10.114247: step 19765, loss 0.133409, acc 0.953125\n",
      "2017-04-03T20:31:10.315659: step 19766, loss 0.0458474, acc 1\n",
      "2017-04-03T20:31:10.516022: step 19767, loss 0.0680905, acc 0.96875\n",
      "2017-04-03T20:31:10.719300: step 19768, loss 0.0320808, acc 0.984375\n",
      "2017-04-03T20:31:10.926381: step 19769, loss 0.046251, acc 0.984375\n",
      "2017-04-03T20:31:11.128393: step 19770, loss 0.0450381, acc 1\n",
      "2017-04-03T20:31:11.335023: step 19771, loss 0.131423, acc 0.96875\n",
      "2017-04-03T20:31:11.541044: step 19772, loss 0.0871873, acc 0.96875\n",
      "2017-04-03T20:31:11.738533: step 19773, loss 0.0429717, acc 0.984375\n",
      "2017-04-03T20:31:11.988118: step 19774, loss 0.185457, acc 0.9375\n",
      "2017-04-03T20:31:12.215478: step 19775, loss 0.0441819, acc 0.984375\n",
      "2017-04-03T20:31:12.462987: step 19776, loss 0.113683, acc 0.96875\n",
      "2017-04-03T20:31:12.667145: step 19777, loss 0.0685929, acc 0.96875\n",
      "2017-04-03T20:31:12.872801: step 19778, loss 0.0774311, acc 0.96875\n",
      "2017-04-03T20:31:13.076652: step 19779, loss 0.0305447, acc 1\n",
      "2017-04-03T20:31:13.275476: step 19780, loss 0.0723066, acc 0.96875\n",
      "2017-04-03T20:31:13.492050: step 19781, loss 0.173811, acc 0.96875\n",
      "2017-04-03T20:31:13.694005: step 19782, loss 0.0433863, acc 0.984375\n",
      "2017-04-03T20:31:13.903632: step 19783, loss 0.0641184, acc 0.96875\n",
      "2017-04-03T20:31:14.107244: step 19784, loss 0.216039, acc 0.9375\n",
      "2017-04-03T20:31:14.309935: step 19785, loss 0.0353937, acc 0.984375\n",
      "2017-04-03T20:31:14.513618: step 19786, loss 0.0200823, acc 1\n",
      "2017-04-03T20:31:14.709904: step 19787, loss 0.123131, acc 0.96875\n",
      "2017-04-03T20:31:14.919820: step 19788, loss 0.0853584, acc 0.96875\n",
      "2017-04-03T20:31:15.166653: step 19789, loss 0.0635002, acc 0.984375\n",
      "2017-04-03T20:31:15.371355: step 19790, loss 0.140605, acc 0.953125\n",
      "2017-04-03T20:31:15.569418: step 19791, loss 0.0433908, acc 1\n",
      "2017-04-03T20:31:15.772650: step 19792, loss 0.0551915, acc 0.96875\n",
      "2017-04-03T20:31:15.988459: step 19793, loss 0.289429, acc 0.9375\n",
      "2017-04-03T20:31:16.188487: step 19794, loss 0.0579409, acc 0.984375\n",
      "2017-04-03T20:31:16.389986: step 19795, loss 0.311999, acc 0.953125\n",
      "2017-04-03T20:31:16.589093: step 19796, loss 0.0572548, acc 0.984375\n",
      "2017-04-03T20:31:16.790618: step 19797, loss 0.0663962, acc 0.984375\n",
      "2017-04-03T20:31:16.993883: step 19798, loss 0.0649639, acc 0.984375\n",
      "2017-04-03T20:31:17.194554: step 19799, loss 0.146003, acc 0.953125\n",
      "2017-04-03T20:31:17.392445: step 19800, loss 0.0766814, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:31:19.511869: step 19800, loss 7.3716, acc 0.285\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-19800\n",
      "\n",
      "2017-04-03T20:31:19.855277: step 19801, loss 0.0728957, acc 0.984375\n",
      "2017-04-03T20:31:20.057062: step 19802, loss 0.197508, acc 0.9375\n",
      "2017-04-03T20:31:20.275581: step 19803, loss 0.0827554, acc 0.984375\n",
      "2017-04-03T20:31:20.475059: step 19804, loss 0.0600082, acc 0.96875\n",
      "2017-04-03T20:31:20.685046: step 19805, loss 0.0488521, acc 1\n",
      "2017-04-03T20:31:20.887238: step 19806, loss 0.108893, acc 0.96875\n",
      "2017-04-03T20:31:21.092269: step 19807, loss 0.0415951, acc 1\n",
      "2017-04-03T20:31:21.297307: step 19808, loss 0.0687148, acc 0.984375\n",
      "2017-04-03T20:31:21.498418: step 19809, loss 0.101243, acc 0.96875\n",
      "2017-04-03T20:31:21.703200: step 19810, loss 0.14388, acc 0.984375\n",
      "2017-04-03T20:31:21.904387: step 19811, loss 0.107597, acc 0.953125\n",
      "2017-04-03T20:31:22.105987: step 19812, loss 0.02599, acc 1\n",
      "2017-04-03T20:31:22.303193: step 19813, loss 0.18646, acc 0.96875\n",
      "2017-04-03T20:31:22.504856: step 19814, loss 0.229926, acc 0.921875\n",
      "2017-04-03T20:31:22.708124: step 19815, loss 0.0180269, acc 1\n",
      "2017-04-03T20:31:22.910002: step 19816, loss 0.093575, acc 0.96875\n",
      "2017-04-03T20:31:23.115012: step 19817, loss 0.0184253, acc 1\n",
      "2017-04-03T20:31:23.325192: step 19818, loss 0.153592, acc 0.953125\n",
      "2017-04-03T20:31:23.533036: step 19819, loss 0.160418, acc 0.9375\n",
      "2017-04-03T20:31:23.735522: step 19820, loss 0.120107, acc 0.984375\n",
      "2017-04-03T20:31:23.936877: step 19821, loss 0.171217, acc 0.921875\n",
      "2017-04-03T20:31:24.138594: step 19822, loss 0.0851382, acc 0.953125\n",
      "2017-04-03T20:31:24.337341: step 19823, loss 0.0357751, acc 1\n",
      "2017-04-03T20:31:24.537112: step 19824, loss 0.108344, acc 0.96875\n",
      "2017-04-03T20:31:24.741976: step 19825, loss 0.118272, acc 0.953125\n",
      "2017-04-03T20:31:24.941608: step 19826, loss 0.0471415, acc 0.96875\n",
      "2017-04-03T20:31:25.141901: step 19827, loss 0.0404016, acc 0.984375\n",
      "2017-04-03T20:31:25.343309: step 19828, loss 0.0888072, acc 0.953125\n",
      "2017-04-03T20:31:25.546317: step 19829, loss 0.158, acc 0.96875\n",
      "2017-04-03T20:31:25.753105: step 19830, loss 0.0370971, acc 1\n",
      "2017-04-03T20:31:25.949919: step 19831, loss 0.183418, acc 0.96875\n",
      "2017-04-03T20:31:26.168297: step 19832, loss 0.0499829, acc 1\n",
      "2017-04-03T20:31:26.369667: step 19833, loss 0.0761392, acc 0.984375\n",
      "2017-04-03T20:31:26.569120: step 19834, loss 0.135781, acc 0.953125\n",
      "2017-04-03T20:31:26.770076: step 19835, loss 0.0337665, acc 1\n",
      "2017-04-03T20:31:26.968719: step 19836, loss 0.0105409, acc 1\n",
      "2017-04-03T20:31:27.167318: step 19837, loss 0.0518655, acc 0.984375\n",
      "2017-04-03T20:31:27.372949: step 19838, loss 0.0844713, acc 0.96875\n",
      "2017-04-03T20:31:27.576654: step 19839, loss 0.32783, acc 0.921875\n",
      "2017-04-03T20:31:27.780925: step 19840, loss 0.0635084, acc 0.984375\n",
      "2017-04-03T20:31:27.981348: step 19841, loss 0.0926253, acc 0.96875\n",
      "2017-04-03T20:31:28.186653: step 19842, loss 0.0814339, acc 0.96875\n",
      "2017-04-03T20:31:28.384680: step 19843, loss 0.054668, acc 0.984375\n",
      "2017-04-03T20:31:28.588982: step 19844, loss 0.11267, acc 0.953125\n",
      "2017-04-03T20:31:28.784827: step 19845, loss 0.0155481, acc 1\n",
      "2017-04-03T20:31:29.018137: step 19846, loss 0.212572, acc 0.9375\n",
      "2017-04-03T20:31:29.229280: step 19847, loss 0.152776, acc 0.953125\n",
      "2017-04-03T20:31:29.432471: step 19848, loss 0.0448634, acc 1\n",
      "2017-04-03T20:31:29.632871: step 19849, loss 0.24951, acc 0.9375\n",
      "2017-04-03T20:31:29.833117: step 19850, loss 0.0601943, acc 0.96875\n",
      "2017-04-03T20:31:30.037597: step 19851, loss 0.0415361, acc 1\n",
      "2017-04-03T20:31:30.239371: step 19852, loss 0.0914406, acc 0.984375\n",
      "2017-04-03T20:31:30.440486: step 19853, loss 0.126313, acc 0.96875\n",
      "2017-04-03T20:31:30.643931: step 19854, loss 0.0415054, acc 1\n",
      "2017-04-03T20:31:30.841466: step 19855, loss 0.0516577, acc 1\n",
      "2017-04-03T20:31:31.040813: step 19856, loss 0.162707, acc 0.953125\n",
      "2017-04-03T20:31:31.245676: step 19857, loss 0.0839196, acc 0.96875\n",
      "2017-04-03T20:31:31.486926: step 19858, loss 0.114264, acc 0.984375\n",
      "2017-04-03T20:31:31.691197: step 19859, loss 0.0725124, acc 0.984375\n",
      "2017-04-03T20:31:31.926320: step 19860, loss 0.0994052, acc 0.96875\n",
      "2017-04-03T20:31:32.128017: step 19861, loss 0.0476576, acc 0.984375\n",
      "2017-04-03T20:31:32.328921: step 19862, loss 0.0596414, acc 0.984375\n",
      "2017-04-03T20:31:32.534639: step 19863, loss 0.0964182, acc 0.96875\n",
      "2017-04-03T20:31:32.750232: step 19864, loss 0.157874, acc 0.9375\n",
      "2017-04-03T20:31:32.952029: step 19865, loss 0.0136708, acc 1\n",
      "2017-04-03T20:31:33.150709: step 19866, loss 0.0668347, acc 0.96875\n",
      "2017-04-03T20:31:33.349346: step 19867, loss 0.116494, acc 0.984375\n",
      "2017-04-03T20:31:33.599437: step 19868, loss 0.0672102, acc 0.96875\n",
      "2017-04-03T20:31:33.819436: step 19869, loss 0.0685352, acc 0.984375\n",
      "2017-04-03T20:31:34.035183: step 19870, loss 0.146656, acc 0.9375\n",
      "2017-04-03T20:31:34.242045: step 19871, loss 0.134487, acc 0.953125\n",
      "2017-04-03T20:31:34.460731: step 19872, loss 0.0597393, acc 0.96875\n",
      "2017-04-03T20:31:34.659682: step 19873, loss 0.0341215, acc 0.984375\n",
      "2017-04-03T20:31:34.858309: step 19874, loss 0.0753469, acc 0.96875\n",
      "2017-04-03T20:31:35.057893: step 19875, loss 0.0114727, acc 1\n",
      "2017-04-03T20:31:35.264044: step 19876, loss 0.108566, acc 0.953125\n",
      "2017-04-03T20:31:35.468047: step 19877, loss 0.0769457, acc 0.96875\n",
      "2017-04-03T20:31:35.713474: step 19878, loss 0.169429, acc 0.984375\n",
      "2017-04-03T20:31:35.918702: step 19879, loss 0.123307, acc 0.96875\n",
      "2017-04-03T20:31:36.122211: step 19880, loss 0.0939316, acc 0.96875\n",
      "2017-04-03T20:31:36.321794: step 19881, loss 0.15302, acc 0.9375\n",
      "2017-04-03T20:31:36.522752: step 19882, loss 0.141513, acc 0.921875\n",
      "2017-04-03T20:31:36.737179: step 19883, loss 0.0281733, acc 0.984375\n",
      "2017-04-03T20:31:36.954791: step 19884, loss 0.0703957, acc 0.984375\n",
      "2017-04-03T20:31:37.155052: step 19885, loss 0.183846, acc 0.90625\n",
      "2017-04-03T20:31:37.355583: step 19886, loss 0.166247, acc 0.9375\n",
      "2017-04-03T20:31:37.559360: step 19887, loss 0.220632, acc 0.9375\n",
      "2017-04-03T20:31:37.760072: step 19888, loss 0.0580306, acc 0.984375\n",
      "2017-04-03T20:31:37.965756: step 19889, loss 0.107614, acc 0.953125\n",
      "2017-04-03T20:31:38.168534: step 19890, loss 0.0486169, acc 0.984375\n",
      "2017-04-03T20:31:38.367008: step 19891, loss 0.0860858, acc 0.96875\n",
      "2017-04-03T20:31:38.570859: step 19892, loss 0.144306, acc 0.96875\n",
      "2017-04-03T20:31:38.772516: step 19893, loss 0.139757, acc 0.953125\n",
      "2017-04-03T20:31:38.983277: step 19894, loss 0.0770522, acc 0.96875\n",
      "2017-04-03T20:31:39.192288: step 19895, loss 0.0449564, acc 0.984375\n",
      "2017-04-03T20:31:39.403474: step 19896, loss 0.0282671, acc 0.984375\n",
      "2017-04-03T20:31:39.602624: step 19897, loss 0.0460678, acc 0.96875\n",
      "2017-04-03T20:31:39.801374: step 19898, loss 0.0589382, acc 0.984375\n",
      "2017-04-03T20:31:40.000792: step 19899, loss 0.216814, acc 0.9375\n",
      "2017-04-03T20:31:40.208226: step 19900, loss 0.0567985, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:31:42.368308: step 19900, loss 7.44973, acc 0.27675\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-19900\n",
      "\n",
      "2017-04-03T20:31:42.723482: step 19901, loss 0.174215, acc 0.96875\n",
      "2017-04-03T20:31:42.945397: step 19902, loss 0.175973, acc 0.953125\n",
      "2017-04-03T20:31:43.161858: step 19903, loss 0.0120662, acc 1\n",
      "2017-04-03T20:31:43.383787: step 19904, loss 0.0290714, acc 1\n",
      "2017-04-03T20:31:43.585964: step 19905, loss 0.0632193, acc 0.96875\n",
      "2017-04-03T20:31:43.821087: step 19906, loss 0.0326183, acc 0.984375\n",
      "2017-04-03T20:31:44.061988: step 19907, loss 0.134282, acc 0.9375\n",
      "2017-04-03T20:31:44.278494: step 19908, loss 0.189607, acc 0.953125\n",
      "2017-04-03T20:31:44.476499: step 19909, loss 0.0632195, acc 0.984375\n",
      "2017-04-03T20:31:44.677587: step 19910, loss 0.0480373, acc 0.984375\n",
      "2017-04-03T20:31:44.884079: step 19911, loss 0.0314901, acc 0.984375\n",
      "2017-04-03T20:31:45.089731: step 19912, loss 0.0247634, acc 1\n",
      "2017-04-03T20:31:45.293480: step 19913, loss 0.0972061, acc 0.96875\n",
      "2017-04-03T20:31:45.494980: step 19914, loss 0.0279675, acc 1\n",
      "2017-04-03T20:31:45.697979: step 19915, loss 0.123222, acc 0.921875\n",
      "2017-04-03T20:31:45.912085: step 19916, loss 0.0845793, acc 0.953125\n",
      "2017-04-03T20:31:46.122069: step 19917, loss 0.0378298, acc 1\n",
      "2017-04-03T20:31:46.343377: step 19918, loss 0.0643423, acc 0.96875\n",
      "2017-04-03T20:31:46.548620: step 19919, loss 0.0715565, acc 0.9375\n",
      "2017-04-03T20:31:46.759535: step 19920, loss 0.0131193, acc 1\n",
      "2017-04-03T20:31:46.959019: step 19921, loss 0.17005, acc 0.96875\n",
      "2017-04-03T20:31:47.160999: step 19922, loss 0.0973006, acc 0.984375\n",
      "2017-04-03T20:31:47.379093: step 19923, loss 0.0143907, acc 1\n",
      "2017-04-03T20:31:47.587465: step 19924, loss 0.232273, acc 0.921875\n",
      "2017-04-03T20:31:47.788195: step 19925, loss 0.0967761, acc 0.953125\n",
      "2017-04-03T20:31:47.991843: step 19926, loss 0.0650249, acc 0.984375\n",
      "2017-04-03T20:31:48.207907: step 19927, loss 0.193224, acc 0.9375\n",
      "2017-04-03T20:31:48.428720: step 19928, loss 0.194222, acc 0.9375\n",
      "2017-04-03T20:31:48.648385: step 19929, loss 0.0435391, acc 1\n",
      "2017-04-03T20:31:48.875505: step 19930, loss 0.140123, acc 0.96875\n",
      "2017-04-03T20:31:49.127888: step 19931, loss 0.157879, acc 0.90625\n",
      "2017-04-03T20:31:49.335484: step 19932, loss 0.231408, acc 0.921875\n",
      "2017-04-03T20:31:49.539726: step 19933, loss 0.110743, acc 0.953125\n",
      "2017-04-03T20:31:49.747302: step 19934, loss 0.0337925, acc 1\n",
      "2017-04-03T20:31:49.948929: step 19935, loss 0.0385963, acc 0.984375\n",
      "2017-04-03T20:31:50.148318: step 19936, loss 0.103807, acc 0.953125\n",
      "2017-04-03T20:31:50.353132: step 19937, loss 0.0349853, acc 0.984375\n",
      "2017-04-03T20:31:50.597773: step 19938, loss 0.108853, acc 0.9375\n",
      "2017-04-03T20:31:50.801753: step 19939, loss 0.0700395, acc 0.984375\n",
      "2017-04-03T20:31:51.049565: step 19940, loss 0.0659959, acc 0.96875\n",
      "2017-04-03T20:31:51.277443: step 19941, loss 0.0625383, acc 0.984375\n",
      "2017-04-03T20:31:51.484591: step 19942, loss 0.07922, acc 0.984375\n",
      "2017-04-03T20:31:51.727767: step 19943, loss 0.0546153, acc 0.984375\n",
      "2017-04-03T20:31:51.934459: step 19944, loss 0.0730006, acc 1\n",
      "2017-04-03T20:31:52.136210: step 19945, loss 0.0397261, acc 1\n",
      "2017-04-03T20:31:52.342300: step 19946, loss 0.104157, acc 0.96875\n",
      "2017-04-03T20:31:52.544194: step 19947, loss 0.0393449, acc 0.984375\n",
      "2017-04-03T20:31:52.743621: step 19948, loss 0.0919936, acc 0.953125\n",
      "2017-04-03T20:31:52.966321: step 19949, loss 0.314118, acc 0.96875\n",
      "2017-04-03T20:31:53.185153: step 19950, loss 0.0292705, acc 1\n",
      "2017-04-03T20:31:53.404940: step 19951, loss 0.153511, acc 0.9375\n",
      "2017-04-03T20:31:53.604328: step 19952, loss 0.0940476, acc 0.984375\n",
      "2017-04-03T20:31:53.817056: step 19953, loss 0.0430223, acc 0.984375\n",
      "2017-04-03T20:31:54.036905: step 19954, loss 0.0919375, acc 0.96875\n",
      "2017-04-03T20:31:54.260026: step 19955, loss 0.0733013, acc 0.984375\n",
      "2017-04-03T20:31:54.478795: step 19956, loss 0.0943681, acc 0.96875\n",
      "2017-04-03T20:31:54.735042: step 19957, loss 0.0492569, acc 0.984375\n",
      "2017-04-03T20:31:54.940968: step 19958, loss 0.0590306, acc 0.984375\n",
      "2017-04-03T20:31:55.144381: step 19959, loss 0.101701, acc 0.96875\n",
      "2017-04-03T20:31:55.350949: step 19960, loss 0.0338934, acc 1\n",
      "2017-04-03T20:31:55.553145: step 19961, loss 0.0440005, acc 0.96875\n",
      "2017-04-03T20:31:55.759014: step 19962, loss 0.076154, acc 0.984375\n",
      "2017-04-03T20:31:55.967649: step 19963, loss 0.0661811, acc 0.984375\n",
      "2017-04-03T20:31:56.170109: step 19964, loss 0.098738, acc 0.96875\n",
      "2017-04-03T20:31:56.373746: step 19965, loss 0.032322, acc 1\n",
      "2017-04-03T20:31:56.616235: step 19966, loss 0.131317, acc 0.984375\n",
      "2017-04-03T20:31:56.816858: step 19967, loss 0.0869666, acc 0.96875\n",
      "2017-04-03T20:31:57.027773: step 19968, loss 0.0431088, acc 0.984375\n",
      "2017-04-03T20:31:57.233980: step 19969, loss 0.127516, acc 0.953125\n",
      "2017-04-03T20:31:57.435721: step 19970, loss 0.318903, acc 0.921875\n",
      "2017-04-03T20:31:57.636561: step 19971, loss 0.0676541, acc 0.984375\n",
      "2017-04-03T20:31:57.842968: step 19972, loss 0.109809, acc 0.96875\n",
      "2017-04-03T20:31:58.046549: step 19973, loss 0.0973623, acc 0.953125\n",
      "2017-04-03T20:31:58.247190: step 19974, loss 0.238692, acc 0.9375\n",
      "2017-04-03T20:31:58.446195: step 19975, loss 0.0201253, acc 1\n",
      "2017-04-03T20:31:58.695046: step 19976, loss 0.116899, acc 0.953125\n",
      "2017-04-03T20:31:58.896245: step 19977, loss 0.093612, acc 0.953125\n",
      "2017-04-03T20:31:59.116700: step 19978, loss 0.116204, acc 0.953125\n",
      "2017-04-03T20:31:59.327934: step 19979, loss 0.0618422, acc 0.984375\n",
      "2017-04-03T20:31:59.527149: step 19980, loss 0.0377433, acc 1\n",
      "2017-04-03T20:31:59.730637: step 19981, loss 0.0753041, acc 0.984375\n",
      "2017-04-03T20:31:59.932690: step 19982, loss 0.0811606, acc 0.984375\n",
      "2017-04-03T20:32:00.140650: step 19983, loss 0.059192, acc 0.984375\n",
      "2017-04-03T20:32:00.341386: step 19984, loss 0.244503, acc 0.984375\n",
      "2017-04-03T20:32:00.543637: step 19985, loss 0.115284, acc 0.96875\n",
      "2017-04-03T20:32:00.745660: step 19986, loss 0.0453687, acc 0.984375\n",
      "2017-04-03T20:32:00.950837: step 19987, loss 0.0623494, acc 0.984375\n",
      "2017-04-03T20:32:01.155238: step 19988, loss 0.21424, acc 0.9375\n",
      "2017-04-03T20:32:01.360202: step 19989, loss 0.0398376, acc 0.984375\n",
      "2017-04-03T20:32:01.564975: step 19990, loss 0.367345, acc 0.921875\n",
      "2017-04-03T20:32:01.765760: step 19991, loss 0.069217, acc 0.96875\n",
      "2017-04-03T20:32:01.968165: step 19992, loss 0.0303551, acc 1\n",
      "2017-04-03T20:32:02.167750: step 19993, loss 0.127802, acc 0.953125\n",
      "2017-04-03T20:32:02.370934: step 19994, loss 0.107464, acc 0.953125\n",
      "2017-04-03T20:32:02.570841: step 19995, loss 0.146117, acc 0.953125\n",
      "2017-04-03T20:32:02.774551: step 19996, loss 0.111056, acc 0.9375\n",
      "2017-04-03T20:32:02.984049: step 19997, loss 0.221652, acc 0.921875\n",
      "2017-04-03T20:32:03.188441: step 19998, loss 0.0247775, acc 1\n",
      "2017-04-03T20:32:03.387735: step 19999, loss 0.0704941, acc 0.984375\n",
      "2017-04-03T20:32:03.587818: step 20000, loss 0.0506423, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:32:05.732262: step 20000, loss 7.5464, acc 0.28125\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-20000\n",
      "\n",
      "2017-04-03T20:32:06.062323: step 20001, loss 0.0496192, acc 0.984375\n",
      "2017-04-03T20:32:06.273986: step 20002, loss 0.139157, acc 0.953125\n",
      "2017-04-03T20:32:06.480316: step 20003, loss 0.2313, acc 0.921875\n",
      "2017-04-03T20:32:06.725543: step 20004, loss 0.199732, acc 0.953125\n",
      "2017-04-03T20:32:06.938556: step 20005, loss 0.0126439, acc 1\n",
      "2017-04-03T20:32:07.151333: step 20006, loss 0.220601, acc 0.953125\n",
      "2017-04-03T20:32:07.359211: step 20007, loss 0.0693964, acc 0.984375\n",
      "2017-04-03T20:32:07.564271: step 20008, loss 0.107615, acc 0.96875\n",
      "2017-04-03T20:32:07.769643: step 20009, loss 0.0774336, acc 0.96875\n",
      "2017-04-03T20:32:07.968580: step 20010, loss 0.0532842, acc 0.984375\n",
      "2017-04-03T20:32:08.174370: step 20011, loss 0.215607, acc 0.96875\n",
      "2017-04-03T20:32:08.382420: step 20012, loss 0.116889, acc 0.984375\n",
      "2017-04-03T20:32:08.628238: step 20013, loss 0.0529632, acc 0.984375\n",
      "2017-04-03T20:32:08.847202: step 20014, loss 0.243697, acc 0.9375\n",
      "2017-04-03T20:32:09.063479: step 20015, loss 0.187529, acc 0.953125\n",
      "2017-04-03T20:32:09.284081: step 20016, loss 0.13778, acc 0.9375\n",
      "2017-04-03T20:32:09.491962: step 20017, loss 0.0503931, acc 0.96875\n",
      "2017-04-03T20:32:09.695758: step 20018, loss 0.0512906, acc 0.984375\n",
      "2017-04-03T20:32:09.920425: step 20019, loss 0.116597, acc 0.9375\n",
      "2017-04-03T20:32:10.121695: step 20020, loss 0.115321, acc 0.9375\n",
      "2017-04-03T20:32:10.322174: step 20021, loss 0.0529243, acc 0.984375\n",
      "2017-04-03T20:32:10.523742: step 20022, loss 0.163368, acc 0.90625\n",
      "2017-04-03T20:32:10.726425: step 20023, loss 0.168433, acc 0.921875\n",
      "2017-04-03T20:32:10.926574: step 20024, loss 0.0864357, acc 0.953125\n",
      "2017-04-03T20:32:11.131271: step 20025, loss 0.0837341, acc 0.96875\n",
      "2017-04-03T20:32:11.330741: step 20026, loss 0.162588, acc 0.90625\n",
      "2017-04-03T20:32:11.535175: step 20027, loss 0.177344, acc 0.9375\n",
      "2017-04-03T20:32:11.737113: step 20028, loss 0.130774, acc 0.953125\n",
      "2017-04-03T20:32:11.979907: step 20029, loss 0.147293, acc 0.953125\n",
      "2017-04-03T20:32:12.220575: step 20030, loss 0.171828, acc 0.96875\n",
      "2017-04-03T20:32:12.424174: step 20031, loss 0.113928, acc 0.953125\n",
      "2017-04-03T20:32:12.632212: step 20032, loss 0.0573767, acc 0.984375\n",
      "2017-04-03T20:32:12.831146: step 20033, loss 0.0657675, acc 0.96875\n",
      "2017-04-03T20:32:13.030771: step 20034, loss 0.0878194, acc 0.953125\n",
      "2017-04-03T20:32:13.242124: step 20035, loss 0.0157763, acc 1\n",
      "2017-04-03T20:32:13.484616: step 20036, loss 0.162698, acc 0.953125\n",
      "2017-04-03T20:32:13.685372: step 20037, loss 0.162854, acc 0.953125\n",
      "2017-04-03T20:32:13.891752: step 20038, loss 0.131812, acc 0.953125\n",
      "2017-04-03T20:32:14.089405: step 20039, loss 0.0601124, acc 0.984375\n",
      "2017-04-03T20:32:14.301465: step 20040, loss 0.0807728, acc 0.96875\n",
      "2017-04-03T20:32:14.505331: step 20041, loss 0.0451822, acc 0.984375\n",
      "2017-04-03T20:32:14.751684: step 20042, loss 0.0817609, acc 0.96875\n",
      "2017-04-03T20:32:14.955086: step 20043, loss 0.0150473, acc 1\n",
      "2017-04-03T20:32:15.203126: step 20044, loss 0.0883023, acc 0.96875\n",
      "2017-04-03T20:32:15.406922: step 20045, loss 0.107688, acc 0.96875\n",
      "2017-04-03T20:32:15.607013: step 20046, loss 0.067712, acc 0.96875\n",
      "2017-04-03T20:32:15.808280: step 20047, loss 0.0373633, acc 1\n",
      "2017-04-03T20:32:16.009844: step 20048, loss 0.0749108, acc 0.984375\n",
      "2017-04-03T20:32:16.210461: step 20049, loss 0.111971, acc 0.96875\n",
      "2017-04-03T20:32:16.411624: step 20050, loss 0.0517633, acc 0.96875\n",
      "2017-04-03T20:32:16.613933: step 20051, loss 0.0628073, acc 0.984375\n",
      "2017-04-03T20:32:16.813067: step 20052, loss 0.0582883, acc 0.984375\n",
      "2017-04-03T20:32:17.061926: step 20053, loss 0.0874302, acc 0.96875\n",
      "2017-04-03T20:32:17.267909: step 20054, loss 0.116576, acc 0.96875\n",
      "2017-04-03T20:32:17.467211: step 20055, loss 0.114186, acc 0.984375\n",
      "2017-04-03T20:32:17.668896: step 20056, loss 0.247485, acc 0.921875\n",
      "2017-04-03T20:32:17.877079: step 20057, loss 0.0857986, acc 0.96875\n",
      "2017-04-03T20:32:18.131025: step 20058, loss 0.0773538, acc 0.984375\n",
      "2017-04-03T20:32:18.336042: step 20059, loss 0.0891338, acc 0.953125\n",
      "2017-04-03T20:32:18.537096: step 20060, loss 0.140271, acc 0.953125\n",
      "2017-04-03T20:32:18.735866: step 20061, loss 0.054351, acc 0.984375\n",
      "2017-04-03T20:32:18.941978: step 20062, loss 0.0298267, acc 1\n",
      "2017-04-03T20:32:19.149531: step 20063, loss 0.0801765, acc 0.984375\n",
      "2017-04-03T20:32:19.352310: step 20064, loss 0.146118, acc 0.953125\n",
      "2017-04-03T20:32:19.551217: step 20065, loss 0.0730428, acc 0.984375\n",
      "2017-04-03T20:32:19.754223: step 20066, loss 0.0561929, acc 0.96875\n",
      "2017-04-03T20:32:19.957805: step 20067, loss 0.0316434, acc 1\n",
      "2017-04-03T20:32:20.157937: step 20068, loss 0.170365, acc 0.96875\n",
      "2017-04-03T20:32:20.356747: step 20069, loss 0.146016, acc 0.953125\n",
      "2017-04-03T20:32:20.560476: step 20070, loss 0.171119, acc 0.953125\n",
      "2017-04-03T20:32:20.764657: step 20071, loss 0.130446, acc 0.953125\n",
      "2017-04-03T20:32:20.964289: step 20072, loss 0.117034, acc 0.921875\n",
      "2017-04-03T20:32:21.169202: step 20073, loss 0.123404, acc 0.96875\n",
      "2017-04-03T20:32:21.387713: step 20074, loss 0.143665, acc 0.953125\n",
      "2017-04-03T20:32:21.591294: step 20075, loss 0.164982, acc 0.90625\n",
      "2017-04-03T20:32:21.791509: step 20076, loss 0.0332662, acc 0.984375\n",
      "2017-04-03T20:32:21.993853: step 20077, loss 0.039245, acc 1\n",
      "2017-04-03T20:32:22.193405: step 20078, loss 0.108264, acc 0.96875\n",
      "2017-04-03T20:32:22.398067: step 20079, loss 0.161548, acc 0.9375\n",
      "2017-04-03T20:32:22.608467: step 20080, loss 0.275639, acc 0.921875\n",
      "2017-04-03T20:32:22.811700: step 20081, loss 0.268891, acc 0.96875\n",
      "2017-04-03T20:32:23.012360: step 20082, loss 0.0468546, acc 0.96875\n",
      "2017-04-03T20:32:23.217195: step 20083, loss 0.0618348, acc 0.984375\n",
      "2017-04-03T20:32:23.422345: step 20084, loss 0.0779762, acc 0.96875\n",
      "2017-04-03T20:32:23.662286: step 20085, loss 0.0931031, acc 0.96875\n",
      "2017-04-03T20:32:23.861729: step 20086, loss 0.114052, acc 0.953125\n",
      "2017-04-03T20:32:24.107827: step 20087, loss 0.210273, acc 0.96875\n",
      "2017-04-03T20:32:24.318582: step 20088, loss 0.108431, acc 0.96875\n",
      "2017-04-03T20:32:24.522153: step 20089, loss 0.0248803, acc 1\n",
      "2017-04-03T20:32:24.725295: step 20090, loss 0.23654, acc 0.953125\n",
      "2017-04-03T20:32:24.933153: step 20091, loss 0.022313, acc 1\n",
      "2017-04-03T20:32:25.132678: step 20092, loss 0.1192, acc 0.953125\n",
      "2017-04-03T20:32:25.336628: step 20093, loss 0.243208, acc 0.9375\n",
      "2017-04-03T20:32:25.574187: step 20094, loss 0.0312367, acc 1\n",
      "2017-04-03T20:32:25.785397: step 20095, loss 0.0737199, acc 0.984375\n",
      "2017-04-03T20:32:25.985585: step 20096, loss 0.0285672, acc 1\n",
      "2017-04-03T20:32:26.196058: step 20097, loss 0.0364991, acc 0.984375\n",
      "2017-04-03T20:32:26.405749: step 20098, loss 0.0466311, acc 0.96875\n",
      "2017-04-03T20:32:26.612158: step 20099, loss 0.050898, acc 0.984375\n",
      "2017-04-03T20:32:26.816001: step 20100, loss 0.126362, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:32:28.967492: step 20100, loss 7.5997, acc 0.28175\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-20100\n",
      "\n",
      "2017-04-03T20:32:29.303914: step 20101, loss 0.185638, acc 0.9375\n",
      "2017-04-03T20:32:29.510242: step 20102, loss 0.199936, acc 0.953125\n",
      "2017-04-03T20:32:29.709661: step 20103, loss 0.0872789, acc 0.96875\n",
      "2017-04-03T20:32:29.907098: step 20104, loss 0.0547352, acc 0.984375\n",
      "2017-04-03T20:32:30.110292: step 20105, loss 0.0318793, acc 0.984375\n",
      "2017-04-03T20:32:30.316283: step 20106, loss 0.0367407, acc 1\n",
      "2017-04-03T20:32:30.520807: step 20107, loss 0.0662034, acc 0.984375\n",
      "2017-04-03T20:32:30.727820: step 20108, loss 0.0478156, acc 0.984375\n",
      "2017-04-03T20:32:30.928605: step 20109, loss 0.23624, acc 0.90625\n",
      "2017-04-03T20:32:31.131010: step 20110, loss 0.0417591, acc 1\n",
      "2017-04-03T20:32:31.332442: step 20111, loss 0.0416867, acc 1\n",
      "2017-04-03T20:32:31.537752: step 20112, loss 0.0536963, acc 0.984375\n",
      "2017-04-03T20:32:31.738875: step 20113, loss 0.079243, acc 0.984375\n",
      "2017-04-03T20:32:31.937868: step 20114, loss 0.0801842, acc 0.96875\n",
      "2017-04-03T20:32:32.138931: step 20115, loss 0.0691635, acc 0.96875\n",
      "2017-04-03T20:32:32.340634: step 20116, loss 0.0590256, acc 0.96875\n",
      "2017-04-03T20:32:32.541348: step 20117, loss 0.105443, acc 0.96875\n",
      "2017-04-03T20:32:32.745472: step 20118, loss 0.0906388, acc 0.96875\n",
      "2017-04-03T20:32:32.949626: step 20119, loss 0.109183, acc 0.953125\n",
      "2017-04-03T20:32:33.152986: step 20120, loss 0.0787317, acc 0.984375\n",
      "2017-04-03T20:32:33.396062: step 20121, loss 0.0514683, acc 0.96875\n",
      "2017-04-03T20:32:33.604862: step 20122, loss 0.092936, acc 0.96875\n",
      "2017-04-03T20:32:33.806244: step 20123, loss 0.0384549, acc 0.984375\n",
      "2017-04-03T20:32:34.007405: step 20124, loss 0.0549626, acc 1\n",
      "2017-04-03T20:32:34.211578: step 20125, loss 0.159984, acc 0.9375\n",
      "2017-04-03T20:32:34.412808: step 20126, loss 0.0403634, acc 0.984375\n",
      "2017-04-03T20:32:34.616720: step 20127, loss 0.0219854, acc 1\n",
      "2017-04-03T20:32:34.820843: step 20128, loss 0.122728, acc 0.9375\n",
      "2017-04-03T20:32:35.039273: step 20129, loss 0.120728, acc 0.953125\n",
      "2017-04-03T20:32:35.239962: step 20130, loss 0.323956, acc 0.96875\n",
      "2017-04-03T20:32:35.440788: step 20131, loss 0.250285, acc 0.90625\n",
      "2017-04-03T20:32:35.645652: step 20132, loss 0.0976845, acc 0.96875\n",
      "2017-04-03T20:32:35.888121: step 20133, loss 0.0190582, acc 1\n",
      "2017-04-03T20:32:36.132529: step 20134, loss 0.0658857, acc 0.96875\n",
      "2017-04-03T20:32:36.336315: step 20135, loss 0.0260634, acc 1\n",
      "2017-04-03T20:32:36.546600: step 20136, loss 0.296387, acc 0.9375\n",
      "2017-04-03T20:32:36.751934: step 20137, loss 0.227635, acc 0.921875\n",
      "2017-04-03T20:32:36.961322: step 20138, loss 0.170935, acc 0.96875\n",
      "2017-04-03T20:32:37.163456: step 20139, loss 0.04111, acc 1\n",
      "2017-04-03T20:32:37.368048: step 20140, loss 0.132558, acc 0.9375\n",
      "2017-04-03T20:32:37.571367: step 20141, loss 0.060237, acc 0.96875\n",
      "2017-04-03T20:32:37.776616: step 20142, loss 0.105722, acc 0.9375\n",
      "2017-04-03T20:32:37.979225: step 20143, loss 0.104274, acc 0.96875\n",
      "2017-04-03T20:32:38.185522: step 20144, loss 0.282637, acc 0.90625\n",
      "2017-04-03T20:32:38.389361: step 20145, loss 0.0946213, acc 0.96875\n",
      "2017-04-03T20:32:38.593632: step 20146, loss 0.131259, acc 0.984375\n",
      "2017-04-03T20:32:38.793755: step 20147, loss 0.0957421, acc 0.984375\n",
      "2017-04-03T20:32:38.998346: step 20148, loss 0.0634433, acc 0.984375\n",
      "2017-04-03T20:32:39.197663: step 20149, loss 0.0647804, acc 0.96875\n",
      "2017-04-03T20:32:39.404955: step 20150, loss 0.0380733, acc 1\n",
      "2017-04-03T20:32:39.602807: step 20151, loss 0.17185, acc 0.9375\n",
      "2017-04-03T20:32:39.813750: step 20152, loss 0.124037, acc 0.953125\n",
      "2017-04-03T20:32:40.017754: step 20153, loss 0.0469896, acc 0.984375\n",
      "2017-04-03T20:32:40.220516: step 20154, loss 0.166809, acc 0.921875\n",
      "2017-04-03T20:32:40.425263: step 20155, loss 0.058355, acc 0.984375\n",
      "2017-04-03T20:32:40.626800: step 20156, loss 0.0343909, acc 1\n",
      "2017-04-03T20:32:40.871645: step 20157, loss 0.104945, acc 0.96875\n",
      "2017-04-03T20:32:41.079991: step 20158, loss 0.0580003, acc 0.984375\n",
      "2017-04-03T20:32:41.285236: step 20159, loss 0.285636, acc 0.921875\n",
      "2017-04-03T20:32:41.493282: step 20160, loss 0.0799821, acc 0.984375\n",
      "2017-04-03T20:32:41.696106: step 20161, loss 0.027173, acc 1\n",
      "2017-04-03T20:32:41.900516: step 20162, loss 0.127586, acc 0.953125\n",
      "2017-04-03T20:32:42.100765: step 20163, loss 0.068921, acc 0.96875\n",
      "2017-04-03T20:32:42.313047: step 20164, loss 0.0971795, acc 0.96875\n",
      "2017-04-03T20:32:42.535626: step 20165, loss 0.0529884, acc 0.984375\n",
      "2017-04-03T20:32:42.759811: step 20166, loss 0.122078, acc 0.953125\n",
      "2017-04-03T20:32:42.961766: step 20167, loss 0.0415732, acc 0.96875\n",
      "2017-04-03T20:32:43.162032: step 20168, loss 0.089995, acc 0.953125\n",
      "2017-04-03T20:32:43.363041: step 20169, loss 0.0738036, acc 0.984375\n",
      "2017-04-03T20:32:43.570218: step 20170, loss 0.109137, acc 0.96875\n",
      "2017-04-03T20:32:43.773962: step 20171, loss 0.0490894, acc 0.984375\n",
      "2017-04-03T20:32:43.997901: step 20172, loss 0.0260508, acc 1\n",
      "2017-04-03T20:32:44.211524: step 20173, loss 0.0858063, acc 0.953125\n",
      "2017-04-03T20:32:44.435597: step 20174, loss 0.042268, acc 1\n",
      "2017-04-03T20:32:44.638961: step 20175, loss 0.090354, acc 0.96875\n",
      "2017-04-03T20:32:44.843376: step 20176, loss 0.0390651, acc 0.96875\n",
      "2017-04-03T20:32:45.047586: step 20177, loss 0.0864656, acc 0.96875\n",
      "2017-04-03T20:32:45.291173: step 20178, loss 0.0251853, acc 1\n",
      "2017-04-03T20:32:45.492306: step 20179, loss 0.10079, acc 0.96875\n",
      "2017-04-03T20:32:45.693630: step 20180, loss 0.0953408, acc 0.984375\n",
      "2017-04-03T20:32:45.895014: step 20181, loss 0.210707, acc 0.9375\n",
      "2017-04-03T20:32:46.138351: step 20182, loss 0.211477, acc 0.921875\n",
      "2017-04-03T20:32:46.344483: step 20183, loss 0.0711827, acc 0.984375\n",
      "2017-04-03T20:32:46.545351: step 20184, loss 0.0647645, acc 0.96875\n",
      "2017-04-03T20:32:46.752286: step 20185, loss 0.177495, acc 0.9375\n",
      "2017-04-03T20:32:46.955656: step 20186, loss 0.136913, acc 0.96875\n",
      "2017-04-03T20:32:47.201805: step 20187, loss 0.167363, acc 0.9375\n",
      "2017-04-03T20:32:47.421622: step 20188, loss 0.0547992, acc 0.984375\n",
      "2017-04-03T20:32:47.631990: step 20189, loss 0.0845058, acc 0.984375\n",
      "2017-04-03T20:32:47.834258: step 20190, loss 0.180488, acc 0.953125\n",
      "2017-04-03T20:32:48.050929: step 20191, loss 0.191828, acc 0.921875\n",
      "2017-04-03T20:32:48.268320: step 20192, loss 0.137138, acc 0.96875\n",
      "2017-04-03T20:32:48.482973: step 20193, loss 0.0821301, acc 0.984375\n",
      "2017-04-03T20:32:48.692280: step 20194, loss 0.103432, acc 0.96875\n",
      "2017-04-03T20:32:48.899096: step 20195, loss 0.118587, acc 0.953125\n",
      "2017-04-03T20:32:49.102549: step 20196, loss 0.0901643, acc 0.96875\n",
      "2017-04-03T20:32:49.307633: step 20197, loss 0.0662607, acc 0.984375\n",
      "2017-04-03T20:32:49.516991: step 20198, loss 0.142552, acc 0.921875\n",
      "2017-04-03T20:32:49.727859: step 20199, loss 0.0372199, acc 0.984375\n",
      "2017-04-03T20:32:49.931687: step 20200, loss 0.10694, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:32:52.113571: step 20200, loss 7.55747, acc 0.28175\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-20200\n",
      "\n",
      "2017-04-03T20:32:52.496332: step 20201, loss 0.102716, acc 0.96875\n",
      "2017-04-03T20:32:52.706102: step 20202, loss 0.211425, acc 0.953125\n",
      "2017-04-03T20:32:52.906139: step 20203, loss 0.0474498, acc 1\n",
      "2017-04-03T20:32:53.110398: step 20204, loss 0.0673919, acc 0.984375\n",
      "2017-04-03T20:32:53.320194: step 20205, loss 0.0765111, acc 0.96875\n",
      "2017-04-03T20:32:53.527684: step 20206, loss 0.0675747, acc 0.96875\n",
      "2017-04-03T20:32:53.727730: step 20207, loss 0.0430293, acc 0.984375\n",
      "2017-04-03T20:32:53.975555: step 20208, loss 0.12511, acc 0.9375\n",
      "2017-04-03T20:32:54.222996: step 20209, loss 0.102666, acc 0.96875\n",
      "2017-04-03T20:32:54.465820: step 20210, loss 0.0510014, acc 1\n",
      "2017-04-03T20:32:54.679948: step 20211, loss 0.274007, acc 0.953125\n",
      "2017-04-03T20:32:54.898025: step 20212, loss 0.0281337, acc 1\n",
      "2017-04-03T20:32:55.115055: step 20213, loss 0.0394456, acc 0.984375\n",
      "2017-04-03T20:32:55.336601: step 20214, loss 0.0737742, acc 0.96875\n",
      "2017-04-03T20:32:55.558520: step 20215, loss 0.0604448, acc 0.984375\n",
      "2017-04-03T20:32:55.760306: step 20216, loss 0.0216971, acc 1\n",
      "2017-04-03T20:32:55.967290: step 20217, loss 0.075086, acc 0.96875\n",
      "2017-04-03T20:32:56.173444: step 20218, loss 0.0064166, acc 1\n",
      "2017-04-03T20:32:56.378898: step 20219, loss 0.107309, acc 0.953125\n",
      "2017-04-03T20:32:56.629178: step 20220, loss 0.0613347, acc 0.984375\n",
      "2017-04-03T20:32:56.839113: step 20221, loss 0.0712894, acc 0.984375\n",
      "2017-04-03T20:32:57.041955: step 20222, loss 0.0734129, acc 0.984375\n",
      "2017-04-03T20:32:57.280403: step 20223, loss 0.198409, acc 0.9375\n",
      "2017-04-03T20:32:57.480542: step 20224, loss 0.0452541, acc 0.984375\n",
      "2017-04-03T20:32:57.688495: step 20225, loss 0.0800929, acc 0.96875\n",
      "2017-04-03T20:32:57.888260: step 20226, loss 0.10084, acc 0.953125\n",
      "2017-04-03T20:32:58.102018: step 20227, loss 0.075339, acc 0.96875\n",
      "2017-04-03T20:32:58.302504: step 20228, loss 0.167259, acc 0.953125\n",
      "2017-04-03T20:32:58.505433: step 20229, loss 0.224876, acc 0.953125\n",
      "2017-04-03T20:32:58.708663: step 20230, loss 0.0723402, acc 0.96875\n",
      "2017-04-03T20:32:58.907021: step 20231, loss 0.0919132, acc 0.96875\n",
      "2017-04-03T20:32:59.115881: step 20232, loss 0.108732, acc 0.96875\n",
      "2017-04-03T20:32:59.322945: step 20233, loss 0.0840551, acc 0.96875\n",
      "2017-04-03T20:32:59.524057: step 20234, loss 0.0951002, acc 0.953125\n",
      "2017-04-03T20:32:59.726095: step 20235, loss 0.07807, acc 0.96875\n",
      "2017-04-03T20:32:59.928795: step 20236, loss 0.276275, acc 0.90625\n",
      "2017-04-03T20:33:00.130229: step 20237, loss 0.0771611, acc 0.96875\n",
      "2017-04-03T20:33:00.332668: step 20238, loss 0.0728379, acc 0.984375\n",
      "2017-04-03T20:33:00.602123: step 20239, loss 0.0901531, acc 0.96875\n",
      "2017-04-03T20:33:00.803171: step 20240, loss 0.157859, acc 0.953125\n",
      "2017-04-03T20:33:01.010279: step 20241, loss 0.0811498, acc 0.984375\n",
      "2017-04-03T20:33:01.257346: step 20242, loss 0.323418, acc 0.921875\n",
      "2017-04-03T20:33:01.461295: step 20243, loss 0.127799, acc 0.953125\n",
      "2017-04-03T20:33:01.669127: step 20244, loss 0.0388053, acc 1\n",
      "2017-04-03T20:33:01.871218: step 20245, loss 0.116478, acc 0.921875\n",
      "2017-04-03T20:33:02.075837: step 20246, loss 0.101678, acc 0.9375\n",
      "2017-04-03T20:33:02.279195: step 20247, loss 0.170762, acc 0.9375\n",
      "2017-04-03T20:33:02.482228: step 20248, loss 0.145659, acc 0.953125\n",
      "2017-04-03T20:33:02.690618: step 20249, loss 0.194708, acc 0.9375\n",
      "2017-04-03T20:33:02.889828: step 20250, loss 0.0874565, acc 0.953125\n",
      "2017-04-03T20:33:03.092810: step 20251, loss 0.0995338, acc 0.953125\n",
      "2017-04-03T20:33:03.295771: step 20252, loss 0.084179, acc 0.984375\n",
      "2017-04-03T20:33:03.506110: step 20253, loss 0.105355, acc 0.96875\n",
      "2017-04-03T20:33:03.708450: step 20254, loss 0.0240455, acc 0.984375\n",
      "2017-04-03T20:33:03.913971: step 20255, loss 0.0949082, acc 0.96875\n",
      "2017-04-03T20:33:04.116885: step 20256, loss 0.0976494, acc 0.953125\n",
      "2017-04-03T20:33:04.320140: step 20257, loss 0.0797855, acc 0.953125\n",
      "2017-04-03T20:33:04.527419: step 20258, loss 0.136892, acc 0.984375\n",
      "2017-04-03T20:33:04.735987: step 20259, loss 0.0585587, acc 0.96875\n",
      "2017-04-03T20:33:04.940834: step 20260, loss 0.065233, acc 0.984375\n",
      "2017-04-03T20:33:05.141934: step 20261, loss 0.144025, acc 0.96875\n",
      "2017-04-03T20:33:05.348076: step 20262, loss 0.164281, acc 0.9375\n",
      "2017-04-03T20:33:05.569521: step 20263, loss 0.126433, acc 0.96875\n",
      "2017-04-03T20:33:05.782581: step 20264, loss 0.0637982, acc 0.96875\n",
      "2017-04-03T20:33:06.002327: step 20265, loss 0.128409, acc 0.984375\n",
      "2017-04-03T20:33:06.209100: step 20266, loss 0.0794241, acc 0.984375\n",
      "2017-04-03T20:33:06.411484: step 20267, loss 0.180243, acc 0.984375\n",
      "2017-04-03T20:33:06.560206: step 20268, loss 0.0467926, acc 0.96875\n",
      "2017-04-03T20:33:06.796128: step 20269, loss 0.10299, acc 0.953125\n",
      "2017-04-03T20:33:07.007760: step 20270, loss 0.0668436, acc 0.96875\n",
      "2017-04-03T20:33:07.215215: step 20271, loss 0.0375885, acc 0.984375\n",
      "2017-04-03T20:33:07.428884: step 20272, loss 0.0712121, acc 0.953125\n",
      "2017-04-03T20:33:07.637721: step 20273, loss 0.140334, acc 0.96875\n",
      "2017-04-03T20:33:07.846339: step 20274, loss 0.133525, acc 0.953125\n",
      "2017-04-03T20:33:08.045369: step 20275, loss 0.0507535, acc 0.984375\n",
      "2017-04-03T20:33:08.248804: step 20276, loss 0.0764, acc 0.96875\n",
      "2017-04-03T20:33:08.465340: step 20277, loss 0.165066, acc 0.953125\n",
      "2017-04-03T20:33:08.669582: step 20278, loss 0.0400472, acc 1\n",
      "2017-04-03T20:33:08.868951: step 20279, loss 0.0865211, acc 0.96875\n",
      "2017-04-03T20:33:09.075570: step 20280, loss 0.107726, acc 0.96875\n",
      "2017-04-03T20:33:09.282061: step 20281, loss 0.0859926, acc 0.96875\n",
      "2017-04-03T20:33:09.488063: step 20282, loss 0.0601401, acc 0.96875\n",
      "2017-04-03T20:33:09.707427: step 20283, loss 0.0319827, acc 1\n",
      "2017-04-03T20:33:09.914126: step 20284, loss 0.0238359, acc 0.984375\n",
      "2017-04-03T20:33:10.112420: step 20285, loss 0.0707896, acc 0.96875\n",
      "2017-04-03T20:33:10.314169: step 20286, loss 0.117206, acc 0.96875\n",
      "2017-04-03T20:33:10.516839: step 20287, loss 0.0266128, acc 1\n",
      "2017-04-03T20:33:10.763511: step 20288, loss 0.14883, acc 0.96875\n",
      "2017-04-03T20:33:10.963711: step 20289, loss 0.0599697, acc 0.984375\n",
      "2017-04-03T20:33:11.203808: step 20290, loss 0.0768514, acc 0.96875\n",
      "2017-04-03T20:33:11.405298: step 20291, loss 0.0238832, acc 0.984375\n",
      "2017-04-03T20:33:11.608015: step 20292, loss 0.109486, acc 0.96875\n",
      "2017-04-03T20:33:11.807173: step 20293, loss 0.0484903, acc 0.984375\n",
      "2017-04-03T20:33:12.007397: step 20294, loss 0.139827, acc 0.9375\n",
      "2017-04-03T20:33:12.216283: step 20295, loss 0.0136429, acc 1\n",
      "2017-04-03T20:33:12.425751: step 20296, loss 0.0413872, acc 0.984375\n",
      "2017-04-03T20:33:12.634800: step 20297, loss 0.0680872, acc 0.96875\n",
      "2017-04-03T20:33:12.836995: step 20298, loss 0.0414504, acc 1\n",
      "2017-04-03T20:33:13.043368: step 20299, loss 0.074549, acc 0.984375\n",
      "2017-04-03T20:33:13.256683: step 20300, loss 0.108831, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:33:15.411783: step 20300, loss 7.5799, acc 0.28625\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-20300\n",
      "\n",
      "2017-04-03T20:33:15.755533: step 20301, loss 0.084807, acc 0.953125\n",
      "2017-04-03T20:33:15.961633: step 20302, loss 0.0211682, acc 1\n",
      "2017-04-03T20:33:16.170142: step 20303, loss 0.0470543, acc 1\n",
      "2017-04-03T20:33:16.413355: step 20304, loss 0.0865898, acc 0.953125\n",
      "2017-04-03T20:33:16.620510: step 20305, loss 0.0272324, acc 1\n",
      "2017-04-03T20:33:16.827225: step 20306, loss 0.0651689, acc 1\n",
      "2017-04-03T20:33:17.032518: step 20307, loss 0.0399805, acc 0.96875\n",
      "2017-04-03T20:33:17.233626: step 20308, loss 0.0924372, acc 0.953125\n",
      "2017-04-03T20:33:17.435836: step 20309, loss 0.102079, acc 0.96875\n",
      "2017-04-03T20:33:17.634676: step 20310, loss 0.219325, acc 0.921875\n",
      "2017-04-03T20:33:17.884626: step 20311, loss 0.0835064, acc 0.953125\n",
      "2017-04-03T20:33:18.087791: step 20312, loss 0.0219054, acc 1\n",
      "2017-04-03T20:33:18.289301: step 20313, loss 0.0383813, acc 1\n",
      "2017-04-03T20:33:18.533868: step 20314, loss 0.00573029, acc 1\n",
      "2017-04-03T20:33:18.740840: step 20315, loss 0.0856654, acc 0.984375\n",
      "2017-04-03T20:33:18.985613: step 20316, loss 0.0678018, acc 0.984375\n",
      "2017-04-03T20:33:19.191622: step 20317, loss 0.0440812, acc 0.984375\n",
      "2017-04-03T20:33:19.396667: step 20318, loss 0.131449, acc 0.953125\n",
      "2017-04-03T20:33:19.599306: step 20319, loss 0.162267, acc 0.953125\n",
      "2017-04-03T20:33:19.804989: step 20320, loss 0.106349, acc 0.953125\n",
      "2017-04-03T20:33:20.011798: step 20321, loss 0.106567, acc 0.984375\n",
      "2017-04-03T20:33:20.213981: step 20322, loss 0.0631199, acc 0.984375\n",
      "2017-04-03T20:33:20.426216: step 20323, loss 0.0113499, acc 1\n",
      "2017-04-03T20:33:20.631109: step 20324, loss 0.140974, acc 0.9375\n",
      "2017-04-03T20:33:20.835690: step 20325, loss 0.0277721, acc 1\n",
      "2017-04-03T20:33:21.036871: step 20326, loss 0.0443091, acc 1\n",
      "2017-04-03T20:33:21.236391: step 20327, loss 0.0433358, acc 1\n",
      "2017-04-03T20:33:21.491070: step 20328, loss 0.059307, acc 0.984375\n",
      "2017-04-03T20:33:21.698450: step 20329, loss 0.0741494, acc 0.96875\n",
      "2017-04-03T20:33:21.905428: step 20330, loss 0.0913591, acc 0.96875\n",
      "2017-04-03T20:33:22.110762: step 20331, loss 0.121195, acc 0.953125\n",
      "2017-04-03T20:33:22.359001: step 20332, loss 0.156351, acc 0.9375\n",
      "2017-04-03T20:33:22.605998: step 20333, loss 0.0735277, acc 0.96875\n",
      "2017-04-03T20:33:22.801902: step 20334, loss 0.0293749, acc 1\n",
      "2017-04-03T20:33:23.042703: step 20335, loss 0.0470372, acc 0.96875\n",
      "2017-04-03T20:33:23.244283: step 20336, loss 0.0788311, acc 0.96875\n",
      "2017-04-03T20:33:23.451529: step 20337, loss 0.0772166, acc 0.96875\n",
      "2017-04-03T20:33:23.656944: step 20338, loss 0.0267575, acc 1\n",
      "2017-04-03T20:33:23.857398: step 20339, loss 0.0749523, acc 0.984375\n",
      "2017-04-03T20:33:24.059068: step 20340, loss 0.11652, acc 0.953125\n",
      "2017-04-03T20:33:24.259541: step 20341, loss 0.101606, acc 0.96875\n",
      "2017-04-03T20:33:24.461748: step 20342, loss 0.0887925, acc 0.953125\n",
      "2017-04-03T20:33:24.667281: step 20343, loss 0.0781765, acc 0.984375\n",
      "2017-04-03T20:33:24.868922: step 20344, loss 0.0446172, acc 0.96875\n",
      "2017-04-03T20:33:25.068334: step 20345, loss 0.131815, acc 0.984375\n",
      "2017-04-03T20:33:25.280468: step 20346, loss 0.0395053, acc 0.984375\n",
      "2017-04-03T20:33:25.482709: step 20347, loss 0.0722721, acc 0.984375\n",
      "2017-04-03T20:33:25.684055: step 20348, loss 0.0630525, acc 0.984375\n",
      "2017-04-03T20:33:25.901612: step 20349, loss 0.0328549, acc 1\n",
      "2017-04-03T20:33:26.122609: step 20350, loss 0.218606, acc 0.953125\n",
      "2017-04-03T20:33:26.329388: step 20351, loss 0.0895067, acc 0.96875\n",
      "2017-04-03T20:33:26.536459: step 20352, loss 0.13106, acc 0.953125\n",
      "2017-04-03T20:33:26.743662: step 20353, loss 0.0604135, acc 0.96875\n",
      "2017-04-03T20:33:26.944301: step 20354, loss 0.158255, acc 0.953125\n",
      "2017-04-03T20:33:27.148208: step 20355, loss 0.11673, acc 0.984375\n",
      "2017-04-03T20:33:27.390515: step 20356, loss 0.204234, acc 0.90625\n",
      "2017-04-03T20:33:27.595101: step 20357, loss 0.0687991, acc 0.96875\n",
      "2017-04-03T20:33:27.812242: step 20358, loss 0.122109, acc 0.921875\n",
      "2017-04-03T20:33:28.027068: step 20359, loss 0.0622491, acc 0.984375\n",
      "2017-04-03T20:33:28.231600: step 20360, loss 0.149466, acc 0.953125\n",
      "2017-04-03T20:33:28.477064: step 20361, loss 0.0880898, acc 0.96875\n",
      "2017-04-03T20:33:28.677762: step 20362, loss 0.201464, acc 0.96875\n",
      "2017-04-03T20:33:28.922097: step 20363, loss 0.00961632, acc 1\n",
      "2017-04-03T20:33:29.116377: step 20364, loss 0.221239, acc 0.96875\n",
      "2017-04-03T20:33:29.324481: step 20365, loss 0.0658098, acc 0.96875\n",
      "2017-04-03T20:33:29.534352: step 20366, loss 0.0899871, acc 0.96875\n",
      "2017-04-03T20:33:29.731932: step 20367, loss 0.140912, acc 0.96875\n",
      "2017-04-03T20:33:29.937009: step 20368, loss 0.277783, acc 0.96875\n",
      "2017-04-03T20:33:30.146207: step 20369, loss 0.0359342, acc 1\n",
      "2017-04-03T20:33:30.350081: step 20370, loss 0.0331015, acc 1\n",
      "2017-04-03T20:33:30.556310: step 20371, loss 0.22664, acc 0.921875\n",
      "2017-04-03T20:33:30.756339: step 20372, loss 0.0970928, acc 0.984375\n",
      "2017-04-03T20:33:30.957155: step 20373, loss 0.142716, acc 0.9375\n",
      "2017-04-03T20:33:31.198485: step 20374, loss 0.0204531, acc 1\n",
      "2017-04-03T20:33:31.400072: step 20375, loss 0.0875752, acc 0.984375\n",
      "2017-04-03T20:33:31.601681: step 20376, loss 0.0254681, acc 1\n",
      "2017-04-03T20:33:31.802359: step 20377, loss 0.00901277, acc 1\n",
      "2017-04-03T20:33:32.006664: step 20378, loss 0.23553, acc 0.96875\n",
      "2017-04-03T20:33:32.205420: step 20379, loss 0.104141, acc 0.984375\n",
      "2017-04-03T20:33:32.409677: step 20380, loss 0.0638641, acc 0.96875\n",
      "2017-04-03T20:33:32.613444: step 20381, loss 0.0815671, acc 0.984375\n",
      "2017-04-03T20:33:32.817487: step 20382, loss 0.108535, acc 0.953125\n",
      "2017-04-03T20:33:33.016201: step 20383, loss 0.152139, acc 0.953125\n",
      "2017-04-03T20:33:33.218352: step 20384, loss 0.0475401, acc 0.984375\n",
      "2017-04-03T20:33:33.422591: step 20385, loss 0.073262, acc 0.984375\n",
      "2017-04-03T20:33:33.621331: step 20386, loss 0.181223, acc 0.9375\n",
      "2017-04-03T20:33:33.821937: step 20387, loss 0.108694, acc 0.953125\n",
      "2017-04-03T20:33:34.034589: step 20388, loss 0.104033, acc 0.96875\n",
      "2017-04-03T20:33:34.233731: step 20389, loss 0.12109, acc 0.9375\n",
      "2017-04-03T20:33:34.445463: step 20390, loss 0.0293811, acc 1\n",
      "2017-04-03T20:33:34.645554: step 20391, loss 0.0837088, acc 0.96875\n",
      "2017-04-03T20:33:34.839012: step 20392, loss 0.0816735, acc 0.953125\n",
      "2017-04-03T20:33:35.044413: step 20393, loss 0.143307, acc 0.96875\n",
      "2017-04-03T20:33:35.260613: step 20394, loss 0.185361, acc 0.984375\n",
      "2017-04-03T20:33:35.466480: step 20395, loss 0.0462854, acc 0.984375\n",
      "2017-04-03T20:33:35.666182: step 20396, loss 0.0635817, acc 0.984375\n",
      "2017-04-03T20:33:35.917854: step 20397, loss 0.0873269, acc 0.984375\n",
      "2017-04-03T20:33:36.120289: step 20398, loss 0.0151101, acc 1\n",
      "2017-04-03T20:33:36.319037: step 20399, loss 0.154665, acc 0.96875\n",
      "2017-04-03T20:33:36.519256: step 20400, loss 0.0432591, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:33:38.647932: step 20400, loss 7.59925, acc 0.2865\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-20400\n",
      "\n",
      "2017-04-03T20:33:39.029331: step 20401, loss 0.0941262, acc 0.96875\n",
      "2017-04-03T20:33:39.247835: step 20402, loss 0.054654, acc 0.984375\n",
      "2017-04-03T20:33:39.505225: step 20403, loss 0.140017, acc 0.9375\n",
      "2017-04-03T20:33:39.708633: step 20404, loss 0.11108, acc 0.953125\n",
      "2017-04-03T20:33:39.912411: step 20405, loss 0.0613916, acc 0.984375\n",
      "2017-04-03T20:33:40.112745: step 20406, loss 0.0919553, acc 0.953125\n",
      "2017-04-03T20:33:40.313704: step 20407, loss 0.0769288, acc 0.96875\n",
      "2017-04-03T20:33:40.521884: step 20408, loss 0.038909, acc 0.984375\n",
      "2017-04-03T20:33:40.729578: step 20409, loss 0.0574815, acc 0.984375\n",
      "2017-04-03T20:33:40.972150: step 20410, loss 0.0364481, acc 0.984375\n",
      "2017-04-03T20:33:41.176771: step 20411, loss 0.0483179, acc 0.96875\n",
      "2017-04-03T20:33:41.379488: step 20412, loss 0.0144941, acc 1\n",
      "2017-04-03T20:33:41.580807: step 20413, loss 0.0525555, acc 0.984375\n",
      "2017-04-03T20:33:41.788038: step 20414, loss 0.110616, acc 0.953125\n",
      "2017-04-03T20:33:41.989968: step 20415, loss 0.0621, acc 1\n",
      "2017-04-03T20:33:42.197395: step 20416, loss 0.135865, acc 0.96875\n",
      "2017-04-03T20:33:42.409865: step 20417, loss 0.116263, acc 0.984375\n",
      "2017-04-03T20:33:42.609722: step 20418, loss 0.125863, acc 0.953125\n",
      "2017-04-03T20:33:42.810721: step 20419, loss 0.0676586, acc 0.984375\n",
      "2017-04-03T20:33:43.017446: step 20420, loss 0.0102241, acc 1\n",
      "2017-04-03T20:33:43.221920: step 20421, loss 0.0682331, acc 1\n",
      "2017-04-03T20:33:43.424910: step 20422, loss 0.06577, acc 0.984375\n",
      "2017-04-03T20:33:43.623485: step 20423, loss 0.0708009, acc 0.984375\n",
      "2017-04-03T20:33:43.874775: step 20424, loss 0.156589, acc 0.96875\n",
      "2017-04-03T20:33:44.117727: step 20425, loss 0.048271, acc 0.984375\n",
      "2017-04-03T20:33:44.323566: step 20426, loss 0.225389, acc 0.9375\n",
      "2017-04-03T20:33:44.522681: step 20427, loss 0.0795445, acc 0.96875\n",
      "2017-04-03T20:33:44.727491: step 20428, loss 0.174396, acc 0.9375\n",
      "2017-04-03T20:33:44.924383: step 20429, loss 0.0435054, acc 0.984375\n",
      "2017-04-03T20:33:45.172165: step 20430, loss 0.177299, acc 0.96875\n",
      "2017-04-03T20:33:45.375343: step 20431, loss 0.215642, acc 0.96875\n",
      "2017-04-03T20:33:45.582333: step 20432, loss 0.0496837, acc 0.96875\n",
      "2017-04-03T20:33:45.825944: step 20433, loss 0.0203026, acc 1\n",
      "2017-04-03T20:33:46.033558: step 20434, loss 0.156547, acc 0.953125\n",
      "2017-04-03T20:33:46.234013: step 20435, loss 0.0199972, acc 1\n",
      "2017-04-03T20:33:46.477677: step 20436, loss 0.0584743, acc 0.984375\n",
      "2017-04-03T20:33:46.720372: step 20437, loss 0.0514718, acc 1\n",
      "2017-04-03T20:33:46.924250: step 20438, loss 0.169318, acc 0.9375\n",
      "2017-04-03T20:33:47.121599: step 20439, loss 0.0962842, acc 0.984375\n",
      "2017-04-03T20:33:47.370901: step 20440, loss 0.0723542, acc 0.96875\n",
      "2017-04-03T20:33:47.564725: step 20441, loss 0.00977973, acc 1\n",
      "2017-04-03T20:33:47.767460: step 20442, loss 0.0488818, acc 0.984375\n",
      "2017-04-03T20:33:47.979737: step 20443, loss 0.0654247, acc 0.984375\n",
      "2017-04-03T20:33:48.195355: step 20444, loss 0.0624096, acc 0.984375\n",
      "2017-04-03T20:33:48.424667: step 20445, loss 0.134011, acc 0.96875\n",
      "2017-04-03T20:33:48.646000: step 20446, loss 0.0426788, acc 0.984375\n",
      "2017-04-03T20:33:48.860408: step 20447, loss 0.156077, acc 0.953125\n",
      "2017-04-03T20:33:49.081293: step 20448, loss 0.0528375, acc 0.984375\n",
      "2017-04-03T20:33:49.324229: step 20449, loss 0.0466435, acc 1\n",
      "2017-04-03T20:33:49.536643: step 20450, loss 0.17867, acc 0.953125\n",
      "2017-04-03T20:33:49.735811: step 20451, loss 0.0272511, acc 1\n",
      "2017-04-03T20:33:49.941339: step 20452, loss 0.124888, acc 0.953125\n",
      "2017-04-03T20:33:50.148244: step 20453, loss 0.0303871, acc 0.984375\n",
      "2017-04-03T20:33:50.347477: step 20454, loss 0.0724791, acc 0.96875\n",
      "2017-04-03T20:33:50.549117: step 20455, loss 0.0895146, acc 0.984375\n",
      "2017-04-03T20:33:50.760256: step 20456, loss 0.10381, acc 0.96875\n",
      "2017-04-03T20:33:50.966334: step 20457, loss 0.0966104, acc 0.953125\n",
      "2017-04-03T20:33:51.213440: step 20458, loss 0.10501, acc 0.96875\n",
      "2017-04-03T20:33:51.421217: step 20459, loss 0.0741925, acc 0.984375\n",
      "2017-04-03T20:33:51.619024: step 20460, loss 0.0942641, acc 0.984375\n",
      "2017-04-03T20:33:51.861902: step 20461, loss 0.00505554, acc 1\n",
      "2017-04-03T20:33:52.066487: step 20462, loss 0.0482556, acc 0.984375\n",
      "2017-04-03T20:33:52.268014: step 20463, loss 0.107772, acc 0.984375\n",
      "2017-04-03T20:33:52.514678: step 20464, loss 0.126519, acc 0.984375\n",
      "2017-04-03T20:33:52.735373: step 20465, loss 0.0331696, acc 0.984375\n",
      "2017-04-03T20:33:52.951265: step 20466, loss 0.124951, acc 0.953125\n",
      "2017-04-03T20:33:53.161907: step 20467, loss 0.120154, acc 0.96875\n",
      "2017-04-03T20:33:53.364254: step 20468, loss 0.0528745, acc 1\n",
      "2017-04-03T20:33:53.571306: step 20469, loss 0.108533, acc 0.984375\n",
      "2017-04-03T20:33:53.785398: step 20470, loss 0.0963275, acc 0.953125\n",
      "2017-04-03T20:33:53.990251: step 20471, loss 0.0817724, acc 0.96875\n",
      "2017-04-03T20:33:54.190610: step 20472, loss 0.254776, acc 0.9375\n",
      "2017-04-03T20:33:54.391570: step 20473, loss 0.281087, acc 0.953125\n",
      "2017-04-03T20:33:54.599244: step 20474, loss 0.158191, acc 0.953125\n",
      "2017-04-03T20:33:54.803261: step 20475, loss 0.0472179, acc 0.96875\n",
      "2017-04-03T20:33:55.002233: step 20476, loss 0.0786108, acc 0.96875\n",
      "2017-04-03T20:33:55.205723: step 20477, loss 0.0479061, acc 0.984375\n",
      "2017-04-03T20:33:55.408236: step 20478, loss 0.0760579, acc 0.96875\n",
      "2017-04-03T20:33:55.614158: step 20479, loss 0.0361681, acc 0.984375\n",
      "2017-04-03T20:33:55.817988: step 20480, loss 0.0493609, acc 0.984375\n",
      "2017-04-03T20:33:56.019091: step 20481, loss 0.103393, acc 0.96875\n",
      "2017-04-03T20:33:56.216662: step 20482, loss 0.0904364, acc 0.96875\n",
      "2017-04-03T20:33:56.427404: step 20483, loss 0.112172, acc 0.9375\n",
      "2017-04-03T20:33:56.638189: step 20484, loss 0.0268513, acc 1\n",
      "2017-04-03T20:33:56.836893: step 20485, loss 0.215545, acc 0.96875\n",
      "2017-04-03T20:33:57.088648: step 20486, loss 0.094437, acc 0.96875\n",
      "2017-04-03T20:33:57.289790: step 20487, loss 0.0342302, acc 1\n",
      "2017-04-03T20:33:57.492735: step 20488, loss 0.108702, acc 0.953125\n",
      "2017-04-03T20:33:57.704047: step 20489, loss 0.141959, acc 0.953125\n",
      "2017-04-03T20:33:57.906887: step 20490, loss 0.0713844, acc 0.984375\n",
      "2017-04-03T20:33:58.105468: step 20491, loss 0.288466, acc 0.9375\n",
      "2017-04-03T20:33:58.306863: step 20492, loss 0.0716753, acc 0.984375\n",
      "2017-04-03T20:33:58.516934: step 20493, loss 0.100017, acc 0.953125\n",
      "2017-04-03T20:33:58.726669: step 20494, loss 0.101578, acc 0.953125\n",
      "2017-04-03T20:33:58.928642: step 20495, loss 0.104638, acc 0.96875\n",
      "2017-04-03T20:33:59.186548: step 20496, loss 0.0319356, acc 0.984375\n",
      "2017-04-03T20:33:59.393885: step 20497, loss 0.166493, acc 0.953125\n",
      "2017-04-03T20:33:59.592610: step 20498, loss 0.0834744, acc 0.953125\n",
      "2017-04-03T20:33:59.791980: step 20499, loss 0.0607717, acc 0.984375\n",
      "2017-04-03T20:33:59.995669: step 20500, loss 0.128651, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:34:02.154182: step 20500, loss 7.65409, acc 0.28375\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-20500\n",
      "\n",
      "2017-04-03T20:34:02.538041: step 20501, loss 0.0816258, acc 0.96875\n",
      "2017-04-03T20:34:02.736693: step 20502, loss 0.0548953, acc 1\n",
      "2017-04-03T20:34:02.942440: step 20503, loss 0.219721, acc 0.96875\n",
      "2017-04-03T20:34:03.146358: step 20504, loss 0.0654958, acc 0.984375\n",
      "2017-04-03T20:34:03.349103: step 20505, loss 0.0619145, acc 0.96875\n",
      "2017-04-03T20:34:03.547156: step 20506, loss 0.110749, acc 0.953125\n",
      "2017-04-03T20:34:03.746073: step 20507, loss 0.213111, acc 0.921875\n",
      "2017-04-03T20:34:03.956925: step 20508, loss 0.10662, acc 0.96875\n",
      "2017-04-03T20:34:04.157041: step 20509, loss 0.0671527, acc 0.984375\n",
      "2017-04-03T20:34:04.406075: step 20510, loss 0.0709542, acc 0.984375\n",
      "2017-04-03T20:34:04.613010: step 20511, loss 0.0684804, acc 0.96875\n",
      "2017-04-03T20:34:04.828504: step 20512, loss 0.104229, acc 0.984375\n",
      "2017-04-03T20:34:05.036293: step 20513, loss 0.0213934, acc 1\n",
      "2017-04-03T20:34:05.238791: step 20514, loss 0.116221, acc 0.96875\n",
      "2017-04-03T20:34:05.438604: step 20515, loss 0.0948428, acc 0.953125\n",
      "2017-04-03T20:34:05.639959: step 20516, loss 0.170949, acc 0.953125\n",
      "2017-04-03T20:34:05.836514: step 20517, loss 0.0691523, acc 0.984375\n",
      "2017-04-03T20:34:06.040709: step 20518, loss 0.0322798, acc 1\n",
      "2017-04-03T20:34:06.239856: step 20519, loss 0.00416804, acc 1\n",
      "2017-04-03T20:34:06.445486: step 20520, loss 0.0761343, acc 0.96875\n",
      "2017-04-03T20:34:06.649444: step 20521, loss 0.0684526, acc 0.96875\n",
      "2017-04-03T20:34:06.848471: step 20522, loss 0.0333028, acc 1\n",
      "2017-04-03T20:34:07.048326: step 20523, loss 0.0950234, acc 0.96875\n",
      "2017-04-03T20:34:07.248103: step 20524, loss 0.203325, acc 0.96875\n",
      "2017-04-03T20:34:07.460766: step 20525, loss 0.050419, acc 1\n",
      "2017-04-03T20:34:07.681158: step 20526, loss 0.0976748, acc 0.96875\n",
      "2017-04-03T20:34:07.896155: step 20527, loss 0.157977, acc 0.953125\n",
      "2017-04-03T20:34:08.118366: step 20528, loss 0.0417541, acc 0.984375\n",
      "2017-04-03T20:34:08.339298: step 20529, loss 0.109783, acc 0.984375\n",
      "2017-04-03T20:34:08.554081: step 20530, loss 0.198656, acc 0.953125\n",
      "2017-04-03T20:34:08.758066: step 20531, loss 0.136862, acc 0.953125\n",
      "2017-04-03T20:34:08.964773: step 20532, loss 0.122692, acc 0.9375\n",
      "2017-04-03T20:34:09.206602: step 20533, loss 0.100094, acc 0.953125\n",
      "2017-04-03T20:34:09.452145: step 20534, loss 0.0479057, acc 1\n",
      "2017-04-03T20:34:09.696417: step 20535, loss 0.0518031, acc 0.984375\n",
      "2017-04-03T20:34:09.897457: step 20536, loss 0.0464547, acc 0.984375\n",
      "2017-04-03T20:34:10.102303: step 20537, loss 0.185552, acc 0.9375\n",
      "2017-04-03T20:34:10.302446: step 20538, loss 0.0445378, acc 0.984375\n",
      "2017-04-03T20:34:10.514399: step 20539, loss 0.0359702, acc 1\n",
      "2017-04-03T20:34:10.717886: step 20540, loss 0.378447, acc 0.90625\n",
      "2017-04-03T20:34:10.922064: step 20541, loss 0.141602, acc 0.9375\n",
      "2017-04-03T20:34:11.128413: step 20542, loss 0.23909, acc 0.984375\n",
      "2017-04-03T20:34:11.331180: step 20543, loss 0.0433528, acc 0.984375\n",
      "2017-04-03T20:34:11.541123: step 20544, loss 0.0502096, acc 0.984375\n",
      "2017-04-03T20:34:11.762595: step 20545, loss 0.0723385, acc 0.96875\n",
      "2017-04-03T20:34:11.963875: step 20546, loss 0.0105881, acc 1\n",
      "2017-04-03T20:34:12.163667: step 20547, loss 0.0839015, acc 0.984375\n",
      "2017-04-03T20:34:12.363423: step 20548, loss 0.0229443, acc 1\n",
      "2017-04-03T20:34:12.605159: step 20549, loss 0.108617, acc 0.9375\n",
      "2017-04-03T20:34:12.807730: step 20550, loss 0.0797747, acc 0.984375\n",
      "2017-04-03T20:34:13.004845: step 20551, loss 0.12189, acc 0.9375\n",
      "2017-04-03T20:34:13.207302: step 20552, loss 0.191077, acc 0.9375\n",
      "2017-04-03T20:34:13.410542: step 20553, loss 0.144072, acc 0.984375\n",
      "2017-04-03T20:34:13.611799: step 20554, loss 0.0347823, acc 0.984375\n",
      "2017-04-03T20:34:13.808891: step 20555, loss 0.0668525, acc 0.984375\n",
      "2017-04-03T20:34:14.011578: step 20556, loss 0.0864551, acc 0.9375\n",
      "2017-04-03T20:34:14.218348: step 20557, loss 0.109278, acc 0.953125\n",
      "2017-04-03T20:34:14.423126: step 20558, loss 0.089908, acc 0.96875\n",
      "2017-04-03T20:34:14.629165: step 20559, loss 0.0120552, acc 1\n",
      "2017-04-03T20:34:14.830922: step 20560, loss 0.0651257, acc 0.984375\n",
      "2017-04-03T20:34:15.030859: step 20561, loss 0.0476072, acc 0.984375\n",
      "2017-04-03T20:34:15.234125: step 20562, loss 0.0896252, acc 0.96875\n",
      "2017-04-03T20:34:15.472864: step 20563, loss 0.222439, acc 0.96875\n",
      "2017-04-03T20:34:15.680595: step 20564, loss 0.0898603, acc 0.96875\n",
      "2017-04-03T20:34:15.922555: step 20565, loss 0.0735454, acc 0.96875\n",
      "2017-04-03T20:34:16.125557: step 20566, loss 0.0682059, acc 0.984375\n",
      "2017-04-03T20:34:16.325623: step 20567, loss 0.124541, acc 0.984375\n",
      "2017-04-03T20:34:16.526303: step 20568, loss 0.102246, acc 0.96875\n",
      "2017-04-03T20:34:16.727959: step 20569, loss 0.145075, acc 0.921875\n",
      "2017-04-03T20:34:16.930406: step 20570, loss 0.0793507, acc 0.96875\n",
      "2017-04-03T20:34:17.131723: step 20571, loss 0.0661809, acc 0.96875\n",
      "2017-04-03T20:34:17.334985: step 20572, loss 0.110173, acc 0.953125\n",
      "2017-04-03T20:34:17.535426: step 20573, loss 0.0671907, acc 0.984375\n",
      "2017-04-03T20:34:17.734952: step 20574, loss 0.0231507, acc 1\n",
      "2017-04-03T20:34:17.939174: step 20575, loss 0.0751257, acc 0.953125\n",
      "2017-04-03T20:34:18.159209: step 20576, loss 0.163795, acc 0.9375\n",
      "2017-04-03T20:34:18.372589: step 20577, loss 0.0998826, acc 0.953125\n",
      "2017-04-03T20:34:18.577633: step 20578, loss 0.0834892, acc 0.984375\n",
      "2017-04-03T20:34:18.779198: step 20579, loss 0.0155797, acc 1\n",
      "2017-04-03T20:34:19.018597: step 20580, loss 0.113329, acc 0.953125\n",
      "2017-04-03T20:34:19.220270: step 20581, loss 0.162578, acc 0.9375\n",
      "2017-04-03T20:34:19.425087: step 20582, loss 0.0824187, acc 0.96875\n",
      "2017-04-03T20:34:19.629614: step 20583, loss 0.121395, acc 0.96875\n",
      "2017-04-03T20:34:19.835332: step 20584, loss 0.128163, acc 0.953125\n",
      "2017-04-03T20:34:20.035484: step 20585, loss 0.105127, acc 0.96875\n",
      "2017-04-03T20:34:20.240109: step 20586, loss 0.135488, acc 0.96875\n",
      "2017-04-03T20:34:20.441209: step 20587, loss 0.059433, acc 1\n",
      "2017-04-03T20:34:20.654223: step 20588, loss 0.114999, acc 0.953125\n",
      "2017-04-03T20:34:20.859072: step 20589, loss 0.0395142, acc 1\n",
      "2017-04-03T20:34:21.106109: step 20590, loss 0.259277, acc 0.9375\n",
      "2017-04-03T20:34:21.304114: step 20591, loss 0.181096, acc 0.90625\n",
      "2017-04-03T20:34:21.500037: step 20592, loss 0.0622295, acc 0.96875\n",
      "2017-04-03T20:34:21.708422: step 20593, loss 0.0366821, acc 1\n",
      "2017-04-03T20:34:21.919093: step 20594, loss 0.0809883, acc 0.984375\n",
      "2017-04-03T20:34:22.164076: step 20595, loss 0.0885377, acc 0.96875\n",
      "2017-04-03T20:34:22.364879: step 20596, loss 0.192151, acc 0.9375\n",
      "2017-04-03T20:34:22.563138: step 20597, loss 0.167166, acc 0.953125\n",
      "2017-04-03T20:34:22.767318: step 20598, loss 0.146001, acc 0.96875\n",
      "2017-04-03T20:34:22.972803: step 20599, loss 0.146775, acc 0.96875\n",
      "2017-04-03T20:34:23.179668: step 20600, loss 0.180961, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:34:25.337899: step 20600, loss 7.69982, acc 0.28075\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-20600\n",
      "\n",
      "2017-04-03T20:34:25.670929: step 20601, loss 0.11427, acc 0.96875\n",
      "2017-04-03T20:34:25.871615: step 20602, loss 0.0477616, acc 0.984375\n",
      "2017-04-03T20:34:26.074838: step 20603, loss 0.225239, acc 0.921875\n",
      "2017-04-03T20:34:26.284714: step 20604, loss 0.0241466, acc 1\n",
      "2017-04-03T20:34:26.488992: step 20605, loss 0.0659819, acc 0.96875\n",
      "2017-04-03T20:34:26.691206: step 20606, loss 0.0386887, acc 0.984375\n",
      "2017-04-03T20:34:26.909542: step 20607, loss 0.0389907, acc 0.984375\n",
      "2017-04-03T20:34:27.124935: step 20608, loss 0.0817296, acc 0.984375\n",
      "2017-04-03T20:34:27.330467: step 20609, loss 0.0879639, acc 0.96875\n",
      "2017-04-03T20:34:27.535800: step 20610, loss 0.0760786, acc 0.984375\n",
      "2017-04-03T20:34:27.734129: step 20611, loss 0.036825, acc 1\n",
      "2017-04-03T20:34:27.937234: step 20612, loss 0.0612573, acc 0.96875\n",
      "2017-04-03T20:34:28.141727: step 20613, loss 0.144302, acc 0.96875\n",
      "2017-04-03T20:34:28.347730: step 20614, loss 0.13784, acc 0.9375\n",
      "2017-04-03T20:34:28.555716: step 20615, loss 0.196442, acc 0.953125\n",
      "2017-04-03T20:34:28.766094: step 20616, loss 0.0913276, acc 0.953125\n",
      "2017-04-03T20:34:29.010510: step 20617, loss 0.27594, acc 0.90625\n",
      "2017-04-03T20:34:29.225857: step 20618, loss 0.0109567, acc 1\n",
      "2017-04-03T20:34:29.442540: step 20619, loss 0.0610429, acc 0.984375\n",
      "2017-04-03T20:34:29.645343: step 20620, loss 0.0351254, acc 0.984375\n",
      "2017-04-03T20:34:29.846832: step 20621, loss 0.167538, acc 0.9375\n",
      "2017-04-03T20:34:30.047023: step 20622, loss 0.105066, acc 0.953125\n",
      "2017-04-03T20:34:30.247154: step 20623, loss 0.0913814, acc 0.984375\n",
      "2017-04-03T20:34:30.451268: step 20624, loss 0.152032, acc 0.9375\n",
      "2017-04-03T20:34:30.699476: step 20625, loss 0.0950622, acc 0.96875\n",
      "2017-04-03T20:34:30.905800: step 20626, loss 0.115476, acc 0.96875\n",
      "2017-04-03T20:34:31.123109: step 20627, loss 0.146188, acc 0.96875\n",
      "2017-04-03T20:34:31.341355: step 20628, loss 0.145633, acc 0.9375\n",
      "2017-04-03T20:34:31.545276: step 20629, loss 0.0298678, acc 1\n",
      "2017-04-03T20:34:31.749432: step 20630, loss 0.100832, acc 0.96875\n",
      "2017-04-03T20:34:31.958856: step 20631, loss 0.10068, acc 0.953125\n",
      "2017-04-03T20:34:32.163627: step 20632, loss 0.0435431, acc 0.984375\n",
      "2017-04-03T20:34:32.368863: step 20633, loss 0.154168, acc 0.953125\n",
      "2017-04-03T20:34:32.591015: step 20634, loss 0.122359, acc 0.96875\n",
      "2017-04-03T20:34:32.808338: step 20635, loss 0.173896, acc 0.9375\n",
      "2017-04-03T20:34:33.030267: step 20636, loss 0.191409, acc 0.921875\n",
      "2017-04-03T20:34:33.249748: step 20637, loss 0.114448, acc 0.953125\n",
      "2017-04-03T20:34:33.461378: step 20638, loss 0.106693, acc 0.9375\n",
      "2017-04-03T20:34:33.667946: step 20639, loss 0.0847627, acc 0.953125\n",
      "2017-04-03T20:34:33.864205: step 20640, loss 0.169377, acc 0.953125\n",
      "2017-04-03T20:34:34.068319: step 20641, loss 0.109354, acc 0.96875\n",
      "2017-04-03T20:34:34.280239: step 20642, loss 0.182498, acc 0.953125\n",
      "2017-04-03T20:34:34.486457: step 20643, loss 0.170368, acc 0.96875\n",
      "2017-04-03T20:34:34.687609: step 20644, loss 0.0733677, acc 0.96875\n",
      "2017-04-03T20:34:34.886380: step 20645, loss 0.135329, acc 0.9375\n",
      "2017-04-03T20:34:35.086844: step 20646, loss 0.246729, acc 0.921875\n",
      "2017-04-03T20:34:35.288535: step 20647, loss 0.11919, acc 0.953125\n",
      "2017-04-03T20:34:35.535053: step 20648, loss 0.175428, acc 0.984375\n",
      "2017-04-03T20:34:35.751069: step 20649, loss 0.0758299, acc 0.953125\n",
      "2017-04-03T20:34:35.955928: step 20650, loss 0.0858243, acc 0.953125\n",
      "2017-04-03T20:34:36.198126: step 20651, loss 0.0766055, acc 0.96875\n",
      "2017-04-03T20:34:36.405560: step 20652, loss 0.0600433, acc 0.96875\n",
      "2017-04-03T20:34:36.604788: step 20653, loss 0.0339646, acc 1\n",
      "2017-04-03T20:34:36.809149: step 20654, loss 0.0280615, acc 0.984375\n",
      "2017-04-03T20:34:37.010876: step 20655, loss 0.125494, acc 0.953125\n",
      "2017-04-03T20:34:37.254167: step 20656, loss 0.0936424, acc 0.984375\n",
      "2017-04-03T20:34:37.459598: step 20657, loss 0.0307768, acc 0.984375\n",
      "2017-04-03T20:34:37.682093: step 20658, loss 0.109887, acc 0.953125\n",
      "2017-04-03T20:34:37.898673: step 20659, loss 0.134009, acc 0.953125\n",
      "2017-04-03T20:34:38.112925: step 20660, loss 0.0669701, acc 0.984375\n",
      "2017-04-03T20:34:38.315292: step 20661, loss 0.0617558, acc 0.96875\n",
      "2017-04-03T20:34:38.517966: step 20662, loss 0.298792, acc 0.921875\n",
      "2017-04-03T20:34:38.722127: step 20663, loss 0.16118, acc 0.96875\n",
      "2017-04-03T20:34:38.929705: step 20664, loss 0.127536, acc 0.953125\n",
      "2017-04-03T20:34:39.146598: step 20665, loss 0.0753879, acc 0.96875\n",
      "2017-04-03T20:34:39.363749: step 20666, loss 0.0841496, acc 0.96875\n",
      "2017-04-03T20:34:39.607272: step 20667, loss 0.0743886, acc 0.984375\n",
      "2017-04-03T20:34:39.827927: step 20668, loss 0.0662634, acc 0.984375\n",
      "2017-04-03T20:34:40.044429: step 20669, loss 0.227203, acc 0.953125\n",
      "2017-04-03T20:34:40.268078: step 20670, loss 0.0250265, acc 1\n",
      "2017-04-03T20:34:40.474510: step 20671, loss 0.0243792, acc 1\n",
      "2017-04-03T20:34:40.675109: step 20672, loss 0.0615921, acc 0.96875\n",
      "2017-04-03T20:34:40.880343: step 20673, loss 0.09202, acc 0.984375\n",
      "2017-04-03T20:34:41.086647: step 20674, loss 0.0867371, acc 0.953125\n",
      "2017-04-03T20:34:41.291719: step 20675, loss 0.245138, acc 0.953125\n",
      "2017-04-03T20:34:41.494434: step 20676, loss 0.120728, acc 0.953125\n",
      "2017-04-03T20:34:41.704460: step 20677, loss 0.111377, acc 0.96875\n",
      "2017-04-03T20:34:41.900259: step 20678, loss 0.0906065, acc 0.984375\n",
      "2017-04-03T20:34:42.099688: step 20679, loss 0.059162, acc 0.984375\n",
      "2017-04-03T20:34:42.299660: step 20680, loss 0.0303752, acc 0.984375\n",
      "2017-04-03T20:34:42.501501: step 20681, loss 0.109088, acc 0.96875\n",
      "2017-04-03T20:34:42.716998: step 20682, loss 0.0148586, acc 1\n",
      "2017-04-03T20:34:42.935230: step 20683, loss 0.22543, acc 0.953125\n",
      "2017-04-03T20:34:43.152032: step 20684, loss 0.227246, acc 0.953125\n",
      "2017-04-03T20:34:43.355696: step 20685, loss 0.135207, acc 0.953125\n",
      "2017-04-03T20:34:43.555526: step 20686, loss 0.659567, acc 0.9375\n",
      "2017-04-03T20:34:43.764599: step 20687, loss 0.134681, acc 0.9375\n",
      "2017-04-03T20:34:43.991962: step 20688, loss 0.149075, acc 0.984375\n",
      "2017-04-03T20:34:44.199254: step 20689, loss 0.049748, acc 0.984375\n",
      "2017-04-03T20:34:44.400762: step 20690, loss 0.267433, acc 0.9375\n",
      "2017-04-03T20:34:44.607563: step 20691, loss 0.0681443, acc 0.984375\n",
      "2017-04-03T20:34:44.828088: step 20692, loss 0.033462, acc 0.96875\n",
      "2017-04-03T20:34:45.051534: step 20693, loss 0.166398, acc 0.953125\n",
      "2017-04-03T20:34:45.259378: step 20694, loss 0.118565, acc 0.984375\n",
      "2017-04-03T20:34:45.457428: step 20695, loss 0.129062, acc 0.96875\n",
      "2017-04-03T20:34:45.660014: step 20696, loss 0.114963, acc 0.96875\n",
      "2017-04-03T20:34:45.860854: step 20697, loss 0.122433, acc 0.96875\n",
      "2017-04-03T20:34:46.069094: step 20698, loss 0.160525, acc 0.9375\n",
      "2017-04-03T20:34:46.273494: step 20699, loss 0.08584, acc 0.953125\n",
      "2017-04-03T20:34:46.478508: step 20700, loss 0.0484161, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:34:48.637781: step 20700, loss 7.59837, acc 0.283\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-20700\n",
      "\n",
      "2017-04-03T20:34:49.003657: step 20701, loss 0.0716881, acc 0.96875\n",
      "2017-04-03T20:34:49.220391: step 20702, loss 0.04713, acc 0.984375\n",
      "2017-04-03T20:34:49.439077: step 20703, loss 0.106327, acc 0.921875\n",
      "2017-04-03T20:34:49.641670: step 20704, loss 0.10285, acc 0.96875\n",
      "2017-04-03T20:34:49.845548: step 20705, loss 0.024856, acc 1\n",
      "2017-04-03T20:34:50.047472: step 20706, loss 0.0673598, acc 0.984375\n",
      "2017-04-03T20:34:50.247469: step 20707, loss 0.0986853, acc 0.984375\n",
      "2017-04-03T20:34:50.458333: step 20708, loss 0.177894, acc 0.96875\n",
      "2017-04-03T20:34:50.672179: step 20709, loss 0.0335925, acc 1\n",
      "2017-04-03T20:34:50.893402: step 20710, loss 0.081874, acc 0.96875\n",
      "2017-04-03T20:34:51.111525: step 20711, loss 0.225323, acc 0.984375\n",
      "2017-04-03T20:34:51.326413: step 20712, loss 0.0704135, acc 0.984375\n",
      "2017-04-03T20:34:51.551132: step 20713, loss 0.0357047, acc 1\n",
      "2017-04-03T20:34:51.755888: step 20714, loss 0.0457576, acc 0.984375\n",
      "2017-04-03T20:34:51.959982: step 20715, loss 0.148291, acc 0.921875\n",
      "2017-04-03T20:34:52.158546: step 20716, loss 0.093641, acc 0.96875\n",
      "2017-04-03T20:34:52.400982: step 20717, loss 0.0290783, acc 1\n",
      "2017-04-03T20:34:52.611033: step 20718, loss 0.0483697, acc 1\n",
      "2017-04-03T20:34:52.823582: step 20719, loss 0.0393688, acc 0.984375\n",
      "2017-04-03T20:34:53.026019: step 20720, loss 0.109684, acc 0.953125\n",
      "2017-04-03T20:34:53.225433: step 20721, loss 0.0443513, acc 1\n",
      "2017-04-03T20:34:53.423671: step 20722, loss 0.1627, acc 0.96875\n",
      "2017-04-03T20:34:53.631744: step 20723, loss 0.107444, acc 0.96875\n",
      "2017-04-03T20:34:53.838048: step 20724, loss 0.142892, acc 0.96875\n",
      "2017-04-03T20:34:54.037766: step 20725, loss 0.045362, acc 0.984375\n",
      "2017-04-03T20:34:54.240655: step 20726, loss 0.114985, acc 0.953125\n",
      "2017-04-03T20:34:54.459383: step 20727, loss 0.0292758, acc 1\n",
      "2017-04-03T20:34:54.670670: step 20728, loss 0.0960871, acc 0.96875\n",
      "2017-04-03T20:34:54.877471: step 20729, loss 0.0648542, acc 0.984375\n",
      "2017-04-03T20:34:55.076611: step 20730, loss 0.11356, acc 0.9375\n",
      "2017-04-03T20:34:55.277540: step 20731, loss 0.0789436, acc 0.96875\n",
      "2017-04-03T20:34:55.476303: step 20732, loss 0.117221, acc 0.953125\n",
      "2017-04-03T20:34:55.677996: step 20733, loss 0.0618069, acc 0.984375\n",
      "2017-04-03T20:34:55.920082: step 20734, loss 0.0782877, acc 0.9375\n",
      "2017-04-03T20:34:56.126020: step 20735, loss 0.026138, acc 1\n",
      "2017-04-03T20:34:56.333069: step 20736, loss 0.072468, acc 0.96875\n",
      "2017-04-03T20:34:56.534139: step 20737, loss 0.0109472, acc 1\n",
      "2017-04-03T20:34:56.736602: step 20738, loss 0.128054, acc 0.953125\n",
      "2017-04-03T20:34:56.936749: step 20739, loss 0.0489975, acc 0.984375\n",
      "2017-04-03T20:34:57.141584: step 20740, loss 0.0190969, acc 1\n",
      "2017-04-03T20:34:57.344871: step 20741, loss 0.181034, acc 0.96875\n",
      "2017-04-03T20:34:57.547994: step 20742, loss 0.133267, acc 0.953125\n",
      "2017-04-03T20:34:57.758895: step 20743, loss 0.269095, acc 0.953125\n",
      "2017-04-03T20:34:57.965250: step 20744, loss 0.193905, acc 0.953125\n",
      "2017-04-03T20:34:58.169128: step 20745, loss 0.0859393, acc 0.96875\n",
      "2017-04-03T20:34:58.366230: step 20746, loss 0.0661511, acc 0.984375\n",
      "2017-04-03T20:34:58.563861: step 20747, loss 0.217677, acc 0.90625\n",
      "2017-04-03T20:34:58.772566: step 20748, loss 0.168917, acc 0.953125\n",
      "2017-04-03T20:34:58.976326: step 20749, loss 0.0957441, acc 0.96875\n",
      "2017-04-03T20:34:59.174798: step 20750, loss 0.2107, acc 0.96875\n",
      "2017-04-03T20:34:59.376156: step 20751, loss 0.0820421, acc 0.96875\n",
      "2017-04-03T20:34:59.577926: step 20752, loss 0.107719, acc 0.96875\n",
      "2017-04-03T20:34:59.778658: step 20753, loss 0.0325892, acc 0.984375\n",
      "2017-04-03T20:34:59.978571: step 20754, loss 0.0388854, acc 0.984375\n",
      "2017-04-03T20:35:00.183519: step 20755, loss 0.13168, acc 0.953125\n",
      "2017-04-03T20:35:00.395358: step 20756, loss 0.0754855, acc 0.96875\n",
      "2017-04-03T20:35:00.598204: step 20757, loss 0.0226684, acc 1\n",
      "2017-04-03T20:35:00.814561: step 20758, loss 0.0561153, acc 0.96875\n",
      "2017-04-03T20:35:01.028546: step 20759, loss 0.0669006, acc 1\n",
      "2017-04-03T20:35:01.226675: step 20760, loss 0.0954433, acc 0.953125\n",
      "2017-04-03T20:35:01.428757: step 20761, loss 0.141891, acc 0.953125\n",
      "2017-04-03T20:35:01.675926: step 20762, loss 0.119485, acc 0.96875\n",
      "2017-04-03T20:35:01.886169: step 20763, loss 0.145594, acc 0.953125\n",
      "2017-04-03T20:35:02.098276: step 20764, loss 0.0489871, acc 0.984375\n",
      "2017-04-03T20:35:02.300748: step 20765, loss 0.065115, acc 0.984375\n",
      "2017-04-03T20:35:02.501517: step 20766, loss 0.0457844, acc 1\n",
      "2017-04-03T20:35:02.707739: step 20767, loss 0.0441666, acc 0.984375\n",
      "2017-04-03T20:35:02.911564: step 20768, loss 0.0517972, acc 0.984375\n",
      "2017-04-03T20:35:03.118386: step 20769, loss 0.235436, acc 0.953125\n",
      "2017-04-03T20:35:03.318878: step 20770, loss 0.0949107, acc 0.9375\n",
      "2017-04-03T20:35:03.524075: step 20771, loss 0.181623, acc 0.953125\n",
      "2017-04-03T20:35:03.726223: step 20772, loss 0.152185, acc 0.953125\n",
      "2017-04-03T20:35:03.930913: step 20773, loss 0.088354, acc 0.984375\n",
      "2017-04-03T20:35:04.138025: step 20774, loss 0.162059, acc 0.9375\n",
      "2017-04-03T20:35:04.341283: step 20775, loss 0.0904062, acc 0.96875\n",
      "2017-04-03T20:35:04.549943: step 20776, loss 0.0309809, acc 0.984375\n",
      "2017-04-03T20:35:04.755597: step 20777, loss 0.160847, acc 0.9375\n",
      "2017-04-03T20:35:04.962054: step 20778, loss 0.0571424, acc 0.984375\n",
      "2017-04-03T20:35:05.166219: step 20779, loss 0.0315415, acc 0.984375\n",
      "2017-04-03T20:35:05.375679: step 20780, loss 0.0632574, acc 0.96875\n",
      "2017-04-03T20:35:05.578252: step 20781, loss 0.0649274, acc 0.96875\n",
      "2017-04-03T20:35:05.780712: step 20782, loss 0.165986, acc 0.953125\n",
      "2017-04-03T20:35:05.984785: step 20783, loss 0.147236, acc 0.9375\n",
      "2017-04-03T20:35:06.186596: step 20784, loss 0.12098, acc 0.953125\n",
      "2017-04-03T20:35:06.388729: step 20785, loss 0.0386462, acc 0.984375\n",
      "2017-04-03T20:35:06.596214: step 20786, loss 0.0579563, acc 0.984375\n",
      "2017-04-03T20:35:06.798748: step 20787, loss 0.244265, acc 0.90625\n",
      "2017-04-03T20:35:07.005941: step 20788, loss 0.243419, acc 0.90625\n",
      "2017-04-03T20:35:07.210707: step 20789, loss 0.140761, acc 0.984375\n",
      "2017-04-03T20:35:07.412709: step 20790, loss 0.0234874, acc 1\n",
      "2017-04-03T20:35:07.619001: step 20791, loss 0.0484655, acc 0.984375\n",
      "2017-04-03T20:35:07.820800: step 20792, loss 0.0622869, acc 0.96875\n",
      "2017-04-03T20:35:08.074787: step 20793, loss 0.107862, acc 0.96875\n",
      "2017-04-03T20:35:08.276717: step 20794, loss 0.110082, acc 0.96875\n",
      "2017-04-03T20:35:08.485163: step 20795, loss 0.146299, acc 0.96875\n",
      "2017-04-03T20:35:08.689789: step 20796, loss 0.139348, acc 0.953125\n",
      "2017-04-03T20:35:08.892055: step 20797, loss 0.0787034, acc 0.96875\n",
      "2017-04-03T20:35:09.094225: step 20798, loss 0.0400663, acc 1\n",
      "2017-04-03T20:35:09.304110: step 20799, loss 0.0291064, acc 1\n",
      "2017-04-03T20:35:09.506071: step 20800, loss 0.0864784, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:35:11.621214: step 20800, loss 7.7396, acc 0.2795\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-20800\n",
      "\n",
      "2017-04-03T20:35:11.955436: step 20801, loss 0.0779728, acc 0.96875\n",
      "2017-04-03T20:35:12.201877: step 20802, loss 0.029589, acc 0.984375\n",
      "2017-04-03T20:35:12.420547: step 20803, loss 0.179173, acc 0.9375\n",
      "2017-04-03T20:35:12.622687: step 20804, loss 0.148797, acc 0.96875\n",
      "2017-04-03T20:35:12.826127: step 20805, loss 0.0424675, acc 1\n",
      "2017-04-03T20:35:13.029758: step 20806, loss 0.177786, acc 0.96875\n",
      "2017-04-03T20:35:13.236787: step 20807, loss 0.170349, acc 0.9375\n",
      "2017-04-03T20:35:13.484778: step 20808, loss 0.36527, acc 0.921875\n",
      "2017-04-03T20:35:13.686817: step 20809, loss 0.212491, acc 0.953125\n",
      "2017-04-03T20:35:13.891895: step 20810, loss 0.336058, acc 0.96875\n",
      "2017-04-03T20:35:14.096206: step 20811, loss 0.0326322, acc 1\n",
      "2017-04-03T20:35:14.304364: step 20812, loss 0.111435, acc 0.953125\n",
      "2017-04-03T20:35:14.503185: step 20813, loss 0.174554, acc 0.953125\n",
      "2017-04-03T20:35:14.714949: step 20814, loss 0.181691, acc 0.9375\n",
      "2017-04-03T20:35:14.922189: step 20815, loss 0.0124909, acc 1\n",
      "2017-04-03T20:35:15.134141: step 20816, loss 0.105757, acc 0.953125\n",
      "2017-04-03T20:35:15.340855: step 20817, loss 0.150395, acc 0.9375\n",
      "2017-04-03T20:35:15.544301: step 20818, loss 0.140041, acc 0.953125\n",
      "2017-04-03T20:35:15.748210: step 20819, loss 0.0861538, acc 0.96875\n",
      "2017-04-03T20:35:15.956914: step 20820, loss 0.061289, acc 0.984375\n",
      "2017-04-03T20:35:16.162547: step 20821, loss 0.102035, acc 0.984375\n",
      "2017-04-03T20:35:16.363818: step 20822, loss 0.112693, acc 0.953125\n",
      "2017-04-03T20:35:16.564870: step 20823, loss 0.151263, acc 0.953125\n",
      "2017-04-03T20:35:16.764060: step 20824, loss 0.0779924, acc 0.984375\n",
      "2017-04-03T20:35:16.963542: step 20825, loss 0.0661399, acc 0.96875\n",
      "2017-04-03T20:35:17.163203: step 20826, loss 0.252018, acc 0.90625\n",
      "2017-04-03T20:35:17.372103: step 20827, loss 0.132627, acc 0.953125\n",
      "2017-04-03T20:35:17.619443: step 20828, loss 0.104977, acc 0.96875\n",
      "2017-04-03T20:35:17.835465: step 20829, loss 0.210752, acc 0.9375\n",
      "2017-04-03T20:35:18.042420: step 20830, loss 0.0417542, acc 0.984375\n",
      "2017-04-03T20:35:18.184387: step 20831, loss 0.0106988, acc 1\n",
      "2017-04-03T20:35:18.433321: step 20832, loss 0.121786, acc 0.921875\n",
      "2017-04-03T20:35:18.677443: step 20833, loss 0.0338504, acc 1\n",
      "2017-04-03T20:35:18.887533: step 20834, loss 0.0452052, acc 0.984375\n",
      "2017-04-03T20:35:19.133673: step 20835, loss 0.148369, acc 0.9375\n",
      "2017-04-03T20:35:19.339162: step 20836, loss 0.031527, acc 1\n",
      "2017-04-03T20:35:19.542292: step 20837, loss 0.0472709, acc 0.984375\n",
      "2017-04-03T20:35:19.745066: step 20838, loss 0.0834566, acc 0.984375\n",
      "2017-04-03T20:35:19.946451: step 20839, loss 0.0551082, acc 0.984375\n",
      "2017-04-03T20:35:20.148900: step 20840, loss 0.123836, acc 0.984375\n",
      "2017-04-03T20:35:20.398964: step 20841, loss 0.0671169, acc 0.984375\n",
      "2017-04-03T20:35:20.611221: step 20842, loss 0.162813, acc 0.953125\n",
      "2017-04-03T20:35:20.823077: step 20843, loss 0.0558931, acc 0.96875\n",
      "2017-04-03T20:35:21.029241: step 20844, loss 0.178171, acc 0.9375\n",
      "2017-04-03T20:35:21.232918: step 20845, loss 0.0447401, acc 0.984375\n",
      "2017-04-03T20:35:21.438886: step 20846, loss 0.0595937, acc 0.984375\n",
      "2017-04-03T20:35:21.645886: step 20847, loss 0.0469313, acc 0.984375\n",
      "2017-04-03T20:35:21.852032: step 20848, loss 0.0505197, acc 0.984375\n",
      "2017-04-03T20:35:22.054860: step 20849, loss 0.0547274, acc 0.984375\n",
      "2017-04-03T20:35:22.257635: step 20850, loss 0.108364, acc 0.9375\n",
      "2017-04-03T20:35:22.504756: step 20851, loss 0.0762785, acc 0.96875\n",
      "2017-04-03T20:35:22.715162: step 20852, loss 0.0291851, acc 1\n",
      "2017-04-03T20:35:22.918896: step 20853, loss 0.197819, acc 0.921875\n",
      "2017-04-03T20:35:23.133052: step 20854, loss 0.0568769, acc 1\n",
      "2017-04-03T20:35:23.336589: step 20855, loss 0.0863285, acc 0.96875\n",
      "2017-04-03T20:35:23.542997: step 20856, loss 0.0527318, acc 0.984375\n",
      "2017-04-03T20:35:23.749235: step 20857, loss 0.0371051, acc 0.984375\n",
      "2017-04-03T20:35:23.955954: step 20858, loss 0.106947, acc 0.953125\n",
      "2017-04-03T20:35:24.154945: step 20859, loss 0.0192393, acc 1\n",
      "2017-04-03T20:35:24.354686: step 20860, loss 0.080776, acc 0.96875\n",
      "2017-04-03T20:35:24.553287: step 20861, loss 0.184333, acc 0.953125\n",
      "2017-04-03T20:35:24.758623: step 20862, loss 0.0762593, acc 0.984375\n",
      "2017-04-03T20:35:24.967540: step 20863, loss 0.172823, acc 0.9375\n",
      "2017-04-03T20:35:25.183735: step 20864, loss 0.0573831, acc 0.984375\n",
      "2017-04-03T20:35:25.393612: step 20865, loss 0.0149788, acc 1\n",
      "2017-04-03T20:35:25.591105: step 20866, loss 0.063851, acc 0.96875\n",
      "2017-04-03T20:35:25.800511: step 20867, loss 0.0604314, acc 0.96875\n",
      "2017-04-03T20:35:26.006449: step 20868, loss 0.0503273, acc 0.984375\n",
      "2017-04-03T20:35:26.209360: step 20869, loss 0.100883, acc 0.96875\n",
      "2017-04-03T20:35:26.408805: step 20870, loss 0.106305, acc 0.984375\n",
      "2017-04-03T20:35:26.608017: step 20871, loss 0.048973, acc 0.984375\n",
      "2017-04-03T20:35:26.863803: step 20872, loss 0.0999985, acc 0.953125\n",
      "2017-04-03T20:35:27.064858: step 20873, loss 0.222693, acc 0.921875\n",
      "2017-04-03T20:35:27.267191: step 20874, loss 0.0559795, acc 0.96875\n",
      "2017-04-03T20:35:27.467656: step 20875, loss 0.0356913, acc 0.984375\n",
      "2017-04-03T20:35:27.671210: step 20876, loss 0.0771258, acc 0.96875\n",
      "2017-04-03T20:35:27.913205: step 20877, loss 0.043641, acc 0.984375\n",
      "2017-04-03T20:35:28.110221: step 20878, loss 0.0942077, acc 0.953125\n",
      "2017-04-03T20:35:28.318111: step 20879, loss 0.0748232, acc 0.984375\n",
      "2017-04-03T20:35:28.513996: step 20880, loss 0.0537424, acc 0.984375\n",
      "2017-04-03T20:35:28.752141: step 20881, loss 0.0150195, acc 1\n",
      "2017-04-03T20:35:28.975204: step 20882, loss 0.0790369, acc 0.96875\n",
      "2017-04-03T20:35:29.181636: step 20883, loss 0.193072, acc 0.921875\n",
      "2017-04-03T20:35:29.387193: step 20884, loss 0.0687496, acc 0.96875\n",
      "2017-04-03T20:35:29.594208: step 20885, loss 0.0540389, acc 0.96875\n",
      "2017-04-03T20:35:29.841042: step 20886, loss 0.105536, acc 0.9375\n",
      "2017-04-03T20:35:30.043783: step 20887, loss 0.0611103, acc 0.984375\n",
      "2017-04-03T20:35:30.249153: step 20888, loss 0.0564559, acc 0.96875\n",
      "2017-04-03T20:35:30.455036: step 20889, loss 0.0775447, acc 0.96875\n",
      "2017-04-03T20:35:30.657809: step 20890, loss 0.0599162, acc 0.984375\n",
      "2017-04-03T20:35:30.860550: step 20891, loss 0.104936, acc 0.9375\n",
      "2017-04-03T20:35:31.066301: step 20892, loss 0.110073, acc 0.953125\n",
      "2017-04-03T20:35:31.284316: step 20893, loss 0.039604, acc 0.984375\n",
      "2017-04-03T20:35:31.484341: step 20894, loss 0.147392, acc 0.953125\n",
      "2017-04-03T20:35:31.684562: step 20895, loss 0.138223, acc 0.96875\n",
      "2017-04-03T20:35:31.884992: step 20896, loss 0.159563, acc 0.96875\n",
      "2017-04-03T20:35:32.088200: step 20897, loss 0.267384, acc 0.953125\n",
      "2017-04-03T20:35:32.290262: step 20898, loss 0.0206166, acc 1\n",
      "2017-04-03T20:35:32.507806: step 20899, loss 0.209909, acc 0.953125\n",
      "2017-04-03T20:35:32.726456: step 20900, loss 0.0319664, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:35:34.871262: step 20900, loss 7.75505, acc 0.2835\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-20900\n",
      "\n",
      "2017-04-03T20:35:35.215239: step 20901, loss 0.108143, acc 0.953125\n",
      "2017-04-03T20:35:35.413774: step 20902, loss 0.0908468, acc 0.984375\n",
      "2017-04-03T20:35:35.652382: step 20903, loss 0.0404231, acc 0.984375\n",
      "2017-04-03T20:35:35.853613: step 20904, loss 0.0677397, acc 0.984375\n",
      "2017-04-03T20:35:36.057172: step 20905, loss 0.126695, acc 0.984375\n",
      "2017-04-03T20:35:36.255484: step 20906, loss 0.0374414, acc 1\n",
      "2017-04-03T20:35:36.459814: step 20907, loss 0.0785989, acc 0.984375\n",
      "2017-04-03T20:35:36.660686: step 20908, loss 0.0442196, acc 0.984375\n",
      "2017-04-03T20:35:36.868425: step 20909, loss 0.0700177, acc 0.96875\n",
      "2017-04-03T20:35:37.071707: step 20910, loss 0.077326, acc 0.96875\n",
      "2017-04-03T20:35:37.272859: step 20911, loss 0.0347382, acc 1\n",
      "2017-04-03T20:35:37.473717: step 20912, loss 0.0858515, acc 0.96875\n",
      "2017-04-03T20:35:37.707133: step 20913, loss 0.0527696, acc 0.96875\n",
      "2017-04-03T20:35:37.926786: step 20914, loss 0.0708009, acc 0.96875\n",
      "2017-04-03T20:35:38.124938: step 20915, loss 0.196775, acc 0.9375\n",
      "2017-04-03T20:35:38.331460: step 20916, loss 0.0330586, acc 1\n",
      "2017-04-03T20:35:38.529099: step 20917, loss 0.0923558, acc 0.953125\n",
      "2017-04-03T20:35:38.727888: step 20918, loss 0.0612151, acc 0.96875\n",
      "2017-04-03T20:35:38.930779: step 20919, loss 0.0322327, acc 0.984375\n",
      "2017-04-03T20:35:39.135259: step 20920, loss 0.0457407, acc 0.984375\n",
      "2017-04-03T20:35:39.342872: step 20921, loss 0.0651671, acc 0.96875\n",
      "2017-04-03T20:35:39.557407: step 20922, loss 0.0554498, acc 0.984375\n",
      "2017-04-03T20:35:39.758702: step 20923, loss 0.107017, acc 0.96875\n",
      "2017-04-03T20:35:39.972848: step 20924, loss 0.0738847, acc 0.96875\n",
      "2017-04-03T20:35:40.182900: step 20925, loss 0.123851, acc 0.96875\n",
      "2017-04-03T20:35:40.387535: step 20926, loss 0.0387739, acc 0.984375\n",
      "2017-04-03T20:35:40.591472: step 20927, loss 0.196125, acc 0.953125\n",
      "2017-04-03T20:35:40.787928: step 20928, loss 0.0837354, acc 0.953125\n",
      "2017-04-03T20:35:41.027319: step 20929, loss 0.121585, acc 0.9375\n",
      "2017-04-03T20:35:41.248140: step 20930, loss 0.0714763, acc 0.96875\n",
      "2017-04-03T20:35:41.450016: step 20931, loss 0.0703976, acc 0.96875\n",
      "2017-04-03T20:35:41.656186: step 20932, loss 0.0449533, acc 1\n",
      "2017-04-03T20:35:41.856217: step 20933, loss 0.0339484, acc 0.984375\n",
      "2017-04-03T20:35:42.102026: step 20934, loss 0.0326962, acc 0.984375\n",
      "2017-04-03T20:35:42.307416: step 20935, loss 0.0459567, acc 0.984375\n",
      "2017-04-03T20:35:42.514672: step 20936, loss 0.0739316, acc 0.984375\n",
      "2017-04-03T20:35:42.715385: step 20937, loss 0.0451687, acc 0.96875\n",
      "2017-04-03T20:35:42.917856: step 20938, loss 0.033937, acc 0.984375\n",
      "2017-04-03T20:35:43.123570: step 20939, loss 0.212098, acc 0.921875\n",
      "2017-04-03T20:35:43.328799: step 20940, loss 0.00583094, acc 1\n",
      "2017-04-03T20:35:43.530451: step 20941, loss 0.0307612, acc 1\n",
      "2017-04-03T20:35:43.773155: step 20942, loss 0.214341, acc 0.9375\n",
      "2017-04-03T20:35:43.990160: step 20943, loss 0.0834017, acc 0.984375\n",
      "2017-04-03T20:35:44.203812: step 20944, loss 0.115039, acc 0.953125\n",
      "2017-04-03T20:35:44.444059: step 20945, loss 0.031922, acc 1\n",
      "2017-04-03T20:35:44.650083: step 20946, loss 0.0729632, acc 0.96875\n",
      "2017-04-03T20:35:44.849811: step 20947, loss 0.0483542, acc 0.984375\n",
      "2017-04-03T20:35:45.052264: step 20948, loss 0.0209797, acc 1\n",
      "2017-04-03T20:35:45.256272: step 20949, loss 0.17519, acc 0.953125\n",
      "2017-04-03T20:35:45.460771: step 20950, loss 0.0732676, acc 0.984375\n",
      "2017-04-03T20:35:45.659803: step 20951, loss 0.197562, acc 0.921875\n",
      "2017-04-03T20:35:45.863547: step 20952, loss 0.0804564, acc 0.953125\n",
      "2017-04-03T20:35:46.064538: step 20953, loss 0.0214988, acc 1\n",
      "2017-04-03T20:35:46.277528: step 20954, loss 0.103555, acc 0.953125\n",
      "2017-04-03T20:35:46.481463: step 20955, loss 0.0647104, acc 0.96875\n",
      "2017-04-03T20:35:46.692623: step 20956, loss 0.139981, acc 0.96875\n",
      "2017-04-03T20:35:46.894238: step 20957, loss 0.0342547, acc 1\n",
      "2017-04-03T20:35:47.093503: step 20958, loss 0.0175968, acc 1\n",
      "2017-04-03T20:35:47.316017: step 20959, loss 0.120439, acc 0.953125\n",
      "2017-04-03T20:35:47.523040: step 20960, loss 0.0146655, acc 1\n",
      "2017-04-03T20:35:47.722890: step 20961, loss 0.0481976, acc 0.984375\n",
      "2017-04-03T20:35:47.924092: step 20962, loss 0.0611396, acc 0.96875\n",
      "2017-04-03T20:35:48.141547: step 20963, loss 0.0462964, acc 0.984375\n",
      "2017-04-03T20:35:48.338343: step 20964, loss 0.0360568, acc 1\n",
      "2017-04-03T20:35:48.544038: step 20965, loss 0.0275105, acc 0.984375\n",
      "2017-04-03T20:35:48.744531: step 20966, loss 0.0593485, acc 0.984375\n",
      "2017-04-03T20:35:48.944396: step 20967, loss 0.0529855, acc 0.96875\n",
      "2017-04-03T20:35:49.143482: step 20968, loss 0.0899307, acc 0.96875\n",
      "2017-04-03T20:35:49.342810: step 20969, loss 0.104127, acc 0.953125\n",
      "2017-04-03T20:35:49.545590: step 20970, loss 0.0696803, acc 0.984375\n",
      "2017-04-03T20:35:49.748343: step 20971, loss 0.177054, acc 0.96875\n",
      "2017-04-03T20:35:49.951541: step 20972, loss 0.262574, acc 0.953125\n",
      "2017-04-03T20:35:50.150667: step 20973, loss 0.153283, acc 0.9375\n",
      "2017-04-03T20:35:50.361331: step 20974, loss 0.0979363, acc 0.9375\n",
      "2017-04-03T20:35:50.578539: step 20975, loss 0.0828246, acc 0.96875\n",
      "2017-04-03T20:35:50.778440: step 20976, loss 0.0677659, acc 0.96875\n",
      "2017-04-03T20:35:50.980973: step 20977, loss 0.0715886, acc 0.984375\n",
      "2017-04-03T20:35:51.180011: step 20978, loss 0.062161, acc 0.953125\n",
      "2017-04-03T20:35:51.399859: step 20979, loss 0.0754314, acc 0.953125\n",
      "2017-04-03T20:35:51.609165: step 20980, loss 0.00938738, acc 1\n",
      "2017-04-03T20:35:51.850160: step 20981, loss 0.0657083, acc 0.984375\n",
      "2017-04-03T20:35:52.049553: step 20982, loss 0.092242, acc 0.953125\n",
      "2017-04-03T20:35:52.250037: step 20983, loss 0.112328, acc 0.953125\n",
      "2017-04-03T20:35:52.451380: step 20984, loss 0.0494854, acc 0.984375\n",
      "2017-04-03T20:35:52.657089: step 20985, loss 0.107995, acc 0.984375\n",
      "2017-04-03T20:35:52.859438: step 20986, loss 0.192297, acc 0.9375\n",
      "2017-04-03T20:35:53.066459: step 20987, loss 0.00545422, acc 1\n",
      "2017-04-03T20:35:53.266402: step 20988, loss 0.133771, acc 0.96875\n",
      "2017-04-03T20:35:53.469522: step 20989, loss 0.214367, acc 0.953125\n",
      "2017-04-03T20:35:53.688143: step 20990, loss 0.160277, acc 0.953125\n",
      "2017-04-03T20:35:53.893501: step 20991, loss 0.135993, acc 0.953125\n",
      "2017-04-03T20:35:54.093688: step 20992, loss 0.031331, acc 0.984375\n",
      "2017-04-03T20:35:54.291929: step 20993, loss 0.0316865, acc 1\n",
      "2017-04-03T20:35:54.491837: step 20994, loss 0.0376448, acc 1\n",
      "2017-04-03T20:35:54.692466: step 20995, loss 0.0202642, acc 1\n",
      "2017-04-03T20:35:54.901600: step 20996, loss 0.0748197, acc 0.953125\n",
      "2017-04-03T20:35:55.099248: step 20997, loss 0.0385018, acc 0.984375\n",
      "2017-04-03T20:35:55.299640: step 20998, loss 0.0584407, acc 0.984375\n",
      "2017-04-03T20:35:55.498794: step 20999, loss 0.0364777, acc 0.984375\n",
      "2017-04-03T20:35:55.739431: step 21000, loss 0.12371, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:35:57.869681: step 21000, loss 7.72994, acc 0.28775\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-21000\n",
      "\n",
      "2017-04-03T20:35:58.198632: step 21001, loss 0.0881833, acc 0.96875\n",
      "2017-04-03T20:35:58.400474: step 21002, loss 0.123891, acc 0.96875\n",
      "2017-04-03T20:35:58.600384: step 21003, loss 0.0583174, acc 0.96875\n",
      "2017-04-03T20:35:58.803983: step 21004, loss 0.0999931, acc 0.953125\n",
      "2017-04-03T20:35:59.004065: step 21005, loss 0.176628, acc 0.953125\n",
      "2017-04-03T20:35:59.209172: step 21006, loss 0.0343582, acc 1\n",
      "2017-04-03T20:35:59.416716: step 21007, loss 0.0736304, acc 0.984375\n",
      "2017-04-03T20:35:59.630391: step 21008, loss 0.0827269, acc 0.984375\n",
      "2017-04-03T20:35:59.834066: step 21009, loss 0.0678892, acc 0.984375\n",
      "2017-04-03T20:36:00.037301: step 21010, loss 0.125481, acc 0.96875\n",
      "2017-04-03T20:36:00.239326: step 21011, loss 0.215414, acc 0.953125\n",
      "2017-04-03T20:36:00.448442: step 21012, loss 0.0766355, acc 0.984375\n",
      "2017-04-03T20:36:00.654989: step 21013, loss 0.154665, acc 0.953125\n",
      "2017-04-03T20:36:00.872635: step 21014, loss 0.0684748, acc 0.96875\n",
      "2017-04-03T20:36:01.092029: step 21015, loss 0.106022, acc 0.96875\n",
      "2017-04-03T20:36:01.308453: step 21016, loss 0.164658, acc 0.9375\n",
      "2017-04-03T20:36:01.506460: step 21017, loss 0.0393881, acc 0.984375\n",
      "2017-04-03T20:36:01.709261: step 21018, loss 0.13625, acc 0.96875\n",
      "2017-04-03T20:36:01.908955: step 21019, loss 0.0343545, acc 1\n",
      "2017-04-03T20:36:02.110970: step 21020, loss 0.0688476, acc 0.96875\n",
      "2017-04-03T20:36:02.309063: step 21021, loss 0.140017, acc 0.96875\n",
      "2017-04-03T20:36:02.552998: step 21022, loss 0.0664564, acc 0.984375\n",
      "2017-04-03T20:36:02.762915: step 21023, loss 0.0346939, acc 1\n",
      "2017-04-03T20:36:02.961507: step 21024, loss 0.0727907, acc 0.984375\n",
      "2017-04-03T20:36:03.168537: step 21025, loss 0.0794124, acc 0.984375\n",
      "2017-04-03T20:36:03.372312: step 21026, loss 0.0904272, acc 0.953125\n",
      "2017-04-03T20:36:03.577998: step 21027, loss 0.09132, acc 0.953125\n",
      "2017-04-03T20:36:03.778263: step 21028, loss 0.084828, acc 0.96875\n",
      "2017-04-03T20:36:03.978237: step 21029, loss 0.0259504, acc 1\n",
      "2017-04-03T20:36:04.193352: step 21030, loss 0.0383089, acc 0.984375\n",
      "2017-04-03T20:36:04.391809: step 21031, loss 0.0191279, acc 1\n",
      "2017-04-03T20:36:04.592275: step 21032, loss 0.0645044, acc 0.96875\n",
      "2017-04-03T20:36:04.798022: step 21033, loss 0.130876, acc 0.984375\n",
      "2017-04-03T20:36:05.000289: step 21034, loss 0.0532652, acc 0.984375\n",
      "2017-04-03T20:36:05.199366: step 21035, loss 0.196038, acc 0.96875\n",
      "2017-04-03T20:36:05.399327: step 21036, loss 0.0958235, acc 0.984375\n",
      "2017-04-03T20:36:05.605688: step 21037, loss 0.0721944, acc 0.984375\n",
      "2017-04-03T20:36:05.817665: step 21038, loss 0.0560539, acc 0.984375\n",
      "2017-04-03T20:36:06.023715: step 21039, loss 0.0262832, acc 1\n",
      "2017-04-03T20:36:06.225244: step 21040, loss 0.102062, acc 0.953125\n",
      "2017-04-03T20:36:06.424104: step 21041, loss 0.0494181, acc 0.96875\n",
      "2017-04-03T20:36:06.626580: step 21042, loss 0.10387, acc 0.953125\n",
      "2017-04-03T20:36:06.826533: step 21043, loss 0.192496, acc 0.96875\n",
      "2017-04-03T20:36:07.028630: step 21044, loss 0.0281702, acc 1\n",
      "2017-04-03T20:36:07.229585: step 21045, loss 0.167615, acc 0.953125\n",
      "2017-04-03T20:36:07.436001: step 21046, loss 0.0395799, acc 0.984375\n",
      "2017-04-03T20:36:07.649925: step 21047, loss 0.0813318, acc 0.953125\n",
      "2017-04-03T20:36:07.852042: step 21048, loss 0.137295, acc 0.953125\n",
      "2017-04-03T20:36:08.066243: step 21049, loss 0.0916417, acc 0.953125\n",
      "2017-04-03T20:36:08.282447: step 21050, loss 0.173773, acc 0.9375\n",
      "2017-04-03T20:36:08.488549: step 21051, loss 0.108202, acc 0.96875\n",
      "2017-04-03T20:36:08.709979: step 21052, loss 0.119082, acc 0.953125\n",
      "2017-04-03T20:36:08.944691: step 21053, loss 0.135597, acc 0.96875\n",
      "2017-04-03T20:36:09.142705: step 21054, loss 0.0609758, acc 0.96875\n",
      "2017-04-03T20:36:09.338768: step 21055, loss 0.0301672, acc 0.984375\n",
      "2017-04-03T20:36:09.543785: step 21056, loss 0.0766997, acc 0.984375\n",
      "2017-04-03T20:36:09.742009: step 21057, loss 0.0342647, acc 1\n",
      "2017-04-03T20:36:09.945220: step 21058, loss 0.0470032, acc 0.984375\n",
      "2017-04-03T20:36:10.186400: step 21059, loss 0.0853942, acc 0.96875\n",
      "2017-04-03T20:36:10.387875: step 21060, loss 0.082648, acc 0.984375\n",
      "2017-04-03T20:36:10.592738: step 21061, loss 0.117572, acc 0.953125\n",
      "2017-04-03T20:36:10.797120: step 21062, loss 0.0330386, acc 1\n",
      "2017-04-03T20:36:11.003202: step 21063, loss 0.0984582, acc 0.96875\n",
      "2017-04-03T20:36:11.210177: step 21064, loss 0.0701762, acc 0.96875\n",
      "2017-04-03T20:36:11.425389: step 21065, loss 0.0261205, acc 1\n",
      "2017-04-03T20:36:11.630488: step 21066, loss 0.136238, acc 0.953125\n",
      "2017-04-03T20:36:11.877753: step 21067, loss 0.171776, acc 0.9375\n",
      "2017-04-03T20:36:12.099527: step 21068, loss 0.12282, acc 0.953125\n",
      "2017-04-03T20:36:12.314899: step 21069, loss 0.0634218, acc 0.984375\n",
      "2017-04-03T20:36:12.583194: step 21070, loss 0.103478, acc 0.96875\n",
      "2017-04-03T20:36:12.790486: step 21071, loss 0.0346199, acc 1\n",
      "2017-04-03T20:36:12.995857: step 21072, loss 0.117244, acc 0.9375\n",
      "2017-04-03T20:36:13.205827: step 21073, loss 0.158975, acc 0.9375\n",
      "2017-04-03T20:36:13.405689: step 21074, loss 0.174871, acc 0.921875\n",
      "2017-04-03T20:36:13.605724: step 21075, loss 0.143232, acc 0.921875\n",
      "2017-04-03T20:36:13.847601: step 21076, loss 0.022795, acc 1\n",
      "2017-04-03T20:36:14.057976: step 21077, loss 0.0835761, acc 0.96875\n",
      "2017-04-03T20:36:14.261600: step 21078, loss 0.146137, acc 0.9375\n",
      "2017-04-03T20:36:14.474805: step 21079, loss 0.0315123, acc 1\n",
      "2017-04-03T20:36:14.685129: step 21080, loss 0.0235945, acc 1\n",
      "2017-04-03T20:36:14.885845: step 21081, loss 0.104391, acc 0.984375\n",
      "2017-04-03T20:36:15.105566: step 21082, loss 0.152223, acc 0.9375\n",
      "2017-04-03T20:36:15.325948: step 21083, loss 0.0790773, acc 0.96875\n",
      "2017-04-03T20:36:15.537465: step 21084, loss 0.0882982, acc 0.984375\n",
      "2017-04-03T20:36:15.738613: step 21085, loss 0.0631066, acc 0.984375\n",
      "2017-04-03T20:36:15.942509: step 21086, loss 0.0948277, acc 0.96875\n",
      "2017-04-03T20:36:16.143056: step 21087, loss 0.00995069, acc 1\n",
      "2017-04-03T20:36:16.344109: step 21088, loss 0.0999639, acc 0.96875\n",
      "2017-04-03T20:36:16.544145: step 21089, loss 0.177873, acc 0.9375\n",
      "2017-04-03T20:36:16.755148: step 21090, loss 0.167655, acc 0.953125\n",
      "2017-04-03T20:36:16.955847: step 21091, loss 0.0495965, acc 0.984375\n",
      "2017-04-03T20:36:17.159919: step 21092, loss 0.102705, acc 0.96875\n",
      "2017-04-03T20:36:17.358457: step 21093, loss 0.108064, acc 0.953125\n",
      "2017-04-03T20:36:17.563815: step 21094, loss 0.0624494, acc 0.96875\n",
      "2017-04-03T20:36:17.763282: step 21095, loss 0.018962, acc 1\n",
      "2017-04-03T20:36:17.978725: step 21096, loss 0.0646225, acc 0.984375\n",
      "2017-04-03T20:36:18.198360: step 21097, loss 0.0137053, acc 1\n",
      "2017-04-03T20:36:18.416906: step 21098, loss 0.0212804, acc 1\n",
      "2017-04-03T20:36:18.621797: step 21099, loss 0.113768, acc 0.953125\n",
      "2017-04-03T20:36:18.827189: step 21100, loss 0.042509, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:36:20.930835: step 21100, loss 7.7631, acc 0.282\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-21100\n",
      "\n",
      "2017-04-03T20:36:21.269696: step 21101, loss 0.176575, acc 0.984375\n",
      "2017-04-03T20:36:21.467865: step 21102, loss 0.163616, acc 0.9375\n",
      "2017-04-03T20:36:21.675674: step 21103, loss 0.091831, acc 0.96875\n",
      "2017-04-03T20:36:21.883556: step 21104, loss 0.117578, acc 0.9375\n",
      "2017-04-03T20:36:22.086503: step 21105, loss 0.0846975, acc 0.96875\n",
      "2017-04-03T20:36:22.284948: step 21106, loss 0.124015, acc 0.953125\n",
      "2017-04-03T20:36:22.494385: step 21107, loss 0.0170284, acc 1\n",
      "2017-04-03T20:36:22.736524: step 21108, loss 0.153309, acc 0.953125\n",
      "2017-04-03T20:36:22.942045: step 21109, loss 0.0836578, acc 0.984375\n",
      "2017-04-03T20:36:23.145447: step 21110, loss 0.13097, acc 0.96875\n",
      "2017-04-03T20:36:23.346450: step 21111, loss 0.0249942, acc 0.984375\n",
      "2017-04-03T20:36:23.547785: step 21112, loss 0.106156, acc 0.96875\n",
      "2017-04-03T20:36:23.749088: step 21113, loss 0.172053, acc 0.9375\n",
      "2017-04-03T20:36:23.948519: step 21114, loss 0.125526, acc 0.953125\n",
      "2017-04-03T20:36:24.162443: step 21115, loss 0.08687, acc 0.96875\n",
      "2017-04-03T20:36:24.368134: step 21116, loss 0.0228962, acc 1\n",
      "2017-04-03T20:36:24.570165: step 21117, loss 0.0737286, acc 0.984375\n",
      "2017-04-03T20:36:24.773899: step 21118, loss 0.0905443, acc 0.96875\n",
      "2017-04-03T20:36:24.976283: step 21119, loss 0.0792271, acc 0.96875\n",
      "2017-04-03T20:36:25.177366: step 21120, loss 0.235427, acc 0.921875\n",
      "2017-04-03T20:36:25.380194: step 21121, loss 0.0217835, acc 1\n",
      "2017-04-03T20:36:25.582617: step 21122, loss 0.0801392, acc 0.96875\n",
      "2017-04-03T20:36:25.782772: step 21123, loss 0.0428543, acc 0.984375\n",
      "2017-04-03T20:36:25.987789: step 21124, loss 0.0507113, acc 0.984375\n",
      "2017-04-03T20:36:26.193606: step 21125, loss 0.0949998, acc 0.953125\n",
      "2017-04-03T20:36:26.393238: step 21126, loss 0.232914, acc 0.921875\n",
      "2017-04-03T20:36:26.592330: step 21127, loss 0.151063, acc 0.953125\n",
      "2017-04-03T20:36:26.793273: step 21128, loss 0.128097, acc 0.96875\n",
      "2017-04-03T20:36:26.994468: step 21129, loss 0.143381, acc 0.953125\n",
      "2017-04-03T20:36:27.203478: step 21130, loss 0.0747226, acc 0.96875\n",
      "2017-04-03T20:36:27.402152: step 21131, loss 0.119438, acc 0.984375\n",
      "2017-04-03T20:36:27.600142: step 21132, loss 0.0521683, acc 1\n",
      "2017-04-03T20:36:27.803649: step 21133, loss 0.147724, acc 0.953125\n",
      "2017-04-03T20:36:28.005220: step 21134, loss 0.0442743, acc 1\n",
      "2017-04-03T20:36:28.215357: step 21135, loss 0.027443, acc 1\n",
      "2017-04-03T20:36:28.462225: step 21136, loss 0.0646682, acc 0.96875\n",
      "2017-04-03T20:36:28.661727: step 21137, loss 0.0686433, acc 0.984375\n",
      "2017-04-03T20:36:28.871261: step 21138, loss 0.079249, acc 0.984375\n",
      "2017-04-03T20:36:29.126067: step 21139, loss 0.081724, acc 0.984375\n",
      "2017-04-03T20:36:29.330602: step 21140, loss 0.0553809, acc 0.984375\n",
      "2017-04-03T20:36:29.532159: step 21141, loss 0.138784, acc 0.9375\n",
      "2017-04-03T20:36:29.771076: step 21142, loss 0.0706235, acc 0.984375\n",
      "2017-04-03T20:36:29.976882: step 21143, loss 0.108931, acc 0.953125\n",
      "2017-04-03T20:36:30.176742: step 21144, loss 0.0898034, acc 0.96875\n",
      "2017-04-03T20:36:30.379686: step 21145, loss 0.105168, acc 0.953125\n",
      "2017-04-03T20:36:30.578457: step 21146, loss 0.367982, acc 0.890625\n",
      "2017-04-03T20:36:30.779280: step 21147, loss 0.115555, acc 0.96875\n",
      "2017-04-03T20:36:30.977697: step 21148, loss 0.183067, acc 0.9375\n",
      "2017-04-03T20:36:31.187487: step 21149, loss 0.0252114, acc 1\n",
      "2017-04-03T20:36:31.394595: step 21150, loss 0.0659898, acc 0.984375\n",
      "2017-04-03T20:36:31.594308: step 21151, loss 0.192839, acc 0.9375\n",
      "2017-04-03T20:36:31.793327: step 21152, loss 0.089847, acc 0.984375\n",
      "2017-04-03T20:36:32.036579: step 21153, loss 0.0432156, acc 1\n",
      "2017-04-03T20:36:32.243682: step 21154, loss 0.109979, acc 0.984375\n",
      "2017-04-03T20:36:32.444756: step 21155, loss 0.114677, acc 0.96875\n",
      "2017-04-03T20:36:32.647273: step 21156, loss 0.137081, acc 0.9375\n",
      "2017-04-03T20:36:32.847395: step 21157, loss 0.0646494, acc 0.984375\n",
      "2017-04-03T20:36:33.047531: step 21158, loss 0.06801, acc 0.984375\n",
      "2017-04-03T20:36:33.249829: step 21159, loss 0.123777, acc 0.953125\n",
      "2017-04-03T20:36:33.489679: step 21160, loss 0.0706841, acc 0.984375\n",
      "2017-04-03T20:36:33.701194: step 21161, loss 0.127073, acc 0.953125\n",
      "2017-04-03T20:36:33.900146: step 21162, loss 0.221461, acc 0.96875\n",
      "2017-04-03T20:36:34.102266: step 21163, loss 0.0516029, acc 0.984375\n",
      "2017-04-03T20:36:34.312553: step 21164, loss 0.0762535, acc 0.984375\n",
      "2017-04-03T20:36:34.534134: step 21165, loss 0.169894, acc 0.953125\n",
      "2017-04-03T20:36:34.750666: step 21166, loss 0.11436, acc 0.96875\n",
      "2017-04-03T20:36:34.967792: step 21167, loss 0.276695, acc 0.96875\n",
      "2017-04-03T20:36:35.221892: step 21168, loss 0.0791223, acc 0.984375\n",
      "2017-04-03T20:36:35.432310: step 21169, loss 0.121354, acc 0.984375\n",
      "2017-04-03T20:36:35.636885: step 21170, loss 0.362854, acc 0.90625\n",
      "2017-04-03T20:36:35.845866: step 21171, loss 0.0622558, acc 0.984375\n",
      "2017-04-03T20:36:36.061442: step 21172, loss 0.10651, acc 0.96875\n",
      "2017-04-03T20:36:36.270954: step 21173, loss 0.110839, acc 0.9375\n",
      "2017-04-03T20:36:36.472114: step 21174, loss 0.221618, acc 0.984375\n",
      "2017-04-03T20:36:36.673192: step 21175, loss 0.109506, acc 0.953125\n",
      "2017-04-03T20:36:36.875256: step 21176, loss 0.115481, acc 0.96875\n",
      "2017-04-03T20:36:37.121323: step 21177, loss 0.251206, acc 0.9375\n",
      "2017-04-03T20:36:37.323240: step 21178, loss 0.109885, acc 0.96875\n",
      "2017-04-03T20:36:37.528642: step 21179, loss 0.237208, acc 0.96875\n",
      "2017-04-03T20:36:37.731755: step 21180, loss 0.0881469, acc 0.96875\n",
      "2017-04-03T20:36:37.935237: step 21181, loss 0.106675, acc 0.9375\n",
      "2017-04-03T20:36:38.174186: step 21182, loss 0.114172, acc 0.984375\n",
      "2017-04-03T20:36:38.376800: step 21183, loss 0.0781486, acc 0.96875\n",
      "2017-04-03T20:36:38.576214: step 21184, loss 0.0693868, acc 0.96875\n",
      "2017-04-03T20:36:38.775536: step 21185, loss 0.0582528, acc 1\n",
      "2017-04-03T20:36:38.977451: step 21186, loss 0.0352093, acc 0.984375\n",
      "2017-04-03T20:36:39.179143: step 21187, loss 0.0935873, acc 0.96875\n",
      "2017-04-03T20:36:39.383042: step 21188, loss 0.0564721, acc 0.984375\n",
      "2017-04-03T20:36:39.589208: step 21189, loss 0.147481, acc 0.9375\n",
      "2017-04-03T20:36:39.789426: step 21190, loss 0.0868362, acc 0.953125\n",
      "2017-04-03T20:36:39.990324: step 21191, loss 0.0124344, acc 1\n",
      "2017-04-03T20:36:40.193871: step 21192, loss 0.0779303, acc 0.984375\n",
      "2017-04-03T20:36:40.406350: step 21193, loss 0.119334, acc 0.96875\n",
      "2017-04-03T20:36:40.616973: step 21194, loss 0.280393, acc 0.953125\n",
      "2017-04-03T20:36:40.818493: step 21195, loss 0.150628, acc 0.9375\n",
      "2017-04-03T20:36:41.020627: step 21196, loss 0.015528, acc 1\n",
      "2017-04-03T20:36:41.276817: step 21197, loss 0.156075, acc 0.96875\n",
      "2017-04-03T20:36:41.476604: step 21198, loss 0.218777, acc 0.953125\n",
      "2017-04-03T20:36:41.678019: step 21199, loss 0.0360305, acc 0.984375\n",
      "2017-04-03T20:36:41.894734: step 21200, loss 0.168883, acc 0.90625\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:36:44.042240: step 21200, loss 7.72997, acc 0.28\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-21200\n",
      "\n",
      "2017-04-03T20:36:44.385912: step 21201, loss 0.0626026, acc 0.984375\n",
      "2017-04-03T20:36:44.583099: step 21202, loss 0.0758114, acc 0.96875\n",
      "2017-04-03T20:36:44.790082: step 21203, loss 0.0194182, acc 1\n",
      "2017-04-03T20:36:44.991861: step 21204, loss 0.0909332, acc 0.96875\n",
      "2017-04-03T20:36:45.196002: step 21205, loss 0.163449, acc 0.921875\n",
      "2017-04-03T20:36:45.412453: step 21206, loss 0.174671, acc 0.890625\n",
      "2017-04-03T20:36:45.654713: step 21207, loss 0.201033, acc 0.921875\n",
      "2017-04-03T20:36:45.857215: step 21208, loss 0.192446, acc 0.953125\n",
      "2017-04-03T20:36:46.082217: step 21209, loss 0.118826, acc 0.9375\n",
      "2017-04-03T20:36:46.297354: step 21210, loss 0.0672723, acc 0.984375\n",
      "2017-04-03T20:36:46.540573: step 21211, loss 0.120131, acc 0.953125\n",
      "2017-04-03T20:36:46.745497: step 21212, loss 0.029099, acc 1\n",
      "2017-04-03T20:36:46.949534: step 21213, loss 0.088423, acc 0.953125\n",
      "2017-04-03T20:36:47.158302: step 21214, loss 0.0481713, acc 0.96875\n",
      "2017-04-03T20:36:47.393024: step 21215, loss 0.17226, acc 0.9375\n",
      "2017-04-03T20:36:47.596662: step 21216, loss 0.138013, acc 0.953125\n",
      "2017-04-03T20:36:47.808411: step 21217, loss 0.129136, acc 0.96875\n",
      "2017-04-03T20:36:48.012566: step 21218, loss 0.0937398, acc 0.96875\n",
      "2017-04-03T20:36:48.216954: step 21219, loss 0.0848095, acc 0.96875\n",
      "2017-04-03T20:36:48.416681: step 21220, loss 0.185068, acc 0.96875\n",
      "2017-04-03T20:36:48.622404: step 21221, loss 0.0694885, acc 0.984375\n",
      "2017-04-03T20:36:48.824225: step 21222, loss 0.0253062, acc 1\n",
      "2017-04-03T20:36:49.024939: step 21223, loss 0.0152717, acc 1\n",
      "2017-04-03T20:36:49.225632: step 21224, loss 0.118999, acc 0.953125\n",
      "2017-04-03T20:36:49.425057: step 21225, loss 0.068526, acc 0.984375\n",
      "2017-04-03T20:36:49.632358: step 21226, loss 0.118767, acc 0.96875\n",
      "2017-04-03T20:36:49.849522: step 21227, loss 0.0375187, acc 1\n",
      "2017-04-03T20:36:50.101453: step 21228, loss 0.0563651, acc 1\n",
      "2017-04-03T20:36:50.304364: step 21229, loss 0.0404841, acc 0.984375\n",
      "2017-04-03T20:36:50.502432: step 21230, loss 0.0817193, acc 0.984375\n",
      "2017-04-03T20:36:50.705604: step 21231, loss 0.179431, acc 0.9375\n",
      "2017-04-03T20:36:50.903535: step 21232, loss 0.121492, acc 0.96875\n",
      "2017-04-03T20:36:51.106804: step 21233, loss 0.0969602, acc 0.9375\n",
      "2017-04-03T20:36:51.306314: step 21234, loss 0.146749, acc 0.96875\n",
      "2017-04-03T20:36:51.509522: step 21235, loss 0.0981471, acc 0.96875\n",
      "2017-04-03T20:36:51.714128: step 21236, loss 0.0792326, acc 0.96875\n",
      "2017-04-03T20:36:51.915648: step 21237, loss 0.0355079, acc 0.984375\n",
      "2017-04-03T20:36:52.136260: step 21238, loss 0.153609, acc 0.953125\n",
      "2017-04-03T20:36:52.352448: step 21239, loss 0.0651103, acc 0.984375\n",
      "2017-04-03T20:36:52.569529: step 21240, loss 0.0783518, acc 0.984375\n",
      "2017-04-03T20:36:52.771344: step 21241, loss 0.0845983, acc 0.96875\n",
      "2017-04-03T20:36:53.015873: step 21242, loss 0.0999179, acc 0.953125\n",
      "2017-04-03T20:36:53.223678: step 21243, loss 0.0533717, acc 0.984375\n",
      "2017-04-03T20:36:53.425301: step 21244, loss 0.380371, acc 0.96875\n",
      "2017-04-03T20:36:53.627378: step 21245, loss 0.0893946, acc 0.96875\n",
      "2017-04-03T20:36:53.829287: step 21246, loss 0.0515507, acc 0.984375\n",
      "2017-04-03T20:36:54.029532: step 21247, loss 0.181804, acc 0.953125\n",
      "2017-04-03T20:36:54.234485: step 21248, loss 0.0975393, acc 0.96875\n",
      "2017-04-03T20:36:54.444255: step 21249, loss 0.250681, acc 0.953125\n",
      "2017-04-03T20:36:54.647779: step 21250, loss 0.137728, acc 0.96875\n",
      "2017-04-03T20:36:54.854278: step 21251, loss 0.0705449, acc 0.96875\n",
      "2017-04-03T20:36:55.060568: step 21252, loss 0.0589419, acc 1\n",
      "2017-04-03T20:36:55.263502: step 21253, loss 0.0286082, acc 0.984375\n",
      "2017-04-03T20:36:55.468857: step 21254, loss 0.010166, acc 1\n",
      "2017-04-03T20:36:55.668192: step 21255, loss 0.084504, acc 0.96875\n",
      "2017-04-03T20:36:55.875348: step 21256, loss 0.108594, acc 0.953125\n",
      "2017-04-03T20:36:56.081235: step 21257, loss 0.106042, acc 0.984375\n",
      "2017-04-03T20:36:56.286861: step 21258, loss 0.17454, acc 0.90625\n",
      "2017-04-03T20:36:56.489351: step 21259, loss 0.141584, acc 0.9375\n",
      "2017-04-03T20:36:56.692309: step 21260, loss 0.062732, acc 0.96875\n",
      "2017-04-03T20:36:56.892917: step 21261, loss 0.135087, acc 0.953125\n",
      "2017-04-03T20:36:57.107596: step 21262, loss 0.100179, acc 0.953125\n",
      "2017-04-03T20:36:57.308992: step 21263, loss 0.0569877, acc 0.984375\n",
      "2017-04-03T20:36:57.523246: step 21264, loss 0.117601, acc 0.984375\n",
      "2017-04-03T20:36:57.729592: step 21265, loss 0.0896149, acc 0.953125\n",
      "2017-04-03T20:36:57.949854: step 21266, loss 0.119441, acc 0.953125\n",
      "2017-04-03T20:36:58.158294: step 21267, loss 0.0683039, acc 0.96875\n",
      "2017-04-03T20:36:58.360719: step 21268, loss 0.0318529, acc 1\n",
      "2017-04-03T20:36:58.567750: step 21269, loss 0.172093, acc 0.9375\n",
      "2017-04-03T20:36:58.769216: step 21270, loss 0.0744431, acc 0.96875\n",
      "2017-04-03T20:36:58.973309: step 21271, loss 0.210603, acc 0.984375\n",
      "2017-04-03T20:36:59.182433: step 21272, loss 0.046144, acc 0.984375\n",
      "2017-04-03T20:36:59.391660: step 21273, loss 0.135489, acc 0.9375\n",
      "2017-04-03T20:36:59.596848: step 21274, loss 0.189975, acc 0.96875\n",
      "2017-04-03T20:36:59.797353: step 21275, loss 0.162666, acc 0.96875\n",
      "2017-04-03T20:37:00.000237: step 21276, loss 0.204949, acc 0.953125\n",
      "2017-04-03T20:37:00.201158: step 21277, loss 0.0861505, acc 0.96875\n",
      "2017-04-03T20:37:00.405704: step 21278, loss 0.0796929, acc 0.984375\n",
      "2017-04-03T20:37:00.616086: step 21279, loss 0.151082, acc 0.953125\n",
      "2017-04-03T20:37:00.834666: step 21280, loss 0.0877532, acc 0.96875\n",
      "2017-04-03T20:37:01.050401: step 21281, loss 0.153275, acc 0.96875\n",
      "2017-04-03T20:37:01.265743: step 21282, loss 0.0351267, acc 0.984375\n",
      "2017-04-03T20:37:01.470128: step 21283, loss 0.214368, acc 0.96875\n",
      "2017-04-03T20:37:01.673352: step 21284, loss 0.19017, acc 0.96875\n",
      "2017-04-03T20:37:01.877727: step 21285, loss 0.0314742, acc 0.984375\n",
      "2017-04-03T20:37:02.076353: step 21286, loss 0.125368, acc 0.9375\n",
      "2017-04-03T20:37:02.276959: step 21287, loss 0.0541718, acc 0.96875\n",
      "2017-04-03T20:37:02.479491: step 21288, loss 0.0726443, acc 0.96875\n",
      "2017-04-03T20:37:02.687713: step 21289, loss 0.0719256, acc 1\n",
      "2017-04-03T20:37:02.889954: step 21290, loss 0.271563, acc 0.890625\n",
      "2017-04-03T20:37:03.088800: step 21291, loss 0.0811577, acc 0.96875\n",
      "2017-04-03T20:37:03.294937: step 21292, loss 0.0317755, acc 1\n",
      "2017-04-03T20:37:03.500009: step 21293, loss 0.139967, acc 0.953125\n",
      "2017-04-03T20:37:03.700163: step 21294, loss 0.0734428, acc 0.96875\n",
      "2017-04-03T20:37:03.906654: step 21295, loss 0.121597, acc 0.953125\n",
      "2017-04-03T20:37:04.110985: step 21296, loss 0.757665, acc 0.9375\n",
      "2017-04-03T20:37:04.314669: step 21297, loss 0.0331782, acc 1\n",
      "2017-04-03T20:37:04.516137: step 21298, loss 0.150994, acc 0.96875\n",
      "2017-04-03T20:37:04.729425: step 21299, loss 0.0914636, acc 0.96875\n",
      "2017-04-03T20:37:04.930933: step 21300, loss 0.270439, acc 0.921875\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:37:07.085086: step 21300, loss 7.69934, acc 0.28025\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-21300\n",
      "\n",
      "2017-04-03T20:37:07.425697: step 21301, loss 0.190076, acc 0.953125\n",
      "2017-04-03T20:37:07.641047: step 21302, loss 0.193127, acc 0.921875\n",
      "2017-04-03T20:37:07.860396: step 21303, loss 0.0965353, acc 0.96875\n",
      "2017-04-03T20:37:08.101714: step 21304, loss 0.103749, acc 0.9375\n",
      "2017-04-03T20:37:08.310976: step 21305, loss 0.1158, acc 0.9375\n",
      "2017-04-03T20:37:08.512495: step 21306, loss 0.0789616, acc 0.984375\n",
      "2017-04-03T20:37:08.755350: step 21307, loss 0.0902282, acc 0.96875\n",
      "2017-04-03T20:37:09.000790: step 21308, loss 0.166967, acc 0.953125\n",
      "2017-04-03T20:37:09.243110: step 21309, loss 0.0870653, acc 0.96875\n",
      "2017-04-03T20:37:09.453685: step 21310, loss 0.030837, acc 1\n",
      "2017-04-03T20:37:09.695045: step 21311, loss 0.0620036, acc 0.984375\n",
      "2017-04-03T20:37:09.901459: step 21312, loss 0.0787672, acc 0.96875\n",
      "2017-04-03T20:37:10.103426: step 21313, loss 0.159798, acc 0.96875\n",
      "2017-04-03T20:37:10.310362: step 21314, loss 0.0574829, acc 0.984375\n",
      "2017-04-03T20:37:10.549767: step 21315, loss 0.135301, acc 0.96875\n",
      "2017-04-03T20:37:10.760569: step 21316, loss 0.0604315, acc 0.984375\n",
      "2017-04-03T20:37:10.961750: step 21317, loss 0.123397, acc 0.96875\n",
      "2017-04-03T20:37:11.162530: step 21318, loss 0.0684114, acc 0.96875\n",
      "2017-04-03T20:37:11.360736: step 21319, loss 0.0957438, acc 0.984375\n",
      "2017-04-03T20:37:11.561243: step 21320, loss 0.177798, acc 0.96875\n",
      "2017-04-03T20:37:11.766109: step 21321, loss 0.0582802, acc 0.984375\n",
      "2017-04-03T20:37:11.969028: step 21322, loss 0.0615127, acc 0.96875\n",
      "2017-04-03T20:37:12.168929: step 21323, loss 0.0354028, acc 1\n",
      "2017-04-03T20:37:12.373504: step 21324, loss 0.0525637, acc 0.984375\n",
      "2017-04-03T20:37:12.574802: step 21325, loss 0.0510041, acc 1\n",
      "2017-04-03T20:37:12.781568: step 21326, loss 0.351203, acc 0.9375\n",
      "2017-04-03T20:37:13.001578: step 21327, loss 0.0890681, acc 0.984375\n",
      "2017-04-03T20:37:13.214743: step 21328, loss 0.0784552, acc 0.96875\n",
      "2017-04-03T20:37:13.421379: step 21329, loss 0.0677277, acc 0.96875\n",
      "2017-04-03T20:37:13.621096: step 21330, loss 0.0562111, acc 0.96875\n",
      "2017-04-03T20:37:13.825169: step 21331, loss 0.0458391, acc 0.984375\n",
      "2017-04-03T20:37:14.029343: step 21332, loss 0.0407718, acc 0.984375\n",
      "2017-04-03T20:37:14.253936: step 21333, loss 0.0639509, acc 0.984375\n",
      "2017-04-03T20:37:14.497357: step 21334, loss 0.0990051, acc 0.9375\n",
      "2017-04-03T20:37:14.691947: step 21335, loss 0.162577, acc 0.953125\n",
      "2017-04-03T20:37:14.895266: step 21336, loss 0.212835, acc 0.921875\n",
      "2017-04-03T20:37:15.102932: step 21337, loss 0.212601, acc 0.96875\n",
      "2017-04-03T20:37:15.305576: step 21338, loss 0.10695, acc 0.953125\n",
      "2017-04-03T20:37:15.511435: step 21339, loss 0.0227146, acc 1\n",
      "2017-04-03T20:37:15.716126: step 21340, loss 0.105405, acc 0.953125\n",
      "2017-04-03T20:37:15.921464: step 21341, loss 0.298588, acc 0.953125\n",
      "2017-04-03T20:37:16.124876: step 21342, loss 0.0817799, acc 0.984375\n",
      "2017-04-03T20:37:16.322258: step 21343, loss 0.111506, acc 0.953125\n",
      "2017-04-03T20:37:16.522340: step 21344, loss 0.509764, acc 0.875\n",
      "2017-04-03T20:37:16.728147: step 21345, loss 0.0738231, acc 0.96875\n",
      "2017-04-03T20:37:16.938179: step 21346, loss 0.0472103, acc 1\n",
      "2017-04-03T20:37:17.138856: step 21347, loss 0.085451, acc 0.96875\n",
      "2017-04-03T20:37:17.343724: step 21348, loss 0.134529, acc 0.953125\n",
      "2017-04-03T20:37:17.546542: step 21349, loss 0.0833227, acc 0.953125\n",
      "2017-04-03T20:37:17.752241: step 21350, loss 0.0763035, acc 0.96875\n",
      "2017-04-03T20:37:17.952190: step 21351, loss 0.0983021, acc 0.984375\n",
      "2017-04-03T20:37:18.155823: step 21352, loss 0.11625, acc 0.953125\n",
      "2017-04-03T20:37:18.354021: step 21353, loss 0.0971297, acc 0.96875\n",
      "2017-04-03T20:37:18.568407: step 21354, loss 0.0845103, acc 0.96875\n",
      "2017-04-03T20:37:18.768389: step 21355, loss 0.0849051, acc 0.96875\n",
      "2017-04-03T20:37:18.973111: step 21356, loss 0.0406265, acc 0.984375\n",
      "2017-04-03T20:37:19.175547: step 21357, loss 0.0428174, acc 1\n",
      "2017-04-03T20:37:19.371499: step 21358, loss 0.0927215, acc 0.96875\n",
      "2017-04-03T20:37:19.572878: step 21359, loss 0.0484094, acc 1\n",
      "2017-04-03T20:37:19.777678: step 21360, loss 0.136183, acc 0.9375\n",
      "2017-04-03T20:37:19.978312: step 21361, loss 0.0678666, acc 0.984375\n",
      "2017-04-03T20:37:20.180942: step 21362, loss 0.0453876, acc 1\n",
      "2017-04-03T20:37:20.388345: step 21363, loss 0.090603, acc 0.96875\n",
      "2017-04-03T20:37:20.593072: step 21364, loss 0.0442143, acc 1\n",
      "2017-04-03T20:37:20.816586: step 21365, loss 0.0840147, acc 0.984375\n",
      "2017-04-03T20:37:21.025216: step 21366, loss 0.0963943, acc 0.984375\n",
      "2017-04-03T20:37:21.241087: step 21367, loss 0.12577, acc 0.953125\n",
      "2017-04-03T20:37:21.487820: step 21368, loss 0.0934631, acc 0.96875\n",
      "2017-04-03T20:37:21.739096: step 21369, loss 0.0985619, acc 0.96875\n",
      "2017-04-03T20:37:21.951344: step 21370, loss 0.155752, acc 0.96875\n",
      "2017-04-03T20:37:22.196181: step 21371, loss 0.010757, acc 1\n",
      "2017-04-03T20:37:22.397530: step 21372, loss 0.19433, acc 0.953125\n",
      "2017-04-03T20:37:22.610750: step 21373, loss 0.115275, acc 0.96875\n",
      "2017-04-03T20:37:22.813727: step 21374, loss 0.21487, acc 0.9375\n",
      "2017-04-03T20:37:23.021765: step 21375, loss 0.112502, acc 0.953125\n",
      "2017-04-03T20:37:23.223142: step 21376, loss 0.174477, acc 0.9375\n",
      "2017-04-03T20:37:23.426112: step 21377, loss 0.0738422, acc 0.96875\n",
      "2017-04-03T20:37:23.640134: step 21378, loss 0.0496023, acc 0.984375\n",
      "2017-04-03T20:37:23.844146: step 21379, loss 0.0830155, acc 0.984375\n",
      "2017-04-03T20:37:24.066570: step 21380, loss 0.206457, acc 0.96875\n",
      "2017-04-03T20:37:24.283375: step 21381, loss 0.247103, acc 0.890625\n",
      "2017-04-03T20:37:24.491654: step 21382, loss 0.180566, acc 0.9375\n",
      "2017-04-03T20:37:24.708118: step 21383, loss 0.219052, acc 0.984375\n",
      "2017-04-03T20:37:24.929400: step 21384, loss 0.171754, acc 0.96875\n",
      "2017-04-03T20:37:25.143701: step 21385, loss 0.0895345, acc 0.984375\n",
      "2017-04-03T20:37:25.364462: step 21386, loss 0.208817, acc 0.9375\n",
      "2017-04-03T20:37:25.578313: step 21387, loss 0.0182305, acc 1\n",
      "2017-04-03T20:37:25.778050: step 21388, loss 0.0176216, acc 1\n",
      "2017-04-03T20:37:26.031050: step 21389, loss 0.102405, acc 0.96875\n",
      "2017-04-03T20:37:26.269866: step 21390, loss 0.0760107, acc 0.96875\n",
      "2017-04-03T20:37:26.477070: step 21391, loss 0.11155, acc 0.96875\n",
      "2017-04-03T20:37:26.685533: step 21392, loss 0.0707218, acc 0.96875\n",
      "2017-04-03T20:37:26.895075: step 21393, loss 0.152309, acc 0.953125\n",
      "2017-04-03T20:37:27.040962: step 21394, loss 0.0442682, acc 1\n",
      "2017-04-03T20:37:27.248344: step 21395, loss 0.0495891, acc 0.984375\n",
      "2017-04-03T20:37:27.447573: step 21396, loss 0.0346612, acc 1\n",
      "2017-04-03T20:37:27.660568: step 21397, loss 0.094119, acc 0.953125\n",
      "2017-04-03T20:37:27.901974: step 21398, loss 0.0764489, acc 0.96875\n",
      "2017-04-03T20:37:28.149723: step 21399, loss 0.107008, acc 0.96875\n",
      "2017-04-03T20:37:28.353751: step 21400, loss 0.0408508, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:37:30.496335: step 21400, loss 7.7109, acc 0.27775\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-21400\n",
      "\n",
      "2017-04-03T20:37:30.883919: step 21401, loss 0.0250401, acc 1\n",
      "2017-04-03T20:37:31.088434: step 21402, loss 0.0300208, acc 1\n",
      "2017-04-03T20:37:31.294404: step 21403, loss 0.0429591, acc 0.984375\n",
      "2017-04-03T20:37:31.495013: step 21404, loss 0.0934556, acc 0.984375\n",
      "2017-04-03T20:37:31.698346: step 21405, loss 0.127274, acc 0.96875\n",
      "2017-04-03T20:37:31.900093: step 21406, loss 0.0554362, acc 0.984375\n",
      "2017-04-03T20:37:32.108408: step 21407, loss 0.0591816, acc 0.96875\n",
      "2017-04-03T20:37:32.316904: step 21408, loss 0.0482819, acc 0.984375\n",
      "2017-04-03T20:37:32.522953: step 21409, loss 0.167301, acc 0.96875\n",
      "2017-04-03T20:37:32.725671: step 21410, loss 0.225409, acc 0.921875\n",
      "2017-04-03T20:37:32.932651: step 21411, loss 0.148276, acc 0.96875\n",
      "2017-04-03T20:37:33.137603: step 21412, loss 0.0478588, acc 0.984375\n",
      "2017-04-03T20:37:33.341021: step 21413, loss 0.0952545, acc 0.96875\n",
      "2017-04-03T20:37:33.541088: step 21414, loss 0.0548659, acc 0.984375\n",
      "2017-04-03T20:37:33.746975: step 21415, loss 0.166774, acc 0.921875\n",
      "2017-04-03T20:37:33.941361: step 21416, loss 0.304048, acc 0.96875\n",
      "2017-04-03T20:37:34.146992: step 21417, loss 0.00911523, acc 1\n",
      "2017-04-03T20:37:34.351506: step 21418, loss 0.0891549, acc 0.953125\n",
      "2017-04-03T20:37:34.593917: step 21419, loss 0.0921653, acc 0.96875\n",
      "2017-04-03T20:37:34.798120: step 21420, loss 0.0094419, acc 1\n",
      "2017-04-03T20:37:34.999000: step 21421, loss 0.095274, acc 0.96875\n",
      "2017-04-03T20:37:35.201189: step 21422, loss 0.0944185, acc 0.96875\n",
      "2017-04-03T20:37:35.400946: step 21423, loss 0.00905664, acc 1\n",
      "2017-04-03T20:37:35.647111: step 21424, loss 0.0959443, acc 0.984375\n",
      "2017-04-03T20:37:35.857822: step 21425, loss 0.0317665, acc 1\n",
      "2017-04-03T20:37:36.101975: step 21426, loss 0.159857, acc 0.953125\n",
      "2017-04-03T20:37:36.309357: step 21427, loss 0.026715, acc 1\n",
      "2017-04-03T20:37:36.555787: step 21428, loss 0.0598469, acc 0.984375\n",
      "2017-04-03T20:37:36.761037: step 21429, loss 0.119511, acc 0.953125\n",
      "2017-04-03T20:37:36.964681: step 21430, loss 0.0749213, acc 0.984375\n",
      "2017-04-03T20:37:37.163561: step 21431, loss 0.0950122, acc 0.96875\n",
      "2017-04-03T20:37:37.365049: step 21432, loss 0.124607, acc 0.9375\n",
      "2017-04-03T20:37:37.572762: step 21433, loss 0.0359824, acc 1\n",
      "2017-04-03T20:37:37.778973: step 21434, loss 0.0782516, acc 0.96875\n",
      "2017-04-03T20:37:37.981735: step 21435, loss 0.0422678, acc 0.984375\n",
      "2017-04-03T20:37:38.180470: step 21436, loss 0.133001, acc 0.953125\n",
      "2017-04-03T20:37:38.382300: step 21437, loss 0.0894043, acc 0.953125\n",
      "2017-04-03T20:37:38.581921: step 21438, loss 0.099993, acc 0.96875\n",
      "2017-04-03T20:37:38.831691: step 21439, loss 0.261781, acc 0.953125\n",
      "2017-04-03T20:37:39.047863: step 21440, loss 0.0449946, acc 0.984375\n",
      "2017-04-03T20:37:39.267465: step 21441, loss 0.0328918, acc 1\n",
      "2017-04-03T20:37:39.492741: step 21442, loss 0.0452412, acc 0.984375\n",
      "2017-04-03T20:37:39.694732: step 21443, loss 0.121814, acc 0.96875\n",
      "2017-04-03T20:37:39.893895: step 21444, loss 0.0587334, acc 0.984375\n",
      "2017-04-03T20:37:40.094345: step 21445, loss 0.0370074, acc 0.984375\n",
      "2017-04-03T20:37:40.293749: step 21446, loss 0.0433163, acc 0.984375\n",
      "2017-04-03T20:37:40.494437: step 21447, loss 0.351616, acc 0.9375\n",
      "2017-04-03T20:37:40.696456: step 21448, loss 0.193633, acc 0.96875\n",
      "2017-04-03T20:37:40.900126: step 21449, loss 0.0946288, acc 0.96875\n",
      "2017-04-03T20:37:41.103978: step 21450, loss 0.0295704, acc 0.984375\n",
      "2017-04-03T20:37:41.303981: step 21451, loss 0.483335, acc 0.9375\n",
      "2017-04-03T20:37:41.511121: step 21452, loss 0.0983526, acc 0.96875\n",
      "2017-04-03T20:37:41.715088: step 21453, loss 0.0895022, acc 0.9375\n",
      "2017-04-03T20:37:41.921844: step 21454, loss 0.0742849, acc 0.984375\n",
      "2017-04-03T20:37:42.130361: step 21455, loss 0.149002, acc 0.96875\n",
      "2017-04-03T20:37:42.373716: step 21456, loss 0.146018, acc 0.9375\n",
      "2017-04-03T20:37:42.577558: step 21457, loss 0.00963683, acc 1\n",
      "2017-04-03T20:37:42.781142: step 21458, loss 0.0828317, acc 0.953125\n",
      "2017-04-03T20:37:42.984792: step 21459, loss 0.0578909, acc 1\n",
      "2017-04-03T20:37:43.186169: step 21460, loss 0.0870439, acc 0.984375\n",
      "2017-04-03T20:37:43.386163: step 21461, loss 0.183343, acc 0.96875\n",
      "2017-04-03T20:37:43.589047: step 21462, loss 0.0550483, acc 0.96875\n",
      "2017-04-03T20:37:43.794168: step 21463, loss 0.0133339, acc 1\n",
      "2017-04-03T20:37:43.994933: step 21464, loss 0.0568901, acc 1\n",
      "2017-04-03T20:37:44.198107: step 21465, loss 0.11833, acc 0.96875\n",
      "2017-04-03T20:37:44.401754: step 21466, loss 0.143602, acc 0.953125\n",
      "2017-04-03T20:37:44.605273: step 21467, loss 0.204917, acc 0.9375\n",
      "2017-04-03T20:37:44.807906: step 21468, loss 0.127676, acc 0.9375\n",
      "2017-04-03T20:37:45.008375: step 21469, loss 0.0886387, acc 0.96875\n",
      "2017-04-03T20:37:45.211750: step 21470, loss 0.145449, acc 0.953125\n",
      "2017-04-03T20:37:45.416412: step 21471, loss 0.0248825, acc 1\n",
      "2017-04-03T20:37:45.622884: step 21472, loss 0.164883, acc 0.96875\n",
      "2017-04-03T20:37:45.831701: step 21473, loss 0.144113, acc 0.96875\n",
      "2017-04-03T20:37:46.039461: step 21474, loss 0.214668, acc 0.90625\n",
      "2017-04-03T20:37:46.265941: step 21475, loss 0.154168, acc 0.953125\n",
      "2017-04-03T20:37:46.471393: step 21476, loss 0.0952176, acc 0.96875\n",
      "2017-04-03T20:37:46.671915: step 21477, loss 0.0686855, acc 0.984375\n",
      "2017-04-03T20:37:46.875843: step 21478, loss 0.124194, acc 0.953125\n",
      "2017-04-03T20:37:47.120227: step 21479, loss 0.0400689, acc 0.984375\n",
      "2017-04-03T20:37:47.328068: step 21480, loss 0.0593953, acc 0.96875\n",
      "2017-04-03T20:37:47.581966: step 21481, loss 0.143402, acc 0.90625\n",
      "2017-04-03T20:37:47.786866: step 21482, loss 0.154237, acc 0.9375\n",
      "2017-04-03T20:37:47.985825: step 21483, loss 0.102174, acc 0.953125\n",
      "2017-04-03T20:37:48.195542: step 21484, loss 0.309069, acc 0.9375\n",
      "2017-04-03T20:37:48.405406: step 21485, loss 0.0822184, acc 0.984375\n",
      "2017-04-03T20:37:48.606698: step 21486, loss 0.0456415, acc 1\n",
      "2017-04-03T20:37:48.807895: step 21487, loss 0.0329709, acc 1\n",
      "2017-04-03T20:37:49.013199: step 21488, loss 0.127937, acc 0.96875\n",
      "2017-04-03T20:37:49.222185: step 21489, loss 0.180104, acc 0.953125\n",
      "2017-04-03T20:37:49.461212: step 21490, loss 0.0704028, acc 0.984375\n",
      "2017-04-03T20:37:49.660111: step 21491, loss 0.0613007, acc 0.984375\n",
      "2017-04-03T20:37:49.921088: step 21492, loss 0.107215, acc 0.96875\n",
      "2017-04-03T20:37:50.131129: step 21493, loss 0.0757926, acc 0.953125\n",
      "2017-04-03T20:37:50.349759: step 21494, loss 0.0979124, acc 0.96875\n",
      "2017-04-03T20:37:50.553617: step 21495, loss 0.101274, acc 0.96875\n",
      "2017-04-03T20:37:50.758424: step 21496, loss 0.0478789, acc 0.984375\n",
      "2017-04-03T20:37:50.956955: step 21497, loss 0.0633425, acc 0.984375\n",
      "2017-04-03T20:37:51.156399: step 21498, loss 0.179364, acc 0.953125\n",
      "2017-04-03T20:37:51.354027: step 21499, loss 0.152479, acc 0.953125\n",
      "2017-04-03T20:37:51.560656: step 21500, loss 0.0617613, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:37:53.742150: step 21500, loss 7.67439, acc 0.28575\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-21500\n",
      "\n",
      "2017-04-03T20:37:54.071111: step 21501, loss 0.0478665, acc 1\n",
      "2017-04-03T20:37:54.275106: step 21502, loss 0.022807, acc 1\n",
      "2017-04-03T20:37:54.478147: step 21503, loss 0.0856664, acc 0.96875\n",
      "2017-04-03T20:37:54.683481: step 21504, loss 0.104073, acc 0.96875\n",
      "2017-04-03T20:37:54.882445: step 21505, loss 0.169957, acc 0.953125\n",
      "2017-04-03T20:37:55.082927: step 21506, loss 0.0960478, acc 0.953125\n",
      "2017-04-03T20:37:55.288241: step 21507, loss 0.0656274, acc 0.953125\n",
      "2017-04-03T20:37:55.487365: step 21508, loss 0.121224, acc 0.96875\n",
      "2017-04-03T20:37:55.723610: step 21509, loss 0.0353751, acc 1\n",
      "2017-04-03T20:37:55.920137: step 21510, loss 0.0778876, acc 0.984375\n",
      "2017-04-03T20:37:56.125105: step 21511, loss 0.0902296, acc 0.984375\n",
      "2017-04-03T20:37:56.325473: step 21512, loss 0.370706, acc 0.984375\n",
      "2017-04-03T20:37:56.526176: step 21513, loss 0.163344, acc 0.953125\n",
      "2017-04-03T20:37:56.728165: step 21514, loss 0.0691587, acc 0.96875\n",
      "2017-04-03T20:37:56.926841: step 21515, loss 0.115847, acc 0.96875\n",
      "2017-04-03T20:37:57.126474: step 21516, loss 0.0402172, acc 1\n",
      "2017-04-03T20:37:57.332923: step 21517, loss 0.0404582, acc 0.984375\n",
      "2017-04-03T20:37:57.538246: step 21518, loss 0.0506084, acc 1\n",
      "2017-04-03T20:37:57.744073: step 21519, loss 0.369532, acc 0.921875\n",
      "2017-04-03T20:37:57.944339: step 21520, loss 0.0316801, acc 1\n",
      "2017-04-03T20:37:58.169296: step 21521, loss 0.0682119, acc 1\n",
      "2017-04-03T20:37:58.382960: step 21522, loss 0.0332287, acc 1\n",
      "2017-04-03T20:37:58.583113: step 21523, loss 0.0388925, acc 0.984375\n",
      "2017-04-03T20:37:58.779938: step 21524, loss 0.0663781, acc 1\n",
      "2017-04-03T20:37:58.977876: step 21525, loss 0.269087, acc 0.921875\n",
      "2017-04-03T20:37:59.178737: step 21526, loss 0.0765026, acc 0.984375\n",
      "2017-04-03T20:37:59.385960: step 21527, loss 0.0902912, acc 0.96875\n",
      "2017-04-03T20:37:59.591995: step 21528, loss 0.0472048, acc 0.984375\n",
      "2017-04-03T20:37:59.831207: step 21529, loss 0.0571952, acc 0.984375\n",
      "2017-04-03T20:38:00.040864: step 21530, loss 0.075914, acc 0.96875\n",
      "2017-04-03T20:38:00.240920: step 21531, loss 0.0307791, acc 0.984375\n",
      "2017-04-03T20:38:00.440751: step 21532, loss 0.0917843, acc 0.96875\n",
      "2017-04-03T20:38:00.645631: step 21533, loss 0.0400181, acc 1\n",
      "2017-04-03T20:38:00.851329: step 21534, loss 0.0623971, acc 0.96875\n",
      "2017-04-03T20:38:01.072494: step 21535, loss 0.0729111, acc 0.984375\n",
      "2017-04-03T20:38:01.286790: step 21536, loss 0.145302, acc 0.953125\n",
      "2017-04-03T20:38:01.502669: step 21537, loss 0.0869474, acc 0.96875\n",
      "2017-04-03T20:38:01.704046: step 21538, loss 0.0787893, acc 0.984375\n",
      "2017-04-03T20:38:01.910602: step 21539, loss 0.0806082, acc 0.96875\n",
      "2017-04-03T20:38:02.122006: step 21540, loss 0.120288, acc 0.953125\n",
      "2017-04-03T20:38:02.322635: step 21541, loss 0.0381092, acc 0.984375\n",
      "2017-04-03T20:38:02.526170: step 21542, loss 0.0423601, acc 0.984375\n",
      "2017-04-03T20:38:02.731608: step 21543, loss 0.128851, acc 0.96875\n",
      "2017-04-03T20:38:02.936388: step 21544, loss 0.0193329, acc 1\n",
      "2017-04-03T20:38:03.135107: step 21545, loss 0.110039, acc 0.96875\n",
      "2017-04-03T20:38:03.340517: step 21546, loss 0.0310286, acc 1\n",
      "2017-04-03T20:38:03.539969: step 21547, loss 0.0411239, acc 0.984375\n",
      "2017-04-03T20:38:03.740631: step 21548, loss 0.0687224, acc 0.96875\n",
      "2017-04-03T20:38:03.941262: step 21549, loss 0.0540053, acc 0.984375\n",
      "2017-04-03T20:38:04.143589: step 21550, loss 0.0168588, acc 1\n",
      "2017-04-03T20:38:04.341416: step 21551, loss 0.0362327, acc 1\n",
      "2017-04-03T20:38:04.542046: step 21552, loss 0.0163265, acc 1\n",
      "2017-04-03T20:38:04.784354: step 21553, loss 0.12937, acc 0.96875\n",
      "2017-04-03T20:38:04.988573: step 21554, loss 0.0585313, acc 0.96875\n",
      "2017-04-03T20:38:05.186557: step 21555, loss 0.0129514, acc 1\n",
      "2017-04-03T20:38:05.384353: step 21556, loss 0.0455669, acc 1\n",
      "2017-04-03T20:38:05.586205: step 21557, loss 0.0124218, acc 1\n",
      "2017-04-03T20:38:05.788823: step 21558, loss 0.0589861, acc 0.984375\n",
      "2017-04-03T20:38:05.999045: step 21559, loss 0.0581673, acc 0.984375\n",
      "2017-04-03T20:38:06.243833: step 21560, loss 0.044006, acc 0.984375\n",
      "2017-04-03T20:38:06.445727: step 21561, loss 0.157319, acc 0.953125\n",
      "2017-04-03T20:38:06.686213: step 21562, loss 0.186844, acc 0.953125\n",
      "2017-04-03T20:38:06.929969: step 21563, loss 0.0535112, acc 0.984375\n",
      "2017-04-03T20:38:07.139263: step 21564, loss 0.0346059, acc 0.984375\n",
      "2017-04-03T20:38:07.348956: step 21565, loss 0.0751313, acc 0.96875\n",
      "2017-04-03T20:38:07.557379: step 21566, loss 0.0866502, acc 0.984375\n",
      "2017-04-03T20:38:07.759551: step 21567, loss 0.0196501, acc 1\n",
      "2017-04-03T20:38:07.960854: step 21568, loss 0.0902626, acc 0.953125\n",
      "2017-04-03T20:38:08.159695: step 21569, loss 0.0555857, acc 1\n",
      "2017-04-03T20:38:08.361159: step 21570, loss 0.0444523, acc 0.984375\n",
      "2017-04-03T20:38:08.567001: step 21571, loss 0.0460468, acc 0.984375\n",
      "2017-04-03T20:38:08.768772: step 21572, loss 0.167756, acc 0.953125\n",
      "2017-04-03T20:38:08.971826: step 21573, loss 0.0278793, acc 1\n",
      "2017-04-03T20:38:09.170431: step 21574, loss 0.0652159, acc 0.984375\n",
      "2017-04-03T20:38:09.372476: step 21575, loss 0.0728393, acc 0.96875\n",
      "2017-04-03T20:38:09.574452: step 21576, loss 0.0109778, acc 1\n",
      "2017-04-03T20:38:09.781735: step 21577, loss 0.0704346, acc 0.96875\n",
      "2017-04-03T20:38:09.977577: step 21578, loss 0.0470121, acc 0.984375\n",
      "2017-04-03T20:38:10.180402: step 21579, loss 0.225641, acc 0.921875\n",
      "2017-04-03T20:38:10.389065: step 21580, loss 0.109406, acc 0.96875\n",
      "2017-04-03T20:38:10.594791: step 21581, loss 0.140136, acc 0.953125\n",
      "2017-04-03T20:38:10.815983: step 21582, loss 0.0343614, acc 0.984375\n",
      "2017-04-03T20:38:11.035248: step 21583, loss 0.111336, acc 0.9375\n",
      "2017-04-03T20:38:11.252293: step 21584, loss 0.039266, acc 0.984375\n",
      "2017-04-03T20:38:11.458967: step 21585, loss 0.117644, acc 0.96875\n",
      "2017-04-03T20:38:11.659225: step 21586, loss 0.012092, acc 1\n",
      "2017-04-03T20:38:11.860116: step 21587, loss 0.0503739, acc 0.984375\n",
      "2017-04-03T20:38:12.108153: step 21588, loss 0.113285, acc 0.953125\n",
      "2017-04-03T20:38:12.314218: step 21589, loss 0.049753, acc 0.984375\n",
      "2017-04-03T20:38:12.520874: step 21590, loss 0.195084, acc 0.921875\n",
      "2017-04-03T20:38:12.732021: step 21591, loss 0.0909015, acc 0.96875\n",
      "2017-04-03T20:38:12.947904: step 21592, loss 0.0377406, acc 1\n",
      "2017-04-03T20:38:13.148790: step 21593, loss 0.0620087, acc 0.96875\n",
      "2017-04-03T20:38:13.355825: step 21594, loss 0.0263498, acc 1\n",
      "2017-04-03T20:38:13.562272: step 21595, loss 0.0577903, acc 0.96875\n",
      "2017-04-03T20:38:13.801448: step 21596, loss 0.120075, acc 0.953125\n",
      "2017-04-03T20:38:14.043626: step 21597, loss 0.13689, acc 0.953125\n",
      "2017-04-03T20:38:14.259026: step 21598, loss 0.026632, acc 1\n",
      "2017-04-03T20:38:14.456782: step 21599, loss 0.090705, acc 0.984375\n",
      "2017-04-03T20:38:14.668234: step 21600, loss 0.0454033, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:38:16.802433: step 21600, loss 7.76346, acc 0.27725\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-21600\n",
      "\n",
      "2017-04-03T20:38:17.134383: step 21601, loss 0.0782595, acc 0.984375\n",
      "2017-04-03T20:38:17.375610: step 21602, loss 0.0212301, acc 1\n",
      "2017-04-03T20:38:17.585514: step 21603, loss 0.0187863, acc 1\n",
      "2017-04-03T20:38:17.799500: step 21604, loss 0.0508661, acc 0.984375\n",
      "2017-04-03T20:38:18.002390: step 21605, loss 0.0947227, acc 0.953125\n",
      "2017-04-03T20:38:18.205070: step 21606, loss 0.0704724, acc 0.984375\n",
      "2017-04-03T20:38:18.404431: step 21607, loss 0.251916, acc 0.90625\n",
      "2017-04-03T20:38:18.606968: step 21608, loss 0.0509193, acc 1\n",
      "2017-04-03T20:38:18.809039: step 21609, loss 0.175698, acc 0.953125\n",
      "2017-04-03T20:38:19.009767: step 21610, loss 0.0430592, acc 1\n",
      "2017-04-03T20:38:19.209890: step 21611, loss 0.0310856, acc 1\n",
      "2017-04-03T20:38:19.411839: step 21612, loss 0.0499753, acc 0.984375\n",
      "2017-04-03T20:38:19.632426: step 21613, loss 0.286525, acc 0.9375\n",
      "2017-04-03T20:38:19.837156: step 21614, loss 0.172843, acc 0.953125\n",
      "2017-04-03T20:38:20.039769: step 21615, loss 0.0443296, acc 1\n",
      "2017-04-03T20:38:20.242029: step 21616, loss 0.0287009, acc 0.984375\n",
      "2017-04-03T20:38:20.448489: step 21617, loss 0.0948483, acc 0.96875\n",
      "2017-04-03T20:38:20.652176: step 21618, loss 0.0834796, acc 0.984375\n",
      "2017-04-03T20:38:20.853482: step 21619, loss 0.0585965, acc 0.984375\n",
      "2017-04-03T20:38:21.093292: step 21620, loss 0.0348173, acc 1\n",
      "2017-04-03T20:38:21.301607: step 21621, loss 0.188272, acc 0.9375\n",
      "2017-04-03T20:38:21.500727: step 21622, loss 0.0270264, acc 0.984375\n",
      "2017-04-03T20:38:21.709666: step 21623, loss 0.00599716, acc 1\n",
      "2017-04-03T20:38:21.922554: step 21624, loss 0.0714505, acc 0.984375\n",
      "2017-04-03T20:38:22.125811: step 21625, loss 0.0298177, acc 1\n",
      "2017-04-03T20:38:22.350913: step 21626, loss 0.0239597, acc 1\n",
      "2017-04-03T20:38:22.567551: step 21627, loss 0.0143874, acc 1\n",
      "2017-04-03T20:38:22.772120: step 21628, loss 0.0668952, acc 0.96875\n",
      "2017-04-03T20:38:23.016826: step 21629, loss 0.101942, acc 0.9375\n",
      "2017-04-03T20:38:23.218384: step 21630, loss 0.126912, acc 0.96875\n",
      "2017-04-03T20:38:23.421116: step 21631, loss 0.207748, acc 0.96875\n",
      "2017-04-03T20:38:23.669142: step 21632, loss 0.0779269, acc 0.96875\n",
      "2017-04-03T20:38:23.875213: step 21633, loss 0.415315, acc 0.90625\n",
      "2017-04-03T20:38:24.076235: step 21634, loss 0.0766094, acc 0.984375\n",
      "2017-04-03T20:38:24.276710: step 21635, loss 0.0143776, acc 1\n",
      "2017-04-03T20:38:24.478799: step 21636, loss 0.0591273, acc 0.984375\n",
      "2017-04-03T20:38:24.720123: step 21637, loss 0.0621621, acc 0.984375\n",
      "2017-04-03T20:38:24.919390: step 21638, loss 0.0607781, acc 0.984375\n",
      "2017-04-03T20:38:25.120187: step 21639, loss 0.152935, acc 0.96875\n",
      "2017-04-03T20:38:25.322847: step 21640, loss 0.200152, acc 0.953125\n",
      "2017-04-03T20:38:25.523767: step 21641, loss 0.026369, acc 1\n",
      "2017-04-03T20:38:25.724913: step 21642, loss 0.0906671, acc 0.953125\n",
      "2017-04-03T20:38:25.922706: step 21643, loss 0.0628156, acc 0.984375\n",
      "2017-04-03T20:38:26.142343: step 21644, loss 0.022205, acc 1\n",
      "2017-04-03T20:38:26.354494: step 21645, loss 0.0916325, acc 0.96875\n",
      "2017-04-03T20:38:26.558762: step 21646, loss 0.0843083, acc 0.953125\n",
      "2017-04-03T20:38:26.759381: step 21647, loss 0.0222039, acc 1\n",
      "2017-04-03T20:38:26.962243: step 21648, loss 0.0493903, acc 0.984375\n",
      "2017-04-03T20:38:27.173069: step 21649, loss 0.0456462, acc 0.984375\n",
      "2017-04-03T20:38:27.381438: step 21650, loss 0.0492768, acc 0.96875\n",
      "2017-04-03T20:38:27.582496: step 21651, loss 0.158314, acc 0.9375\n",
      "2017-04-03T20:38:27.786243: step 21652, loss 0.113746, acc 0.96875\n",
      "2017-04-03T20:38:27.992410: step 21653, loss 0.0589875, acc 1\n",
      "2017-04-03T20:38:28.242535: step 21654, loss 0.0153189, acc 1\n",
      "2017-04-03T20:38:28.447353: step 21655, loss 0.264226, acc 0.953125\n",
      "2017-04-03T20:38:28.652724: step 21656, loss 0.31238, acc 0.953125\n",
      "2017-04-03T20:38:28.865109: step 21657, loss 0.0608329, acc 0.984375\n",
      "2017-04-03T20:38:29.104058: step 21658, loss 0.0382673, acc 1\n",
      "2017-04-03T20:38:29.307300: step 21659, loss 0.0873717, acc 0.953125\n",
      "2017-04-03T20:38:29.516443: step 21660, loss 0.0570044, acc 0.953125\n",
      "2017-04-03T20:38:29.725878: step 21661, loss 0.0312366, acc 1\n",
      "2017-04-03T20:38:29.933203: step 21662, loss 0.117713, acc 0.96875\n",
      "2017-04-03T20:38:30.142927: step 21663, loss 0.0374821, acc 1\n",
      "2017-04-03T20:38:30.344909: step 21664, loss 0.0996238, acc 0.96875\n",
      "2017-04-03T20:38:30.546118: step 21665, loss 0.278871, acc 0.9375\n",
      "2017-04-03T20:38:30.751273: step 21666, loss 0.0322669, acc 1\n",
      "2017-04-03T20:38:30.954301: step 21667, loss 0.0273256, acc 1\n",
      "2017-04-03T20:38:31.152384: step 21668, loss 0.0921263, acc 0.96875\n",
      "2017-04-03T20:38:31.349444: step 21669, loss 0.0522616, acc 1\n",
      "2017-04-03T20:38:31.553410: step 21670, loss 0.178808, acc 0.96875\n",
      "2017-04-03T20:38:31.754684: step 21671, loss 0.0926018, acc 0.96875\n",
      "2017-04-03T20:38:31.952688: step 21672, loss 0.108485, acc 0.96875\n",
      "2017-04-03T20:38:32.154393: step 21673, loss 0.0864038, acc 0.96875\n",
      "2017-04-03T20:38:32.358298: step 21674, loss 0.0827546, acc 0.984375\n",
      "2017-04-03T20:38:32.561265: step 21675, loss 0.0738548, acc 0.953125\n",
      "2017-04-03T20:38:32.762782: step 21676, loss 0.075982, acc 0.984375\n",
      "2017-04-03T20:38:32.967143: step 21677, loss 0.0907622, acc 0.953125\n",
      "2017-04-03T20:38:33.168322: step 21678, loss 0.0639455, acc 0.96875\n",
      "2017-04-03T20:38:33.369676: step 21679, loss 0.0248237, acc 1\n",
      "2017-04-03T20:38:33.571198: step 21680, loss 0.0879133, acc 0.953125\n",
      "2017-04-03T20:38:33.774930: step 21681, loss 0.0571803, acc 1\n",
      "2017-04-03T20:38:33.979013: step 21682, loss 0.241327, acc 0.921875\n",
      "2017-04-03T20:38:34.179461: step 21683, loss 0.0645987, acc 0.96875\n",
      "2017-04-03T20:38:34.381955: step 21684, loss 0.174476, acc 0.953125\n",
      "2017-04-03T20:38:34.581885: step 21685, loss 0.0246559, acc 1\n",
      "2017-04-03T20:38:34.785538: step 21686, loss 0.107735, acc 0.953125\n",
      "2017-04-03T20:38:34.991437: step 21687, loss 0.0479156, acc 0.96875\n",
      "2017-04-03T20:38:35.239339: step 21688, loss 0.171182, acc 0.96875\n",
      "2017-04-03T20:38:35.443988: step 21689, loss 0.0984805, acc 0.9375\n",
      "2017-04-03T20:38:35.650889: step 21690, loss 0.0429572, acc 1\n",
      "2017-04-03T20:38:35.854956: step 21691, loss 0.0439425, acc 0.96875\n",
      "2017-04-03T20:38:36.070015: step 21692, loss 0.0858982, acc 0.96875\n",
      "2017-04-03T20:38:36.277714: step 21693, loss 0.0264679, acc 1\n",
      "2017-04-03T20:38:36.485644: step 21694, loss 0.0780794, acc 0.984375\n",
      "2017-04-03T20:38:36.687338: step 21695, loss 0.102257, acc 0.96875\n",
      "2017-04-03T20:38:36.891753: step 21696, loss 0.0649566, acc 0.96875\n",
      "2017-04-03T20:38:37.134251: step 21697, loss 0.094516, acc 0.96875\n",
      "2017-04-03T20:38:37.336962: step 21698, loss 0.251919, acc 0.9375\n",
      "2017-04-03T20:38:37.536056: step 21699, loss 0.0938544, acc 0.984375\n",
      "2017-04-03T20:38:37.735642: step 21700, loss 0.0666153, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:38:39.840469: step 21700, loss 7.83628, acc 0.28525\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-21700\n",
      "\n",
      "2017-04-03T20:38:40.178948: step 21701, loss 0.100002, acc 0.984375\n",
      "2017-04-03T20:38:40.387794: step 21702, loss 0.114234, acc 0.96875\n",
      "2017-04-03T20:38:40.587063: step 21703, loss 0.0320643, acc 1\n",
      "2017-04-03T20:38:40.791398: step 21704, loss 0.0180203, acc 1\n",
      "2017-04-03T20:38:40.990594: step 21705, loss 0.196456, acc 0.953125\n",
      "2017-04-03T20:38:41.197010: step 21706, loss 0.0823322, acc 0.96875\n",
      "2017-04-03T20:38:41.403877: step 21707, loss 0.20787, acc 0.9375\n",
      "2017-04-03T20:38:41.602731: step 21708, loss 0.0802424, acc 0.96875\n",
      "2017-04-03T20:38:41.809535: step 21709, loss 0.204907, acc 0.96875\n",
      "2017-04-03T20:38:42.017381: step 21710, loss 0.0979474, acc 0.953125\n",
      "2017-04-03T20:38:42.220183: step 21711, loss 0.0330176, acc 0.984375\n",
      "2017-04-03T20:38:42.420961: step 21712, loss 0.0739638, acc 0.984375\n",
      "2017-04-03T20:38:42.629450: step 21713, loss 0.149858, acc 0.953125\n",
      "2017-04-03T20:38:42.834788: step 21714, loss 0.198305, acc 0.9375\n",
      "2017-04-03T20:38:43.039237: step 21715, loss 0.0392525, acc 0.984375\n",
      "2017-04-03T20:38:43.239978: step 21716, loss 0.23661, acc 0.9375\n",
      "2017-04-03T20:38:43.442187: step 21717, loss 0.0526726, acc 0.984375\n",
      "2017-04-03T20:38:43.643090: step 21718, loss 0.103853, acc 0.953125\n",
      "2017-04-03T20:38:43.847755: step 21719, loss 0.0897693, acc 0.96875\n",
      "2017-04-03T20:38:44.047998: step 21720, loss 0.0940652, acc 0.953125\n",
      "2017-04-03T20:38:44.253129: step 21721, loss 0.136591, acc 0.9375\n",
      "2017-04-03T20:38:44.500822: step 21722, loss 0.128799, acc 0.984375\n",
      "2017-04-03T20:38:44.719880: step 21723, loss 0.0761824, acc 0.96875\n",
      "2017-04-03T20:38:44.966490: step 21724, loss 0.0841577, acc 0.96875\n",
      "2017-04-03T20:38:45.170289: step 21725, loss 0.0521441, acc 0.96875\n",
      "2017-04-03T20:38:45.370557: step 21726, loss 0.0453497, acc 0.984375\n",
      "2017-04-03T20:38:45.581266: step 21727, loss 0.0819077, acc 0.953125\n",
      "2017-04-03T20:38:45.784024: step 21728, loss 0.0505975, acc 0.984375\n",
      "2017-04-03T20:38:45.980751: step 21729, loss 0.114469, acc 0.953125\n",
      "2017-04-03T20:38:46.179243: step 21730, loss 0.0252192, acc 1\n",
      "2017-04-03T20:38:46.390472: step 21731, loss 0.0706043, acc 0.96875\n",
      "2017-04-03T20:38:46.597607: step 21732, loss 0.0562439, acc 0.984375\n",
      "2017-04-03T20:38:46.798357: step 21733, loss 0.0966142, acc 0.96875\n",
      "2017-04-03T20:38:47.001590: step 21734, loss 0.0199266, acc 1\n",
      "2017-04-03T20:38:47.200217: step 21735, loss 0.123252, acc 0.984375\n",
      "2017-04-03T20:38:47.403991: step 21736, loss 0.0901489, acc 0.953125\n",
      "2017-04-03T20:38:47.608559: step 21737, loss 0.127161, acc 0.96875\n",
      "2017-04-03T20:38:47.818089: step 21738, loss 0.0928345, acc 0.953125\n",
      "2017-04-03T20:38:48.036817: step 21739, loss 0.118579, acc 0.984375\n",
      "2017-04-03T20:38:48.253272: step 21740, loss 0.177357, acc 0.9375\n",
      "2017-04-03T20:38:48.456928: step 21741, loss 0.0163268, acc 1\n",
      "2017-04-03T20:38:48.656593: step 21742, loss 0.0804309, acc 0.96875\n",
      "2017-04-03T20:38:48.859517: step 21743, loss 0.153321, acc 0.984375\n",
      "2017-04-03T20:38:49.059763: step 21744, loss 0.0867643, acc 0.96875\n",
      "2017-04-03T20:38:49.266481: step 21745, loss 0.0929498, acc 0.96875\n",
      "2017-04-03T20:38:49.474286: step 21746, loss 0.0814488, acc 0.96875\n",
      "2017-04-03T20:38:49.678870: step 21747, loss 0.102593, acc 0.953125\n",
      "2017-04-03T20:38:49.884684: step 21748, loss 0.186358, acc 0.90625\n",
      "2017-04-03T20:38:50.086531: step 21749, loss 0.102867, acc 0.984375\n",
      "2017-04-03T20:38:50.283503: step 21750, loss 0.118282, acc 0.953125\n",
      "2017-04-03T20:38:50.497233: step 21751, loss 0.0721297, acc 0.96875\n",
      "2017-04-03T20:38:50.718331: step 21752, loss 0.249873, acc 0.90625\n",
      "2017-04-03T20:38:50.933688: step 21753, loss 0.0472088, acc 0.984375\n",
      "2017-04-03T20:38:51.153308: step 21754, loss 0.101986, acc 0.96875\n",
      "2017-04-03T20:38:51.371177: step 21755, loss 0.0738837, acc 0.984375\n",
      "2017-04-03T20:38:51.576716: step 21756, loss 0.0892785, acc 0.96875\n",
      "2017-04-03T20:38:51.779928: step 21757, loss 0.0232192, acc 1\n",
      "2017-04-03T20:38:51.993740: step 21758, loss 0.130131, acc 0.984375\n",
      "2017-04-03T20:38:52.202867: step 21759, loss 0.127942, acc 0.9375\n",
      "2017-04-03T20:38:52.404806: step 21760, loss 0.0722197, acc 0.96875\n",
      "2017-04-03T20:38:52.653793: step 21761, loss 0.116749, acc 0.9375\n",
      "2017-04-03T20:38:52.855991: step 21762, loss 0.0833727, acc 0.96875\n",
      "2017-04-03T20:38:53.059135: step 21763, loss 0.106952, acc 0.953125\n",
      "2017-04-03T20:38:53.259681: step 21764, loss 0.0742845, acc 0.96875\n",
      "2017-04-03T20:38:53.464316: step 21765, loss 0.0873636, acc 0.96875\n",
      "2017-04-03T20:38:53.668704: step 21766, loss 0.168016, acc 0.953125\n",
      "2017-04-03T20:38:53.867346: step 21767, loss 0.0736756, acc 0.984375\n",
      "2017-04-03T20:38:54.068879: step 21768, loss 0.1997, acc 0.9375\n",
      "2017-04-03T20:38:54.271506: step 21769, loss 0.0251743, acc 1\n",
      "2017-04-03T20:38:54.483634: step 21770, loss 0.297938, acc 0.90625\n",
      "2017-04-03T20:38:54.712311: step 21771, loss 0.107625, acc 0.953125\n",
      "2017-04-03T20:38:54.926494: step 21772, loss 0.048241, acc 0.984375\n",
      "2017-04-03T20:38:55.127576: step 21773, loss 0.0157922, acc 1\n",
      "2017-04-03T20:38:55.328479: step 21774, loss 0.216881, acc 0.9375\n",
      "2017-04-03T20:38:55.530546: step 21775, loss 0.191089, acc 0.9375\n",
      "2017-04-03T20:38:55.734380: step 21776, loss 0.0457916, acc 0.984375\n",
      "2017-04-03T20:38:55.933204: step 21777, loss 0.141686, acc 0.96875\n",
      "2017-04-03T20:38:56.144664: step 21778, loss 0.0390409, acc 0.984375\n",
      "2017-04-03T20:38:56.362554: step 21779, loss 0.0538991, acc 0.984375\n",
      "2017-04-03T20:38:56.569993: step 21780, loss 0.125333, acc 0.9375\n",
      "2017-04-03T20:38:56.782230: step 21781, loss 0.0698772, acc 0.96875\n",
      "2017-04-03T20:38:56.983717: step 21782, loss 0.0672166, acc 0.96875\n",
      "2017-04-03T20:38:57.182768: step 21783, loss 0.118114, acc 0.953125\n",
      "2017-04-03T20:38:57.384080: step 21784, loss 0.146129, acc 0.96875\n",
      "2017-04-03T20:38:57.584732: step 21785, loss 0.0357948, acc 0.984375\n",
      "2017-04-03T20:38:57.786308: step 21786, loss 0.106024, acc 0.953125\n",
      "2017-04-03T20:38:57.994689: step 21787, loss 0.158755, acc 0.921875\n",
      "2017-04-03T20:38:58.200702: step 21788, loss 0.0800193, acc 0.953125\n",
      "2017-04-03T20:38:58.426841: step 21789, loss 0.0560893, acc 0.984375\n",
      "2017-04-03T20:38:58.632978: step 21790, loss 0.17233, acc 0.9375\n",
      "2017-04-03T20:38:58.851841: step 21791, loss 0.0255383, acc 1\n",
      "2017-04-03T20:38:59.060941: step 21792, loss 0.0139928, acc 1\n",
      "2017-04-03T20:38:59.264298: step 21793, loss 0.270262, acc 0.921875\n",
      "2017-04-03T20:38:59.471410: step 21794, loss 0.0575616, acc 0.984375\n",
      "2017-04-03T20:38:59.672543: step 21795, loss 0.166179, acc 0.9375\n",
      "2017-04-03T20:38:59.889000: step 21796, loss 0.137659, acc 0.96875\n",
      "2017-04-03T20:39:00.090629: step 21797, loss 0.03311, acc 1\n",
      "2017-04-03T20:39:00.295969: step 21798, loss 0.123763, acc 0.96875\n",
      "2017-04-03T20:39:00.540295: step 21799, loss 0.0739182, acc 0.953125\n",
      "2017-04-03T20:39:00.747015: step 21800, loss 0.169822, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:39:02.884468: step 21800, loss 7.87921, acc 0.283\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-21800\n",
      "\n",
      "2017-04-03T20:39:03.233393: step 21801, loss 0.0580775, acc 0.984375\n",
      "2017-04-03T20:39:03.434356: step 21802, loss 0.10247, acc 0.9375\n",
      "2017-04-03T20:39:03.636011: step 21803, loss 0.045823, acc 0.984375\n",
      "2017-04-03T20:39:03.876336: step 21804, loss 0.038994, acc 1\n",
      "2017-04-03T20:39:04.073743: step 21805, loss 0.0646016, acc 0.96875\n",
      "2017-04-03T20:39:04.276496: step 21806, loss 0.0308493, acc 1\n",
      "2017-04-03T20:39:04.477815: step 21807, loss 0.346679, acc 0.921875\n",
      "2017-04-03T20:39:04.678003: step 21808, loss 0.0808835, acc 0.96875\n",
      "2017-04-03T20:39:04.879826: step 21809, loss 0.0212124, acc 0.984375\n",
      "2017-04-03T20:39:05.085497: step 21810, loss 0.0172367, acc 1\n",
      "2017-04-03T20:39:05.291849: step 21811, loss 0.0868508, acc 0.96875\n",
      "2017-04-03T20:39:05.491164: step 21812, loss 0.0554488, acc 0.984375\n",
      "2017-04-03T20:39:05.695059: step 21813, loss 0.208472, acc 0.890625\n",
      "2017-04-03T20:39:05.894816: step 21814, loss 0.0995765, acc 0.953125\n",
      "2017-04-03T20:39:06.092607: step 21815, loss 0.110049, acc 0.953125\n",
      "2017-04-03T20:39:06.296643: step 21816, loss 0.0396497, acc 0.984375\n",
      "2017-04-03T20:39:06.496992: step 21817, loss 0.113886, acc 0.953125\n",
      "2017-04-03T20:39:06.702798: step 21818, loss 0.103505, acc 0.953125\n",
      "2017-04-03T20:39:06.906347: step 21819, loss 0.144589, acc 0.9375\n",
      "2017-04-03T20:39:07.112055: step 21820, loss 0.0913199, acc 0.953125\n",
      "2017-04-03T20:39:07.315495: step 21821, loss 0.0762892, acc 0.96875\n",
      "2017-04-03T20:39:07.516678: step 21822, loss 0.0449769, acc 0.984375\n",
      "2017-04-03T20:39:07.716513: step 21823, loss 0.0368079, acc 1\n",
      "2017-04-03T20:39:07.962698: step 21824, loss 0.0769559, acc 0.984375\n",
      "2017-04-03T20:39:08.166118: step 21825, loss 0.0780174, acc 0.96875\n",
      "2017-04-03T20:39:08.369853: step 21826, loss 0.0569437, acc 0.984375\n",
      "2017-04-03T20:39:08.572414: step 21827, loss 0.0593246, acc 1\n",
      "2017-04-03T20:39:08.769806: step 21828, loss 0.0706578, acc 0.984375\n",
      "2017-04-03T20:39:08.969371: step 21829, loss 0.140692, acc 0.953125\n",
      "2017-04-03T20:39:09.170886: step 21830, loss 0.0365731, acc 1\n",
      "2017-04-03T20:39:09.382724: step 21831, loss 0.0628349, acc 0.96875\n",
      "2017-04-03T20:39:09.581055: step 21832, loss 0.036003, acc 1\n",
      "2017-04-03T20:39:09.779577: step 21833, loss 0.0937109, acc 0.953125\n",
      "2017-04-03T20:39:09.979428: step 21834, loss 0.114099, acc 0.96875\n",
      "2017-04-03T20:39:10.195628: step 21835, loss 0.0345097, acc 0.984375\n",
      "2017-04-03T20:39:10.394516: step 21836, loss 0.080136, acc 0.953125\n",
      "2017-04-03T20:39:10.602372: step 21837, loss 0.0872343, acc 0.984375\n",
      "2017-04-03T20:39:10.808275: step 21838, loss 0.0166928, acc 1\n",
      "2017-04-03T20:39:11.016027: step 21839, loss 0.0994018, acc 0.96875\n",
      "2017-04-03T20:39:11.221993: step 21840, loss 0.0791954, acc 0.984375\n",
      "2017-04-03T20:39:11.469317: step 21841, loss 0.184379, acc 0.921875\n",
      "2017-04-03T20:39:11.677550: step 21842, loss 0.172677, acc 0.96875\n",
      "2017-04-03T20:39:11.878557: step 21843, loss 0.0731779, acc 0.984375\n",
      "2017-04-03T20:39:12.076271: step 21844, loss 0.0840473, acc 0.96875\n",
      "2017-04-03T20:39:12.287116: step 21845, loss 0.0890101, acc 0.953125\n",
      "2017-04-03T20:39:12.541684: step 21846, loss 0.0779767, acc 0.953125\n",
      "2017-04-03T20:39:12.741996: step 21847, loss 0.0675749, acc 0.984375\n",
      "2017-04-03T20:39:12.945067: step 21848, loss 0.050343, acc 0.984375\n",
      "2017-04-03T20:39:13.187941: step 21849, loss 0.172624, acc 0.9375\n",
      "2017-04-03T20:39:13.393224: step 21850, loss 0.151463, acc 0.96875\n",
      "2017-04-03T20:39:13.592404: step 21851, loss 0.0463057, acc 0.984375\n",
      "2017-04-03T20:39:13.801383: step 21852, loss 0.0791521, acc 0.96875\n",
      "2017-04-03T20:39:14.008160: step 21853, loss 0.0652026, acc 0.984375\n",
      "2017-04-03T20:39:14.213064: step 21854, loss 0.0504696, acc 0.96875\n",
      "2017-04-03T20:39:14.420384: step 21855, loss 0.063247, acc 0.984375\n",
      "2017-04-03T20:39:14.670071: step 21856, loss 0.170968, acc 0.96875\n",
      "2017-04-03T20:39:14.872793: step 21857, loss 0.0902899, acc 0.953125\n",
      "2017-04-03T20:39:15.076610: step 21858, loss 0.0691598, acc 0.984375\n",
      "2017-04-03T20:39:15.277362: step 21859, loss 0.16593, acc 0.953125\n",
      "2017-04-03T20:39:15.485029: step 21860, loss 0.0679646, acc 0.984375\n",
      "2017-04-03T20:39:15.689023: step 21861, loss 0.126426, acc 0.9375\n",
      "2017-04-03T20:39:15.890540: step 21862, loss 0.03704, acc 0.984375\n",
      "2017-04-03T20:39:16.135708: step 21863, loss 0.0933599, acc 0.96875\n",
      "2017-04-03T20:39:16.341378: step 21864, loss 0.0878575, acc 0.953125\n",
      "2017-04-03T20:39:16.545500: step 21865, loss 0.232782, acc 0.984375\n",
      "2017-04-03T20:39:16.750560: step 21866, loss 0.161424, acc 0.9375\n",
      "2017-04-03T20:39:16.953555: step 21867, loss 0.0345896, acc 1\n",
      "2017-04-03T20:39:17.166286: step 21868, loss 0.0850527, acc 0.96875\n",
      "2017-04-03T20:39:17.371670: step 21869, loss 0.114491, acc 0.953125\n",
      "2017-04-03T20:39:17.570841: step 21870, loss 0.12468, acc 0.953125\n",
      "2017-04-03T20:39:17.781718: step 21871, loss 0.0949484, acc 0.96875\n",
      "2017-04-03T20:39:17.982962: step 21872, loss 0.0947098, acc 0.953125\n",
      "2017-04-03T20:39:18.188992: step 21873, loss 0.0428574, acc 0.984375\n",
      "2017-04-03T20:39:18.399818: step 21874, loss 0.0384099, acc 1\n",
      "2017-04-03T20:39:18.601567: step 21875, loss 0.0623321, acc 0.96875\n",
      "2017-04-03T20:39:18.803203: step 21876, loss 0.121794, acc 0.953125\n",
      "2017-04-03T20:39:19.010581: step 21877, loss 0.149707, acc 0.96875\n",
      "2017-04-03T20:39:19.213044: step 21878, loss 0.111594, acc 0.984375\n",
      "2017-04-03T20:39:19.419453: step 21879, loss 0.0320237, acc 1\n",
      "2017-04-03T20:39:19.619347: step 21880, loss 0.0727382, acc 0.96875\n",
      "2017-04-03T20:39:19.824335: step 21881, loss 0.0784836, acc 0.984375\n",
      "2017-04-03T20:39:20.024675: step 21882, loss 0.0776335, acc 0.96875\n",
      "2017-04-03T20:39:20.233513: step 21883, loss 0.2501, acc 0.96875\n",
      "2017-04-03T20:39:20.487601: step 21884, loss 0.175504, acc 0.953125\n",
      "2017-04-03T20:39:20.695305: step 21885, loss 0.0236527, acc 1\n",
      "2017-04-03T20:39:20.905654: step 21886, loss 0.0919128, acc 0.96875\n",
      "2017-04-03T20:39:21.105823: step 21887, loss 0.108069, acc 0.96875\n",
      "2017-04-03T20:39:21.349543: step 21888, loss 0.0888026, acc 0.953125\n",
      "2017-04-03T20:39:21.552302: step 21889, loss 0.158885, acc 0.9375\n",
      "2017-04-03T20:39:21.753851: step 21890, loss 0.195362, acc 0.921875\n",
      "2017-04-03T20:39:21.956042: step 21891, loss 0.132662, acc 0.953125\n",
      "2017-04-03T20:39:22.162599: step 21892, loss 0.0218425, acc 1\n",
      "2017-04-03T20:39:22.364458: step 21893, loss 0.1286, acc 0.9375\n",
      "2017-04-03T20:39:22.568935: step 21894, loss 0.0102553, acc 1\n",
      "2017-04-03T20:39:22.775293: step 21895, loss 0.413637, acc 0.984375\n",
      "2017-04-03T20:39:22.977690: step 21896, loss 0.0866368, acc 0.96875\n",
      "2017-04-03T20:39:23.179118: step 21897, loss 0.0692187, acc 0.96875\n",
      "2017-04-03T20:39:23.379892: step 21898, loss 0.0672414, acc 0.984375\n",
      "2017-04-03T20:39:23.581484: step 21899, loss 0.101059, acc 0.9375\n",
      "2017-04-03T20:39:23.806504: step 21900, loss 0.0924161, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:39:25.971848: step 21900, loss 7.90768, acc 0.27725\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-21900\n",
      "\n",
      "2017-04-03T20:39:26.355279: step 21901, loss 0.131338, acc 0.96875\n",
      "2017-04-03T20:39:26.568879: step 21902, loss 0.0968828, acc 0.96875\n",
      "2017-04-03T20:39:26.772954: step 21903, loss 0.0566016, acc 0.984375\n",
      "2017-04-03T20:39:26.977290: step 21904, loss 0.0704716, acc 0.96875\n",
      "2017-04-03T20:39:27.179085: step 21905, loss 0.152616, acc 0.953125\n",
      "2017-04-03T20:39:27.386717: step 21906, loss 0.0590657, acc 0.96875\n",
      "2017-04-03T20:39:27.592730: step 21907, loss 0.0892493, acc 0.96875\n",
      "2017-04-03T20:39:27.794681: step 21908, loss 0.131132, acc 0.953125\n",
      "2017-04-03T20:39:28.001597: step 21909, loss 0.12026, acc 0.953125\n",
      "2017-04-03T20:39:28.244713: step 21910, loss 0.125333, acc 0.96875\n",
      "2017-04-03T20:39:28.461914: step 21911, loss 0.109817, acc 0.953125\n",
      "2017-04-03T20:39:28.685819: step 21912, loss 0.138797, acc 0.984375\n",
      "2017-04-03T20:39:28.907832: step 21913, loss 0.0811273, acc 0.953125\n",
      "2017-04-03T20:39:29.131188: step 21914, loss 0.180693, acc 0.890625\n",
      "2017-04-03T20:39:29.350535: step 21915, loss 0.252798, acc 0.921875\n",
      "2017-04-03T20:39:29.561895: step 21916, loss 0.0756095, acc 0.984375\n",
      "2017-04-03T20:39:29.810035: step 21917, loss 0.131977, acc 0.984375\n",
      "2017-04-03T20:39:30.013289: step 21918, loss 0.0791174, acc 0.984375\n",
      "2017-04-03T20:39:30.216210: step 21919, loss 0.0600573, acc 0.96875\n",
      "2017-04-03T20:39:30.420563: step 21920, loss 0.0727335, acc 0.96875\n",
      "2017-04-03T20:39:30.623455: step 21921, loss 0.122397, acc 0.953125\n",
      "2017-04-03T20:39:30.831108: step 21922, loss 0.069284, acc 0.984375\n",
      "2017-04-03T20:39:31.036427: step 21923, loss 0.0637599, acc 0.984375\n",
      "2017-04-03T20:39:31.242000: step 21924, loss 0.0911837, acc 0.953125\n",
      "2017-04-03T20:39:31.443450: step 21925, loss 0.130517, acc 0.984375\n",
      "2017-04-03T20:39:31.647610: step 21926, loss 0.105482, acc 0.96875\n",
      "2017-04-03T20:39:31.849988: step 21927, loss 0.0527374, acc 0.984375\n",
      "2017-04-03T20:39:32.051015: step 21928, loss 0.100851, acc 0.96875\n",
      "2017-04-03T20:39:32.272870: step 21929, loss 0.0629511, acc 0.984375\n",
      "2017-04-03T20:39:32.513152: step 21930, loss 0.108058, acc 0.953125\n",
      "2017-04-03T20:39:32.762509: step 21931, loss 0.162775, acc 0.9375\n",
      "2017-04-03T20:39:32.962816: step 21932, loss 0.0733704, acc 0.96875\n",
      "2017-04-03T20:39:33.166809: step 21933, loss 0.168984, acc 0.953125\n",
      "2017-04-03T20:39:33.409133: step 21934, loss 0.105104, acc 0.96875\n",
      "2017-04-03T20:39:33.616404: step 21935, loss 0.103571, acc 0.953125\n",
      "2017-04-03T20:39:33.829225: step 21936, loss 0.134816, acc 0.953125\n",
      "2017-04-03T20:39:34.043160: step 21937, loss 0.137156, acc 0.96875\n",
      "2017-04-03T20:39:34.247318: step 21938, loss 0.279605, acc 0.90625\n",
      "2017-04-03T20:39:34.492729: step 21939, loss 0.169157, acc 0.953125\n",
      "2017-04-03T20:39:34.700845: step 21940, loss 0.320074, acc 0.90625\n",
      "2017-04-03T20:39:34.906137: step 21941, loss 0.125402, acc 0.96875\n",
      "2017-04-03T20:39:35.106698: step 21942, loss 0.0359758, acc 0.984375\n",
      "2017-04-03T20:39:35.306759: step 21943, loss 0.155316, acc 0.953125\n",
      "2017-04-03T20:39:35.509721: step 21944, loss 0.0369286, acc 0.984375\n",
      "2017-04-03T20:39:35.713428: step 21945, loss 0.00654102, acc 1\n",
      "2017-04-03T20:39:35.915475: step 21946, loss 0.076272, acc 0.96875\n",
      "2017-04-03T20:39:36.117465: step 21947, loss 0.0589341, acc 0.96875\n",
      "2017-04-03T20:39:36.325632: step 21948, loss 0.100247, acc 0.96875\n",
      "2017-04-03T20:39:36.530135: step 21949, loss 0.0229679, acc 1\n",
      "2017-04-03T20:39:36.750144: step 21950, loss 0.198534, acc 0.9375\n",
      "2017-04-03T20:39:36.968492: step 21951, loss 0.183851, acc 0.984375\n",
      "2017-04-03T20:39:37.181489: step 21952, loss 0.0156254, acc 1\n",
      "2017-04-03T20:39:37.381019: step 21953, loss 0.148639, acc 0.96875\n",
      "2017-04-03T20:39:37.584543: step 21954, loss 0.100333, acc 0.96875\n",
      "2017-04-03T20:39:37.788733: step 21955, loss 0.0449397, acc 1\n",
      "2017-04-03T20:39:38.036991: step 21956, loss 0.111935, acc 0.96875\n",
      "2017-04-03T20:39:38.184063: step 21957, loss 0.00925473, acc 1\n",
      "2017-04-03T20:39:38.388909: step 21958, loss 0.0329949, acc 0.984375\n",
      "2017-04-03T20:39:38.596020: step 21959, loss 0.042995, acc 0.984375\n",
      "2017-04-03T20:39:38.837857: step 21960, loss 0.134771, acc 0.96875\n",
      "2017-04-03T20:39:39.043803: step 21961, loss 0.0116548, acc 1\n",
      "2017-04-03T20:39:39.245942: step 21962, loss 0.0479862, acc 0.984375\n",
      "2017-04-03T20:39:39.489008: step 21963, loss 0.0428078, acc 0.984375\n",
      "2017-04-03T20:39:39.691796: step 21964, loss 0.117589, acc 0.96875\n",
      "2017-04-03T20:39:39.942853: step 21965, loss 0.126955, acc 0.984375\n",
      "2017-04-03T20:39:40.145042: step 21966, loss 0.124346, acc 0.953125\n",
      "2017-04-03T20:39:40.347223: step 21967, loss 0.0482983, acc 0.984375\n",
      "2017-04-03T20:39:40.594010: step 21968, loss 0.129227, acc 0.96875\n",
      "2017-04-03T20:39:40.828332: step 21969, loss 0.0659133, acc 0.96875\n",
      "2017-04-03T20:39:41.032761: step 21970, loss 0.0453034, acc 1\n",
      "2017-04-03T20:39:41.239799: step 21971, loss 0.0638386, acc 0.953125\n",
      "2017-04-03T20:39:41.439334: step 21972, loss 0.0608083, acc 0.984375\n",
      "2017-04-03T20:39:41.686191: step 21973, loss 0.0693951, acc 0.984375\n",
      "2017-04-03T20:39:41.891071: step 21974, loss 0.134813, acc 0.96875\n",
      "2017-04-03T20:39:42.089342: step 21975, loss 0.0225503, acc 1\n",
      "2017-04-03T20:39:42.293328: step 21976, loss 0.0222421, acc 1\n",
      "2017-04-03T20:39:42.494223: step 21977, loss 0.0420667, acc 0.984375\n",
      "2017-04-03T20:39:42.699166: step 21978, loss 0.0364611, acc 0.984375\n",
      "2017-04-03T20:39:42.902356: step 21979, loss 0.102277, acc 0.96875\n",
      "2017-04-03T20:39:43.107655: step 21980, loss 0.106978, acc 0.953125\n",
      "2017-04-03T20:39:43.311919: step 21981, loss 0.0766281, acc 0.984375\n",
      "2017-04-03T20:39:43.521226: step 21982, loss 0.104632, acc 0.984375\n",
      "2017-04-03T20:39:43.724622: step 21983, loss 0.00675714, acc 1\n",
      "2017-04-03T20:39:43.926808: step 21984, loss 0.071172, acc 0.96875\n",
      "2017-04-03T20:39:44.127489: step 21985, loss 0.0493154, acc 0.984375\n",
      "2017-04-03T20:39:44.367393: step 21986, loss 0.0725746, acc 0.984375\n",
      "2017-04-03T20:39:44.569459: step 21987, loss 0.0564387, acc 1\n",
      "2017-04-03T20:39:44.768938: step 21988, loss 0.0299399, acc 1\n",
      "2017-04-03T20:39:45.017724: step 21989, loss 0.0389861, acc 0.984375\n",
      "2017-04-03T20:39:45.225758: step 21990, loss 0.089798, acc 0.96875\n",
      "2017-04-03T20:39:45.446897: step 21991, loss 0.0219402, acc 1\n",
      "2017-04-03T20:39:45.646593: step 21992, loss 0.0408665, acc 1\n",
      "2017-04-03T20:39:45.847737: step 21993, loss 0.111139, acc 0.984375\n",
      "2017-04-03T20:39:46.051877: step 21994, loss 0.0529271, acc 0.984375\n",
      "2017-04-03T20:39:46.251576: step 21995, loss 0.0842949, acc 0.96875\n",
      "2017-04-03T20:39:46.460662: step 21996, loss 0.0380733, acc 0.984375\n",
      "2017-04-03T20:39:46.663009: step 21997, loss 0.159335, acc 0.953125\n",
      "2017-04-03T20:39:46.860871: step 21998, loss 0.0879089, acc 0.96875\n",
      "2017-04-03T20:39:47.061149: step 21999, loss 0.0248268, acc 1\n",
      "2017-04-03T20:39:47.267984: step 22000, loss 0.0949274, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:39:49.378684: step 22000, loss 7.99555, acc 0.287\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-22000\n",
      "\n",
      "2017-04-03T20:39:49.770215: step 22001, loss 0.0650657, acc 0.984375\n",
      "2017-04-03T20:39:49.973208: step 22002, loss 0.165605, acc 0.953125\n",
      "2017-04-03T20:39:50.180384: step 22003, loss 0.0457882, acc 0.984375\n",
      "2017-04-03T20:39:50.387000: step 22004, loss 0.0407224, acc 1\n",
      "2017-04-03T20:39:50.614595: step 22005, loss 0.120597, acc 0.9375\n",
      "2017-04-03T20:39:50.821514: step 22006, loss 0.106617, acc 0.96875\n",
      "2017-04-03T20:39:51.024481: step 22007, loss 0.0680409, acc 0.984375\n",
      "2017-04-03T20:39:51.271540: step 22008, loss 0.0430274, acc 1\n",
      "2017-04-03T20:39:51.469605: step 22009, loss 0.0706483, acc 0.984375\n",
      "2017-04-03T20:39:51.680892: step 22010, loss 0.144001, acc 0.984375\n",
      "2017-04-03T20:39:51.906477: step 22011, loss 0.0622863, acc 0.984375\n",
      "2017-04-03T20:39:52.118536: step 22012, loss 0.137082, acc 0.96875\n",
      "2017-04-03T20:39:52.318233: step 22013, loss 0.134984, acc 0.953125\n",
      "2017-04-03T20:39:52.527749: step 22014, loss 0.0837464, acc 0.984375\n",
      "2017-04-03T20:39:52.728007: step 22015, loss 0.102769, acc 0.96875\n",
      "2017-04-03T20:39:52.941183: step 22016, loss 0.0791319, acc 0.96875\n",
      "2017-04-03T20:39:53.161965: step 22017, loss 0.0553028, acc 0.984375\n",
      "2017-04-03T20:39:53.378710: step 22018, loss 0.0339463, acc 1\n",
      "2017-04-03T20:39:53.585271: step 22019, loss 0.0863112, acc 0.96875\n",
      "2017-04-03T20:39:53.799967: step 22020, loss 0.0948921, acc 0.96875\n",
      "2017-04-03T20:39:54.006717: step 22021, loss 0.0576965, acc 0.96875\n",
      "2017-04-03T20:39:54.206617: step 22022, loss 0.0685723, acc 0.96875\n",
      "2017-04-03T20:39:54.411784: step 22023, loss 0.0821544, acc 0.96875\n",
      "2017-04-03T20:39:54.612663: step 22024, loss 0.088907, acc 0.984375\n",
      "2017-04-03T20:39:54.808926: step 22025, loss 0.073109, acc 0.984375\n",
      "2017-04-03T20:39:55.010288: step 22026, loss 0.0976868, acc 0.984375\n",
      "2017-04-03T20:39:55.220413: step 22027, loss 0.156527, acc 0.953125\n",
      "2017-04-03T20:39:55.422959: step 22028, loss 0.0565115, acc 0.984375\n",
      "2017-04-03T20:39:55.626851: step 22029, loss 0.161845, acc 0.96875\n",
      "2017-04-03T20:39:55.832888: step 22030, loss 0.0271038, acc 1\n",
      "2017-04-03T20:39:56.034484: step 22031, loss 0.121117, acc 0.953125\n",
      "2017-04-03T20:39:56.237285: step 22032, loss 0.066988, acc 0.96875\n",
      "2017-04-03T20:39:56.440187: step 22033, loss 0.0622778, acc 0.96875\n",
      "2017-04-03T20:39:56.638806: step 22034, loss 0.012606, acc 1\n",
      "2017-04-03T20:39:56.837650: step 22035, loss 0.040847, acc 0.984375\n",
      "2017-04-03T20:39:57.042965: step 22036, loss 0.0700807, acc 0.96875\n",
      "2017-04-03T20:39:57.245436: step 22037, loss 0.0601013, acc 0.984375\n",
      "2017-04-03T20:39:57.446781: step 22038, loss 0.0393168, acc 0.984375\n",
      "2017-04-03T20:39:57.672619: step 22039, loss 0.137572, acc 0.953125\n",
      "2017-04-03T20:39:57.886523: step 22040, loss 0.094515, acc 0.96875\n",
      "2017-04-03T20:39:58.090394: step 22041, loss 0.173455, acc 0.921875\n",
      "2017-04-03T20:39:58.289990: step 22042, loss 0.0114737, acc 1\n",
      "2017-04-03T20:39:58.491889: step 22043, loss 0.0560175, acc 0.984375\n",
      "2017-04-03T20:39:58.693617: step 22044, loss 0.0665576, acc 1\n",
      "2017-04-03T20:39:58.946048: step 22045, loss 0.0753466, acc 0.953125\n",
      "2017-04-03T20:39:59.154853: step 22046, loss 0.0268338, acc 0.984375\n",
      "2017-04-03T20:39:59.356111: step 22047, loss 0.22863, acc 0.921875\n",
      "2017-04-03T20:39:59.557288: step 22048, loss 0.0267442, acc 1\n",
      "2017-04-03T20:39:59.755976: step 22049, loss 0.0493613, acc 0.984375\n",
      "2017-04-03T20:40:00.006101: step 22050, loss 0.0303063, acc 1\n",
      "2017-04-03T20:40:00.219897: step 22051, loss 0.037503, acc 1\n",
      "2017-04-03T20:40:00.421563: step 22052, loss 0.0311298, acc 1\n",
      "2017-04-03T20:40:00.622719: step 22053, loss 0.12274, acc 0.96875\n",
      "2017-04-03T20:40:00.824030: step 22054, loss 0.0414157, acc 0.984375\n",
      "2017-04-03T20:40:01.064447: step 22055, loss 0.0389904, acc 1\n",
      "2017-04-03T20:40:01.274852: step 22056, loss 0.0487631, acc 0.984375\n",
      "2017-04-03T20:40:01.479624: step 22057, loss 0.0195927, acc 1\n",
      "2017-04-03T20:40:01.685165: step 22058, loss 0.0880021, acc 0.984375\n",
      "2017-04-03T20:40:01.893399: step 22059, loss 0.0909614, acc 0.96875\n",
      "2017-04-03T20:40:02.095268: step 22060, loss 0.0550242, acc 0.96875\n",
      "2017-04-03T20:40:02.337164: step 22061, loss 0.108948, acc 0.953125\n",
      "2017-04-03T20:40:02.542565: step 22062, loss 0.0992913, acc 0.9375\n",
      "2017-04-03T20:40:02.743988: step 22063, loss 0.0600984, acc 0.984375\n",
      "2017-04-03T20:40:02.954029: step 22064, loss 0.103423, acc 0.96875\n",
      "2017-04-03T20:40:03.155481: step 22065, loss 0.0583736, acc 0.984375\n",
      "2017-04-03T20:40:03.355414: step 22066, loss 0.0625987, acc 0.96875\n",
      "2017-04-03T20:40:03.558076: step 22067, loss 0.0346285, acc 0.984375\n",
      "2017-04-03T20:40:03.764380: step 22068, loss 0.196907, acc 0.9375\n",
      "2017-04-03T20:40:04.008381: step 22069, loss 0.0520514, acc 0.984375\n",
      "2017-04-03T20:40:04.214010: step 22070, loss 0.1576, acc 0.9375\n",
      "2017-04-03T20:40:04.420420: step 22071, loss 0.16072, acc 0.921875\n",
      "2017-04-03T20:40:04.660691: step 22072, loss 0.0683115, acc 0.96875\n",
      "2017-04-03T20:40:04.872975: step 22073, loss 0.0485963, acc 1\n",
      "2017-04-03T20:40:05.078243: step 22074, loss 0.0565034, acc 0.96875\n",
      "2017-04-03T20:40:05.281615: step 22075, loss 0.106151, acc 0.96875\n",
      "2017-04-03T20:40:05.483693: step 22076, loss 0.0435236, acc 0.984375\n",
      "2017-04-03T20:40:05.690142: step 22077, loss 0.076676, acc 0.984375\n",
      "2017-04-03T20:40:05.888837: step 22078, loss 0.143044, acc 0.9375\n",
      "2017-04-03T20:40:06.090672: step 22079, loss 0.0608157, acc 0.96875\n",
      "2017-04-03T20:40:06.297109: step 22080, loss 0.121608, acc 0.9375\n",
      "2017-04-03T20:40:06.534062: step 22081, loss 0.153712, acc 0.953125\n",
      "2017-04-03T20:40:06.744486: step 22082, loss 0.0538379, acc 0.984375\n",
      "2017-04-03T20:40:06.945878: step 22083, loss 0.0973279, acc 0.953125\n",
      "2017-04-03T20:40:07.155828: step 22084, loss 0.0283916, acc 1\n",
      "2017-04-03T20:40:07.361600: step 22085, loss 0.0274267, acc 1\n",
      "2017-04-03T20:40:07.560247: step 22086, loss 0.0953817, acc 0.984375\n",
      "2017-04-03T20:40:07.767878: step 22087, loss 0.058425, acc 0.984375\n",
      "2017-04-03T20:40:07.974519: step 22088, loss 0.207393, acc 0.9375\n",
      "2017-04-03T20:40:08.174845: step 22089, loss 0.177302, acc 0.953125\n",
      "2017-04-03T20:40:08.377653: step 22090, loss 0.0375519, acc 0.984375\n",
      "2017-04-03T20:40:08.579526: step 22091, loss 0.101689, acc 0.9375\n",
      "2017-04-03T20:40:08.774895: step 22092, loss 0.0477888, acc 0.984375\n",
      "2017-04-03T20:40:08.981959: step 22093, loss 0.0604088, acc 0.984375\n",
      "2017-04-03T20:40:09.182530: step 22094, loss 0.0726094, acc 0.96875\n",
      "2017-04-03T20:40:09.386037: step 22095, loss 0.0313307, acc 0.984375\n",
      "2017-04-03T20:40:09.596742: step 22096, loss 0.059091, acc 0.984375\n",
      "2017-04-03T20:40:09.796599: step 22097, loss 0.236479, acc 0.9375\n",
      "2017-04-03T20:40:10.004287: step 22098, loss 0.0588277, acc 0.984375\n",
      "2017-04-03T20:40:10.205373: step 22099, loss 0.0870232, acc 0.953125\n",
      "2017-04-03T20:40:10.413456: step 22100, loss 0.0250671, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:40:12.607757: step 22100, loss 8.06994, acc 0.2855\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-22100\n",
      "\n",
      "2017-04-03T20:40:12.969463: step 22101, loss 0.0268023, acc 0.984375\n",
      "2017-04-03T20:40:13.191784: step 22102, loss 0.0395601, acc 0.984375\n",
      "2017-04-03T20:40:13.395838: step 22103, loss 0.055522, acc 0.96875\n",
      "2017-04-03T20:40:13.598966: step 22104, loss 0.0214244, acc 1\n",
      "2017-04-03T20:40:13.800176: step 22105, loss 0.0730828, acc 0.984375\n",
      "2017-04-03T20:40:14.001230: step 22106, loss 0.0876609, acc 0.953125\n",
      "2017-04-03T20:40:14.204271: step 22107, loss 0.0374932, acc 1\n",
      "2017-04-03T20:40:14.403590: step 22108, loss 0.0636436, acc 0.96875\n",
      "2017-04-03T20:40:14.607603: step 22109, loss 0.0840396, acc 0.953125\n",
      "2017-04-03T20:40:14.806205: step 22110, loss 0.059818, acc 0.96875\n",
      "2017-04-03T20:40:15.007270: step 22111, loss 0.144428, acc 0.9375\n",
      "2017-04-03T20:40:15.204097: step 22112, loss 0.0987545, acc 0.96875\n",
      "2017-04-03T20:40:15.406570: step 22113, loss 0.052628, acc 0.984375\n",
      "2017-04-03T20:40:15.615107: step 22114, loss 0.0189053, acc 1\n",
      "2017-04-03T20:40:15.821569: step 22115, loss 0.0614876, acc 0.984375\n",
      "2017-04-03T20:40:16.021597: step 22116, loss 0.0577353, acc 1\n",
      "2017-04-03T20:40:16.219938: step 22117, loss 0.0720361, acc 0.984375\n",
      "2017-04-03T20:40:16.418844: step 22118, loss 0.0603205, acc 0.96875\n",
      "2017-04-03T20:40:16.618814: step 22119, loss 0.0928258, acc 0.984375\n",
      "2017-04-03T20:40:16.816514: step 22120, loss 0.0460882, acc 0.984375\n",
      "2017-04-03T20:40:17.024949: step 22121, loss 0.263911, acc 0.9375\n",
      "2017-04-03T20:40:17.228113: step 22122, loss 0.0581396, acc 0.96875\n",
      "2017-04-03T20:40:17.429066: step 22123, loss 0.0414821, acc 0.984375\n",
      "2017-04-03T20:40:17.621795: step 22124, loss 0.0997322, acc 0.984375\n",
      "2017-04-03T20:40:17.833965: step 22125, loss 0.0145429, acc 1\n",
      "2017-04-03T20:40:18.038745: step 22126, loss 0.065075, acc 1\n",
      "2017-04-03T20:40:18.245861: step 22127, loss 0.0411406, acc 0.984375\n",
      "2017-04-03T20:40:18.444418: step 22128, loss 0.0647036, acc 0.984375\n",
      "2017-04-03T20:40:18.651291: step 22129, loss 0.0302926, acc 1\n",
      "2017-04-03T20:40:18.855702: step 22130, loss 0.106329, acc 0.953125\n",
      "2017-04-03T20:40:19.069772: step 22131, loss 0.042865, acc 0.984375\n",
      "2017-04-03T20:40:19.286432: step 22132, loss 0.0669134, acc 0.96875\n",
      "2017-04-03T20:40:19.504430: step 22133, loss 0.0461588, acc 0.984375\n",
      "2017-04-03T20:40:19.748833: step 22134, loss 0.0603855, acc 1\n",
      "2017-04-03T20:40:19.955785: step 22135, loss 0.137179, acc 0.9375\n",
      "2017-04-03T20:40:20.187170: step 22136, loss 0.0374345, acc 0.984375\n",
      "2017-04-03T20:40:20.388924: step 22137, loss 0.28583, acc 0.9375\n",
      "2017-04-03T20:40:20.588943: step 22138, loss 0.0146814, acc 1\n",
      "2017-04-03T20:40:20.789445: step 22139, loss 0.196485, acc 0.90625\n",
      "2017-04-03T20:40:20.987860: step 22140, loss 0.132979, acc 0.921875\n",
      "2017-04-03T20:40:21.192231: step 22141, loss 0.0195772, acc 1\n",
      "2017-04-03T20:40:21.397252: step 22142, loss 0.211923, acc 0.953125\n",
      "2017-04-03T20:40:21.598527: step 22143, loss 0.0594129, acc 0.984375\n",
      "2017-04-03T20:40:21.800512: step 22144, loss 0.0578548, acc 1\n",
      "2017-04-03T20:40:22.008831: step 22145, loss 0.0534051, acc 0.984375\n",
      "2017-04-03T20:40:22.211859: step 22146, loss 0.045124, acc 0.984375\n",
      "2017-04-03T20:40:22.456935: step 22147, loss 0.0318761, acc 1\n",
      "2017-04-03T20:40:22.665975: step 22148, loss 0.0666055, acc 0.96875\n",
      "2017-04-03T20:40:22.870794: step 22149, loss 0.0314029, acc 1\n",
      "2017-04-03T20:40:23.067479: step 22150, loss 0.115685, acc 0.953125\n",
      "2017-04-03T20:40:23.273641: step 22151, loss 0.240232, acc 0.9375\n",
      "2017-04-03T20:40:23.475642: step 22152, loss 0.103852, acc 0.96875\n",
      "2017-04-03T20:40:23.720864: step 22153, loss 0.0188301, acc 1\n",
      "2017-04-03T20:40:23.968999: step 22154, loss 0.0825571, acc 0.96875\n",
      "2017-04-03T20:40:24.174721: step 22155, loss 0.125416, acc 0.953125\n",
      "2017-04-03T20:40:24.380314: step 22156, loss 0.00661112, acc 1\n",
      "2017-04-03T20:40:24.579726: step 22157, loss 0.204509, acc 0.96875\n",
      "2017-04-03T20:40:24.781322: step 22158, loss 0.107462, acc 0.96875\n",
      "2017-04-03T20:40:24.994199: step 22159, loss 0.0948097, acc 0.984375\n",
      "2017-04-03T20:40:25.209304: step 22160, loss 0.0570569, acc 0.984375\n",
      "2017-04-03T20:40:25.428580: step 22161, loss 0.0322302, acc 1\n",
      "2017-04-03T20:40:25.630746: step 22162, loss 0.119443, acc 0.953125\n",
      "2017-04-03T20:40:25.842446: step 22163, loss 0.0923409, acc 0.984375\n",
      "2017-04-03T20:40:26.043746: step 22164, loss 0.072899, acc 0.984375\n",
      "2017-04-03T20:40:26.240955: step 22165, loss 0.0775839, acc 0.953125\n",
      "2017-04-03T20:40:26.444016: step 22166, loss 0.0837899, acc 0.96875\n",
      "2017-04-03T20:40:26.648235: step 22167, loss 0.223285, acc 0.9375\n",
      "2017-04-03T20:40:26.849492: step 22168, loss 0.0760875, acc 0.96875\n",
      "2017-04-03T20:40:27.058240: step 22169, loss 0.114672, acc 0.96875\n",
      "2017-04-03T20:40:27.257652: step 22170, loss 0.0633449, acc 0.984375\n",
      "2017-04-03T20:40:27.459310: step 22171, loss 0.0445271, acc 0.984375\n",
      "2017-04-03T20:40:27.659714: step 22172, loss 0.0146032, acc 1\n",
      "2017-04-03T20:40:27.860206: step 22173, loss 0.111583, acc 0.96875\n",
      "2017-04-03T20:40:28.059172: step 22174, loss 0.054517, acc 0.96875\n",
      "2017-04-03T20:40:28.266301: step 22175, loss 0.0538661, acc 0.96875\n",
      "2017-04-03T20:40:28.463979: step 22176, loss 0.10219, acc 0.96875\n",
      "2017-04-03T20:40:28.665618: step 22177, loss 0.0598394, acc 0.96875\n",
      "2017-04-03T20:40:28.866693: step 22178, loss 0.0781385, acc 0.984375\n",
      "2017-04-03T20:40:29.076878: step 22179, loss 0.0294344, acc 1\n",
      "2017-04-03T20:40:29.282562: step 22180, loss 0.0557865, acc 0.96875\n",
      "2017-04-03T20:40:29.493910: step 22181, loss 0.013881, acc 1\n",
      "2017-04-03T20:40:29.713217: step 22182, loss 0.0604096, acc 0.984375\n",
      "2017-04-03T20:40:29.919769: step 22183, loss 0.0763962, acc 0.984375\n",
      "2017-04-03T20:40:30.121878: step 22184, loss 0.0572562, acc 0.984375\n",
      "2017-04-03T20:40:30.320465: step 22185, loss 0.0405818, acc 0.984375\n",
      "2017-04-03T20:40:30.521779: step 22186, loss 0.123811, acc 0.9375\n",
      "2017-04-03T20:40:30.764634: step 22187, loss 0.0175083, acc 1\n",
      "2017-04-03T20:40:31.004920: step 22188, loss 0.125454, acc 0.9375\n",
      "2017-04-03T20:40:31.226868: step 22189, loss 0.102321, acc 0.953125\n",
      "2017-04-03T20:40:31.427133: step 22190, loss 0.264679, acc 0.9375\n",
      "2017-04-03T20:40:31.636352: step 22191, loss 0.169694, acc 0.9375\n",
      "2017-04-03T20:40:31.833145: step 22192, loss 0.0970521, acc 0.96875\n",
      "2017-04-03T20:40:32.035827: step 22193, loss 0.140601, acc 0.953125\n",
      "2017-04-03T20:40:32.235940: step 22194, loss 0.120296, acc 0.96875\n",
      "2017-04-03T20:40:32.438165: step 22195, loss 0.0738005, acc 0.984375\n",
      "2017-04-03T20:40:32.640333: step 22196, loss 0.0469429, acc 0.984375\n",
      "2017-04-03T20:40:32.885015: step 22197, loss 0.0381434, acc 0.984375\n",
      "2017-04-03T20:40:33.087664: step 22198, loss 0.180821, acc 0.96875\n",
      "2017-04-03T20:40:33.289503: step 22199, loss 0.0663813, acc 0.984375\n",
      "2017-04-03T20:40:33.492117: step 22200, loss 0.0408912, acc 1\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:40:35.629546: step 22200, loss 8.08211, acc 0.281\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-22200\n",
      "\n",
      "2017-04-03T20:40:35.962249: step 22201, loss 0.0421442, acc 0.984375\n",
      "2017-04-03T20:40:36.164489: step 22202, loss 0.0533417, acc 0.984375\n",
      "2017-04-03T20:40:36.364391: step 22203, loss 0.103062, acc 0.96875\n",
      "2017-04-03T20:40:36.567485: step 22204, loss 0.0899545, acc 0.96875\n",
      "2017-04-03T20:40:36.774319: step 22205, loss 0.0486098, acc 0.984375\n",
      "2017-04-03T20:40:36.992832: step 22206, loss 0.194994, acc 0.9375\n",
      "2017-04-03T20:40:37.203120: step 22207, loss 0.0487279, acc 1\n",
      "2017-04-03T20:40:37.399709: step 22208, loss 0.0399987, acc 0.984375\n",
      "2017-04-03T20:40:37.603419: step 22209, loss 0.0768538, acc 0.96875\n",
      "2017-04-03T20:40:37.809114: step 22210, loss 0.0780484, acc 0.953125\n",
      "2017-04-03T20:40:38.008663: step 22211, loss 0.0291921, acc 1\n",
      "2017-04-03T20:40:38.211094: step 22212, loss 0.208605, acc 0.90625\n",
      "2017-04-03T20:40:38.412490: step 22213, loss 0.0703353, acc 0.984375\n",
      "2017-04-03T20:40:38.656552: step 22214, loss 0.087896, acc 0.96875\n",
      "2017-04-03T20:40:38.851439: step 22215, loss 0.184214, acc 0.9375\n",
      "2017-04-03T20:40:39.059591: step 22216, loss 0.07374, acc 0.96875\n",
      "2017-04-03T20:40:39.257303: step 22217, loss 0.084673, acc 0.96875\n",
      "2017-04-03T20:40:39.464339: step 22218, loss 0.164681, acc 0.9375\n",
      "2017-04-03T20:40:39.666636: step 22219, loss 0.0437067, acc 0.984375\n",
      "2017-04-03T20:40:39.870137: step 22220, loss 0.102735, acc 0.953125\n",
      "2017-04-03T20:40:40.070132: step 22221, loss 0.131424, acc 0.96875\n",
      "2017-04-03T20:40:40.317128: step 22222, loss 0.154954, acc 0.9375\n",
      "2017-04-03T20:40:40.561311: step 22223, loss 0.0479996, acc 1\n",
      "2017-04-03T20:40:40.766279: step 22224, loss 0.0183937, acc 1\n",
      "2017-04-03T20:40:40.967550: step 22225, loss 0.100216, acc 0.96875\n",
      "2017-04-03T20:40:41.166750: step 22226, loss 0.109047, acc 0.9375\n",
      "2017-04-03T20:40:41.409007: step 22227, loss 0.00388151, acc 1\n",
      "2017-04-03T20:40:41.615115: step 22228, loss 0.164023, acc 0.953125\n",
      "2017-04-03T20:40:41.814651: step 22229, loss 0.0782278, acc 0.953125\n",
      "2017-04-03T20:40:42.017193: step 22230, loss 0.0286007, acc 1\n",
      "2017-04-03T20:40:42.222215: step 22231, loss 0.0476675, acc 1\n",
      "2017-04-03T20:40:42.424164: step 22232, loss 0.0449548, acc 0.984375\n",
      "2017-04-03T20:40:42.621629: step 22233, loss 0.0499175, acc 0.96875\n",
      "2017-04-03T20:40:42.823245: step 22234, loss 0.106404, acc 0.96875\n",
      "2017-04-03T20:40:43.033651: step 22235, loss 0.123139, acc 0.96875\n",
      "2017-04-03T20:40:43.235639: step 22236, loss 0.0788404, acc 0.96875\n",
      "2017-04-03T20:40:43.445805: step 22237, loss 0.0521536, acc 0.984375\n",
      "2017-04-03T20:40:43.650773: step 22238, loss 0.0269816, acc 1\n",
      "2017-04-03T20:40:43.856201: step 22239, loss 0.07036, acc 0.953125\n",
      "2017-04-03T20:40:44.057418: step 22240, loss 0.156741, acc 0.984375\n",
      "2017-04-03T20:40:44.263822: step 22241, loss 0.267165, acc 0.9375\n",
      "2017-04-03T20:40:44.467373: step 22242, loss 0.0585137, acc 0.984375\n",
      "2017-04-03T20:40:44.669461: step 22243, loss 0.0680704, acc 0.984375\n",
      "2017-04-03T20:40:44.871846: step 22244, loss 0.124198, acc 0.96875\n",
      "2017-04-03T20:40:45.075285: step 22245, loss 0.0673081, acc 0.96875\n",
      "2017-04-03T20:40:45.280879: step 22246, loss 0.0675985, acc 0.96875\n",
      "2017-04-03T20:40:45.487734: step 22247, loss 0.0436008, acc 0.984375\n",
      "2017-04-03T20:40:45.691762: step 22248, loss 0.141122, acc 0.984375\n",
      "2017-04-03T20:40:45.892228: step 22249, loss 0.0650051, acc 0.96875\n",
      "2017-04-03T20:40:46.092603: step 22250, loss 0.0641177, acc 0.984375\n",
      "2017-04-03T20:40:46.296167: step 22251, loss 0.0338297, acc 1\n",
      "2017-04-03T20:40:46.502901: step 22252, loss 0.0304183, acc 0.984375\n",
      "2017-04-03T20:40:46.709952: step 22253, loss 0.0426082, acc 0.984375\n",
      "2017-04-03T20:40:46.911507: step 22254, loss 0.0247666, acc 1\n",
      "2017-04-03T20:40:47.116594: step 22255, loss 0.0684632, acc 0.96875\n",
      "2017-04-03T20:40:47.316423: step 22256, loss 0.18152, acc 0.96875\n",
      "2017-04-03T20:40:47.515990: step 22257, loss 0.00297223, acc 1\n",
      "2017-04-03T20:40:47.726077: step 22258, loss 0.0915221, acc 0.96875\n",
      "2017-04-03T20:40:47.935158: step 22259, loss 0.0488076, acc 0.984375\n",
      "2017-04-03T20:40:48.132917: step 22260, loss 0.0989866, acc 0.953125\n",
      "2017-04-03T20:40:48.334639: step 22261, loss 0.199134, acc 0.984375\n",
      "2017-04-03T20:40:48.537373: step 22262, loss 0.146783, acc 0.9375\n",
      "2017-04-03T20:40:48.739470: step 22263, loss 0.100178, acc 0.96875\n",
      "2017-04-03T20:40:48.942903: step 22264, loss 0.0736645, acc 0.984375\n",
      "2017-04-03T20:40:49.146653: step 22265, loss 0.111312, acc 0.96875\n",
      "2017-04-03T20:40:49.352687: step 22266, loss 0.0316254, acc 1\n",
      "2017-04-03T20:40:49.553626: step 22267, loss 0.0493759, acc 0.984375\n",
      "2017-04-03T20:40:49.763767: step 22268, loss 0.104889, acc 0.984375\n",
      "2017-04-03T20:40:49.967359: step 22269, loss 0.101009, acc 0.96875\n",
      "2017-04-03T20:40:50.208688: step 22270, loss 0.0592592, acc 0.96875\n",
      "2017-04-03T20:40:50.413521: step 22271, loss 0.15775, acc 0.953125\n",
      "2017-04-03T20:40:50.615468: step 22272, loss 0.0753029, acc 0.96875\n",
      "2017-04-03T20:40:50.814694: step 22273, loss 0.0409802, acc 1\n",
      "2017-04-03T20:40:51.016868: step 22274, loss 0.19116, acc 0.953125\n",
      "2017-04-03T20:40:51.221544: step 22275, loss 0.0361108, acc 1\n",
      "2017-04-03T20:40:51.424664: step 22276, loss 0.0979279, acc 0.984375\n",
      "2017-04-03T20:40:51.631522: step 22277, loss 0.0933547, acc 0.9375\n",
      "2017-04-03T20:40:51.834104: step 22278, loss 0.119176, acc 0.953125\n",
      "2017-04-03T20:40:52.039133: step 22279, loss 0.066396, acc 0.984375\n",
      "2017-04-03T20:40:52.241147: step 22280, loss 0.219096, acc 0.9375\n",
      "2017-04-03T20:40:52.443542: step 22281, loss 0.154381, acc 0.96875\n",
      "2017-04-03T20:40:52.643286: step 22282, loss 0.0890828, acc 0.96875\n",
      "2017-04-03T20:40:52.845099: step 22283, loss 0.0119462, acc 1\n",
      "2017-04-03T20:40:53.086784: step 22284, loss 0.0537669, acc 1\n",
      "2017-04-03T20:40:53.300483: step 22285, loss 0.114924, acc 0.984375\n",
      "2017-04-03T20:40:53.504453: step 22286, loss 0.0914204, acc 0.96875\n",
      "2017-04-03T20:40:53.707489: step 22287, loss 0.0749847, acc 0.984375\n",
      "2017-04-03T20:40:53.905303: step 22288, loss 0.107701, acc 0.96875\n",
      "2017-04-03T20:40:54.148502: step 22289, loss 0.026181, acc 1\n",
      "2017-04-03T20:40:54.390022: step 22290, loss 0.0444675, acc 0.984375\n",
      "2017-04-03T20:40:54.594949: step 22291, loss 0.0960216, acc 0.953125\n",
      "2017-04-03T20:40:54.810274: step 22292, loss 0.0633599, acc 0.96875\n",
      "2017-04-03T20:40:55.016256: step 22293, loss 0.114919, acc 0.953125\n",
      "2017-04-03T20:40:55.214807: step 22294, loss 0.0731564, acc 0.984375\n",
      "2017-04-03T20:40:55.412496: step 22295, loss 0.0458546, acc 0.984375\n",
      "2017-04-03T20:40:55.611831: step 22296, loss 0.034025, acc 1\n",
      "2017-04-03T20:40:55.812835: step 22297, loss 0.0217237, acc 0.984375\n",
      "2017-04-03T20:40:56.018612: step 22298, loss 0.0749827, acc 0.96875\n",
      "2017-04-03T20:40:56.218892: step 22299, loss 0.0825468, acc 0.96875\n",
      "2017-04-03T20:40:56.423767: step 22300, loss 0.156622, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:40:58.543246: step 22300, loss 8.12023, acc 0.286\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-22300\n",
      "\n",
      "2017-04-03T20:40:58.888777: step 22301, loss 0.206563, acc 0.96875\n",
      "2017-04-03T20:40:59.090657: step 22302, loss 0.120821, acc 0.953125\n",
      "2017-04-03T20:40:59.337073: step 22303, loss 0.200167, acc 0.953125\n",
      "2017-04-03T20:40:59.545517: step 22304, loss 0.0293698, acc 0.984375\n",
      "2017-04-03T20:40:59.747505: step 22305, loss 0.069445, acc 0.953125\n",
      "2017-04-03T20:40:59.952096: step 22306, loss 0.125466, acc 0.96875\n",
      "2017-04-03T20:41:00.167799: step 22307, loss 0.167909, acc 0.953125\n",
      "2017-04-03T20:41:00.368906: step 22308, loss 0.137166, acc 0.96875\n",
      "2017-04-03T20:41:00.572437: step 22309, loss 0.0154473, acc 1\n",
      "2017-04-03T20:41:00.778136: step 22310, loss 0.102462, acc 0.96875\n",
      "2017-04-03T20:41:00.978653: step 22311, loss 0.108444, acc 0.9375\n",
      "2017-04-03T20:41:01.182272: step 22312, loss 0.160161, acc 0.96875\n",
      "2017-04-03T20:41:01.382432: step 22313, loss 0.0353036, acc 0.984375\n",
      "2017-04-03T20:41:01.583085: step 22314, loss 0.118044, acc 0.984375\n",
      "2017-04-03T20:41:01.786280: step 22315, loss 0.0638684, acc 0.96875\n",
      "2017-04-03T20:41:01.987053: step 22316, loss 0.0936181, acc 0.984375\n",
      "2017-04-03T20:41:02.192082: step 22317, loss 0.0602029, acc 0.984375\n",
      "2017-04-03T20:41:02.400165: step 22318, loss 0.0678269, acc 0.96875\n",
      "2017-04-03T20:41:02.605687: step 22319, loss 0.10161, acc 0.984375\n",
      "2017-04-03T20:41:02.807766: step 22320, loss 0.17175, acc 0.9375\n",
      "2017-04-03T20:41:03.016134: step 22321, loss 0.0479644, acc 0.984375\n",
      "2017-04-03T20:41:03.256546: step 22322, loss 0.201806, acc 0.953125\n",
      "2017-04-03T20:41:03.460751: step 22323, loss 0.065586, acc 0.984375\n",
      "2017-04-03T20:41:03.663306: step 22324, loss 0.079789, acc 0.96875\n",
      "2017-04-03T20:41:03.864626: step 22325, loss 0.206847, acc 0.9375\n",
      "2017-04-03T20:41:04.072659: step 22326, loss 0.164454, acc 0.953125\n",
      "2017-04-03T20:41:04.275158: step 22327, loss 0.0232427, acc 1\n",
      "2017-04-03T20:41:04.480974: step 22328, loss 0.110425, acc 0.96875\n",
      "2017-04-03T20:41:04.699175: step 22329, loss 0.0400375, acc 0.984375\n",
      "2017-04-03T20:41:04.916359: step 22330, loss 0.0960208, acc 0.96875\n",
      "2017-04-03T20:41:05.132148: step 22331, loss 0.0499677, acc 0.984375\n",
      "2017-04-03T20:41:05.354687: step 22332, loss 0.0264416, acc 0.984375\n",
      "2017-04-03T20:41:05.569225: step 22333, loss 0.0327391, acc 0.984375\n",
      "2017-04-03T20:41:05.772285: step 22334, loss 0.114283, acc 0.96875\n",
      "2017-04-03T20:41:05.987368: step 22335, loss 0.080437, acc 0.96875\n",
      "2017-04-03T20:41:06.228568: step 22336, loss 0.13795, acc 0.96875\n",
      "2017-04-03T20:41:06.428717: step 22337, loss 0.125025, acc 0.96875\n",
      "2017-04-03T20:41:06.870274: step 22338, loss 0.107048, acc 0.96875\n",
      "2017-04-03T20:41:07.069268: step 22339, loss 0.0695485, acc 0.96875\n",
      "2017-04-03T20:41:07.272538: step 22340, loss 0.271933, acc 0.921875\n",
      "2017-04-03T20:41:07.481818: step 22341, loss 0.187671, acc 0.9375\n",
      "2017-04-03T20:41:07.692773: step 22342, loss 0.153785, acc 0.953125\n",
      "2017-04-03T20:41:07.895948: step 22343, loss 0.0621281, acc 0.984375\n",
      "2017-04-03T20:41:08.147138: step 22344, loss 0.061686, acc 0.984375\n",
      "2017-04-03T20:41:08.402288: step 22345, loss 0.129978, acc 0.96875\n",
      "2017-04-03T20:41:08.627132: step 22346, loss 0.0717741, acc 0.96875\n",
      "2017-04-03T20:41:08.851456: step 22347, loss 0.0232844, acc 0.984375\n",
      "2017-04-03T20:41:09.062060: step 22348, loss 0.0469196, acc 0.984375\n",
      "2017-04-03T20:41:09.309473: step 22349, loss 0.157239, acc 0.921875\n",
      "2017-04-03T20:41:09.519962: step 22350, loss 0.0431046, acc 0.984375\n",
      "2017-04-03T20:41:09.734933: step 22351, loss 0.00697608, acc 1\n",
      "2017-04-03T20:41:09.981910: step 22352, loss 0.129086, acc 0.9375\n",
      "2017-04-03T20:41:10.197141: step 22353, loss 0.135297, acc 0.984375\n",
      "2017-04-03T20:41:10.410158: step 22354, loss 0.147766, acc 0.96875\n",
      "2017-04-03T20:41:10.613775: step 22355, loss 0.0567801, acc 0.96875\n",
      "2017-04-03T20:41:10.815703: step 22356, loss 0.1338, acc 0.9375\n",
      "2017-04-03T20:41:11.027045: step 22357, loss 0.0648169, acc 0.96875\n",
      "2017-04-03T20:41:11.231433: step 22358, loss 0.112685, acc 0.953125\n",
      "2017-04-03T20:41:11.432081: step 22359, loss 0.0238238, acc 1\n",
      "2017-04-03T20:41:11.636358: step 22360, loss 0.0752329, acc 0.984375\n",
      "2017-04-03T20:41:11.839016: step 22361, loss 0.0781113, acc 0.984375\n",
      "2017-04-03T20:41:12.053343: step 22362, loss 0.0338201, acc 0.984375\n",
      "2017-04-03T20:41:12.256130: step 22363, loss 0.0988369, acc 0.9375\n",
      "2017-04-03T20:41:12.458526: step 22364, loss 0.0912032, acc 0.96875\n",
      "2017-04-03T20:41:12.660555: step 22365, loss 0.0750123, acc 0.984375\n",
      "2017-04-03T20:41:12.871538: step 22366, loss 0.156665, acc 0.953125\n",
      "2017-04-03T20:41:13.080944: step 22367, loss 0.0940409, acc 0.953125\n",
      "2017-04-03T20:41:13.317703: step 22368, loss 0.140511, acc 0.984375\n",
      "2017-04-03T20:41:13.546653: step 22369, loss 0.110636, acc 0.96875\n",
      "2017-04-03T20:41:13.746880: step 22370, loss 0.0926199, acc 0.984375\n",
      "2017-04-03T20:41:13.950227: step 22371, loss 0.0389839, acc 0.984375\n",
      "2017-04-03T20:41:14.150427: step 22372, loss 0.107765, acc 0.96875\n",
      "2017-04-03T20:41:14.352094: step 22373, loss 0.0536443, acc 1\n",
      "2017-04-03T20:41:14.555244: step 22374, loss 0.0334905, acc 1\n",
      "2017-04-03T20:41:14.767206: step 22375, loss 0.172049, acc 0.96875\n",
      "2017-04-03T20:41:14.975882: step 22376, loss 0.0641464, acc 0.984375\n",
      "2017-04-03T20:41:15.188941: step 22377, loss 0.0695977, acc 0.984375\n",
      "2017-04-03T20:41:15.390752: step 22378, loss 0.0326014, acc 0.96875\n",
      "2017-04-03T20:41:15.593278: step 22379, loss 0.0262652, acc 1\n",
      "2017-04-03T20:41:15.798327: step 22380, loss 0.0728257, acc 0.96875\n",
      "2017-04-03T20:41:16.000095: step 22381, loss 0.0813113, acc 0.984375\n",
      "2017-04-03T20:41:16.204461: step 22382, loss 0.0359292, acc 0.984375\n",
      "2017-04-03T20:41:16.422612: step 22383, loss 0.0913706, acc 0.953125\n",
      "2017-04-03T20:41:16.626555: step 22384, loss 0.110761, acc 0.9375\n",
      "2017-04-03T20:41:16.873765: step 22385, loss 0.0166149, acc 1\n",
      "2017-04-03T20:41:17.078956: step 22386, loss 0.179348, acc 0.953125\n",
      "2017-04-03T20:41:17.280910: step 22387, loss 0.0988237, acc 0.953125\n",
      "2017-04-03T20:41:17.476555: step 22388, loss 0.117092, acc 0.984375\n",
      "2017-04-03T20:41:17.680294: step 22389, loss 0.0777464, acc 0.96875\n",
      "2017-04-03T20:41:17.881291: step 22390, loss 0.166004, acc 0.953125\n",
      "2017-04-03T20:41:18.091978: step 22391, loss 0.135519, acc 0.953125\n",
      "2017-04-03T20:41:18.291939: step 22392, loss 0.167635, acc 0.953125\n",
      "2017-04-03T20:41:18.513684: step 22393, loss 0.0167781, acc 1\n",
      "2017-04-03T20:41:18.720282: step 22394, loss 0.0954737, acc 0.953125\n",
      "2017-04-03T20:41:18.916864: step 22395, loss 0.0500484, acc 0.984375\n",
      "2017-04-03T20:41:19.118005: step 22396, loss 0.074442, acc 0.96875\n",
      "2017-04-03T20:41:19.320552: step 22397, loss 0.131505, acc 0.96875\n",
      "2017-04-03T20:41:19.525012: step 22398, loss 0.0205332, acc 1\n",
      "2017-04-03T20:41:19.730189: step 22399, loss 0.153992, acc 0.96875\n",
      "2017-04-03T20:41:19.936616: step 22400, loss 0.141359, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:41:22.080507: step 22400, loss 8.1948, acc 0.28375\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-22400\n",
      "\n",
      "2017-04-03T20:41:22.425775: step 22401, loss 0.232345, acc 0.953125\n",
      "2017-04-03T20:41:22.626956: step 22402, loss 0.0862942, acc 0.984375\n",
      "2017-04-03T20:41:22.829436: step 22403, loss 0.0777971, acc 0.96875\n",
      "2017-04-03T20:41:23.036759: step 22404, loss 0.12621, acc 0.921875\n",
      "2017-04-03T20:41:23.240000: step 22405, loss 0.127465, acc 0.9375\n",
      "2017-04-03T20:41:23.442567: step 22406, loss 0.306179, acc 0.953125\n",
      "2017-04-03T20:41:23.683547: step 22407, loss 0.0580436, acc 0.984375\n",
      "2017-04-03T20:41:23.897397: step 22408, loss 0.0698993, acc 0.96875\n",
      "2017-04-03T20:41:24.105864: step 22409, loss 0.196687, acc 0.96875\n",
      "2017-04-03T20:41:24.313479: step 22410, loss 0.0936146, acc 0.984375\n",
      "2017-04-03T20:41:24.514848: step 22411, loss 0.189903, acc 0.96875\n",
      "2017-04-03T20:41:24.718529: step 22412, loss 0.108378, acc 0.953125\n",
      "2017-04-03T20:41:24.920268: step 22413, loss 0.0693467, acc 0.984375\n",
      "2017-04-03T20:41:25.124442: step 22414, loss 0.0879361, acc 0.96875\n",
      "2017-04-03T20:41:25.328044: step 22415, loss 0.171192, acc 0.953125\n",
      "2017-04-03T20:41:25.529782: step 22416, loss 0.0733817, acc 0.984375\n",
      "2017-04-03T20:41:25.731268: step 22417, loss 0.199853, acc 0.9375\n",
      "2017-04-03T20:41:25.940792: step 22418, loss 0.0796898, acc 0.984375\n",
      "2017-04-03T20:41:26.149139: step 22419, loss 0.0341759, acc 0.984375\n",
      "2017-04-03T20:41:26.397224: step 22420, loss 0.615265, acc 0.9375\n",
      "2017-04-03T20:41:26.599920: step 22421, loss 0.0548461, acc 0.96875\n",
      "2017-04-03T20:41:26.853921: step 22422, loss 0.0310479, acc 1\n",
      "2017-04-03T20:41:27.053964: step 22423, loss 0.0142354, acc 1\n",
      "2017-04-03T20:41:27.260493: step 22424, loss 0.180124, acc 0.90625\n",
      "2017-04-03T20:41:27.458437: step 22425, loss 0.0609848, acc 0.953125\n",
      "2017-04-03T20:41:27.665849: step 22426, loss 0.0603194, acc 0.984375\n",
      "2017-04-03T20:41:27.871169: step 22427, loss 0.0738923, acc 0.96875\n",
      "2017-04-03T20:41:28.111185: step 22428, loss 0.276542, acc 0.96875\n",
      "2017-04-03T20:41:28.313796: step 22429, loss 0.0416829, acc 1\n",
      "2017-04-03T20:41:28.527046: step 22430, loss 0.208934, acc 0.96875\n",
      "2017-04-03T20:41:28.735251: step 22431, loss 0.193338, acc 0.953125\n",
      "2017-04-03T20:41:28.945882: step 22432, loss 0.0892569, acc 0.96875\n",
      "2017-04-03T20:41:29.162189: step 22433, loss 0.257938, acc 0.890625\n",
      "2017-04-03T20:41:29.379237: step 22434, loss 0.0914412, acc 0.96875\n",
      "2017-04-03T20:41:29.628587: step 22435, loss 0.0972919, acc 0.984375\n",
      "2017-04-03T20:41:29.833043: step 22436, loss 0.0606093, acc 0.984375\n",
      "2017-04-03T20:41:30.037462: step 22437, loss 0.341846, acc 0.96875\n",
      "2017-04-03T20:41:30.240871: step 22438, loss 0.189421, acc 0.953125\n",
      "2017-04-03T20:41:30.444218: step 22439, loss 0.0720616, acc 0.953125\n",
      "2017-04-03T20:41:30.642153: step 22440, loss 0.0860702, acc 0.96875\n",
      "2017-04-03T20:41:30.852232: step 22441, loss 0.0280443, acc 0.984375\n",
      "2017-04-03T20:41:31.059064: step 22442, loss 0.0386238, acc 1\n",
      "2017-04-03T20:41:31.300461: step 22443, loss 0.285946, acc 0.953125\n",
      "2017-04-03T20:41:31.513610: step 22444, loss 0.0278843, acc 0.984375\n",
      "2017-04-03T20:41:31.721363: step 22445, loss 0.108116, acc 0.953125\n",
      "2017-04-03T20:41:31.930411: step 22446, loss 0.0847948, acc 0.984375\n",
      "2017-04-03T20:41:32.150359: step 22447, loss 0.0641325, acc 0.96875\n",
      "2017-04-03T20:41:32.364974: step 22448, loss 0.103658, acc 0.953125\n",
      "2017-04-03T20:41:32.584978: step 22449, loss 0.123644, acc 0.984375\n",
      "2017-04-03T20:41:32.783398: step 22450, loss 0.0882354, acc 0.96875\n",
      "2017-04-03T20:41:33.026482: step 22451, loss 0.188005, acc 0.953125\n",
      "2017-04-03T20:41:33.236428: step 22452, loss 0.0819718, acc 0.96875\n",
      "2017-04-03T20:41:33.446258: step 22453, loss 0.0388203, acc 0.984375\n",
      "2017-04-03T20:41:33.649869: step 22454, loss 0.164053, acc 0.96875\n",
      "2017-04-03T20:41:33.893776: step 22455, loss 0.0709112, acc 0.984375\n",
      "2017-04-03T20:41:34.095445: step 22456, loss 0.141178, acc 0.953125\n",
      "2017-04-03T20:41:34.295982: step 22457, loss 0.126665, acc 0.953125\n",
      "2017-04-03T20:41:34.496538: step 22458, loss 0.237321, acc 0.90625\n",
      "2017-04-03T20:41:34.688770: step 22459, loss 0.145801, acc 0.953125\n",
      "2017-04-03T20:41:34.888762: step 22460, loss 0.239327, acc 0.921875\n",
      "2017-04-03T20:41:35.089247: step 22461, loss 0.154415, acc 0.921875\n",
      "2017-04-03T20:41:35.297913: step 22462, loss 0.104892, acc 0.96875\n",
      "2017-04-03T20:41:35.502855: step 22463, loss 0.120731, acc 0.96875\n",
      "2017-04-03T20:41:35.713639: step 22464, loss 0.150025, acc 0.96875\n",
      "2017-04-03T20:41:35.913593: step 22465, loss 0.0946371, acc 0.96875\n",
      "2017-04-03T20:41:36.115793: step 22466, loss 0.00684565, acc 1\n",
      "2017-04-03T20:41:36.323283: step 22467, loss 0.16749, acc 0.9375\n",
      "2017-04-03T20:41:36.524553: step 22468, loss 0.180451, acc 0.90625\n",
      "2017-04-03T20:41:36.727659: step 22469, loss 0.128525, acc 0.9375\n",
      "2017-04-03T20:41:36.930458: step 22470, loss 0.0691772, acc 0.96875\n",
      "2017-04-03T20:41:37.176403: step 22471, loss 0.061548, acc 0.984375\n",
      "2017-04-03T20:41:37.383701: step 22472, loss 0.244326, acc 0.9375\n",
      "2017-04-03T20:41:37.585969: step 22473, loss 0.0916939, acc 0.953125\n",
      "2017-04-03T20:41:37.826208: step 22474, loss 0.112968, acc 0.96875\n",
      "2017-04-03T20:41:38.031693: step 22475, loss 0.0925473, acc 0.96875\n",
      "2017-04-03T20:41:38.249030: step 22476, loss 0.321367, acc 0.9375\n",
      "2017-04-03T20:41:38.458966: step 22477, loss 0.0222119, acc 1\n",
      "2017-04-03T20:41:38.659117: step 22478, loss 0.0497087, acc 0.984375\n",
      "2017-04-03T20:41:38.869945: step 22479, loss 0.191532, acc 0.921875\n",
      "2017-04-03T20:41:39.088786: step 22480, loss 0.0218872, acc 1\n",
      "2017-04-03T20:41:39.293972: step 22481, loss 0.0607122, acc 0.984375\n",
      "2017-04-03T20:41:39.498919: step 22482, loss 0.0844427, acc 0.984375\n",
      "2017-04-03T20:41:39.698345: step 22483, loss 0.0859035, acc 0.984375\n",
      "2017-04-03T20:41:39.901028: step 22484, loss 0.0917007, acc 0.984375\n",
      "2017-04-03T20:41:40.113517: step 22485, loss 0.0151771, acc 1\n",
      "2017-04-03T20:41:40.319540: step 22486, loss 0.0395252, acc 1\n",
      "2017-04-03T20:41:40.521629: step 22487, loss 0.25546, acc 0.953125\n",
      "2017-04-03T20:41:40.724078: step 22488, loss 0.0834281, acc 0.96875\n",
      "2017-04-03T20:41:40.923553: step 22489, loss 0.0467372, acc 0.984375\n",
      "2017-04-03T20:41:41.125978: step 22490, loss 0.0393254, acc 0.984375\n",
      "2017-04-03T20:41:41.329045: step 22491, loss 0.0355206, acc 0.984375\n",
      "2017-04-03T20:41:41.534252: step 22492, loss 0.134787, acc 0.96875\n",
      "2017-04-03T20:41:41.739149: step 22493, loss 0.0699402, acc 0.984375\n",
      "2017-04-03T20:41:41.941904: step 22494, loss 0.0594169, acc 0.96875\n",
      "2017-04-03T20:41:42.146030: step 22495, loss 0.0348018, acc 1\n",
      "2017-04-03T20:41:42.351424: step 22496, loss 0.161348, acc 0.953125\n",
      "2017-04-03T20:41:42.551928: step 22497, loss 0.0595746, acc 0.984375\n",
      "2017-04-03T20:41:42.754030: step 22498, loss 0.0818507, acc 0.984375\n",
      "2017-04-03T20:41:42.956568: step 22499, loss 0.0198798, acc 1\n",
      "2017-04-03T20:41:43.156339: step 22500, loss 0.0430356, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:41:45.282620: step 22500, loss 8.12878, acc 0.28075\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-22500\n",
      "\n",
      "2017-04-03T20:41:45.620082: step 22501, loss 0.0713764, acc 0.953125\n",
      "2017-04-03T20:41:45.821335: step 22502, loss 0.102044, acc 0.96875\n",
      "2017-04-03T20:41:46.043736: step 22503, loss 0.0546429, acc 1\n",
      "2017-04-03T20:41:46.263863: step 22504, loss 0.150936, acc 0.984375\n",
      "2017-04-03T20:41:46.528284: step 22505, loss 0.0601713, acc 0.984375\n",
      "2017-04-03T20:41:46.743303: step 22506, loss 0.0642491, acc 0.96875\n",
      "2017-04-03T20:41:46.984642: step 22507, loss 0.00999603, acc 1\n",
      "2017-04-03T20:41:47.192881: step 22508, loss 0.0973755, acc 0.953125\n",
      "2017-04-03T20:41:47.403709: step 22509, loss 0.0408998, acc 0.984375\n",
      "2017-04-03T20:41:47.617753: step 22510, loss 0.0571825, acc 0.96875\n",
      "2017-04-03T20:41:47.840983: step 22511, loss 0.0962907, acc 0.96875\n",
      "2017-04-03T20:41:48.059714: step 22512, loss 0.104808, acc 0.984375\n",
      "2017-04-03T20:41:48.262400: step 22513, loss 0.0904712, acc 0.96875\n",
      "2017-04-03T20:41:48.506630: step 22514, loss 0.165982, acc 0.9375\n",
      "2017-04-03T20:41:48.713798: step 22515, loss 0.167834, acc 0.9375\n",
      "2017-04-03T20:41:48.930121: step 22516, loss 0.115956, acc 0.953125\n",
      "2017-04-03T20:41:49.130641: step 22517, loss 0.169194, acc 0.953125\n",
      "2017-04-03T20:41:49.333279: step 22518, loss 0.0762583, acc 0.984375\n",
      "2017-04-03T20:41:49.530674: step 22519, loss 0.08752, acc 0.96875\n",
      "2017-04-03T20:41:49.674599: step 22520, loss 0.0830386, acc 0.9375\n",
      "2017-04-03T20:41:49.883291: step 22521, loss 0.0530194, acc 0.96875\n",
      "2017-04-03T20:41:50.087642: step 22522, loss 0.226516, acc 0.953125\n",
      "2017-04-03T20:41:50.286080: step 22523, loss 0.0431879, acc 0.984375\n",
      "2017-04-03T20:41:50.534696: step 22524, loss 0.0304175, acc 1\n",
      "2017-04-03T20:41:50.736473: step 22525, loss 0.0404731, acc 1\n",
      "2017-04-03T20:41:50.940537: step 22526, loss 0.0456998, acc 1\n",
      "2017-04-03T20:41:51.139197: step 22527, loss 0.10183, acc 0.96875\n",
      "2017-04-03T20:41:51.341331: step 22528, loss 0.0697753, acc 0.984375\n",
      "2017-04-03T20:41:51.555760: step 22529, loss 0.147509, acc 0.953125\n",
      "2017-04-03T20:41:51.759772: step 22530, loss 0.0423547, acc 1\n",
      "2017-04-03T20:41:51.973031: step 22531, loss 0.181458, acc 0.96875\n",
      "2017-04-03T20:41:52.216680: step 22532, loss 0.0620813, acc 0.96875\n",
      "2017-04-03T20:41:52.420312: step 22533, loss 0.0456753, acc 0.96875\n",
      "2017-04-03T20:41:52.626906: step 22534, loss 0.0189126, acc 1\n",
      "2017-04-03T20:41:52.825493: step 22535, loss 0.0346247, acc 1\n",
      "2017-04-03T20:41:53.032128: step 22536, loss 0.0479356, acc 0.984375\n",
      "2017-04-03T20:41:53.231860: step 22537, loss 0.0328483, acc 0.984375\n",
      "2017-04-03T20:41:53.476824: step 22538, loss 0.101854, acc 0.96875\n",
      "2017-04-03T20:41:53.716756: step 22539, loss 0.0445982, acc 0.96875\n",
      "2017-04-03T20:41:53.920546: step 22540, loss 0.0642389, acc 0.984375\n",
      "2017-04-03T20:41:54.120953: step 22541, loss 0.181308, acc 0.96875\n",
      "2017-04-03T20:41:54.322351: step 22542, loss 0.0291462, acc 1\n",
      "2017-04-03T20:41:54.533823: step 22543, loss 0.148438, acc 0.953125\n",
      "2017-04-03T20:41:54.739909: step 22544, loss 0.0706426, acc 0.96875\n",
      "2017-04-03T20:41:54.945525: step 22545, loss 0.0862531, acc 0.96875\n",
      "2017-04-03T20:41:55.152287: step 22546, loss 0.141151, acc 0.96875\n",
      "2017-04-03T20:41:55.352195: step 22547, loss 0.0379438, acc 0.984375\n",
      "2017-04-03T20:41:55.559009: step 22548, loss 0.0221123, acc 0.984375\n",
      "2017-04-03T20:41:55.765216: step 22549, loss 0.0794234, acc 0.953125\n",
      "2017-04-03T20:41:55.971509: step 22550, loss 0.103099, acc 0.96875\n",
      "2017-04-03T20:41:56.173216: step 22551, loss 0.0473068, acc 0.96875\n",
      "2017-04-03T20:41:56.377916: step 22552, loss 0.0550295, acc 0.984375\n",
      "2017-04-03T20:41:56.583975: step 22553, loss 0.0625686, acc 0.96875\n",
      "2017-04-03T20:41:56.789637: step 22554, loss 0.195803, acc 0.9375\n",
      "2017-04-03T20:41:57.033423: step 22555, loss 0.0730723, acc 0.953125\n",
      "2017-04-03T20:41:57.249070: step 22556, loss 0.0553638, acc 0.984375\n",
      "2017-04-03T20:41:57.469291: step 22557, loss 0.151199, acc 0.96875\n",
      "2017-04-03T20:41:57.687063: step 22558, loss 0.0313004, acc 0.984375\n",
      "2017-04-03T20:41:57.886543: step 22559, loss 0.204892, acc 0.90625\n",
      "2017-04-03T20:41:58.092540: step 22560, loss 0.267367, acc 0.953125\n",
      "2017-04-03T20:41:58.306026: step 22561, loss 0.0960735, acc 0.96875\n",
      "2017-04-03T20:41:58.501420: step 22562, loss 0.00901125, acc 1\n",
      "2017-04-03T20:41:58.700718: step 22563, loss 0.0714052, acc 0.96875\n",
      "2017-04-03T20:41:58.895276: step 22564, loss 0.0288292, acc 1\n",
      "2017-04-03T20:41:59.094943: step 22565, loss 0.0889974, acc 0.984375\n",
      "2017-04-03T20:41:59.302526: step 22566, loss 0.147257, acc 0.953125\n",
      "2017-04-03T20:41:59.506314: step 22567, loss 0.189734, acc 0.9375\n",
      "2017-04-03T20:41:59.708380: step 22568, loss 0.0892977, acc 0.96875\n",
      "2017-04-03T20:41:59.915794: step 22569, loss 0.0683758, acc 0.96875\n",
      "2017-04-03T20:42:00.119974: step 22570, loss 0.0235992, acc 0.984375\n",
      "2017-04-03T20:42:00.321837: step 22571, loss 0.0762592, acc 0.984375\n",
      "2017-04-03T20:42:00.529493: step 22572, loss 0.0850937, acc 0.953125\n",
      "2017-04-03T20:42:00.734085: step 22573, loss 0.137563, acc 0.953125\n",
      "2017-04-03T20:42:00.946529: step 22574, loss 0.0376277, acc 0.984375\n",
      "2017-04-03T20:42:01.160193: step 22575, loss 0.428801, acc 0.921875\n",
      "2017-04-03T20:42:01.374389: step 22576, loss 0.0221414, acc 1\n",
      "2017-04-03T20:42:01.576528: step 22577, loss 0.0553235, acc 0.984375\n",
      "2017-04-03T20:42:01.782767: step 22578, loss 0.139965, acc 0.953125\n",
      "2017-04-03T20:42:01.983840: step 22579, loss 0.124773, acc 0.9375\n",
      "2017-04-03T20:42:02.193783: step 22580, loss 0.00837311, acc 1\n",
      "2017-04-03T20:42:02.398975: step 22581, loss 0.148156, acc 0.96875\n",
      "2017-04-03T20:42:02.601002: step 22582, loss 0.0579242, acc 0.96875\n",
      "2017-04-03T20:42:02.808471: step 22583, loss 0.0536611, acc 0.984375\n",
      "2017-04-03T20:42:03.011485: step 22584, loss 0.0953757, acc 0.96875\n",
      "2017-04-03T20:42:03.218034: step 22585, loss 0.0610485, acc 0.96875\n",
      "2017-04-03T20:42:03.427591: step 22586, loss 0.174774, acc 0.953125\n",
      "2017-04-03T20:42:03.627681: step 22587, loss 0.0225349, acc 1\n",
      "2017-04-03T20:42:03.832755: step 22588, loss 0.189636, acc 0.953125\n",
      "2017-04-03T20:42:04.034492: step 22589, loss 0.026435, acc 1\n",
      "2017-04-03T20:42:04.235963: step 22590, loss 0.0589325, acc 0.984375\n",
      "2017-04-03T20:42:04.443523: step 22591, loss 0.171684, acc 0.953125\n",
      "2017-04-03T20:42:04.644954: step 22592, loss 0.0389541, acc 1\n",
      "2017-04-03T20:42:04.886359: step 22593, loss 0.0897661, acc 0.96875\n",
      "2017-04-03T20:42:05.091713: step 22594, loss 0.120212, acc 0.953125\n",
      "2017-04-03T20:42:05.297209: step 22595, loss 0.129623, acc 0.953125\n",
      "2017-04-03T20:42:05.503462: step 22596, loss 0.0778567, acc 0.984375\n",
      "2017-04-03T20:42:05.704965: step 22597, loss 0.0162568, acc 1\n",
      "2017-04-03T20:42:05.940246: step 22598, loss 0.113038, acc 0.984375\n",
      "2017-04-03T20:42:06.146745: step 22599, loss 0.153163, acc 0.953125\n",
      "2017-04-03T20:42:06.351026: step 22600, loss 0.112499, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:42:08.467633: step 22600, loss 8.15869, acc 0.281\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-22600\n",
      "\n",
      "2017-04-03T20:42:08.804722: step 22601, loss 0.0157802, acc 1\n",
      "2017-04-03T20:42:09.010911: step 22602, loss 0.109905, acc 0.953125\n",
      "2017-04-03T20:42:09.210366: step 22603, loss 0.0554712, acc 1\n",
      "2017-04-03T20:42:09.409863: step 22604, loss 0.0507349, acc 1\n",
      "2017-04-03T20:42:09.613760: step 22605, loss 0.0653709, acc 0.96875\n",
      "2017-04-03T20:42:09.818716: step 22606, loss 0.0581039, acc 0.984375\n",
      "2017-04-03T20:42:10.024783: step 22607, loss 0.088212, acc 0.96875\n",
      "2017-04-03T20:42:10.226368: step 22608, loss 0.0536229, acc 0.984375\n",
      "2017-04-03T20:42:10.428226: step 22609, loss 0.0227362, acc 1\n",
      "2017-04-03T20:42:10.631792: step 22610, loss 0.05124, acc 0.984375\n",
      "2017-04-03T20:42:10.846273: step 22611, loss 0.0780799, acc 0.96875\n",
      "2017-04-03T20:42:11.045854: step 22612, loss 0.0738443, acc 0.96875\n",
      "2017-04-03T20:42:11.291912: step 22613, loss 0.243788, acc 0.890625\n",
      "2017-04-03T20:42:11.497419: step 22614, loss 0.0463053, acc 0.984375\n",
      "2017-04-03T20:42:11.706326: step 22615, loss 0.0942028, acc 0.984375\n",
      "2017-04-03T20:42:11.918427: step 22616, loss 0.0877853, acc 0.96875\n",
      "2017-04-03T20:42:12.135984: step 22617, loss 0.352754, acc 0.953125\n",
      "2017-04-03T20:42:12.348509: step 22618, loss 0.0835271, acc 0.984375\n",
      "2017-04-03T20:42:12.557901: step 22619, loss 0.0932709, acc 0.953125\n",
      "2017-04-03T20:42:12.760782: step 22620, loss 0.209324, acc 0.9375\n",
      "2017-04-03T20:42:12.967794: step 22621, loss 0.028919, acc 1\n",
      "2017-04-03T20:42:13.167045: step 22622, loss 0.0374055, acc 1\n",
      "2017-04-03T20:42:13.373586: step 22623, loss 0.0876194, acc 0.96875\n",
      "2017-04-03T20:42:13.580524: step 22624, loss 0.12066, acc 0.96875\n",
      "2017-04-03T20:42:13.786516: step 22625, loss 0.179506, acc 0.921875\n",
      "2017-04-03T20:42:13.997096: step 22626, loss 0.176535, acc 0.921875\n",
      "2017-04-03T20:42:14.209110: step 22627, loss 0.134199, acc 0.96875\n",
      "2017-04-03T20:42:14.407841: step 22628, loss 0.155379, acc 0.9375\n",
      "2017-04-03T20:42:14.616308: step 22629, loss 0.0210564, acc 0.984375\n",
      "2017-04-03T20:42:14.825884: step 22630, loss 0.0192633, acc 1\n",
      "2017-04-03T20:42:15.041342: step 22631, loss 0.0665333, acc 0.96875\n",
      "2017-04-03T20:42:15.243803: step 22632, loss 0.176008, acc 0.921875\n",
      "2017-04-03T20:42:15.453265: step 22633, loss 0.192963, acc 0.9375\n",
      "2017-04-03T20:42:15.662330: step 22634, loss 0.116751, acc 0.984375\n",
      "2017-04-03T20:42:15.874067: step 22635, loss 0.0720848, acc 0.96875\n",
      "2017-04-03T20:42:16.069491: step 22636, loss 0.0454496, acc 0.984375\n",
      "2017-04-03T20:42:16.316362: step 22637, loss 0.155031, acc 0.9375\n",
      "2017-04-03T20:42:16.521540: step 22638, loss 0.127806, acc 0.9375\n",
      "2017-04-03T20:42:16.725091: step 22639, loss 0.133644, acc 0.984375\n",
      "2017-04-03T20:42:16.972180: step 22640, loss 0.124962, acc 0.984375\n",
      "2017-04-03T20:42:17.173206: step 22641, loss 0.193026, acc 0.9375\n",
      "2017-04-03T20:42:17.375716: step 22642, loss 0.0500658, acc 1\n",
      "2017-04-03T20:42:17.584404: step 22643, loss 0.0822075, acc 0.984375\n",
      "2017-04-03T20:42:17.787846: step 22644, loss 0.0772386, acc 0.96875\n",
      "2017-04-03T20:42:17.988503: step 22645, loss 0.0255543, acc 1\n",
      "2017-04-03T20:42:18.189228: step 22646, loss 0.0709493, acc 0.984375\n",
      "2017-04-03T20:42:18.394526: step 22647, loss 0.0126694, acc 1\n",
      "2017-04-03T20:42:18.615921: step 22648, loss 0.135502, acc 0.96875\n",
      "2017-04-03T20:42:18.817625: step 22649, loss 0.0191414, acc 1\n",
      "2017-04-03T20:42:19.022153: step 22650, loss 0.0757789, acc 0.984375\n",
      "2017-04-03T20:42:19.227257: step 22651, loss 0.221305, acc 0.96875\n",
      "2017-04-03T20:42:19.430743: step 22652, loss 0.0774027, acc 0.96875\n",
      "2017-04-03T20:42:19.672264: step 22653, loss 0.13298, acc 0.96875\n",
      "2017-04-03T20:42:19.889311: step 22654, loss 0.0274447, acc 1\n",
      "2017-04-03T20:42:20.096197: step 22655, loss 0.173952, acc 0.96875\n",
      "2017-04-03T20:42:20.297591: step 22656, loss 0.0644524, acc 0.984375\n",
      "2017-04-03T20:42:20.505937: step 22657, loss 0.0373247, acc 1\n",
      "2017-04-03T20:42:20.707936: step 22658, loss 0.0748371, acc 1\n",
      "2017-04-03T20:42:20.911668: step 22659, loss 0.0290602, acc 0.984375\n",
      "2017-04-03T20:42:21.120439: step 22660, loss 0.05131, acc 0.984375\n",
      "2017-04-03T20:42:21.320653: step 22661, loss 0.0549812, acc 0.984375\n",
      "2017-04-03T20:42:21.525712: step 22662, loss 0.0629662, acc 0.96875\n",
      "2017-04-03T20:42:21.733099: step 22663, loss 0.13896, acc 0.953125\n",
      "2017-04-03T20:42:21.936630: step 22664, loss 0.0747781, acc 0.984375\n",
      "2017-04-03T20:42:22.181366: step 22665, loss 0.0839673, acc 0.96875\n",
      "2017-04-03T20:42:22.391843: step 22666, loss 0.0147026, acc 1\n",
      "2017-04-03T20:42:22.634353: step 22667, loss 0.031456, acc 1\n",
      "2017-04-03T20:42:22.842380: step 22668, loss 0.0198123, acc 1\n",
      "2017-04-03T20:42:23.044345: step 22669, loss 0.0243522, acc 1\n",
      "2017-04-03T20:42:23.244529: step 22670, loss 0.0965017, acc 0.984375\n",
      "2017-04-03T20:42:23.453408: step 22671, loss 0.191001, acc 0.9375\n",
      "2017-04-03T20:42:23.662606: step 22672, loss 0.0152788, acc 1\n",
      "2017-04-03T20:42:23.882300: step 22673, loss 0.120755, acc 0.96875\n",
      "2017-04-03T20:42:24.088171: step 22674, loss 0.0606564, acc 0.984375\n",
      "2017-04-03T20:42:24.300637: step 22675, loss 0.0295654, acc 1\n",
      "2017-04-03T20:42:24.501896: step 22676, loss 0.0918131, acc 0.984375\n",
      "2017-04-03T20:42:24.705266: step 22677, loss 0.294227, acc 0.9375\n",
      "2017-04-03T20:42:24.906874: step 22678, loss 0.0646913, acc 0.984375\n",
      "2017-04-03T20:42:25.108888: step 22679, loss 0.199026, acc 0.953125\n",
      "2017-04-03T20:42:25.310650: step 22680, loss 0.123339, acc 0.984375\n",
      "2017-04-03T20:42:25.531546: step 22681, loss 0.012165, acc 1\n",
      "2017-04-03T20:42:25.757420: step 22682, loss 0.0661105, acc 0.96875\n",
      "2017-04-03T20:42:25.974259: step 22683, loss 0.0149382, acc 1\n",
      "2017-04-03T20:42:26.191671: step 22684, loss 0.0930193, acc 0.96875\n",
      "2017-04-03T20:42:26.397778: step 22685, loss 0.129181, acc 0.953125\n",
      "2017-04-03T20:42:26.603485: step 22686, loss 0.0699315, acc 0.984375\n",
      "2017-04-03T20:42:26.805801: step 22687, loss 0.132236, acc 0.96875\n",
      "2017-04-03T20:42:27.020537: step 22688, loss 0.078225, acc 0.96875\n",
      "2017-04-03T20:42:27.238638: step 22689, loss 0.0251461, acc 1\n",
      "2017-04-03T20:42:27.482030: step 22690, loss 0.188499, acc 0.921875\n",
      "2017-04-03T20:42:27.684878: step 22691, loss 0.205116, acc 0.96875\n",
      "2017-04-03T20:42:27.883703: step 22692, loss 0.0204661, acc 1\n",
      "2017-04-03T20:42:28.096450: step 22693, loss 0.113251, acc 0.9375\n",
      "2017-04-03T20:42:28.298657: step 22694, loss 0.0468385, acc 0.984375\n",
      "2017-04-03T20:42:28.500490: step 22695, loss 0.0699607, acc 0.984375\n",
      "2017-04-03T20:42:28.713663: step 22696, loss 0.0136775, acc 1\n",
      "2017-04-03T20:42:28.916677: step 22697, loss 0.103413, acc 0.984375\n",
      "2017-04-03T20:42:29.120947: step 22698, loss 0.123763, acc 0.96875\n",
      "2017-04-03T20:42:29.322365: step 22699, loss 0.0711273, acc 0.96875\n",
      "2017-04-03T20:42:29.527253: step 22700, loss 0.224492, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:42:31.679463: step 22700, loss 8.26845, acc 0.2825\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-22700\n",
      "\n",
      "2017-04-03T20:42:32.037059: step 22701, loss 0.0619044, acc 0.96875\n",
      "2017-04-03T20:42:32.240055: step 22702, loss 0.084227, acc 0.96875\n",
      "2017-04-03T20:42:32.442623: step 22703, loss 0.0602807, acc 0.984375\n",
      "2017-04-03T20:42:32.649165: step 22704, loss 0.0393976, acc 1\n",
      "2017-04-03T20:42:32.857597: step 22705, loss 0.0963604, acc 0.96875\n",
      "2017-04-03T20:42:33.066745: step 22706, loss 0.0225279, acc 1\n",
      "2017-04-03T20:42:33.312622: step 22707, loss 0.0948338, acc 0.96875\n",
      "2017-04-03T20:42:33.511026: step 22708, loss 0.0398511, acc 0.984375\n",
      "2017-04-03T20:42:33.717646: step 22709, loss 0.0286636, acc 0.984375\n",
      "2017-04-03T20:42:33.920677: step 22710, loss 0.0110523, acc 1\n",
      "2017-04-03T20:42:34.123421: step 22711, loss 0.285722, acc 0.96875\n",
      "2017-04-03T20:42:34.328370: step 22712, loss 0.111222, acc 0.953125\n",
      "2017-04-03T20:42:34.531101: step 22713, loss 0.070803, acc 0.984375\n",
      "2017-04-03T20:42:34.733797: step 22714, loss 0.0539258, acc 0.984375\n",
      "2017-04-03T20:42:34.932555: step 22715, loss 0.0293202, acc 1\n",
      "2017-04-03T20:42:35.131965: step 22716, loss 0.514689, acc 0.96875\n",
      "2017-04-03T20:42:35.336792: step 22717, loss 0.106685, acc 0.9375\n",
      "2017-04-03T20:42:35.539378: step 22718, loss 0.0883147, acc 0.953125\n",
      "2017-04-03T20:42:35.746361: step 22719, loss 0.0798781, acc 0.96875\n",
      "2017-04-03T20:42:35.992758: step 22720, loss 0.0603198, acc 0.96875\n",
      "2017-04-03T20:42:36.195141: step 22721, loss 0.178323, acc 0.953125\n",
      "2017-04-03T20:42:36.396739: step 22722, loss 0.203837, acc 0.9375\n",
      "2017-04-03T20:42:36.601485: step 22723, loss 0.0366668, acc 1\n",
      "2017-04-03T20:42:36.810592: step 22724, loss 0.362997, acc 0.953125\n",
      "2017-04-03T20:42:37.013984: step 22725, loss 0.0701897, acc 0.96875\n",
      "2017-04-03T20:42:37.217946: step 22726, loss 0.0130522, acc 1\n",
      "2017-04-03T20:42:37.422333: step 22727, loss 0.130394, acc 0.9375\n",
      "2017-04-03T20:42:37.624305: step 22728, loss 0.0811917, acc 0.953125\n",
      "2017-04-03T20:42:37.832585: step 22729, loss 0.0564764, acc 0.984375\n",
      "2017-04-03T20:42:38.043014: step 22730, loss 0.274097, acc 0.96875\n",
      "2017-04-03T20:42:38.248307: step 22731, loss 0.113907, acc 0.953125\n",
      "2017-04-03T20:42:38.449749: step 22732, loss 0.114162, acc 0.953125\n",
      "2017-04-03T20:42:38.651912: step 22733, loss 0.0523385, acc 0.984375\n",
      "2017-04-03T20:42:38.861967: step 22734, loss 0.0799859, acc 0.953125\n",
      "2017-04-03T20:42:39.065926: step 22735, loss 0.0972718, acc 0.96875\n",
      "2017-04-03T20:42:39.275429: step 22736, loss 0.112358, acc 0.953125\n",
      "2017-04-03T20:42:39.479904: step 22737, loss 0.0341089, acc 0.984375\n",
      "2017-04-03T20:42:39.685229: step 22738, loss 0.186837, acc 0.953125\n",
      "2017-04-03T20:42:39.889452: step 22739, loss 0.115095, acc 0.96875\n",
      "2017-04-03T20:42:40.087943: step 22740, loss 0.0490783, acc 0.984375\n",
      "2017-04-03T20:42:40.294036: step 22741, loss 0.0360647, acc 1\n",
      "2017-04-03T20:42:40.538152: step 22742, loss 0.0460056, acc 0.984375\n",
      "2017-04-03T20:42:40.751989: step 22743, loss 0.0219192, acc 1\n",
      "2017-04-03T20:42:40.957775: step 22744, loss 0.0404527, acc 0.96875\n",
      "2017-04-03T20:42:41.162544: step 22745, loss 0.0626278, acc 0.96875\n",
      "2017-04-03T20:42:41.366865: step 22746, loss 0.0634432, acc 0.984375\n",
      "2017-04-03T20:42:41.611237: step 22747, loss 0.0847981, acc 0.953125\n",
      "2017-04-03T20:42:42.089364: step 22748, loss 0.0658182, acc 0.96875\n",
      "2017-04-03T20:42:42.295618: step 22749, loss 0.0401065, acc 0.984375\n",
      "2017-04-03T20:42:42.495647: step 22750, loss 0.032067, acc 1\n",
      "2017-04-03T20:42:42.709016: step 22751, loss 0.0739531, acc 0.9375\n",
      "2017-04-03T20:42:42.910646: step 22752, loss 0.0465831, acc 0.984375\n",
      "2017-04-03T20:42:43.130383: step 22753, loss 0.0703886, acc 0.984375\n",
      "2017-04-03T20:42:43.330839: step 22754, loss 0.0846149, acc 0.96875\n",
      "2017-04-03T20:42:43.535676: step 22755, loss 0.0532401, acc 0.984375\n",
      "2017-04-03T20:42:43.740725: step 22756, loss 0.0553654, acc 0.96875\n",
      "2017-04-03T20:42:43.940165: step 22757, loss 0.0473734, acc 0.984375\n",
      "2017-04-03T20:42:44.152994: step 22758, loss 0.0712685, acc 0.96875\n",
      "2017-04-03T20:42:44.358643: step 22759, loss 0.054125, acc 0.984375\n",
      "2017-04-03T20:42:44.559149: step 22760, loss 0.110639, acc 0.953125\n",
      "2017-04-03T20:42:44.757120: step 22761, loss 0.11227, acc 0.953125\n",
      "2017-04-03T20:42:44.958539: step 22762, loss 0.0618736, acc 0.96875\n",
      "2017-04-03T20:42:45.160996: step 22763, loss 0.0445053, acc 1\n",
      "2017-04-03T20:42:45.368918: step 22764, loss 0.021195, acc 1\n",
      "2017-04-03T20:42:45.570082: step 22765, loss 0.0594906, acc 0.96875\n",
      "2017-04-03T20:42:45.771894: step 22766, loss 0.146637, acc 0.9375\n",
      "2017-04-03T20:42:45.971076: step 22767, loss 0.0870864, acc 0.953125\n",
      "2017-04-03T20:42:46.176582: step 22768, loss 0.112111, acc 0.96875\n",
      "2017-04-03T20:42:46.425274: step 22769, loss 0.113515, acc 0.96875\n",
      "2017-04-03T20:42:46.628795: step 22770, loss 0.060661, acc 0.984375\n",
      "2017-04-03T20:42:46.829025: step 22771, loss 0.0668191, acc 0.96875\n",
      "2017-04-03T20:42:47.028514: step 22772, loss 0.0540023, acc 0.984375\n",
      "2017-04-03T20:42:47.225421: step 22773, loss 0.0353285, acc 0.984375\n",
      "2017-04-03T20:42:47.424329: step 22774, loss 0.0849422, acc 0.9375\n",
      "2017-04-03T20:42:47.628819: step 22775, loss 0.066657, acc 0.96875\n",
      "2017-04-03T20:42:47.837475: step 22776, loss 0.0140192, acc 1\n",
      "2017-04-03T20:42:48.051053: step 22777, loss 0.108423, acc 0.96875\n",
      "2017-04-03T20:42:48.269435: step 22778, loss 0.155184, acc 0.921875\n",
      "2017-04-03T20:42:48.473538: step 22779, loss 0.0525166, acc 0.984375\n",
      "2017-04-03T20:42:48.679422: step 22780, loss 0.0530485, acc 0.96875\n",
      "2017-04-03T20:42:48.896436: step 22781, loss 0.230708, acc 0.9375\n",
      "2017-04-03T20:42:49.116527: step 22782, loss 0.121578, acc 0.96875\n",
      "2017-04-03T20:42:49.337516: step 22783, loss 0.0266364, acc 0.984375\n",
      "2017-04-03T20:42:49.541050: step 22784, loss 0.121617, acc 0.96875\n",
      "2017-04-03T20:42:49.744241: step 22785, loss 0.0688282, acc 0.984375\n",
      "2017-04-03T20:42:49.941246: step 22786, loss 0.0428431, acc 0.96875\n",
      "2017-04-03T20:42:50.141856: step 22787, loss 0.0643505, acc 0.96875\n",
      "2017-04-03T20:42:50.340797: step 22788, loss 0.0198431, acc 1\n",
      "2017-04-03T20:42:50.541038: step 22789, loss 0.0615831, acc 0.984375\n",
      "2017-04-03T20:42:50.742930: step 22790, loss 0.159476, acc 0.953125\n",
      "2017-04-03T20:42:50.944598: step 22791, loss 0.0295159, acc 0.984375\n",
      "2017-04-03T20:42:51.150355: step 22792, loss 0.0578173, acc 0.984375\n",
      "2017-04-03T20:42:51.406153: step 22793, loss 0.0702689, acc 0.96875\n",
      "2017-04-03T20:42:51.604932: step 22794, loss 0.130992, acc 0.96875\n",
      "2017-04-03T20:42:51.806477: step 22795, loss 0.203189, acc 0.984375\n",
      "2017-04-03T20:42:52.008417: step 22796, loss 0.0657965, acc 0.96875\n",
      "2017-04-03T20:42:52.209987: step 22797, loss 0.272001, acc 0.953125\n",
      "2017-04-03T20:42:52.460381: step 22798, loss 0.0916632, acc 0.953125\n",
      "2017-04-03T20:42:52.659900: step 22799, loss 0.0574972, acc 0.984375\n",
      "2017-04-03T20:42:52.863826: step 22800, loss 0.0449963, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:42:54.998561: step 22800, loss 8.32526, acc 0.27975\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-22800\n",
      "\n",
      "2017-04-03T20:42:55.360684: step 22801, loss 0.0363428, acc 0.984375\n",
      "2017-04-03T20:42:55.568056: step 22802, loss 0.0351859, acc 0.984375\n",
      "2017-04-03T20:42:55.771289: step 22803, loss 0.144249, acc 0.953125\n",
      "2017-04-03T20:42:55.973752: step 22804, loss 0.131181, acc 0.9375\n",
      "2017-04-03T20:42:56.218789: step 22805, loss 0.0751528, acc 0.96875\n",
      "2017-04-03T20:42:56.425588: step 22806, loss 0.0686532, acc 0.96875\n",
      "2017-04-03T20:42:56.634588: step 22807, loss 0.153448, acc 0.953125\n",
      "2017-04-03T20:42:56.833524: step 22808, loss 0.121503, acc 0.96875\n",
      "2017-04-03T20:42:57.034047: step 22809, loss 0.230806, acc 0.953125\n",
      "2017-04-03T20:42:57.276211: step 22810, loss 0.122172, acc 0.96875\n",
      "2017-04-03T20:42:57.481472: step 22811, loss 0.0419411, acc 0.984375\n",
      "2017-04-03T20:42:57.706260: step 22812, loss 0.104387, acc 0.9375\n",
      "2017-04-03T20:42:57.912800: step 22813, loss 0.114776, acc 0.96875\n",
      "2017-04-03T20:42:58.116093: step 22814, loss 0.0347968, acc 1\n",
      "2017-04-03T20:42:58.322659: step 22815, loss 0.0748856, acc 0.984375\n",
      "2017-04-03T20:42:58.527041: step 22816, loss 0.024388, acc 1\n",
      "2017-04-03T20:42:58.731002: step 22817, loss 0.0760562, acc 0.96875\n",
      "2017-04-03T20:42:58.932482: step 22818, loss 0.0323002, acc 1\n",
      "2017-04-03T20:42:59.152726: step 22819, loss 0.108212, acc 0.96875\n",
      "2017-04-03T20:42:59.359244: step 22820, loss 0.14049, acc 0.96875\n",
      "2017-04-03T20:42:59.564035: step 22821, loss 0.0407542, acc 1\n",
      "2017-04-03T20:42:59.766057: step 22822, loss 0.0975775, acc 0.96875\n",
      "2017-04-03T20:42:59.966531: step 22823, loss 0.0743819, acc 0.984375\n",
      "2017-04-03T20:43:00.175437: step 22824, loss 0.0871043, acc 0.953125\n",
      "2017-04-03T20:43:00.383089: step 22825, loss 0.0659269, acc 0.984375\n",
      "2017-04-03T20:43:00.596140: step 22826, loss 0.0398208, acc 1\n",
      "2017-04-03T20:43:00.846725: step 22827, loss 0.334647, acc 0.921875\n",
      "2017-04-03T20:43:01.089929: step 22828, loss 0.0275401, acc 1\n",
      "2017-04-03T20:43:01.313694: step 22829, loss 0.0648473, acc 1\n",
      "2017-04-03T20:43:01.534168: step 22830, loss 0.0686584, acc 0.984375\n",
      "2017-04-03T20:43:01.740618: step 22831, loss 0.0216561, acc 1\n",
      "2017-04-03T20:43:01.946498: step 22832, loss 0.0578115, acc 0.984375\n",
      "2017-04-03T20:43:02.157658: step 22833, loss 0.170124, acc 0.9375\n",
      "2017-04-03T20:43:02.360993: step 22834, loss 0.196234, acc 0.96875\n",
      "2017-04-03T20:43:02.561013: step 22835, loss 0.331492, acc 0.953125\n",
      "2017-04-03T20:43:02.762731: step 22836, loss 0.054425, acc 0.984375\n",
      "2017-04-03T20:43:03.010693: step 22837, loss 0.0535714, acc 0.984375\n",
      "2017-04-03T20:43:03.219872: step 22838, loss 0.106508, acc 0.96875\n",
      "2017-04-03T20:43:03.421468: step 22839, loss 0.140998, acc 0.953125\n",
      "2017-04-03T20:43:03.622986: step 22840, loss 0.0316637, acc 0.984375\n",
      "2017-04-03T20:43:03.829932: step 22841, loss 0.173987, acc 0.96875\n",
      "2017-04-03T20:43:04.031082: step 22842, loss 0.0856761, acc 0.953125\n",
      "2017-04-03T20:43:04.250524: step 22843, loss 0.100512, acc 0.984375\n",
      "2017-04-03T20:43:04.475099: step 22844, loss 0.043744, acc 1\n",
      "2017-04-03T20:43:04.696218: step 22845, loss 0.03905, acc 1\n",
      "2017-04-03T20:43:04.917524: step 22846, loss 0.189401, acc 0.96875\n",
      "2017-04-03T20:43:05.146954: step 22847, loss 0.0697971, acc 0.96875\n",
      "2017-04-03T20:43:05.369025: step 22848, loss 0.07576, acc 0.96875\n",
      "2017-04-03T20:43:05.627347: step 22849, loss 0.0321019, acc 0.984375\n",
      "2017-04-03T20:43:05.836386: step 22850, loss 0.176381, acc 0.953125\n",
      "2017-04-03T20:43:06.083951: step 22851, loss 0.375302, acc 0.921875\n",
      "2017-04-03T20:43:06.293730: step 22852, loss 0.13036, acc 0.953125\n",
      "2017-04-03T20:43:06.501659: step 22853, loss 0.0947298, acc 0.96875\n",
      "2017-04-03T20:43:06.747838: step 22854, loss 0.420515, acc 0.953125\n",
      "2017-04-03T20:43:06.957864: step 22855, loss 0.0891143, acc 0.96875\n",
      "2017-04-03T20:43:07.160745: step 22856, loss 0.176227, acc 0.96875\n",
      "2017-04-03T20:43:07.361844: step 22857, loss 0.0396968, acc 0.984375\n",
      "2017-04-03T20:43:07.604407: step 22858, loss 0.136351, acc 0.9375\n",
      "2017-04-03T20:43:07.810761: step 22859, loss 0.161316, acc 0.96875\n",
      "2017-04-03T20:43:08.015180: step 22860, loss 0.0467644, acc 0.984375\n",
      "2017-04-03T20:43:08.262828: step 22861, loss 0.0259844, acc 1\n",
      "2017-04-03T20:43:08.465353: step 22862, loss 0.0165978, acc 1\n",
      "2017-04-03T20:43:08.667899: step 22863, loss 0.0591922, acc 0.984375\n",
      "2017-04-03T20:43:08.866758: step 22864, loss 0.0285654, acc 0.984375\n",
      "2017-04-03T20:43:09.075338: step 22865, loss 0.0989673, acc 0.96875\n",
      "2017-04-03T20:43:09.280003: step 22866, loss 0.120643, acc 0.96875\n",
      "2017-04-03T20:43:09.486580: step 22867, loss 0.062005, acc 0.984375\n",
      "2017-04-03T20:43:09.690532: step 22868, loss 0.0921589, acc 0.953125\n",
      "2017-04-03T20:43:09.890885: step 22869, loss 0.076753, acc 0.984375\n",
      "2017-04-03T20:43:10.100533: step 22870, loss 0.207968, acc 0.953125\n",
      "2017-04-03T20:43:10.304127: step 22871, loss 0.0270147, acc 1\n",
      "2017-04-03T20:43:10.509795: step 22872, loss 0.066315, acc 0.984375\n",
      "2017-04-03T20:43:10.719303: step 22873, loss 0.101935, acc 0.953125\n",
      "2017-04-03T20:43:10.921723: step 22874, loss 0.310616, acc 0.875\n",
      "2017-04-03T20:43:11.123356: step 22875, loss 0.0338552, acc 1\n",
      "2017-04-03T20:43:11.328708: step 22876, loss 0.201174, acc 0.9375\n",
      "2017-04-03T20:43:11.532957: step 22877, loss 0.0904455, acc 0.96875\n",
      "2017-04-03T20:43:11.734738: step 22878, loss 0.113904, acc 0.984375\n",
      "2017-04-03T20:43:11.935402: step 22879, loss 0.133459, acc 0.953125\n",
      "2017-04-03T20:43:12.146122: step 22880, loss 0.0589338, acc 0.96875\n",
      "2017-04-03T20:43:12.348885: step 22881, loss 0.0673206, acc 0.984375\n",
      "2017-04-03T20:43:12.566876: step 22882, loss 0.0295875, acc 1\n",
      "2017-04-03T20:43:12.777063: step 22883, loss 0.14578, acc 0.9375\n",
      "2017-04-03T20:43:12.980737: step 22884, loss 0.0555099, acc 0.984375\n",
      "2017-04-03T20:43:13.182893: step 22885, loss 0.0664878, acc 0.96875\n",
      "2017-04-03T20:43:13.381962: step 22886, loss 0.107344, acc 0.9375\n",
      "2017-04-03T20:43:13.583348: step 22887, loss 0.0807798, acc 0.984375\n",
      "2017-04-03T20:43:13.793845: step 22888, loss 0.11344, acc 0.96875\n",
      "2017-04-03T20:43:14.009689: step 22889, loss 0.109577, acc 0.96875\n",
      "2017-04-03T20:43:14.229426: step 22890, loss 0.0820902, acc 0.984375\n",
      "2017-04-03T20:43:14.440601: step 22891, loss 0.0328344, acc 0.984375\n",
      "2017-04-03T20:43:14.643104: step 22892, loss 0.0356356, acc 0.984375\n",
      "2017-04-03T20:43:14.855459: step 22893, loss 0.123539, acc 0.9375\n",
      "2017-04-03T20:43:15.064895: step 22894, loss 0.0752242, acc 0.96875\n",
      "2017-04-03T20:43:15.278549: step 22895, loss 0.201624, acc 0.953125\n",
      "2017-04-03T20:43:15.483569: step 22896, loss 0.174705, acc 0.953125\n",
      "2017-04-03T20:43:15.690220: step 22897, loss 0.224347, acc 0.96875\n",
      "2017-04-03T20:43:15.906168: step 22898, loss 0.0347837, acc 0.984375\n",
      "2017-04-03T20:43:16.113213: step 22899, loss 0.0616977, acc 0.96875\n",
      "2017-04-03T20:43:16.325437: step 22900, loss 0.0822481, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:43:18.495295: step 22900, loss 8.38815, acc 0.2765\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-22900\n",
      "\n",
      "2017-04-03T20:43:18.842736: step 22901, loss 0.0653521, acc 0.984375\n",
      "2017-04-03T20:43:19.053850: step 22902, loss 0.0717727, acc 0.984375\n",
      "2017-04-03T20:43:19.261439: step 22903, loss 0.0774423, acc 0.984375\n",
      "2017-04-03T20:43:19.504275: step 22904, loss 0.133358, acc 0.96875\n",
      "2017-04-03T20:43:19.721186: step 22905, loss 0.0318719, acc 1\n",
      "2017-04-03T20:43:19.924785: step 22906, loss 0.160123, acc 0.9375\n",
      "2017-04-03T20:43:20.130700: step 22907, loss 0.0838729, acc 0.96875\n",
      "2017-04-03T20:43:20.349570: step 22908, loss 0.0276266, acc 1\n",
      "2017-04-03T20:43:20.562208: step 22909, loss 0.0856044, acc 0.984375\n",
      "2017-04-03T20:43:20.769329: step 22910, loss 0.140188, acc 0.953125\n",
      "2017-04-03T20:43:20.974546: step 22911, loss 0.117454, acc 0.96875\n",
      "2017-04-03T20:43:21.178392: step 22912, loss 0.0656883, acc 0.984375\n",
      "2017-04-03T20:43:21.381071: step 22913, loss 0.122496, acc 0.953125\n",
      "2017-04-03T20:43:21.592682: step 22914, loss 0.0596795, acc 0.96875\n",
      "2017-04-03T20:43:21.797318: step 22915, loss 0.16707, acc 0.953125\n",
      "2017-04-03T20:43:21.997425: step 22916, loss 0.0800002, acc 0.984375\n",
      "2017-04-03T20:43:22.200823: step 22917, loss 0.0651241, acc 0.96875\n",
      "2017-04-03T20:43:22.411581: step 22918, loss 0.0605071, acc 0.984375\n",
      "2017-04-03T20:43:22.619490: step 22919, loss 0.215081, acc 0.984375\n",
      "2017-04-03T20:43:22.822968: step 22920, loss 0.0866709, acc 0.984375\n",
      "2017-04-03T20:43:23.024374: step 22921, loss 0.052711, acc 0.984375\n",
      "2017-04-03T20:43:23.230745: step 22922, loss 0.152475, acc 0.921875\n",
      "2017-04-03T20:43:23.438021: step 22923, loss 0.0837508, acc 0.96875\n",
      "2017-04-03T20:43:23.647080: step 22924, loss 0.137094, acc 0.921875\n",
      "2017-04-03T20:43:23.860563: step 22925, loss 0.0469498, acc 0.984375\n",
      "2017-04-03T20:43:24.079182: step 22926, loss 0.0195421, acc 1\n",
      "2017-04-03T20:43:24.297779: step 22927, loss 0.0828995, acc 0.984375\n",
      "2017-04-03T20:43:24.513967: step 22928, loss 0.0976129, acc 0.96875\n",
      "2017-04-03T20:43:24.761967: step 22929, loss 0.191023, acc 0.9375\n",
      "2017-04-03T20:43:24.971383: step 22930, loss 0.172502, acc 0.953125\n",
      "2017-04-03T20:43:25.215489: step 22931, loss 0.01683, acc 1\n",
      "2017-04-03T20:43:25.415276: step 22932, loss 0.24794, acc 0.953125\n",
      "2017-04-03T20:43:25.617287: step 22933, loss 0.158989, acc 0.9375\n",
      "2017-04-03T20:43:25.821400: step 22934, loss 0.0302286, acc 1\n",
      "2017-04-03T20:43:26.064693: step 22935, loss 0.0805543, acc 0.953125\n",
      "2017-04-03T20:43:26.272829: step 22936, loss 0.0858308, acc 0.96875\n",
      "2017-04-03T20:43:26.475019: step 22937, loss 0.116523, acc 0.953125\n",
      "2017-04-03T20:43:26.677356: step 22938, loss 0.0376728, acc 0.984375\n",
      "2017-04-03T20:43:26.913190: step 22939, loss 0.0740771, acc 0.96875\n",
      "2017-04-03T20:43:27.137846: step 22940, loss 0.203997, acc 0.9375\n",
      "2017-04-03T20:43:27.351200: step 22941, loss 0.14593, acc 0.96875\n",
      "2017-04-03T20:43:27.555364: step 22942, loss 0.01974, acc 1\n",
      "2017-04-03T20:43:27.761453: step 22943, loss 0.142139, acc 0.9375\n",
      "2017-04-03T20:43:27.959862: step 22944, loss 0.0336751, acc 1\n",
      "2017-04-03T20:43:28.205840: step 22945, loss 0.178038, acc 0.953125\n",
      "2017-04-03T20:43:28.410539: step 22946, loss 0.0431995, acc 1\n",
      "2017-04-03T20:43:28.653478: step 22947, loss 0.0150812, acc 1\n",
      "2017-04-03T20:43:28.857682: step 22948, loss 0.0674878, acc 0.984375\n",
      "2017-04-03T20:43:29.067205: step 22949, loss 0.0492114, acc 1\n",
      "2017-04-03T20:43:29.269776: step 22950, loss 0.0993571, acc 0.953125\n",
      "2017-04-03T20:43:29.482152: step 22951, loss 0.0541989, acc 1\n",
      "2017-04-03T20:43:29.687192: step 22952, loss 0.042479, acc 0.984375\n",
      "2017-04-03T20:43:29.930112: step 22953, loss 0.147422, acc 0.953125\n",
      "2017-04-03T20:43:30.138736: step 22954, loss 0.0796075, acc 0.96875\n",
      "2017-04-03T20:43:30.346442: step 22955, loss 0.100847, acc 0.984375\n",
      "2017-04-03T20:43:30.550442: step 22956, loss 0.063065, acc 0.96875\n",
      "2017-04-03T20:43:30.755526: step 22957, loss 0.0665901, acc 0.96875\n",
      "2017-04-03T20:43:31.003363: step 22958, loss 0.0636884, acc 0.984375\n",
      "2017-04-03T20:43:31.224935: step 22959, loss 0.0793235, acc 0.96875\n",
      "2017-04-03T20:43:31.476916: step 22960, loss 0.191153, acc 0.921875\n",
      "2017-04-03T20:43:31.684187: step 22961, loss 0.0423566, acc 0.984375\n",
      "2017-04-03T20:43:31.886109: step 22962, loss 0.0441344, acc 1\n",
      "2017-04-03T20:43:32.128183: step 22963, loss 0.0137414, acc 1\n",
      "2017-04-03T20:43:32.346466: step 22964, loss 0.0978508, acc 0.9375\n",
      "2017-04-03T20:43:32.600394: step 22965, loss 0.0937849, acc 0.953125\n",
      "2017-04-03T20:43:32.811179: step 22966, loss 0.175149, acc 0.921875\n",
      "2017-04-03T20:43:33.016458: step 22967, loss 0.0519487, acc 0.96875\n",
      "2017-04-03T20:43:33.226954: step 22968, loss 0.1643, acc 0.953125\n",
      "2017-04-03T20:43:33.444373: step 22969, loss 0.132739, acc 0.96875\n",
      "2017-04-03T20:43:33.653646: step 22970, loss 0.0389313, acc 0.984375\n",
      "2017-04-03T20:43:33.872043: step 22971, loss 0.175674, acc 0.953125\n",
      "2017-04-03T20:43:34.108556: step 22972, loss 0.0569331, acc 0.96875\n",
      "2017-04-03T20:43:34.381076: step 22973, loss 0.0235527, acc 0.984375\n",
      "2017-04-03T20:43:34.602663: step 22974, loss 0.0833842, acc 0.984375\n",
      "2017-04-03T20:43:34.815866: step 22975, loss 0.115453, acc 0.96875\n",
      "2017-04-03T20:43:35.021035: step 22976, loss 0.102958, acc 0.96875\n",
      "2017-04-03T20:43:35.227305: step 22977, loss 0.0279491, acc 1\n",
      "2017-04-03T20:43:35.430449: step 22978, loss 0.118124, acc 0.96875\n",
      "2017-04-03T20:43:35.647077: step 22979, loss 0.103062, acc 0.953125\n",
      "2017-04-03T20:43:35.851005: step 22980, loss 0.0355905, acc 1\n",
      "2017-04-03T20:43:36.067101: step 22981, loss 0.167607, acc 0.96875\n",
      "2017-04-03T20:43:36.275995: step 22982, loss 0.142352, acc 0.9375\n",
      "2017-04-03T20:43:36.499708: step 22983, loss 0.3301, acc 0.890625\n",
      "2017-04-03T20:43:36.714302: step 22984, loss 0.126896, acc 0.921875\n",
      "2017-04-03T20:43:36.931004: step 22985, loss 0.0793465, acc 0.96875\n",
      "2017-04-03T20:43:37.142126: step 22986, loss 0.114122, acc 0.953125\n",
      "2017-04-03T20:43:37.351727: step 22987, loss 0.109573, acc 0.953125\n",
      "2017-04-03T20:43:37.560341: step 22988, loss 0.147269, acc 0.9375\n",
      "2017-04-03T20:43:37.771199: step 22989, loss 0.0797572, acc 0.984375\n",
      "2017-04-03T20:43:37.974165: step 22990, loss 0.0415438, acc 1\n",
      "2017-04-03T20:43:38.179018: step 22991, loss 0.0684785, acc 0.96875\n",
      "2017-04-03T20:43:38.387157: step 22992, loss 0.0799439, acc 0.96875\n",
      "2017-04-03T20:43:38.598724: step 22993, loss 0.155543, acc 0.9375\n",
      "2017-04-03T20:43:38.805663: step 22994, loss 0.119055, acc 0.96875\n",
      "2017-04-03T20:43:39.021435: step 22995, loss 0.0271106, acc 0.984375\n",
      "2017-04-03T20:43:39.226368: step 22996, loss 0.107415, acc 0.984375\n",
      "2017-04-03T20:43:39.431629: step 22997, loss 0.0382454, acc 0.984375\n",
      "2017-04-03T20:43:39.636618: step 22998, loss 0.118597, acc 0.96875\n",
      "2017-04-03T20:43:39.840275: step 22999, loss 0.0301139, acc 0.984375\n",
      "2017-04-03T20:43:40.045422: step 23000, loss 0.0636532, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:43:42.194224: step 23000, loss 8.35401, acc 0.2775\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-23000\n",
      "\n",
      "2017-04-03T20:43:42.533049: step 23001, loss 0.186035, acc 0.9375\n",
      "2017-04-03T20:43:42.746699: step 23002, loss 0.0886309, acc 0.953125\n",
      "2017-04-03T20:43:42.954521: step 23003, loss 0.0392896, acc 0.984375\n",
      "2017-04-03T20:43:43.163550: step 23004, loss 0.070413, acc 0.953125\n",
      "2017-04-03T20:43:43.374154: step 23005, loss 0.138579, acc 0.96875\n",
      "2017-04-03T20:43:43.589149: step 23006, loss 0.050843, acc 0.984375\n",
      "2017-04-03T20:43:43.798107: step 23007, loss 0.305385, acc 0.9375\n",
      "2017-04-03T20:43:43.998120: step 23008, loss 0.11668, acc 0.96875\n",
      "2017-04-03T20:43:44.200568: step 23009, loss 0.0897758, acc 0.953125\n",
      "2017-04-03T20:43:44.408052: step 23010, loss 0.0705572, acc 0.984375\n",
      "2017-04-03T20:43:44.623275: step 23011, loss 0.119057, acc 0.984375\n",
      "2017-04-03T20:43:44.838908: step 23012, loss 0.150062, acc 0.953125\n",
      "2017-04-03T20:43:45.062765: step 23013, loss 0.10177, acc 0.96875\n",
      "2017-04-03T20:43:45.285759: step 23014, loss 0.196277, acc 0.96875\n",
      "2017-04-03T20:43:45.494548: step 23015, loss 0.0922178, acc 0.9375\n",
      "2017-04-03T20:43:45.705455: step 23016, loss 0.103559, acc 0.96875\n",
      "2017-04-03T20:43:45.924461: step 23017, loss 0.0697149, acc 0.984375\n",
      "2017-04-03T20:43:46.133721: step 23018, loss 0.0931609, acc 0.984375\n",
      "2017-04-03T20:43:46.337983: step 23019, loss 0.125617, acc 0.96875\n",
      "2017-04-03T20:43:46.582870: step 23020, loss 0.0921143, acc 0.96875\n",
      "2017-04-03T20:43:46.806428: step 23021, loss 0.065046, acc 0.984375\n",
      "2017-04-03T20:43:47.011934: step 23022, loss 0.2443, acc 0.921875\n",
      "2017-04-03T20:43:47.231037: step 23023, loss 0.0292672, acc 0.984375\n",
      "2017-04-03T20:43:47.434152: step 23024, loss 0.0724598, acc 0.984375\n",
      "2017-04-03T20:43:47.632612: step 23025, loss 0.187678, acc 0.953125\n",
      "2017-04-03T20:43:47.872443: step 23026, loss 0.0457401, acc 0.984375\n",
      "2017-04-03T20:43:48.085331: step 23027, loss 0.0426343, acc 1\n",
      "2017-04-03T20:43:48.290028: step 23028, loss 0.0493444, acc 0.984375\n",
      "2017-04-03T20:43:48.504104: step 23029, loss 0.212327, acc 0.953125\n",
      "2017-04-03T20:43:48.721515: step 23030, loss 0.156444, acc 0.9375\n",
      "2017-04-03T20:43:48.939660: step 23031, loss 0.14857, acc 0.96875\n",
      "2017-04-03T20:43:49.172045: step 23032, loss 0.0619302, acc 0.96875\n",
      "2017-04-03T20:43:49.374199: step 23033, loss 0.130211, acc 0.96875\n",
      "2017-04-03T20:43:49.580394: step 23034, loss 0.072556, acc 0.96875\n",
      "2017-04-03T20:43:49.783129: step 23035, loss 0.228141, acc 0.953125\n",
      "2017-04-03T20:43:49.990478: step 23036, loss 0.271174, acc 0.921875\n",
      "2017-04-03T20:43:50.199343: step 23037, loss 0.0287901, acc 0.984375\n",
      "2017-04-03T20:43:50.403347: step 23038, loss 0.0100887, acc 1\n",
      "2017-04-03T20:43:50.607683: step 23039, loss 0.134683, acc 0.96875\n",
      "2017-04-03T20:43:50.815019: step 23040, loss 0.36235, acc 0.96875\n",
      "2017-04-03T20:43:51.026876: step 23041, loss 0.300986, acc 0.9375\n",
      "2017-04-03T20:43:51.234566: step 23042, loss 0.0438022, acc 1\n",
      "2017-04-03T20:43:51.449013: step 23043, loss 0.0274012, acc 0.984375\n",
      "2017-04-03T20:43:51.653261: step 23044, loss 0.191546, acc 0.921875\n",
      "2017-04-03T20:43:51.863500: step 23045, loss 0.220911, acc 0.96875\n",
      "2017-04-03T20:43:52.071317: step 23046, loss 0.0223339, acc 0.984375\n",
      "2017-04-03T20:43:52.274561: step 23047, loss 0.101642, acc 0.953125\n",
      "2017-04-03T20:43:52.522867: step 23048, loss 0.222145, acc 0.984375\n",
      "2017-04-03T20:43:52.724201: step 23049, loss 0.0433607, acc 1\n",
      "2017-04-03T20:43:52.929920: step 23050, loss 0.0604752, acc 0.984375\n",
      "2017-04-03T20:43:53.155032: step 23051, loss 0.0449983, acc 0.984375\n",
      "2017-04-03T20:43:53.377945: step 23052, loss 0.180814, acc 0.9375\n",
      "2017-04-03T20:43:53.592599: step 23053, loss 0.538195, acc 0.921875\n",
      "2017-04-03T20:43:53.796210: step 23054, loss 0.0926341, acc 0.953125\n",
      "2017-04-03T20:43:54.004066: step 23055, loss 0.0675904, acc 0.984375\n",
      "2017-04-03T20:43:54.206249: step 23056, loss 0.118796, acc 0.953125\n",
      "2017-04-03T20:43:54.413259: step 23057, loss 0.171613, acc 0.921875\n",
      "2017-04-03T20:43:54.621294: step 23058, loss 0.0613758, acc 0.984375\n",
      "2017-04-03T20:43:54.820604: step 23059, loss 0.0694768, acc 0.96875\n",
      "2017-04-03T20:43:55.030751: step 23060, loss 0.19135, acc 0.984375\n",
      "2017-04-03T20:43:55.277614: step 23061, loss 0.257189, acc 0.9375\n",
      "2017-04-03T20:43:55.520489: step 23062, loss 0.13679, acc 0.96875\n",
      "2017-04-03T20:43:55.731994: step 23063, loss 0.14618, acc 0.96875\n",
      "2017-04-03T20:43:55.945464: step 23064, loss 0.125303, acc 0.96875\n",
      "2017-04-03T20:43:56.159518: step 23065, loss 0.0430858, acc 0.984375\n",
      "2017-04-03T20:43:56.379045: step 23066, loss 0.0217599, acc 1\n",
      "2017-04-03T20:43:56.579020: step 23067, loss 0.0821525, acc 0.96875\n",
      "2017-04-03T20:43:56.784401: step 23068, loss 0.176368, acc 0.9375\n",
      "2017-04-03T20:43:57.015173: step 23069, loss 0.131959, acc 0.96875\n",
      "2017-04-03T20:43:57.278902: step 23070, loss 0.122916, acc 0.953125\n",
      "2017-04-03T20:43:57.486225: step 23071, loss 0.167111, acc 0.96875\n",
      "2017-04-03T20:43:57.695732: step 23072, loss 0.10912, acc 0.96875\n",
      "2017-04-03T20:43:57.902467: step 23073, loss 0.0483052, acc 0.984375\n",
      "2017-04-03T20:43:58.113017: step 23074, loss 0.0537131, acc 0.96875\n",
      "2017-04-03T20:43:58.324824: step 23075, loss 0.0722299, acc 0.96875\n",
      "2017-04-03T20:43:58.530286: step 23076, loss 0.244389, acc 0.9375\n",
      "2017-04-03T20:43:58.734540: step 23077, loss 0.0620433, acc 0.984375\n",
      "2017-04-03T20:43:58.947788: step 23078, loss 0.0737645, acc 0.953125\n",
      "2017-04-03T20:43:59.152036: step 23079, loss 0.129124, acc 0.953125\n",
      "2017-04-03T20:43:59.353965: step 23080, loss 0.0700603, acc 0.984375\n",
      "2017-04-03T20:43:59.558388: step 23081, loss 0.0634379, acc 0.96875\n",
      "2017-04-03T20:43:59.762891: step 23082, loss 0.175196, acc 0.953125\n",
      "2017-04-03T20:43:59.910042: step 23083, loss 0.0721107, acc 0.96875\n",
      "2017-04-03T20:44:00.164419: step 23084, loss 0.0691223, acc 0.984375\n",
      "2017-04-03T20:44:00.380550: step 23085, loss 0.0570452, acc 1\n",
      "2017-04-03T20:44:00.590076: step 23086, loss 0.0968804, acc 0.9375\n",
      "2017-04-03T20:44:00.796015: step 23087, loss 0.150305, acc 0.953125\n",
      "2017-04-03T20:44:01.003919: step 23088, loss 0.0278437, acc 1\n",
      "2017-04-03T20:44:01.214767: step 23089, loss 0.0471686, acc 0.984375\n",
      "2017-04-03T20:44:01.423836: step 23090, loss 0.0462849, acc 0.984375\n",
      "2017-04-03T20:44:01.674266: step 23091, loss 0.0649095, acc 0.96875\n",
      "2017-04-03T20:44:01.887780: step 23092, loss 0.0421674, acc 0.984375\n",
      "2017-04-03T20:44:02.097340: step 23093, loss 0.0713015, acc 0.984375\n",
      "2017-04-03T20:44:02.310879: step 23094, loss 0.159291, acc 0.953125\n",
      "2017-04-03T20:44:02.517840: step 23095, loss 0.0465769, acc 0.984375\n",
      "2017-04-03T20:44:02.728309: step 23096, loss 0.0450482, acc 0.96875\n",
      "2017-04-03T20:44:02.940745: step 23097, loss 0.262234, acc 0.953125\n",
      "2017-04-03T20:44:03.152809: step 23098, loss 0.0188196, acc 1\n",
      "2017-04-03T20:44:03.359056: step 23099, loss 0.0464109, acc 0.984375\n",
      "2017-04-03T20:44:03.596555: step 23100, loss 0.0676684, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:44:05.704757: step 23100, loss 8.19281, acc 0.2745\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-23100\n",
      "\n",
      "2017-04-03T20:44:06.050310: step 23101, loss 0.0728935, acc 0.96875\n",
      "2017-04-03T20:44:06.252910: step 23102, loss 0.0686385, acc 0.984375\n",
      "2017-04-03T20:44:06.455999: step 23103, loss 0.11047, acc 0.984375\n",
      "2017-04-03T20:44:06.658919: step 23104, loss 0.0622211, acc 0.96875\n",
      "2017-04-03T20:44:06.878962: step 23105, loss 0.0520851, acc 1\n",
      "2017-04-03T20:44:07.125144: step 23106, loss 0.0549797, acc 0.96875\n",
      "2017-04-03T20:44:07.335669: step 23107, loss 0.0993716, acc 0.953125\n",
      "2017-04-03T20:44:07.542293: step 23108, loss 0.02433, acc 1\n",
      "2017-04-03T20:44:07.744707: step 23109, loss 0.0267084, acc 1\n",
      "2017-04-03T20:44:07.950449: step 23110, loss 0.0435792, acc 0.984375\n",
      "2017-04-03T20:44:08.158866: step 23111, loss 0.0785786, acc 0.96875\n",
      "2017-04-03T20:44:08.364821: step 23112, loss 0.0879112, acc 0.984375\n",
      "2017-04-03T20:44:08.570099: step 23113, loss 0.0336493, acc 1\n",
      "2017-04-03T20:44:08.769641: step 23114, loss 0.0407336, acc 1\n",
      "2017-04-03T20:44:08.970983: step 23115, loss 0.0279797, acc 1\n",
      "2017-04-03T20:44:09.175752: step 23116, loss 0.0613256, acc 0.984375\n",
      "2017-04-03T20:44:09.385975: step 23117, loss 0.213412, acc 0.984375\n",
      "2017-04-03T20:44:09.589637: step 23118, loss 0.0473868, acc 1\n",
      "2017-04-03T20:44:09.806894: step 23119, loss 0.0841085, acc 0.96875\n",
      "2017-04-03T20:44:10.022220: step 23120, loss 0.0772048, acc 0.984375\n",
      "2017-04-03T20:44:10.239591: step 23121, loss 0.0765269, acc 0.96875\n",
      "2017-04-03T20:44:10.466222: step 23122, loss 0.0209726, acc 1\n",
      "2017-04-03T20:44:10.688983: step 23123, loss 0.132907, acc 0.9375\n",
      "2017-04-03T20:44:10.908692: step 23124, loss 0.0393393, acc 0.984375\n",
      "2017-04-03T20:44:11.125260: step 23125, loss 0.257814, acc 0.953125\n",
      "2017-04-03T20:44:11.331788: step 23126, loss 0.0563164, acc 0.96875\n",
      "2017-04-03T20:44:11.538938: step 23127, loss 0.124519, acc 0.96875\n",
      "2017-04-03T20:44:11.751000: step 23128, loss 0.101754, acc 0.984375\n",
      "2017-04-03T20:44:11.961502: step 23129, loss 0.00645791, acc 1\n",
      "2017-04-03T20:44:12.163723: step 23130, loss 0.0982782, acc 0.953125\n",
      "2017-04-03T20:44:12.366128: step 23131, loss 0.0543309, acc 0.96875\n",
      "2017-04-03T20:44:12.575499: step 23132, loss 0.0835512, acc 0.953125\n",
      "2017-04-03T20:44:12.778525: step 23133, loss 0.0512492, acc 0.96875\n",
      "2017-04-03T20:44:12.984038: step 23134, loss 0.0755667, acc 0.96875\n",
      "2017-04-03T20:44:13.196323: step 23135, loss 0.0566548, acc 0.984375\n",
      "2017-04-03T20:44:13.405149: step 23136, loss 0.0511603, acc 0.984375\n",
      "2017-04-03T20:44:13.611708: step 23137, loss 0.067087, acc 0.96875\n",
      "2017-04-03T20:44:13.814133: step 23138, loss 0.0463364, acc 0.984375\n",
      "2017-04-03T20:44:14.041895: step 23139, loss 0.037919, acc 0.984375\n",
      "2017-04-03T20:44:14.265101: step 23140, loss 0.0796867, acc 0.984375\n",
      "2017-04-03T20:44:14.475933: step 23141, loss 0.147398, acc 0.9375\n",
      "2017-04-03T20:44:14.683749: step 23142, loss 0.0259162, acc 0.984375\n",
      "2017-04-03T20:44:14.901838: step 23143, loss 0.064134, acc 0.953125\n",
      "2017-04-03T20:44:15.123625: step 23144, loss 0.0886909, acc 0.984375\n",
      "2017-04-03T20:44:15.345710: step 23145, loss 0.0522408, acc 0.984375\n",
      "2017-04-03T20:44:15.545370: step 23146, loss 0.0296286, acc 1\n",
      "2017-04-03T20:44:15.766839: step 23147, loss 0.0598266, acc 0.96875\n",
      "2017-04-03T20:44:15.972100: step 23148, loss 0.0424613, acc 0.984375\n",
      "2017-04-03T20:44:16.176589: step 23149, loss 0.0685306, acc 0.96875\n",
      "2017-04-03T20:44:16.381792: step 23150, loss 0.031988, acc 1\n",
      "2017-04-03T20:44:16.581891: step 23151, loss 0.0580235, acc 0.96875\n",
      "2017-04-03T20:44:16.788264: step 23152, loss 0.115286, acc 0.96875\n",
      "2017-04-03T20:44:16.993458: step 23153, loss 0.0363528, acc 0.984375\n",
      "2017-04-03T20:44:17.196497: step 23154, loss 0.0286762, acc 0.984375\n",
      "2017-04-03T20:44:17.398391: step 23155, loss 0.101716, acc 0.96875\n",
      "2017-04-03T20:44:17.599270: step 23156, loss 0.143426, acc 0.96875\n",
      "2017-04-03T20:44:17.806072: step 23157, loss 0.066846, acc 0.984375\n",
      "2017-04-03T20:44:18.018474: step 23158, loss 0.0607164, acc 0.96875\n",
      "2017-04-03T20:44:18.219711: step 23159, loss 0.133265, acc 0.953125\n",
      "2017-04-03T20:44:18.421383: step 23160, loss 0.0152673, acc 1\n",
      "2017-04-03T20:44:18.625135: step 23161, loss 0.0792969, acc 0.96875\n",
      "2017-04-03T20:44:18.824928: step 23162, loss 0.0759344, acc 0.984375\n",
      "2017-04-03T20:44:19.029998: step 23163, loss 0.14969, acc 0.984375\n",
      "2017-04-03T20:44:19.239191: step 23164, loss 0.0715644, acc 0.96875\n",
      "2017-04-03T20:44:19.439526: step 23165, loss 0.0493436, acc 0.984375\n",
      "2017-04-03T20:44:19.654992: step 23166, loss 0.0994552, acc 0.9375\n",
      "2017-04-03T20:44:19.870945: step 23167, loss 0.0218152, acc 0.984375\n",
      "2017-04-03T20:44:20.074020: step 23168, loss 0.133824, acc 0.9375\n",
      "2017-04-03T20:44:20.279338: step 23169, loss 0.0204, acc 1\n",
      "2017-04-03T20:44:20.530741: step 23170, loss 0.123855, acc 0.96875\n",
      "2017-04-03T20:44:20.739278: step 23171, loss 0.155943, acc 0.953125\n",
      "2017-04-03T20:44:20.939580: step 23172, loss 0.0575047, acc 0.96875\n",
      "2017-04-03T20:44:21.156390: step 23173, loss 0.0157214, acc 1\n",
      "2017-04-03T20:44:21.357377: step 23174, loss 0.115814, acc 0.953125\n",
      "2017-04-03T20:44:21.557772: step 23175, loss 0.141216, acc 0.953125\n",
      "2017-04-03T20:44:21.767916: step 23176, loss 0.0876153, acc 0.96875\n",
      "2017-04-03T20:44:21.976705: step 23177, loss 0.117241, acc 0.953125\n",
      "2017-04-03T20:44:22.181374: step 23178, loss 0.0606128, acc 0.984375\n",
      "2017-04-03T20:44:22.382995: step 23179, loss 0.0601027, acc 0.96875\n",
      "2017-04-03T20:44:22.590581: step 23180, loss 0.0919853, acc 0.96875\n",
      "2017-04-03T20:44:22.795356: step 23181, loss 0.0435488, acc 0.984375\n",
      "2017-04-03T20:44:22.997330: step 23182, loss 0.0900397, acc 0.96875\n",
      "2017-04-03T20:44:23.215584: step 23183, loss 0.0639056, acc 0.96875\n",
      "2017-04-03T20:44:23.416466: step 23184, loss 0.033335, acc 0.984375\n",
      "2017-04-03T20:44:23.619858: step 23185, loss 0.0352705, acc 1\n",
      "2017-04-03T20:44:23.820646: step 23186, loss 0.0961458, acc 0.96875\n",
      "2017-04-03T20:44:24.025355: step 23187, loss 0.064352, acc 0.984375\n",
      "2017-04-03T20:44:24.227863: step 23188, loss 0.0547421, acc 0.984375\n",
      "2017-04-03T20:44:24.434663: step 23189, loss 0.147751, acc 0.9375\n",
      "2017-04-03T20:44:24.635014: step 23190, loss 0.0513098, acc 0.984375\n",
      "2017-04-03T20:44:24.837709: step 23191, loss 0.124793, acc 0.96875\n",
      "2017-04-03T20:44:25.042610: step 23192, loss 0.0288816, acc 1\n",
      "2017-04-03T20:44:25.243146: step 23193, loss 0.089893, acc 0.96875\n",
      "2017-04-03T20:44:25.443022: step 23194, loss 0.0499896, acc 1\n",
      "2017-04-03T20:44:25.649441: step 23195, loss 0.027895, acc 0.984375\n",
      "2017-04-03T20:44:25.859596: step 23196, loss 0.0844333, acc 0.96875\n",
      "2017-04-03T20:44:26.058701: step 23197, loss 0.0121965, acc 1\n",
      "2017-04-03T20:44:26.296532: step 23198, loss 0.0341615, acc 0.984375\n",
      "2017-04-03T20:44:26.510610: step 23199, loss 0.109551, acc 0.953125\n",
      "2017-04-03T20:44:26.719743: step 23200, loss 0.235984, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:44:28.862625: step 23200, loss 8.32291, acc 0.27925\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-23200\n",
      "\n",
      "2017-04-03T20:44:29.214599: step 23201, loss 0.19324, acc 0.953125\n",
      "2017-04-03T20:44:29.426994: step 23202, loss 0.0951561, acc 0.96875\n",
      "2017-04-03T20:44:29.628216: step 23203, loss 0.043262, acc 0.984375\n",
      "2017-04-03T20:44:29.835203: step 23204, loss 0.16123, acc 0.96875\n",
      "2017-04-03T20:44:30.081750: step 23205, loss 0.123064, acc 0.96875\n",
      "2017-04-03T20:44:30.295755: step 23206, loss 0.0614305, acc 0.984375\n",
      "2017-04-03T20:44:30.509702: step 23207, loss 0.164271, acc 0.9375\n",
      "2017-04-03T20:44:30.717346: step 23208, loss 0.0651607, acc 0.984375\n",
      "2017-04-03T20:44:30.965272: step 23209, loss 0.0333841, acc 1\n",
      "2017-04-03T20:44:31.173133: step 23210, loss 0.125291, acc 0.96875\n",
      "2017-04-03T20:44:31.418301: step 23211, loss 0.069269, acc 1\n",
      "2017-04-03T20:44:31.619823: step 23212, loss 0.114725, acc 0.984375\n",
      "2017-04-03T20:44:31.823817: step 23213, loss 0.299519, acc 0.96875\n",
      "2017-04-03T20:44:32.029247: step 23214, loss 0.0359836, acc 1\n",
      "2017-04-03T20:44:32.251934: step 23215, loss 0.0559249, acc 0.96875\n",
      "2017-04-03T20:44:32.469391: step 23216, loss 0.0453023, acc 1\n",
      "2017-04-03T20:44:32.681902: step 23217, loss 0.160218, acc 0.9375\n",
      "2017-04-03T20:44:32.897389: step 23218, loss 0.0626584, acc 0.96875\n",
      "2017-04-03T20:44:33.104562: step 23219, loss 0.0653192, acc 0.984375\n",
      "2017-04-03T20:44:33.310547: step 23220, loss 0.0852395, acc 0.96875\n",
      "2017-04-03T20:44:33.511729: step 23221, loss 0.13857, acc 0.96875\n",
      "2017-04-03T20:44:33.714685: step 23222, loss 0.049024, acc 0.984375\n",
      "2017-04-03T20:44:33.953463: step 23223, loss 0.068735, acc 0.96875\n",
      "2017-04-03T20:44:34.163269: step 23224, loss 0.169582, acc 0.9375\n",
      "2017-04-03T20:44:34.367765: step 23225, loss 0.0543481, acc 0.984375\n",
      "2017-04-03T20:44:34.571113: step 23226, loss 0.0458596, acc 0.984375\n",
      "2017-04-03T20:44:34.776739: step 23227, loss 0.124268, acc 0.953125\n",
      "2017-04-03T20:44:34.976684: step 23228, loss 0.0667169, acc 0.984375\n",
      "2017-04-03T20:44:35.188056: step 23229, loss 0.0453579, acc 0.984375\n",
      "2017-04-03T20:44:35.404829: step 23230, loss 0.0943682, acc 0.953125\n",
      "2017-04-03T20:44:35.610527: step 23231, loss 0.184439, acc 0.921875\n",
      "2017-04-03T20:44:35.856721: step 23232, loss 0.0641662, acc 0.984375\n",
      "2017-04-03T20:44:36.062764: step 23233, loss 0.0595163, acc 0.984375\n",
      "2017-04-03T20:44:36.264376: step 23234, loss 0.165715, acc 0.9375\n",
      "2017-04-03T20:44:36.465810: step 23235, loss 0.0364674, acc 1\n",
      "2017-04-03T20:44:36.681944: step 23236, loss 0.0810373, acc 0.96875\n",
      "2017-04-03T20:44:36.892020: step 23237, loss 0.0440487, acc 0.984375\n",
      "2017-04-03T20:44:37.098145: step 23238, loss 0.0281282, acc 0.984375\n",
      "2017-04-03T20:44:37.309224: step 23239, loss 0.152689, acc 0.984375\n",
      "2017-04-03T20:44:37.515321: step 23240, loss 0.040534, acc 0.984375\n",
      "2017-04-03T20:44:37.715960: step 23241, loss 0.0274193, acc 1\n",
      "2017-04-03T20:44:37.928089: step 23242, loss 0.0759678, acc 0.984375\n",
      "2017-04-03T20:44:38.134304: step 23243, loss 0.0827608, acc 0.953125\n",
      "2017-04-03T20:44:38.350414: step 23244, loss 0.0190919, acc 1\n",
      "2017-04-03T20:44:38.554021: step 23245, loss 0.149183, acc 0.96875\n",
      "2017-04-03T20:44:38.794963: step 23246, loss 0.0243019, acc 1\n",
      "2017-04-03T20:44:39.003541: step 23247, loss 0.0528512, acc 0.984375\n",
      "2017-04-03T20:44:39.205720: step 23248, loss 0.15776, acc 0.953125\n",
      "2017-04-03T20:44:39.460449: step 23249, loss 0.0367991, acc 1\n",
      "2017-04-03T20:44:39.667260: step 23250, loss 0.0418183, acc 0.984375\n",
      "2017-04-03T20:44:39.877894: step 23251, loss 0.131049, acc 0.96875\n",
      "2017-04-03T20:44:40.082917: step 23252, loss 0.249774, acc 0.96875\n",
      "2017-04-03T20:44:40.287530: step 23253, loss 0.0607534, acc 0.96875\n",
      "2017-04-03T20:44:40.485191: step 23254, loss 0.19013, acc 0.984375\n",
      "2017-04-03T20:44:40.692271: step 23255, loss 0.0402539, acc 0.984375\n",
      "2017-04-03T20:44:40.900689: step 23256, loss 0.0731951, acc 0.96875\n",
      "2017-04-03T20:44:41.104259: step 23257, loss 0.0510043, acc 0.984375\n",
      "2017-04-03T20:44:41.312305: step 23258, loss 0.287849, acc 0.921875\n",
      "2017-04-03T20:44:41.529059: step 23259, loss 0.0502134, acc 0.984375\n",
      "2017-04-03T20:44:41.747027: step 23260, loss 0.0455154, acc 0.984375\n",
      "2017-04-03T20:44:41.963153: step 23261, loss 0.120326, acc 0.984375\n",
      "2017-04-03T20:44:42.177117: step 23262, loss 0.0769377, acc 0.96875\n",
      "2017-04-03T20:44:42.391152: step 23263, loss 0.0730611, acc 0.96875\n",
      "2017-04-03T20:44:42.654113: step 23264, loss 0.0790364, acc 0.984375\n",
      "2017-04-03T20:44:42.856233: step 23265, loss 0.0379244, acc 0.984375\n",
      "2017-04-03T20:44:43.103276: step 23266, loss 0.148141, acc 0.96875\n",
      "2017-04-03T20:44:43.316483: step 23267, loss 0.0871555, acc 0.953125\n",
      "2017-04-03T20:44:43.532663: step 23268, loss 0.0628743, acc 0.96875\n",
      "2017-04-03T20:44:43.759058: step 23269, loss 0.088214, acc 0.96875\n",
      "2017-04-03T20:44:43.975005: step 23270, loss 0.0747454, acc 0.96875\n",
      "2017-04-03T20:44:44.195467: step 23271, loss 0.0508173, acc 0.984375\n",
      "2017-04-03T20:44:44.398923: step 23272, loss 0.115015, acc 0.953125\n",
      "2017-04-03T20:44:44.606673: step 23273, loss 0.0342556, acc 1\n",
      "2017-04-03T20:44:44.824896: step 23274, loss 0.0731746, acc 0.984375\n",
      "2017-04-03T20:44:45.028122: step 23275, loss 0.14361, acc 0.953125\n",
      "2017-04-03T20:44:45.238689: step 23276, loss 0.0825949, acc 0.953125\n",
      "2017-04-03T20:44:45.444643: step 23277, loss 0.0430778, acc 0.984375\n",
      "2017-04-03T20:44:45.647168: step 23278, loss 0.105752, acc 0.96875\n",
      "2017-04-03T20:44:45.851338: step 23279, loss 0.0794303, acc 0.953125\n",
      "2017-04-03T20:44:46.080229: step 23280, loss 0.277988, acc 0.96875\n",
      "2017-04-03T20:44:46.330773: step 23281, loss 0.0617877, acc 0.984375\n",
      "2017-04-03T20:44:46.535648: step 23282, loss 0.0256934, acc 1\n",
      "2017-04-03T20:44:46.744853: step 23283, loss 0.0720113, acc 0.96875\n",
      "2017-04-03T20:44:46.947616: step 23284, loss 0.0123307, acc 1\n",
      "2017-04-03T20:44:47.149097: step 23285, loss 0.06231, acc 0.984375\n",
      "2017-04-03T20:44:47.351289: step 23286, loss 0.0299605, acc 0.984375\n",
      "2017-04-03T20:44:47.559853: step 23287, loss 0.0402369, acc 0.984375\n",
      "2017-04-03T20:44:47.800044: step 23288, loss 0.0374018, acc 1\n",
      "2017-04-03T20:44:48.003166: step 23289, loss 0.0476792, acc 0.984375\n",
      "2017-04-03T20:44:48.213289: step 23290, loss 0.011726, acc 1\n",
      "2017-04-03T20:44:48.420069: step 23291, loss 0.286823, acc 0.96875\n",
      "2017-04-03T20:44:48.628096: step 23292, loss 0.101082, acc 0.953125\n",
      "2017-04-03T20:44:48.843678: step 23293, loss 0.343593, acc 0.984375\n",
      "2017-04-03T20:44:49.105918: step 23294, loss 0.0591695, acc 0.984375\n",
      "2017-04-03T20:44:49.317250: step 23295, loss 0.0341368, acc 0.984375\n",
      "2017-04-03T20:44:49.526784: step 23296, loss 0.133842, acc 0.921875\n",
      "2017-04-03T20:44:49.733024: step 23297, loss 0.184033, acc 0.953125\n",
      "2017-04-03T20:44:49.937427: step 23298, loss 0.208886, acc 0.9375\n",
      "2017-04-03T20:44:50.142682: step 23299, loss 0.0856867, acc 0.96875\n",
      "2017-04-03T20:44:50.352786: step 23300, loss 0.31293, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:44:52.534980: step 23300, loss 8.35507, acc 0.28125\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-23300\n",
      "\n",
      "2017-04-03T20:44:52.932946: step 23301, loss 0.254159, acc 0.96875\n",
      "2017-04-03T20:44:53.146719: step 23302, loss 0.0442792, acc 0.984375\n",
      "2017-04-03T20:44:53.359655: step 23303, loss 0.0853023, acc 0.96875\n",
      "2017-04-03T20:44:53.575460: step 23304, loss 0.00847246, acc 1\n",
      "2017-04-03T20:44:53.787988: step 23305, loss 0.0735399, acc 0.984375\n",
      "2017-04-03T20:44:54.039234: step 23306, loss 0.0485913, acc 0.984375\n",
      "2017-04-03T20:44:54.285961: step 23307, loss 0.02072, acc 1\n",
      "2017-04-03T20:44:54.500298: step 23308, loss 0.0829003, acc 0.96875\n",
      "2017-04-03T20:44:54.704289: step 23309, loss 0.0613605, acc 0.96875\n",
      "2017-04-03T20:44:54.908743: step 23310, loss 0.16788, acc 0.9375\n",
      "2017-04-03T20:44:55.114989: step 23311, loss 0.149517, acc 0.984375\n",
      "2017-04-03T20:44:55.322211: step 23312, loss 0.0480323, acc 0.96875\n",
      "2017-04-03T20:44:55.522949: step 23313, loss 0.0272328, acc 1\n",
      "2017-04-03T20:44:55.724967: step 23314, loss 0.0264267, acc 1\n",
      "2017-04-03T20:44:55.925516: step 23315, loss 0.196414, acc 0.953125\n",
      "2017-04-03T20:44:56.128652: step 23316, loss 0.02627, acc 0.984375\n",
      "2017-04-03T20:44:56.329185: step 23317, loss 0.0281309, acc 0.984375\n",
      "2017-04-03T20:44:56.528839: step 23318, loss 0.0300292, acc 1\n",
      "2017-04-03T20:44:56.771243: step 23319, loss 0.0163845, acc 1\n",
      "2017-04-03T20:44:56.982656: step 23320, loss 0.119061, acc 0.953125\n",
      "2017-04-03T20:44:57.227992: step 23321, loss 0.0557096, acc 0.984375\n",
      "2017-04-03T20:44:57.450983: step 23322, loss 0.0344364, acc 0.984375\n",
      "2017-04-03T20:44:57.664644: step 23323, loss 0.0969046, acc 0.984375\n",
      "2017-04-03T20:44:57.872577: step 23324, loss 0.0504272, acc 0.984375\n",
      "2017-04-03T20:44:58.075747: step 23325, loss 0.25671, acc 0.9375\n",
      "2017-04-03T20:44:58.287320: step 23326, loss 0.159878, acc 0.96875\n",
      "2017-04-03T20:44:58.541519: step 23327, loss 0.031796, acc 1\n",
      "2017-04-03T20:44:58.764789: step 23328, loss 0.0817978, acc 0.96875\n",
      "2017-04-03T20:44:58.968915: step 23329, loss 0.0943118, acc 0.96875\n",
      "2017-04-03T20:44:59.175327: step 23330, loss 0.178635, acc 0.953125\n",
      "2017-04-03T20:44:59.387021: step 23331, loss 0.0344178, acc 0.984375\n",
      "2017-04-03T20:44:59.588345: step 23332, loss 0.0672532, acc 0.984375\n",
      "2017-04-03T20:44:59.790000: step 23333, loss 0.177552, acc 0.890625\n",
      "2017-04-03T20:45:00.001271: step 23334, loss 0.0575878, acc 0.984375\n",
      "2017-04-03T20:45:00.206816: step 23335, loss 0.0630573, acc 0.96875\n",
      "2017-04-03T20:45:00.406429: step 23336, loss 0.149492, acc 0.96875\n",
      "2017-04-03T20:45:00.610200: step 23337, loss 0.0987235, acc 0.953125\n",
      "2017-04-03T20:45:00.815658: step 23338, loss 0.125834, acc 0.953125\n",
      "2017-04-03T20:45:01.016920: step 23339, loss 0.220658, acc 0.921875\n",
      "2017-04-03T20:45:01.220461: step 23340, loss 0.0813911, acc 0.96875\n",
      "2017-04-03T20:45:01.421809: step 23341, loss 0.103556, acc 0.984375\n",
      "2017-04-03T20:45:01.623636: step 23342, loss 0.120176, acc 0.953125\n",
      "2017-04-03T20:45:01.828394: step 23343, loss 0.0527879, acc 0.96875\n",
      "2017-04-03T20:45:02.038110: step 23344, loss 0.154556, acc 0.9375\n",
      "2017-04-03T20:45:02.244871: step 23345, loss 0.0438766, acc 0.984375\n",
      "2017-04-03T20:45:02.450307: step 23346, loss 0.0968603, acc 0.9375\n",
      "2017-04-03T20:45:02.652655: step 23347, loss 0.103603, acc 0.96875\n",
      "2017-04-03T20:45:02.870696: step 23348, loss 0.036759, acc 1\n",
      "2017-04-03T20:45:03.117947: step 23349, loss 0.0183758, acc 1\n",
      "2017-04-03T20:45:03.325909: step 23350, loss 0.107765, acc 0.96875\n",
      "2017-04-03T20:45:03.525947: step 23351, loss 0.0746038, acc 0.96875\n",
      "2017-04-03T20:45:03.743554: step 23352, loss 0.0197255, acc 1\n",
      "2017-04-03T20:45:03.949629: step 23353, loss 0.0830074, acc 0.96875\n",
      "2017-04-03T20:45:04.153069: step 23354, loss 0.0653326, acc 0.96875\n",
      "2017-04-03T20:45:04.352269: step 23355, loss 0.0838921, acc 0.96875\n",
      "2017-04-03T20:45:04.568442: step 23356, loss 0.0239801, acc 1\n",
      "2017-04-03T20:45:04.778224: step 23357, loss 0.0634099, acc 0.984375\n",
      "2017-04-03T20:45:04.985693: step 23358, loss 0.0204597, acc 1\n",
      "2017-04-03T20:45:05.190285: step 23359, loss 0.201144, acc 0.96875\n",
      "2017-04-03T20:45:05.394644: step 23360, loss 0.0990783, acc 0.953125\n",
      "2017-04-03T20:45:05.594251: step 23361, loss 0.0733026, acc 0.984375\n",
      "2017-04-03T20:45:05.802850: step 23362, loss 0.0754979, acc 0.984375\n",
      "2017-04-03T20:45:06.013946: step 23363, loss 0.00703539, acc 1\n",
      "2017-04-03T20:45:06.213912: step 23364, loss 0.0818981, acc 0.96875\n",
      "2017-04-03T20:45:06.418931: step 23365, loss 0.0336383, acc 0.984375\n",
      "2017-04-03T20:45:06.624543: step 23366, loss 0.0462002, acc 0.984375\n",
      "2017-04-03T20:45:06.871151: step 23367, loss 0.0356541, acc 1\n",
      "2017-04-03T20:45:07.089891: step 23368, loss 0.103724, acc 0.96875\n",
      "2017-04-03T20:45:07.296215: step 23369, loss 0.122548, acc 0.96875\n",
      "2017-04-03T20:45:07.505923: step 23370, loss 0.0964806, acc 0.984375\n",
      "2017-04-03T20:45:07.709883: step 23371, loss 0.0465206, acc 0.984375\n",
      "2017-04-03T20:45:07.928953: step 23372, loss 0.075091, acc 0.96875\n",
      "2017-04-03T20:45:08.143434: step 23373, loss 0.221945, acc 0.953125\n",
      "2017-04-03T20:45:08.350676: step 23374, loss 0.0465948, acc 0.984375\n",
      "2017-04-03T20:45:08.554216: step 23375, loss 0.0391695, acc 0.984375\n",
      "2017-04-03T20:45:08.758863: step 23376, loss 0.0456811, acc 0.984375\n",
      "2017-04-03T20:45:08.962352: step 23377, loss 0.0202502, acc 1\n",
      "2017-04-03T20:45:09.165600: step 23378, loss 0.0323085, acc 1\n",
      "2017-04-03T20:45:09.366442: step 23379, loss 0.0598541, acc 0.96875\n",
      "2017-04-03T20:45:09.573912: step 23380, loss 0.0334738, acc 0.984375\n",
      "2017-04-03T20:45:09.779700: step 23381, loss 0.0735366, acc 0.984375\n",
      "2017-04-03T20:45:09.983171: step 23382, loss 0.00530916, acc 1\n",
      "2017-04-03T20:45:10.189417: step 23383, loss 0.32077, acc 0.9375\n",
      "2017-04-03T20:45:10.416739: step 23384, loss 0.143964, acc 0.953125\n",
      "2017-04-03T20:45:10.631338: step 23385, loss 0.0584076, acc 0.984375\n",
      "2017-04-03T20:45:10.850622: step 23386, loss 0.0606504, acc 0.96875\n",
      "2017-04-03T20:45:11.064027: step 23387, loss 0.17974, acc 0.9375\n",
      "2017-04-03T20:45:11.270891: step 23388, loss 0.0641227, acc 0.984375\n",
      "2017-04-03T20:45:11.478003: step 23389, loss 0.0286207, acc 1\n",
      "2017-04-03T20:45:11.719980: step 23390, loss 0.0460458, acc 1\n",
      "2017-04-03T20:45:11.971192: step 23391, loss 0.17827, acc 0.90625\n",
      "2017-04-03T20:45:12.178700: step 23392, loss 0.0400945, acc 1\n",
      "2017-04-03T20:45:12.385294: step 23393, loss 0.0309728, acc 0.984375\n",
      "2017-04-03T20:45:12.593596: step 23394, loss 0.108534, acc 0.953125\n",
      "2017-04-03T20:45:12.849090: step 23395, loss 0.0638641, acc 0.984375\n",
      "2017-04-03T20:45:13.089126: step 23396, loss 0.0432409, acc 1\n",
      "2017-04-03T20:45:13.299524: step 23397, loss 0.152748, acc 0.984375\n",
      "2017-04-03T20:45:13.503468: step 23398, loss 0.045413, acc 0.984375\n",
      "2017-04-03T20:45:13.716272: step 23399, loss 0.106043, acc 0.953125\n",
      "2017-04-03T20:45:13.958437: step 23400, loss 0.176197, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:45:16.078625: step 23400, loss 8.32073, acc 0.27475\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-23400\n",
      "\n",
      "2017-04-03T20:45:16.422139: step 23401, loss 0.0396233, acc 0.984375\n",
      "2017-04-03T20:45:16.653304: step 23402, loss 0.0892637, acc 0.984375\n",
      "2017-04-03T20:45:16.874410: step 23403, loss 0.0779414, acc 0.953125\n",
      "2017-04-03T20:45:17.083421: step 23404, loss 0.16718, acc 0.953125\n",
      "2017-04-03T20:45:17.344604: step 23405, loss 0.0804038, acc 0.984375\n",
      "2017-04-03T20:45:17.548847: step 23406, loss 0.117027, acc 0.984375\n",
      "2017-04-03T20:45:17.749929: step 23407, loss 0.0908106, acc 0.96875\n",
      "2017-04-03T20:45:17.953380: step 23408, loss 0.0560713, acc 0.984375\n",
      "2017-04-03T20:45:18.159936: step 23409, loss 0.0942431, acc 0.953125\n",
      "2017-04-03T20:45:18.408839: step 23410, loss 0.0736434, acc 0.984375\n",
      "2017-04-03T20:45:18.610136: step 23411, loss 0.0420307, acc 0.984375\n",
      "2017-04-03T20:45:18.856171: step 23412, loss 0.106791, acc 0.96875\n",
      "2017-04-03T20:45:19.070968: step 23413, loss 0.0694745, acc 0.984375\n",
      "2017-04-03T20:45:19.269780: step 23414, loss 0.105984, acc 0.96875\n",
      "2017-04-03T20:45:19.475446: step 23415, loss 0.289883, acc 0.9375\n",
      "2017-04-03T20:45:19.675211: step 23416, loss 0.0327317, acc 1\n",
      "2017-04-03T20:45:19.883539: step 23417, loss 0.052422, acc 0.984375\n",
      "2017-04-03T20:45:20.084720: step 23418, loss 0.132266, acc 0.953125\n",
      "2017-04-03T20:45:20.297032: step 23419, loss 0.00581302, acc 1\n",
      "2017-04-03T20:45:20.522539: step 23420, loss 0.10058, acc 0.96875\n",
      "2017-04-03T20:45:20.737940: step 23421, loss 0.083894, acc 0.96875\n",
      "2017-04-03T20:45:20.940987: step 23422, loss 0.0265827, acc 1\n",
      "2017-04-03T20:45:21.138647: step 23423, loss 0.0613318, acc 0.96875\n",
      "2017-04-03T20:45:21.340711: step 23424, loss 0.114406, acc 0.96875\n",
      "2017-04-03T20:45:21.552469: step 23425, loss 0.0477152, acc 0.984375\n",
      "2017-04-03T20:45:21.757479: step 23426, loss 0.0696825, acc 0.984375\n",
      "2017-04-03T20:45:21.961867: step 23427, loss 0.167671, acc 0.953125\n",
      "2017-04-03T20:45:22.170219: step 23428, loss 0.0960616, acc 0.953125\n",
      "2017-04-03T20:45:22.369446: step 23429, loss 0.0793439, acc 0.96875\n",
      "2017-04-03T20:45:22.598054: step 23430, loss 0.0483929, acc 0.984375\n",
      "2017-04-03T20:45:22.813321: step 23431, loss 0.0526305, acc 0.984375\n",
      "2017-04-03T20:45:23.017344: step 23432, loss 0.0982779, acc 0.984375\n",
      "2017-04-03T20:45:23.221855: step 23433, loss 0.115624, acc 0.984375\n",
      "2017-04-03T20:45:23.437495: step 23434, loss 0.0604201, acc 0.953125\n",
      "2017-04-03T20:45:23.648593: step 23435, loss 0.100933, acc 0.953125\n",
      "2017-04-03T20:45:23.852840: step 23436, loss 0.0805824, acc 0.984375\n",
      "2017-04-03T20:45:24.058422: step 23437, loss 0.24498, acc 0.9375\n",
      "2017-04-03T20:45:24.274707: step 23438, loss 0.0159347, acc 1\n",
      "2017-04-03T20:45:24.537938: step 23439, loss 0.0726334, acc 0.984375\n",
      "2017-04-03T20:45:24.743472: step 23440, loss 0.0722009, acc 0.984375\n",
      "2017-04-03T20:45:24.951850: step 23441, loss 0.147401, acc 0.953125\n",
      "2017-04-03T20:45:25.162927: step 23442, loss 0.0540492, acc 1\n",
      "2017-04-03T20:45:25.378737: step 23443, loss 0.046009, acc 0.984375\n",
      "2017-04-03T20:45:25.599613: step 23444, loss 0.100925, acc 0.984375\n",
      "2017-04-03T20:45:25.845906: step 23445, loss 0.277948, acc 0.953125\n",
      "2017-04-03T20:45:26.056498: step 23446, loss 0.0660166, acc 0.984375\n",
      "2017-04-03T20:45:26.271607: step 23447, loss 0.083825, acc 0.953125\n",
      "2017-04-03T20:45:26.515018: step 23448, loss 0.0733547, acc 0.96875\n",
      "2017-04-03T20:45:26.724800: step 23449, loss 0.176735, acc 0.9375\n",
      "2017-04-03T20:45:26.956524: step 23450, loss 0.0891069, acc 0.953125\n",
      "2017-04-03T20:45:27.165780: step 23451, loss 0.0905796, acc 0.96875\n",
      "2017-04-03T20:45:27.371998: step 23452, loss 0.0812888, acc 0.953125\n",
      "2017-04-03T20:45:27.576901: step 23453, loss 0.135389, acc 0.96875\n",
      "2017-04-03T20:45:27.793240: step 23454, loss 0.153995, acc 0.953125\n",
      "2017-04-03T20:45:28.011296: step 23455, loss 0.0774597, acc 0.953125\n",
      "2017-04-03T20:45:28.211986: step 23456, loss 0.0461094, acc 0.96875\n",
      "2017-04-03T20:45:28.434207: step 23457, loss 0.12573, acc 0.96875\n",
      "2017-04-03T20:45:28.637524: step 23458, loss 0.105657, acc 0.953125\n",
      "2017-04-03T20:45:28.887039: step 23459, loss 0.072275, acc 0.984375\n",
      "2017-04-03T20:45:29.102145: step 23460, loss 0.0779398, acc 0.9375\n",
      "2017-04-03T20:45:29.313432: step 23461, loss 0.0649831, acc 0.984375\n",
      "2017-04-03T20:45:29.532857: step 23462, loss 0.112845, acc 0.96875\n",
      "2017-04-03T20:45:29.746792: step 23463, loss 0.108379, acc 0.953125\n",
      "2017-04-03T20:45:29.963996: step 23464, loss 0.074179, acc 0.96875\n",
      "2017-04-03T20:45:30.183457: step 23465, loss 0.0828336, acc 0.96875\n",
      "2017-04-03T20:45:30.395424: step 23466, loss 0.0457266, acc 0.984375\n",
      "2017-04-03T20:45:30.598274: step 23467, loss 0.0550907, acc 0.96875\n",
      "2017-04-03T20:45:30.818750: step 23468, loss 0.0877695, acc 0.984375\n",
      "2017-04-03T20:45:31.028352: step 23469, loss 0.0171306, acc 1\n",
      "2017-04-03T20:45:31.248937: step 23470, loss 0.0869075, acc 0.96875\n",
      "2017-04-03T20:45:31.471231: step 23471, loss 0.0705858, acc 0.96875\n",
      "2017-04-03T20:45:31.692876: step 23472, loss 0.0634328, acc 0.984375\n",
      "2017-04-03T20:45:31.906868: step 23473, loss 0.13451, acc 0.984375\n",
      "2017-04-03T20:45:32.128901: step 23474, loss 0.0403548, acc 1\n",
      "2017-04-03T20:45:32.335937: step 23475, loss 0.116079, acc 0.953125\n",
      "2017-04-03T20:45:32.538445: step 23476, loss 0.0932321, acc 0.984375\n",
      "2017-04-03T20:45:32.742165: step 23477, loss 0.0414381, acc 0.984375\n",
      "2017-04-03T20:45:32.943519: step 23478, loss 0.148511, acc 0.9375\n",
      "2017-04-03T20:45:33.146806: step 23479, loss 0.161084, acc 0.953125\n",
      "2017-04-03T20:45:33.361705: step 23480, loss 0.129262, acc 0.984375\n",
      "2017-04-03T20:45:33.581392: step 23481, loss 0.109584, acc 0.953125\n",
      "2017-04-03T20:45:33.812191: step 23482, loss 0.0910513, acc 0.96875\n",
      "2017-04-03T20:45:34.031217: step 23483, loss 0.0518544, acc 0.96875\n",
      "2017-04-03T20:45:34.267566: step 23484, loss 0.0801995, acc 0.96875\n",
      "2017-04-03T20:45:34.482177: step 23485, loss 0.107419, acc 0.96875\n",
      "2017-04-03T20:45:34.694967: step 23486, loss 0.106364, acc 0.953125\n",
      "2017-04-03T20:45:34.910479: step 23487, loss 0.0505448, acc 0.984375\n",
      "2017-04-03T20:45:35.108670: step 23488, loss 0.0677568, acc 0.96875\n",
      "2017-04-03T20:45:35.321077: step 23489, loss 0.104821, acc 0.953125\n",
      "2017-04-03T20:45:35.529446: step 23490, loss 0.0389956, acc 0.984375\n",
      "2017-04-03T20:45:35.732863: step 23491, loss 0.0737906, acc 0.984375\n",
      "2017-04-03T20:45:35.948128: step 23492, loss 0.137354, acc 0.984375\n",
      "2017-04-03T20:45:36.153430: step 23493, loss 0.116743, acc 0.953125\n",
      "2017-04-03T20:45:36.361709: step 23494, loss 0.153887, acc 0.953125\n",
      "2017-04-03T20:45:36.576454: step 23495, loss 0.0963933, acc 0.96875\n",
      "2017-04-03T20:45:36.785911: step 23496, loss 0.106041, acc 0.96875\n",
      "2017-04-03T20:45:36.993931: step 23497, loss 0.0581863, acc 0.96875\n",
      "2017-04-03T20:45:37.202923: step 23498, loss 0.0196724, acc 1\n",
      "2017-04-03T20:45:37.410002: step 23499, loss 0.045845, acc 1\n",
      "2017-04-03T20:45:37.621368: step 23500, loss 0.12934, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:45:39.759518: step 23500, loss 8.40172, acc 0.28\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-23500\n",
      "\n",
      "2017-04-03T20:45:40.097786: step 23501, loss 0.0923633, acc 0.96875\n",
      "2017-04-03T20:45:40.306240: step 23502, loss 0.119709, acc 0.96875\n",
      "2017-04-03T20:45:40.520476: step 23503, loss 0.0662381, acc 0.96875\n",
      "2017-04-03T20:45:40.724935: step 23504, loss 0.111538, acc 0.953125\n",
      "2017-04-03T20:45:40.928265: step 23505, loss 0.126644, acc 0.9375\n",
      "2017-04-03T20:45:41.130727: step 23506, loss 0.020923, acc 1\n",
      "2017-04-03T20:45:41.338577: step 23507, loss 0.336146, acc 0.921875\n",
      "2017-04-03T20:45:41.548195: step 23508, loss 0.14663, acc 0.953125\n",
      "2017-04-03T20:45:41.755270: step 23509, loss 0.0260789, acc 1\n",
      "2017-04-03T20:45:41.957130: step 23510, loss 0.164716, acc 0.9375\n",
      "2017-04-03T20:45:42.163718: step 23511, loss 0.205937, acc 0.921875\n",
      "2017-04-03T20:45:42.410534: step 23512, loss 0.0163574, acc 1\n",
      "2017-04-03T20:45:42.620387: step 23513, loss 0.0618168, acc 0.984375\n",
      "2017-04-03T20:45:42.834014: step 23514, loss 0.110568, acc 0.984375\n",
      "2017-04-03T20:45:43.045716: step 23515, loss 0.219528, acc 0.953125\n",
      "2017-04-03T20:45:43.255121: step 23516, loss 0.169467, acc 0.953125\n",
      "2017-04-03T20:45:43.461294: step 23517, loss 0.0386499, acc 0.96875\n",
      "2017-04-03T20:45:43.665887: step 23518, loss 0.120281, acc 0.984375\n",
      "2017-04-03T20:45:43.915085: step 23519, loss 0.0368236, acc 0.984375\n",
      "2017-04-03T20:45:44.132982: step 23520, loss 0.0550725, acc 0.984375\n",
      "2017-04-03T20:45:44.356994: step 23521, loss 0.152102, acc 0.9375\n",
      "2017-04-03T20:45:44.568474: step 23522, loss 0.177855, acc 0.953125\n",
      "2017-04-03T20:45:44.818369: step 23523, loss 0.0608547, acc 0.984375\n",
      "2017-04-03T20:45:45.031180: step 23524, loss 0.0502264, acc 0.984375\n",
      "2017-04-03T20:45:45.241256: step 23525, loss 0.21837, acc 0.953125\n",
      "2017-04-03T20:45:45.462779: step 23526, loss 0.0696813, acc 0.984375\n",
      "2017-04-03T20:45:45.696239: step 23527, loss 0.066963, acc 0.96875\n",
      "2017-04-03T20:45:45.906735: step 23528, loss 0.0588057, acc 0.984375\n",
      "2017-04-03T20:45:46.125866: step 23529, loss 0.0943836, acc 0.9375\n",
      "2017-04-03T20:45:46.330898: step 23530, loss 0.102175, acc 0.96875\n",
      "2017-04-03T20:45:46.544173: step 23531, loss 0.191207, acc 0.953125\n",
      "2017-04-03T20:45:46.756243: step 23532, loss 0.0473971, acc 1\n",
      "2017-04-03T20:45:46.976739: step 23533, loss 0.0203932, acc 1\n",
      "2017-04-03T20:45:47.194401: step 23534, loss 0.0641659, acc 0.96875\n",
      "2017-04-03T20:45:47.400946: step 23535, loss 0.0733398, acc 0.984375\n",
      "2017-04-03T20:45:47.605156: step 23536, loss 0.0826717, acc 0.96875\n",
      "2017-04-03T20:45:47.844157: step 23537, loss 0.080073, acc 0.96875\n",
      "2017-04-03T20:45:48.056700: step 23538, loss 0.0680311, acc 0.96875\n",
      "2017-04-03T20:45:48.263347: step 23539, loss 0.0661827, acc 0.984375\n",
      "2017-04-03T20:45:48.471417: step 23540, loss 0.166739, acc 0.96875\n",
      "2017-04-03T20:45:48.677996: step 23541, loss 0.0520675, acc 1\n",
      "2017-04-03T20:45:48.879643: step 23542, loss 0.0574139, acc 0.984375\n",
      "2017-04-03T20:45:49.084128: step 23543, loss 0.0431062, acc 0.984375\n",
      "2017-04-03T20:45:49.285696: step 23544, loss 0.10103, acc 0.96875\n",
      "2017-04-03T20:45:49.489474: step 23545, loss 0.116423, acc 0.9375\n",
      "2017-04-03T20:45:49.699889: step 23546, loss 0.120996, acc 0.953125\n",
      "2017-04-03T20:45:49.902736: step 23547, loss 0.0336768, acc 0.984375\n",
      "2017-04-03T20:45:50.115133: step 23548, loss 0.105836, acc 0.9375\n",
      "2017-04-03T20:45:50.336477: step 23549, loss 0.0806033, acc 0.96875\n",
      "2017-04-03T20:45:50.552856: step 23550, loss 0.0258905, acc 1\n",
      "2017-04-03T20:45:50.802969: step 23551, loss 0.0391951, acc 1\n",
      "2017-04-03T20:45:51.011295: step 23552, loss 0.336744, acc 0.921875\n",
      "2017-04-03T20:45:51.215341: step 23553, loss 0.0327902, acc 1\n",
      "2017-04-03T20:45:51.422314: step 23554, loss 0.051243, acc 0.984375\n",
      "2017-04-03T20:45:51.627672: step 23555, loss 0.0489784, acc 0.984375\n",
      "2017-04-03T20:45:51.840345: step 23556, loss 0.0981423, acc 0.984375\n",
      "2017-04-03T20:45:52.048114: step 23557, loss 0.171391, acc 0.9375\n",
      "2017-04-03T20:45:52.267422: step 23558, loss 0.0342286, acc 0.984375\n",
      "2017-04-03T20:45:52.478134: step 23559, loss 0.0666635, acc 0.953125\n",
      "2017-04-03T20:45:52.696785: step 23560, loss 0.0855374, acc 0.984375\n",
      "2017-04-03T20:45:52.909192: step 23561, loss 0.173948, acc 0.953125\n",
      "2017-04-03T20:45:53.137022: step 23562, loss 0.0620701, acc 0.96875\n",
      "2017-04-03T20:45:53.359288: step 23563, loss 0.215772, acc 0.984375\n",
      "2017-04-03T20:45:53.572482: step 23564, loss 0.210522, acc 0.90625\n",
      "2017-04-03T20:45:53.774576: step 23565, loss 0.0527195, acc 0.96875\n",
      "2017-04-03T20:45:54.011852: step 23566, loss 0.0369613, acc 1\n",
      "2017-04-03T20:45:54.233820: step 23567, loss 0.0584108, acc 0.984375\n",
      "2017-04-03T20:45:54.440218: step 23568, loss 0.0713305, acc 0.96875\n",
      "2017-04-03T20:45:54.647076: step 23569, loss 0.159633, acc 0.953125\n",
      "2017-04-03T20:45:54.865840: step 23570, loss 0.121519, acc 0.953125\n",
      "2017-04-03T20:45:55.084572: step 23571, loss 0.0260559, acc 1\n",
      "2017-04-03T20:45:55.325852: step 23572, loss 0.0984895, acc 0.984375\n",
      "2017-04-03T20:45:55.540373: step 23573, loss 0.182004, acc 0.9375\n",
      "2017-04-03T20:45:55.748692: step 23574, loss 0.0750289, acc 0.953125\n",
      "2017-04-03T20:45:55.951252: step 23575, loss 0.0892115, acc 0.953125\n",
      "2017-04-03T20:45:56.159889: step 23576, loss 0.244515, acc 0.921875\n",
      "2017-04-03T20:45:56.363344: step 23577, loss 0.175821, acc 0.953125\n",
      "2017-04-03T20:45:56.571710: step 23578, loss 0.0386432, acc 1\n",
      "2017-04-03T20:45:56.777401: step 23579, loss 0.12029, acc 0.96875\n",
      "2017-04-03T20:45:56.985539: step 23580, loss 0.0768711, acc 0.984375\n",
      "2017-04-03T20:45:57.188692: step 23581, loss 0.0218432, acc 1\n",
      "2017-04-03T20:45:57.391589: step 23582, loss 0.191974, acc 0.953125\n",
      "2017-04-03T20:45:57.591724: step 23583, loss 0.113974, acc 0.953125\n",
      "2017-04-03T20:45:57.790529: step 23584, loss 0.207621, acc 0.9375\n",
      "2017-04-03T20:45:57.996902: step 23585, loss 0.20271, acc 0.90625\n",
      "2017-04-03T20:45:58.202496: step 23586, loss 0.108769, acc 0.953125\n",
      "2017-04-03T20:45:58.408375: step 23587, loss 0.107318, acc 0.953125\n",
      "2017-04-03T20:45:58.611972: step 23588, loss 0.510451, acc 0.953125\n",
      "2017-04-03T20:45:58.821663: step 23589, loss 0.0946872, acc 0.96875\n",
      "2017-04-03T20:45:59.028065: step 23590, loss 0.10945, acc 0.9375\n",
      "2017-04-03T20:45:59.275237: step 23591, loss 0.0564096, acc 0.96875\n",
      "2017-04-03T20:45:59.482672: step 23592, loss 0.114251, acc 0.984375\n",
      "2017-04-03T20:45:59.696484: step 23593, loss 0.0650831, acc 0.984375\n",
      "2017-04-03T20:45:59.940232: step 23594, loss 0.0614552, acc 0.96875\n",
      "2017-04-03T20:46:00.199961: step 23595, loss 0.135382, acc 0.953125\n",
      "2017-04-03T20:46:00.407562: step 23596, loss 0.0641479, acc 0.984375\n",
      "2017-04-03T20:46:00.617770: step 23597, loss 0.0533708, acc 0.984375\n",
      "2017-04-03T20:46:00.842441: step 23598, loss 0.0554253, acc 0.984375\n",
      "2017-04-03T20:46:01.100074: step 23599, loss 0.0609189, acc 0.984375\n",
      "2017-04-03T20:46:01.321339: step 23600, loss 0.137249, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:46:03.498872: step 23600, loss 8.42118, acc 0.285\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-23600\n",
      "\n",
      "2017-04-03T20:46:03.890879: step 23601, loss 0.0723823, acc 0.96875\n",
      "2017-04-03T20:46:04.131878: step 23602, loss 0.0674735, acc 0.96875\n",
      "2017-04-03T20:46:04.335692: step 23603, loss 0.0388837, acc 0.984375\n",
      "2017-04-03T20:46:04.546776: step 23604, loss 0.0761425, acc 0.984375\n",
      "2017-04-03T20:46:04.764389: step 23605, loss 0.125876, acc 0.96875\n",
      "2017-04-03T20:46:04.975628: step 23606, loss 0.075933, acc 0.984375\n",
      "2017-04-03T20:46:05.200808: step 23607, loss 0.101073, acc 0.984375\n",
      "2017-04-03T20:46:05.420304: step 23608, loss 0.370005, acc 0.953125\n",
      "2017-04-03T20:46:05.633251: step 23609, loss 0.0695937, acc 0.96875\n",
      "2017-04-03T20:46:05.840971: step 23610, loss 0.163934, acc 0.953125\n",
      "2017-04-03T20:46:06.051570: step 23611, loss 0.0314547, acc 0.984375\n",
      "2017-04-03T20:46:06.260976: step 23612, loss 0.0586699, acc 0.984375\n",
      "2017-04-03T20:46:06.463675: step 23613, loss 0.177981, acc 0.9375\n",
      "2017-04-03T20:46:06.667976: step 23614, loss 0.120948, acc 0.96875\n",
      "2017-04-03T20:46:06.872395: step 23615, loss 0.0910569, acc 0.953125\n",
      "2017-04-03T20:46:07.078763: step 23616, loss 0.170339, acc 0.953125\n",
      "2017-04-03T20:46:07.283905: step 23617, loss 0.017584, acc 1\n",
      "2017-04-03T20:46:07.489438: step 23618, loss 0.0632923, acc 0.96875\n",
      "2017-04-03T20:46:07.691052: step 23619, loss 0.0326974, acc 1\n",
      "2017-04-03T20:46:07.896335: step 23620, loss 0.0986803, acc 0.96875\n",
      "2017-04-03T20:46:08.097154: step 23621, loss 0.10257, acc 0.96875\n",
      "2017-04-03T20:46:08.299058: step 23622, loss 0.154015, acc 0.96875\n",
      "2017-04-03T20:46:08.500173: step 23623, loss 0.185796, acc 0.96875\n",
      "2017-04-03T20:46:08.709966: step 23624, loss 0.248802, acc 0.984375\n",
      "2017-04-03T20:46:08.922143: step 23625, loss 0.0660349, acc 0.96875\n",
      "2017-04-03T20:46:09.136450: step 23626, loss 0.0245704, acc 1\n",
      "2017-04-03T20:46:09.342881: step 23627, loss 0.145412, acc 0.953125\n",
      "2017-04-03T20:46:09.554461: step 23628, loss 0.151303, acc 0.96875\n",
      "2017-04-03T20:46:09.802086: step 23629, loss 0.11727, acc 0.9375\n",
      "2017-04-03T20:46:10.011364: step 23630, loss 0.14841, acc 0.9375\n",
      "2017-04-03T20:46:10.213237: step 23631, loss 0.184099, acc 0.953125\n",
      "2017-04-03T20:46:10.421560: step 23632, loss 0.179276, acc 0.9375\n",
      "2017-04-03T20:46:10.619719: step 23633, loss 0.0432375, acc 0.984375\n",
      "2017-04-03T20:46:10.828856: step 23634, loss 0.124968, acc 0.96875\n",
      "2017-04-03T20:46:11.030118: step 23635, loss 0.121603, acc 0.96875\n",
      "2017-04-03T20:46:11.237860: step 23636, loss 0.146859, acc 0.9375\n",
      "2017-04-03T20:46:11.439652: step 23637, loss 0.033509, acc 1\n",
      "2017-04-03T20:46:11.686408: step 23638, loss 0.061687, acc 0.984375\n",
      "2017-04-03T20:46:11.890980: step 23639, loss 0.343723, acc 0.921875\n",
      "2017-04-03T20:46:12.096852: step 23640, loss 0.0397293, acc 0.984375\n",
      "2017-04-03T20:46:12.305560: step 23641, loss 0.0206015, acc 1\n",
      "2017-04-03T20:46:12.512369: step 23642, loss 0.0504967, acc 0.96875\n",
      "2017-04-03T20:46:12.717292: step 23643, loss 0.0976499, acc 0.984375\n",
      "2017-04-03T20:46:12.920542: step 23644, loss 0.0456752, acc 1\n",
      "2017-04-03T20:46:13.167296: step 23645, loss 0.157142, acc 0.953125\n",
      "2017-04-03T20:46:13.311657: step 23646, loss 0.120306, acc 0.9375\n",
      "2017-04-03T20:46:13.522469: step 23647, loss 0.142074, acc 0.984375\n",
      "2017-04-03T20:46:13.744072: step 23648, loss 0.0587545, acc 0.984375\n",
      "2017-04-03T20:46:13.955987: step 23649, loss 0.0876682, acc 0.96875\n",
      "2017-04-03T20:46:14.162771: step 23650, loss 0.0289591, acc 0.984375\n",
      "2017-04-03T20:46:14.368498: step 23651, loss 0.480964, acc 0.953125\n",
      "2017-04-03T20:46:14.582000: step 23652, loss 0.0570036, acc 0.984375\n",
      "2017-04-03T20:46:14.791432: step 23653, loss 0.0653759, acc 0.96875\n",
      "2017-04-03T20:46:14.995693: step 23654, loss 0.0280235, acc 0.984375\n",
      "2017-04-03T20:46:15.201686: step 23655, loss 0.0501767, acc 0.984375\n",
      "2017-04-03T20:46:15.402891: step 23656, loss 0.0424465, acc 0.984375\n",
      "2017-04-03T20:46:15.604606: step 23657, loss 0.076525, acc 0.984375\n",
      "2017-04-03T20:46:15.843073: step 23658, loss 0.452121, acc 0.953125\n",
      "2017-04-03T20:46:16.058945: step 23659, loss 0.058077, acc 0.984375\n",
      "2017-04-03T20:46:16.275505: step 23660, loss 0.0873128, acc 0.96875\n",
      "2017-04-03T20:46:16.481215: step 23661, loss 0.0364236, acc 1\n",
      "2017-04-03T20:46:16.685733: step 23662, loss 0.154376, acc 0.953125\n",
      "2017-04-03T20:46:16.886917: step 23663, loss 0.1428, acc 0.953125\n",
      "2017-04-03T20:46:17.093988: step 23664, loss 0.064778, acc 0.984375\n",
      "2017-04-03T20:46:17.296110: step 23665, loss 0.0456602, acc 0.984375\n",
      "2017-04-03T20:46:17.503413: step 23666, loss 0.142561, acc 0.96875\n",
      "2017-04-03T20:46:17.712817: step 23667, loss 0.161259, acc 0.96875\n",
      "2017-04-03T20:46:17.959086: step 23668, loss 0.0593353, acc 0.984375\n",
      "2017-04-03T20:46:18.174244: step 23669, loss 0.0963818, acc 0.96875\n",
      "2017-04-03T20:46:18.380787: step 23670, loss 0.0238766, acc 1\n",
      "2017-04-03T20:46:18.585029: step 23671, loss 0.0679528, acc 0.96875\n",
      "2017-04-03T20:46:18.794093: step 23672, loss 0.0453213, acc 0.984375\n",
      "2017-04-03T20:46:18.998135: step 23673, loss 0.0810411, acc 0.984375\n",
      "2017-04-03T20:46:19.201650: step 23674, loss 0.215638, acc 0.96875\n",
      "2017-04-03T20:46:19.445560: step 23675, loss 0.029073, acc 0.984375\n",
      "2017-04-03T20:46:19.658125: step 23676, loss 0.0647885, acc 0.96875\n",
      "2017-04-03T20:46:19.860091: step 23677, loss 0.0438005, acc 1\n",
      "2017-04-03T20:46:20.065090: step 23678, loss 0.0318781, acc 1\n",
      "2017-04-03T20:46:20.267739: step 23679, loss 0.0175634, acc 1\n",
      "2017-04-03T20:46:20.481692: step 23680, loss 0.102569, acc 0.96875\n",
      "2017-04-03T20:46:20.693453: step 23681, loss 0.0311645, acc 1\n",
      "2017-04-03T20:46:20.901378: step 23682, loss 0.155184, acc 0.96875\n",
      "2017-04-03T20:46:21.103575: step 23683, loss 0.0712579, acc 0.984375\n",
      "2017-04-03T20:46:21.308056: step 23684, loss 0.105942, acc 0.96875\n",
      "2017-04-03T20:46:21.506611: step 23685, loss 0.0994557, acc 0.953125\n",
      "2017-04-03T20:46:21.713834: step 23686, loss 0.00596921, acc 1\n",
      "2017-04-03T20:46:21.921525: step 23687, loss 0.0744136, acc 0.984375\n",
      "2017-04-03T20:46:22.127678: step 23688, loss 0.0361478, acc 1\n",
      "2017-04-03T20:46:22.334743: step 23689, loss 0.0944239, acc 0.953125\n",
      "2017-04-03T20:46:22.534193: step 23690, loss 0.120091, acc 0.96875\n",
      "2017-04-03T20:46:22.762201: step 23691, loss 0.038161, acc 1\n",
      "2017-04-03T20:46:22.973506: step 23692, loss 0.0949048, acc 0.96875\n",
      "2017-04-03T20:46:23.180318: step 23693, loss 0.0816445, acc 0.96875\n",
      "2017-04-03T20:46:23.388065: step 23694, loss 0.0425292, acc 0.96875\n",
      "2017-04-03T20:46:23.590324: step 23695, loss 0.0316775, acc 1\n",
      "2017-04-03T20:46:23.793309: step 23696, loss 0.0379515, acc 0.984375\n",
      "2017-04-03T20:46:24.004768: step 23697, loss 0.0749842, acc 0.96875\n",
      "2017-04-03T20:46:24.207807: step 23698, loss 0.0614275, acc 0.984375\n",
      "2017-04-03T20:46:24.413861: step 23699, loss 0.074429, acc 0.96875\n",
      "2017-04-03T20:46:24.622214: step 23700, loss 0.0931318, acc 0.96875\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:46:26.785565: step 23700, loss 8.4528, acc 0.28275\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-23700\n",
      "\n",
      "2017-04-03T20:46:27.122306: step 23701, loss 0.0161093, acc 1\n",
      "2017-04-03T20:46:27.324542: step 23702, loss 0.124292, acc 0.984375\n",
      "2017-04-03T20:46:27.526490: step 23703, loss 0.0674224, acc 0.984375\n",
      "2017-04-03T20:46:27.732976: step 23704, loss 0.0269217, acc 1\n",
      "2017-04-03T20:46:27.936923: step 23705, loss 0.0278356, acc 0.984375\n",
      "2017-04-03T20:46:28.138073: step 23706, loss 0.0373365, acc 1\n",
      "2017-04-03T20:46:28.347824: step 23707, loss 0.080674, acc 0.96875\n",
      "2017-04-03T20:46:28.556192: step 23708, loss 0.0240137, acc 1\n",
      "2017-04-03T20:46:28.767425: step 23709, loss 0.0735331, acc 0.96875\n",
      "2017-04-03T20:46:28.971750: step 23710, loss 0.0552022, acc 0.984375\n",
      "2017-04-03T20:46:29.171568: step 23711, loss 0.0136531, acc 1\n",
      "2017-04-03T20:46:29.373514: step 23712, loss 0.0218129, acc 0.984375\n",
      "2017-04-03T20:46:29.577633: step 23713, loss 0.0549632, acc 0.96875\n",
      "2017-04-03T20:46:29.783648: step 23714, loss 0.0761473, acc 0.96875\n",
      "2017-04-03T20:46:29.989441: step 23715, loss 0.11087, acc 0.96875\n",
      "2017-04-03T20:46:30.192277: step 23716, loss 0.124192, acc 0.9375\n",
      "2017-04-03T20:46:30.398321: step 23717, loss 0.0989626, acc 0.96875\n",
      "2017-04-03T20:46:30.605964: step 23718, loss 0.0280748, acc 1\n",
      "2017-04-03T20:46:30.804613: step 23719, loss 0.261319, acc 0.96875\n",
      "2017-04-03T20:46:31.009878: step 23720, loss 0.186393, acc 0.953125\n",
      "2017-04-03T20:46:31.214628: step 23721, loss 0.0984851, acc 0.96875\n",
      "2017-04-03T20:46:31.422896: step 23722, loss 0.0476666, acc 0.984375\n",
      "2017-04-03T20:46:31.631248: step 23723, loss 0.0994696, acc 0.96875\n",
      "2017-04-03T20:46:31.839378: step 23724, loss 0.176181, acc 0.921875\n",
      "2017-04-03T20:46:32.046304: step 23725, loss 0.0280481, acc 1\n",
      "2017-04-03T20:46:32.264676: step 23726, loss 0.0266146, acc 0.984375\n",
      "2017-04-03T20:46:32.474257: step 23727, loss 0.0324635, acc 1\n",
      "2017-04-03T20:46:32.679575: step 23728, loss 0.139495, acc 0.953125\n",
      "2017-04-03T20:46:32.882397: step 23729, loss 0.236929, acc 0.984375\n",
      "2017-04-03T20:46:33.085803: step 23730, loss 0.0942372, acc 0.96875\n",
      "2017-04-03T20:46:33.288336: step 23731, loss 0.086145, acc 0.953125\n",
      "2017-04-03T20:46:33.495940: step 23732, loss 0.059201, acc 0.984375\n",
      "2017-04-03T20:46:33.702451: step 23733, loss 0.141427, acc 0.9375\n",
      "2017-04-03T20:46:33.903433: step 23734, loss 0.0657637, acc 0.96875\n",
      "2017-04-03T20:46:34.107265: step 23735, loss 0.0769055, acc 0.96875\n",
      "2017-04-03T20:46:34.323332: step 23736, loss 0.0638953, acc 0.984375\n",
      "2017-04-03T20:46:34.527768: step 23737, loss 0.0917109, acc 0.96875\n",
      "2017-04-03T20:46:34.776035: step 23738, loss 0.0424658, acc 0.984375\n",
      "2017-04-03T20:46:35.009735: step 23739, loss 0.0186487, acc 1\n",
      "2017-04-03T20:46:35.219480: step 23740, loss 0.0720132, acc 0.96875\n",
      "2017-04-03T20:46:35.428518: step 23741, loss 0.0238702, acc 0.984375\n",
      "2017-04-03T20:46:35.637173: step 23742, loss 0.207373, acc 0.984375\n",
      "2017-04-03T20:46:35.843043: step 23743, loss 0.0160389, acc 1\n",
      "2017-04-03T20:46:36.052741: step 23744, loss 0.0723352, acc 0.984375\n",
      "2017-04-03T20:46:36.261246: step 23745, loss 0.0302942, acc 1\n",
      "2017-04-03T20:46:36.465111: step 23746, loss 0.0692407, acc 0.984375\n",
      "2017-04-03T20:46:36.703292: step 23747, loss 0.0307067, acc 0.984375\n",
      "2017-04-03T20:46:36.908802: step 23748, loss 0.0826621, acc 0.984375\n",
      "2017-04-03T20:46:37.112984: step 23749, loss 0.0258009, acc 1\n",
      "2017-04-03T20:46:37.314551: step 23750, loss 0.060611, acc 0.984375\n",
      "2017-04-03T20:46:37.522107: step 23751, loss 0.120971, acc 0.96875\n",
      "2017-04-03T20:46:37.726430: step 23752, loss 0.148673, acc 0.953125\n",
      "2017-04-03T20:46:37.931480: step 23753, loss 0.0693113, acc 0.953125\n",
      "2017-04-03T20:46:38.135589: step 23754, loss 0.115288, acc 0.96875\n",
      "2017-04-03T20:46:38.340759: step 23755, loss 0.0527266, acc 0.984375\n",
      "2017-04-03T20:46:38.545050: step 23756, loss 0.0418314, acc 0.984375\n",
      "2017-04-03T20:46:38.746268: step 23757, loss 0.0965164, acc 0.96875\n",
      "2017-04-03T20:46:38.956494: step 23758, loss 0.150118, acc 0.953125\n",
      "2017-04-03T20:46:39.169008: step 23759, loss 0.00915151, acc 1\n",
      "2017-04-03T20:46:39.381239: step 23760, loss 0.0247352, acc 1\n",
      "2017-04-03T20:46:39.586527: step 23761, loss 0.134888, acc 0.953125\n",
      "2017-04-03T20:46:39.789401: step 23762, loss 0.0256264, acc 1\n",
      "2017-04-03T20:46:39.997388: step 23763, loss 0.060483, acc 0.984375\n",
      "2017-04-03T20:46:40.205106: step 23764, loss 0.0173817, acc 1\n",
      "2017-04-03T20:46:40.411923: step 23765, loss 0.143636, acc 0.953125\n",
      "2017-04-03T20:46:40.662479: step 23766, loss 0.112475, acc 0.953125\n",
      "2017-04-03T20:46:40.906487: step 23767, loss 0.0491724, acc 0.984375\n",
      "2017-04-03T20:46:41.112502: step 23768, loss 0.027514, acc 0.984375\n",
      "2017-04-03T20:46:41.324060: step 23769, loss 0.0126209, acc 1\n",
      "2017-04-03T20:46:41.533861: step 23770, loss 0.148158, acc 0.9375\n",
      "2017-04-03T20:46:41.739600: step 23771, loss 0.0365676, acc 1\n",
      "2017-04-03T20:46:41.941376: step 23772, loss 0.0574123, acc 0.984375\n",
      "2017-04-03T20:46:42.145356: step 23773, loss 0.0492206, acc 1\n",
      "2017-04-03T20:46:42.340500: step 23774, loss 0.109685, acc 0.953125\n",
      "2017-04-03T20:46:42.558122: step 23775, loss 0.0411107, acc 0.96875\n",
      "2017-04-03T20:46:42.764559: step 23776, loss 0.0352313, acc 1\n",
      "2017-04-03T20:46:42.967793: step 23777, loss 0.0462311, acc 0.96875\n",
      "2017-04-03T20:46:43.170831: step 23778, loss 0.00797253, acc 1\n",
      "2017-04-03T20:46:43.373188: step 23779, loss 0.115999, acc 0.96875\n",
      "2017-04-03T20:46:43.575867: step 23780, loss 0.107911, acc 0.96875\n",
      "2017-04-03T20:46:43.775638: step 23781, loss 0.16861, acc 0.921875\n",
      "2017-04-03T20:46:44.019270: step 23782, loss 0.0091991, acc 1\n",
      "2017-04-03T20:46:44.266871: step 23783, loss 0.0445355, acc 0.96875\n",
      "2017-04-03T20:46:44.470648: step 23784, loss 0.0389138, acc 0.984375\n",
      "2017-04-03T20:46:44.716236: step 23785, loss 0.0388699, acc 1\n",
      "2017-04-03T20:46:44.924659: step 23786, loss 0.0205942, acc 1\n",
      "2017-04-03T20:46:45.135458: step 23787, loss 0.151769, acc 0.96875\n",
      "2017-04-03T20:46:45.340196: step 23788, loss 0.0740899, acc 0.96875\n",
      "2017-04-03T20:46:45.544697: step 23789, loss 0.0605234, acc 0.984375\n",
      "2017-04-03T20:46:45.755257: step 23790, loss 0.154758, acc 0.984375\n",
      "2017-04-03T20:46:45.966244: step 23791, loss 0.056253, acc 0.984375\n",
      "2017-04-03T20:46:46.174771: step 23792, loss 0.0457692, acc 0.984375\n",
      "2017-04-03T20:46:46.394329: step 23793, loss 0.0797839, acc 0.984375\n",
      "2017-04-03T20:46:46.600756: step 23794, loss 0.0200932, acc 0.984375\n",
      "2017-04-03T20:46:46.811831: step 23795, loss 0.00986053, acc 1\n",
      "2017-04-03T20:46:47.019658: step 23796, loss 0.109922, acc 0.953125\n",
      "2017-04-03T20:46:47.227536: step 23797, loss 0.274018, acc 0.9375\n",
      "2017-04-03T20:46:47.429299: step 23798, loss 0.0906529, acc 0.96875\n",
      "2017-04-03T20:46:47.645968: step 23799, loss 0.0538198, acc 0.984375\n",
      "2017-04-03T20:46:47.842691: step 23800, loss 0.0429307, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:46:49.985320: step 23800, loss 8.52475, acc 0.27625\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-23800\n",
      "\n",
      "2017-04-03T20:46:50.413491: step 23801, loss 0.0292219, acc 1\n",
      "2017-04-03T20:46:50.615574: step 23802, loss 0.0362169, acc 0.984375\n",
      "2017-04-03T20:46:50.817987: step 23803, loss 0.0279153, acc 0.984375\n",
      "2017-04-03T20:46:51.072799: step 23804, loss 0.0492968, acc 0.984375\n",
      "2017-04-03T20:46:51.274612: step 23805, loss 0.100514, acc 0.96875\n",
      "2017-04-03T20:46:51.521150: step 23806, loss 0.0646316, acc 0.96875\n",
      "2017-04-03T20:46:51.723858: step 23807, loss 0.0790415, acc 0.984375\n",
      "2017-04-03T20:46:51.927029: step 23808, loss 0.123414, acc 0.984375\n",
      "2017-04-03T20:46:52.131019: step 23809, loss 0.144013, acc 0.9375\n",
      "2017-04-03T20:46:52.341624: step 23810, loss 0.11155, acc 0.953125\n",
      "2017-04-03T20:46:52.545408: step 23811, loss 0.0739786, acc 0.96875\n",
      "2017-04-03T20:46:52.749326: step 23812, loss 0.0898828, acc 0.96875\n",
      "2017-04-03T20:46:52.954952: step 23813, loss 0.0515974, acc 0.984375\n",
      "2017-04-03T20:46:53.158078: step 23814, loss 0.101705, acc 0.96875\n",
      "2017-04-03T20:46:53.362095: step 23815, loss 0.0227736, acc 1\n",
      "2017-04-03T20:46:53.567190: step 23816, loss 0.196985, acc 0.953125\n",
      "2017-04-03T20:46:53.768232: step 23817, loss 0.150622, acc 0.9375\n",
      "2017-04-03T20:46:53.969231: step 23818, loss 0.0733102, acc 0.984375\n",
      "2017-04-03T20:46:54.171537: step 23819, loss 0.0717703, acc 0.953125\n",
      "2017-04-03T20:46:54.376179: step 23820, loss 0.179048, acc 0.96875\n",
      "2017-04-03T20:46:54.602558: step 23821, loss 0.122763, acc 0.984375\n",
      "2017-04-03T20:46:54.846867: step 23822, loss 0.0787695, acc 0.96875\n",
      "2017-04-03T20:46:55.070594: step 23823, loss 0.265142, acc 0.921875\n",
      "2017-04-03T20:46:55.280769: step 23824, loss 0.110672, acc 0.984375\n",
      "2017-04-03T20:46:55.524241: step 23825, loss 0.0569654, acc 0.984375\n",
      "2017-04-03T20:46:55.726421: step 23826, loss 0.085113, acc 0.96875\n",
      "2017-04-03T20:46:55.930703: step 23827, loss 0.16685, acc 0.921875\n",
      "2017-04-03T20:46:56.130219: step 23828, loss 0.0615129, acc 0.984375\n",
      "2017-04-03T20:46:56.335666: step 23829, loss 0.0759382, acc 0.96875\n",
      "2017-04-03T20:46:56.541803: step 23830, loss 0.0917806, acc 0.96875\n",
      "2017-04-03T20:46:56.744309: step 23831, loss 0.109645, acc 0.96875\n",
      "2017-04-03T20:46:56.959083: step 23832, loss 0.0478773, acc 0.984375\n",
      "2017-04-03T20:46:57.176386: step 23833, loss 0.0176912, acc 1\n",
      "2017-04-03T20:46:57.390073: step 23834, loss 0.0697392, acc 0.96875\n",
      "2017-04-03T20:46:57.601968: step 23835, loss 0.0425512, acc 0.984375\n",
      "2017-04-03T20:46:57.799562: step 23836, loss 0.0195256, acc 1\n",
      "2017-04-03T20:46:58.003114: step 23837, loss 0.0625671, acc 0.96875\n",
      "2017-04-03T20:46:58.203429: step 23838, loss 0.137042, acc 0.9375\n",
      "2017-04-03T20:46:58.412683: step 23839, loss 0.436711, acc 0.96875\n",
      "2017-04-03T20:46:58.660932: step 23840, loss 0.0244233, acc 1\n",
      "2017-04-03T20:46:58.915756: step 23841, loss 0.113343, acc 0.984375\n",
      "2017-04-03T20:46:59.130850: step 23842, loss 0.079387, acc 0.96875\n",
      "2017-04-03T20:46:59.353520: step 23843, loss 0.0537245, acc 0.984375\n",
      "2017-04-03T20:46:59.575608: step 23844, loss 0.10471, acc 0.984375\n",
      "2017-04-03T20:46:59.790776: step 23845, loss 0.104941, acc 0.953125\n",
      "2017-04-03T20:47:00.029231: step 23846, loss 0.0986779, acc 0.96875\n",
      "2017-04-03T20:47:00.238332: step 23847, loss 0.0396968, acc 0.984375\n",
      "2017-04-03T20:47:00.438619: step 23848, loss 0.0320442, acc 0.984375\n",
      "2017-04-03T20:47:00.640065: step 23849, loss 0.0465817, acc 0.984375\n",
      "2017-04-03T20:47:00.841563: step 23850, loss 0.0594754, acc 0.96875\n",
      "2017-04-03T20:47:01.050963: step 23851, loss 0.270953, acc 0.953125\n",
      "2017-04-03T20:47:01.272381: step 23852, loss 0.070139, acc 0.96875\n",
      "2017-04-03T20:47:01.480273: step 23853, loss 0.0629483, acc 0.96875\n",
      "2017-04-03T20:47:01.682681: step 23854, loss 0.0522053, acc 0.984375\n",
      "2017-04-03T20:47:01.883055: step 23855, loss 0.0269157, acc 0.984375\n",
      "2017-04-03T20:47:02.091776: step 23856, loss 0.0719546, acc 0.953125\n",
      "2017-04-03T20:47:02.298842: step 23857, loss 0.0745144, acc 0.953125\n",
      "2017-04-03T20:47:02.504445: step 23858, loss 0.0384748, acc 0.984375\n",
      "2017-04-03T20:47:02.711960: step 23859, loss 0.0715434, acc 0.984375\n",
      "2017-04-03T20:47:02.918108: step 23860, loss 0.0924575, acc 0.96875\n",
      "2017-04-03T20:47:03.137833: step 23861, loss 0.0582442, acc 0.96875\n",
      "2017-04-03T20:47:03.347684: step 23862, loss 0.110796, acc 0.96875\n",
      "2017-04-03T20:47:03.559903: step 23863, loss 0.0477574, acc 0.984375\n",
      "2017-04-03T20:47:03.762468: step 23864, loss 0.199208, acc 0.9375\n",
      "2017-04-03T20:47:04.007216: step 23865, loss 0.0949762, acc 0.984375\n",
      "2017-04-03T20:47:04.247001: step 23866, loss 0.130638, acc 0.96875\n",
      "2017-04-03T20:47:04.456780: step 23867, loss 0.0325843, acc 1\n",
      "2017-04-03T20:47:04.669904: step 23868, loss 0.024435, acc 0.984375\n",
      "2017-04-03T20:47:04.872893: step 23869, loss 0.110285, acc 0.9375\n",
      "2017-04-03T20:47:05.114068: step 23870, loss 0.0710917, acc 0.96875\n",
      "2017-04-03T20:47:05.313893: step 23871, loss 0.054495, acc 0.96875\n",
      "2017-04-03T20:47:05.516835: step 23872, loss 0.0455628, acc 1\n",
      "2017-04-03T20:47:05.721039: step 23873, loss 0.0230566, acc 1\n",
      "2017-04-03T20:47:05.930253: step 23874, loss 0.0448956, acc 0.984375\n",
      "2017-04-03T20:47:06.133271: step 23875, loss 0.0340167, acc 1\n",
      "2017-04-03T20:47:06.337612: step 23876, loss 0.0857613, acc 0.953125\n",
      "2017-04-03T20:47:06.539364: step 23877, loss 0.0728402, acc 0.96875\n",
      "2017-04-03T20:47:06.740556: step 23878, loss 0.0261507, acc 0.984375\n",
      "2017-04-03T20:47:06.950900: step 23879, loss 0.111057, acc 0.953125\n",
      "2017-04-03T20:47:07.154966: step 23880, loss 0.0824846, acc 0.96875\n",
      "2017-04-03T20:47:07.361575: step 23881, loss 0.014319, acc 1\n",
      "2017-04-03T20:47:07.566668: step 23882, loss 0.0430566, acc 1\n",
      "2017-04-03T20:47:07.769375: step 23883, loss 0.0475306, acc 1\n",
      "2017-04-03T20:47:07.972475: step 23884, loss 0.0505116, acc 0.984375\n",
      "2017-04-03T20:47:08.185067: step 23885, loss 0.0287066, acc 0.984375\n",
      "2017-04-03T20:47:08.392278: step 23886, loss 0.0825411, acc 0.984375\n",
      "2017-04-03T20:47:08.601251: step 23887, loss 0.196497, acc 0.9375\n",
      "2017-04-03T20:47:08.807445: step 23888, loss 0.0425771, acc 1\n",
      "2017-04-03T20:47:09.009673: step 23889, loss 0.0865177, acc 0.953125\n",
      "2017-04-03T20:47:09.213725: step 23890, loss 0.379792, acc 0.90625\n",
      "2017-04-03T20:47:09.416063: step 23891, loss 0.0122043, acc 1\n",
      "2017-04-03T20:47:09.623451: step 23892, loss 0.0448824, acc 0.984375\n",
      "2017-04-03T20:47:09.837242: step 23893, loss 0.056424, acc 0.984375\n",
      "2017-04-03T20:47:10.038801: step 23894, loss 0.0294253, acc 1\n",
      "2017-04-03T20:47:10.244909: step 23895, loss 0.0842712, acc 0.96875\n",
      "2017-04-03T20:47:10.449493: step 23896, loss 0.0934, acc 0.96875\n",
      "2017-04-03T20:47:10.658247: step 23897, loss 0.0768436, acc 0.96875\n",
      "2017-04-03T20:47:10.884517: step 23898, loss 0.0951915, acc 0.953125\n",
      "2017-04-03T20:47:11.116636: step 23899, loss 0.0259276, acc 0.984375\n",
      "2017-04-03T20:47:11.341432: step 23900, loss 0.116108, acc 0.9375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:47:13.514207: step 23900, loss 8.54418, acc 0.286\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-23900\n",
      "\n",
      "2017-04-03T20:47:13.852435: step 23901, loss 0.0871096, acc 0.984375\n",
      "2017-04-03T20:47:14.065261: step 23902, loss 0.0402587, acc 0.984375\n",
      "2017-04-03T20:47:14.272334: step 23903, loss 0.0148619, acc 0.984375\n",
      "2017-04-03T20:47:14.516644: step 23904, loss 0.137959, acc 0.953125\n",
      "2017-04-03T20:47:14.725223: step 23905, loss 0.103436, acc 0.96875\n",
      "2017-04-03T20:47:14.925923: step 23906, loss 0.0781541, acc 0.96875\n",
      "2017-04-03T20:47:15.128823: step 23907, loss 0.245218, acc 0.953125\n",
      "2017-04-03T20:47:15.342947: step 23908, loss 0.0355917, acc 0.984375\n",
      "2017-04-03T20:47:15.551275: step 23909, loss 0.0639829, acc 0.984375\n",
      "2017-04-03T20:47:15.758375: step 23910, loss 0.10003, acc 0.9375\n",
      "2017-04-03T20:47:15.999921: step 23911, loss 0.100856, acc 0.953125\n",
      "2017-04-03T20:47:16.252240: step 23912, loss 0.0626435, acc 0.984375\n",
      "2017-04-03T20:47:16.454425: step 23913, loss 0.10104, acc 0.96875\n",
      "2017-04-03T20:47:16.656534: step 23914, loss 0.038186, acc 0.984375\n",
      "2017-04-03T20:47:16.855253: step 23915, loss 0.0374035, acc 1\n",
      "2017-04-03T20:47:17.061512: step 23916, loss 0.178434, acc 0.953125\n",
      "2017-04-03T20:47:17.276074: step 23917, loss 0.163558, acc 0.953125\n",
      "2017-04-03T20:47:17.482347: step 23918, loss 0.111264, acc 0.953125\n",
      "2017-04-03T20:47:17.683499: step 23919, loss 0.0991796, acc 0.953125\n",
      "2017-04-03T20:47:17.884772: step 23920, loss 0.061765, acc 0.984375\n",
      "2017-04-03T20:47:18.097878: step 23921, loss 0.051348, acc 1\n",
      "2017-04-03T20:47:18.303836: step 23922, loss 0.0422936, acc 0.984375\n",
      "2017-04-03T20:47:18.508054: step 23923, loss 0.064948, acc 0.984375\n",
      "2017-04-03T20:47:18.748062: step 23924, loss 0.0780152, acc 0.96875\n",
      "2017-04-03T20:47:18.948416: step 23925, loss 0.0868774, acc 0.96875\n",
      "2017-04-03T20:47:19.147413: step 23926, loss 0.147672, acc 0.953125\n",
      "2017-04-03T20:47:19.389279: step 23927, loss 0.100155, acc 0.96875\n",
      "2017-04-03T20:47:19.591093: step 23928, loss 0.0795571, acc 0.96875\n",
      "2017-04-03T20:47:19.828826: step 23929, loss 0.0962881, acc 0.984375\n",
      "2017-04-03T20:47:20.037557: step 23930, loss 0.083382, acc 0.984375\n",
      "2017-04-03T20:47:20.242740: step 23931, loss 0.0969373, acc 0.96875\n",
      "2017-04-03T20:47:20.449754: step 23932, loss 0.0364818, acc 0.984375\n",
      "2017-04-03T20:47:20.651732: step 23933, loss 0.118429, acc 0.96875\n",
      "2017-04-03T20:47:20.854187: step 23934, loss 0.0822645, acc 0.984375\n",
      "2017-04-03T20:47:21.063339: step 23935, loss 0.0582606, acc 0.984375\n",
      "2017-04-03T20:47:21.268871: step 23936, loss 0.0310797, acc 1\n",
      "2017-04-03T20:47:21.471174: step 23937, loss 0.129486, acc 0.96875\n",
      "2017-04-03T20:47:21.683153: step 23938, loss 0.0603164, acc 0.984375\n",
      "2017-04-03T20:47:21.889451: step 23939, loss 0.0514513, acc 0.984375\n",
      "2017-04-03T20:47:22.091254: step 23940, loss 0.196985, acc 0.9375\n",
      "2017-04-03T20:47:22.301878: step 23941, loss 0.0988651, acc 0.96875\n",
      "2017-04-03T20:47:22.504064: step 23942, loss 0.0901568, acc 0.984375\n",
      "2017-04-03T20:47:22.711757: step 23943, loss 0.0410348, acc 0.984375\n",
      "2017-04-03T20:47:22.919057: step 23944, loss 0.0744627, acc 0.984375\n",
      "2017-04-03T20:47:23.123872: step 23945, loss 0.161963, acc 0.9375\n",
      "2017-04-03T20:47:23.350412: step 23946, loss 0.111396, acc 0.96875\n",
      "2017-04-03T20:47:23.565563: step 23947, loss 0.0167155, acc 1\n",
      "2017-04-03T20:47:23.774675: step 23948, loss 0.0575811, acc 0.96875\n",
      "2017-04-03T20:47:23.974101: step 23949, loss 0.119938, acc 0.984375\n",
      "2017-04-03T20:47:24.190178: step 23950, loss 0.170423, acc 0.921875\n",
      "2017-04-03T20:47:24.389797: step 23951, loss 0.048329, acc 0.984375\n",
      "2017-04-03T20:47:24.638568: step 23952, loss 0.0806042, acc 0.953125\n",
      "2017-04-03T20:47:24.837702: step 23953, loss 0.156523, acc 0.953125\n",
      "2017-04-03T20:47:25.043299: step 23954, loss 0.0681827, acc 0.96875\n",
      "2017-04-03T20:47:25.261852: step 23955, loss 0.0189873, acc 1\n",
      "2017-04-03T20:47:25.466498: step 23956, loss 0.112017, acc 0.953125\n",
      "2017-04-03T20:47:25.671194: step 23957, loss 0.0293611, acc 1\n",
      "2017-04-03T20:47:25.872843: step 23958, loss 0.180337, acc 0.96875\n",
      "2017-04-03T20:47:26.077906: step 23959, loss 0.0719311, acc 0.984375\n",
      "2017-04-03T20:47:26.279197: step 23960, loss 0.0848911, acc 0.984375\n",
      "2017-04-03T20:47:26.488615: step 23961, loss 0.0268713, acc 1\n",
      "2017-04-03T20:47:26.697034: step 23962, loss 0.0574958, acc 0.984375\n",
      "2017-04-03T20:47:26.897970: step 23963, loss 0.027987, acc 1\n",
      "2017-04-03T20:47:27.099620: step 23964, loss 0.0315536, acc 1\n",
      "2017-04-03T20:47:27.301407: step 23965, loss 0.022411, acc 1\n",
      "2017-04-03T20:47:27.501246: step 23966, loss 0.266303, acc 0.953125\n",
      "2017-04-03T20:47:27.703885: step 23967, loss 0.0889175, acc 0.96875\n",
      "2017-04-03T20:47:27.910202: step 23968, loss 0.0470214, acc 0.984375\n",
      "2017-04-03T20:47:28.122254: step 23969, loss 0.0454676, acc 0.96875\n",
      "2017-04-03T20:47:28.324554: step 23970, loss 0.062527, acc 0.984375\n",
      "2017-04-03T20:47:28.545742: step 23971, loss 0.174379, acc 0.96875\n",
      "2017-04-03T20:47:28.762390: step 23972, loss 0.115437, acc 0.953125\n",
      "2017-04-03T20:47:28.972597: step 23973, loss 0.096412, acc 0.96875\n",
      "2017-04-03T20:47:29.191893: step 23974, loss 0.11869, acc 0.96875\n",
      "2017-04-03T20:47:29.401389: step 23975, loss 0.184875, acc 0.984375\n",
      "2017-04-03T20:47:29.617288: step 23976, loss 0.00533905, acc 1\n",
      "2017-04-03T20:47:29.818868: step 23977, loss 0.0982911, acc 0.96875\n",
      "2017-04-03T20:47:30.027188: step 23978, loss 0.120098, acc 0.953125\n",
      "2017-04-03T20:47:30.235144: step 23979, loss 0.102453, acc 0.96875\n",
      "2017-04-03T20:47:30.481198: step 23980, loss 0.0985939, acc 0.953125\n",
      "2017-04-03T20:47:30.724352: step 23981, loss 0.0925596, acc 0.96875\n",
      "2017-04-03T20:47:30.936939: step 23982, loss 0.0262318, acc 1\n",
      "2017-04-03T20:47:31.140978: step 23983, loss 0.0516437, acc 0.984375\n",
      "2017-04-03T20:47:31.349761: step 23984, loss 0.0536386, acc 0.984375\n",
      "2017-04-03T20:47:31.557941: step 23985, loss 0.193062, acc 0.9375\n",
      "2017-04-03T20:47:31.761521: step 23986, loss 0.19966, acc 0.921875\n",
      "2017-04-03T20:47:31.976190: step 23987, loss 0.0371168, acc 1\n",
      "2017-04-03T20:47:32.194934: step 23988, loss 0.0341544, acc 1\n",
      "2017-04-03T20:47:32.419015: step 23989, loss 0.0708888, acc 0.96875\n",
      "2017-04-03T20:47:32.639722: step 23990, loss 0.0452495, acc 0.984375\n",
      "2017-04-03T20:47:32.849303: step 23991, loss 0.170615, acc 0.921875\n",
      "2017-04-03T20:47:33.056614: step 23992, loss 0.151608, acc 0.953125\n",
      "2017-04-03T20:47:33.271275: step 23993, loss 0.123224, acc 0.953125\n",
      "2017-04-03T20:47:33.469560: step 23994, loss 0.123591, acc 0.96875\n",
      "2017-04-03T20:47:33.682356: step 23995, loss 0.0830591, acc 0.96875\n",
      "2017-04-03T20:47:33.884365: step 23996, loss 0.16486, acc 0.9375\n",
      "2017-04-03T20:47:34.114395: step 23997, loss 0.116056, acc 0.953125\n",
      "2017-04-03T20:47:34.344859: step 23998, loss 0.0434294, acc 1\n",
      "2017-04-03T20:47:34.562742: step 23999, loss 0.128911, acc 0.984375\n",
      "2017-04-03T20:47:34.786360: step 24000, loss 0.0370501, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:47:36.917365: step 24000, loss 8.67875, acc 0.2835\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-24000\n",
      "\n",
      "2017-04-03T20:47:37.272278: step 24001, loss 0.249341, acc 0.921875\n",
      "2017-04-03T20:47:37.517216: step 24002, loss 0.0885052, acc 0.96875\n",
      "2017-04-03T20:47:37.728142: step 24003, loss 0.0396478, acc 1\n",
      "2017-04-03T20:47:37.941697: step 24004, loss 0.0293634, acc 1\n",
      "2017-04-03T20:47:38.142944: step 24005, loss 0.129746, acc 0.9375\n",
      "2017-04-03T20:47:38.345809: step 24006, loss 0.0601951, acc 0.96875\n",
      "2017-04-03T20:47:38.549619: step 24007, loss 0.0941473, acc 0.953125\n",
      "2017-04-03T20:47:38.793536: step 24008, loss 0.0696849, acc 0.96875\n",
      "2017-04-03T20:47:38.995716: step 24009, loss 0.10794, acc 0.96875\n",
      "2017-04-03T20:47:39.209554: step 24010, loss 0.242614, acc 0.921875\n",
      "2017-04-03T20:47:39.423690: step 24011, loss 0.09189, acc 0.9375\n",
      "2017-04-03T20:47:39.625995: step 24012, loss 0.0536481, acc 0.984375\n",
      "2017-04-03T20:47:39.834835: step 24013, loss 0.172376, acc 0.9375\n",
      "2017-04-03T20:47:40.037791: step 24014, loss 0.0788324, acc 0.984375\n",
      "2017-04-03T20:47:40.291653: step 24015, loss 0.135437, acc 0.984375\n",
      "2017-04-03T20:47:40.498771: step 24016, loss 0.0851722, acc 0.953125\n",
      "2017-04-03T20:47:40.705163: step 24017, loss 0.0895715, acc 0.984375\n",
      "2017-04-03T20:47:40.908304: step 24018, loss 0.0590394, acc 0.984375\n",
      "2017-04-03T20:47:41.110308: step 24019, loss 0.0488224, acc 0.96875\n",
      "2017-04-03T20:47:41.313718: step 24020, loss 0.0454626, acc 1\n",
      "2017-04-03T20:47:41.516731: step 24021, loss 0.0812829, acc 0.984375\n",
      "2017-04-03T20:47:41.733412: step 24022, loss 0.0695054, acc 0.984375\n",
      "2017-04-03T20:47:41.943040: step 24023, loss 0.0776454, acc 0.984375\n",
      "2017-04-03T20:47:42.149588: step 24024, loss 0.0389824, acc 0.984375\n",
      "2017-04-03T20:47:42.366805: step 24025, loss 0.102849, acc 0.96875\n",
      "2017-04-03T20:47:42.574552: step 24026, loss 0.0672383, acc 0.96875\n",
      "2017-04-03T20:47:42.811251: step 24027, loss 0.0509857, acc 0.984375\n",
      "2017-04-03T20:47:43.020904: step 24028, loss 0.0179471, acc 1\n",
      "2017-04-03T20:47:43.225480: step 24029, loss 0.0646811, acc 0.984375\n",
      "2017-04-03T20:47:43.436149: step 24030, loss 0.0760514, acc 0.953125\n",
      "2017-04-03T20:47:43.640328: step 24031, loss 0.0197182, acc 1\n",
      "2017-04-03T20:47:43.846852: step 24032, loss 0.0877771, acc 0.9375\n",
      "2017-04-03T20:47:44.049713: step 24033, loss 0.0621247, acc 0.96875\n",
      "2017-04-03T20:47:44.294329: step 24034, loss 0.0553722, acc 0.984375\n",
      "2017-04-03T20:47:44.536712: step 24035, loss 0.0902673, acc 0.96875\n",
      "2017-04-03T20:47:44.749757: step 24036, loss 0.0789084, acc 0.96875\n",
      "2017-04-03T20:47:44.970480: step 24037, loss 0.204308, acc 0.921875\n",
      "2017-04-03T20:47:45.177015: step 24038, loss 0.0940871, acc 0.953125\n",
      "2017-04-03T20:47:45.383100: step 24039, loss 0.00595352, acc 1\n",
      "2017-04-03T20:47:45.584929: step 24040, loss 0.0656297, acc 0.984375\n",
      "2017-04-03T20:47:45.788306: step 24041, loss 0.23135, acc 0.96875\n",
      "2017-04-03T20:47:45.999593: step 24042, loss 0.0815503, acc 0.9375\n",
      "2017-04-03T20:47:46.203946: step 24043, loss 0.119218, acc 0.984375\n",
      "2017-04-03T20:47:46.414874: step 24044, loss 0.059542, acc 0.984375\n",
      "2017-04-03T20:47:46.627598: step 24045, loss 0.0858468, acc 0.96875\n",
      "2017-04-03T20:47:46.832455: step 24046, loss 0.0591128, acc 0.96875\n",
      "2017-04-03T20:47:47.036004: step 24047, loss 0.13315, acc 0.953125\n",
      "2017-04-03T20:47:47.252022: step 24048, loss 0.0999, acc 0.96875\n",
      "2017-04-03T20:47:47.473952: step 24049, loss 0.010437, acc 1\n",
      "2017-04-03T20:47:47.694663: step 24050, loss 0.0575225, acc 0.984375\n",
      "2017-04-03T20:47:47.915290: step 24051, loss 0.0385617, acc 0.984375\n",
      "2017-04-03T20:47:48.116728: step 24052, loss 0.0271069, acc 1\n",
      "2017-04-03T20:47:48.323696: step 24053, loss 0.175179, acc 0.9375\n",
      "2017-04-03T20:47:48.525625: step 24054, loss 0.158218, acc 0.921875\n",
      "2017-04-03T20:47:48.731170: step 24055, loss 0.044403, acc 0.984375\n",
      "2017-04-03T20:47:48.938111: step 24056, loss 0.0170265, acc 1\n",
      "2017-04-03T20:47:49.139767: step 24057, loss 0.270207, acc 0.921875\n",
      "2017-04-03T20:47:49.347747: step 24058, loss 0.0742281, acc 0.96875\n",
      "2017-04-03T20:47:49.556781: step 24059, loss 0.027748, acc 1\n",
      "2017-04-03T20:47:49.769494: step 24060, loss 0.0115042, acc 1\n",
      "2017-04-03T20:47:49.987805: step 24061, loss 0.112887, acc 0.96875\n",
      "2017-04-03T20:47:50.191776: step 24062, loss 0.0210123, acc 1\n",
      "2017-04-03T20:47:50.398839: step 24063, loss 0.185755, acc 0.921875\n",
      "2017-04-03T20:47:50.608181: step 24064, loss 0.169303, acc 0.9375\n",
      "2017-04-03T20:47:50.811821: step 24065, loss 0.0710905, acc 0.96875\n",
      "2017-04-03T20:47:51.018680: step 24066, loss 0.0403638, acc 0.984375\n",
      "2017-04-03T20:47:51.220652: step 24067, loss 0.0683044, acc 0.984375\n",
      "2017-04-03T20:47:51.423494: step 24068, loss 0.0448409, acc 0.984375\n",
      "2017-04-03T20:47:51.627578: step 24069, loss 0.0558798, acc 0.96875\n",
      "2017-04-03T20:47:51.850419: step 24070, loss 0.238329, acc 0.9375\n",
      "2017-04-03T20:47:52.078519: step 24071, loss 0.111173, acc 0.96875\n",
      "2017-04-03T20:47:52.292676: step 24072, loss 0.0215376, acc 1\n",
      "2017-04-03T20:47:52.535389: step 24073, loss 0.0380611, acc 0.984375\n",
      "2017-04-03T20:47:52.744348: step 24074, loss 0.0192805, acc 1\n",
      "2017-04-03T20:47:52.969148: step 24075, loss 0.178982, acc 0.9375\n",
      "2017-04-03T20:47:53.173585: step 24076, loss 0.0721362, acc 0.953125\n",
      "2017-04-03T20:47:53.379112: step 24077, loss 0.0525968, acc 0.984375\n",
      "2017-04-03T20:47:53.588082: step 24078, loss 0.0703699, acc 0.984375\n",
      "2017-04-03T20:47:53.787999: step 24079, loss 0.102559, acc 0.96875\n",
      "2017-04-03T20:47:53.989350: step 24080, loss 0.0572582, acc 0.96875\n",
      "2017-04-03T20:47:54.201228: step 24081, loss 0.0510773, acc 0.984375\n",
      "2017-04-03T20:47:54.406443: step 24082, loss 0.178231, acc 0.921875\n",
      "2017-04-03T20:47:54.652260: step 24083, loss 0.11121, acc 0.953125\n",
      "2017-04-03T20:47:54.862114: step 24084, loss 0.0601542, acc 0.984375\n",
      "2017-04-03T20:47:55.069602: step 24085, loss 0.160856, acc 0.953125\n",
      "2017-04-03T20:47:55.273072: step 24086, loss 0.107458, acc 0.96875\n",
      "2017-04-03T20:47:55.476139: step 24087, loss 0.0504834, acc 0.984375\n",
      "2017-04-03T20:47:55.679971: step 24088, loss 0.0392522, acc 0.984375\n",
      "2017-04-03T20:47:55.891703: step 24089, loss 0.0831994, acc 0.96875\n",
      "2017-04-03T20:47:56.098230: step 24090, loss 0.132877, acc 0.953125\n",
      "2017-04-03T20:47:56.315395: step 24091, loss 0.19217, acc 0.9375\n",
      "2017-04-03T20:47:56.539325: step 24092, loss 0.135946, acc 0.953125\n",
      "2017-04-03T20:47:56.740442: step 24093, loss 0.0425747, acc 0.984375\n",
      "2017-04-03T20:47:56.944937: step 24094, loss 0.0347247, acc 0.96875\n",
      "2017-04-03T20:47:57.159766: step 24095, loss 0.107916, acc 0.96875\n",
      "2017-04-03T20:47:57.377678: step 24096, loss 0.122908, acc 0.96875\n",
      "2017-04-03T20:47:57.591952: step 24097, loss 0.188805, acc 0.953125\n",
      "2017-04-03T20:47:57.801898: step 24098, loss 0.0416188, acc 1\n",
      "2017-04-03T20:47:58.004169: step 24099, loss 0.0555273, acc 0.984375\n",
      "2017-04-03T20:47:58.210137: step 24100, loss 0.193322, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:48:00.386952: step 24100, loss 8.62497, acc 0.277\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-24100\n",
      "\n",
      "2017-04-03T20:48:00.743476: step 24101, loss 0.131316, acc 0.984375\n",
      "2017-04-03T20:48:00.950371: step 24102, loss 0.0457285, acc 1\n",
      "2017-04-03T20:48:01.153432: step 24103, loss 0.0769199, acc 0.953125\n",
      "2017-04-03T20:48:01.375198: step 24104, loss 0.0551991, acc 0.984375\n",
      "2017-04-03T20:48:01.584060: step 24105, loss 0.115291, acc 0.953125\n",
      "2017-04-03T20:48:01.785753: step 24106, loss 0.0620401, acc 0.984375\n",
      "2017-04-03T20:48:02.032015: step 24107, loss 0.0502484, acc 0.984375\n",
      "2017-04-03T20:48:02.234085: step 24108, loss 0.0219813, acc 0.984375\n",
      "2017-04-03T20:48:02.448813: step 24109, loss 0.159978, acc 0.9375\n",
      "2017-04-03T20:48:02.695797: step 24110, loss 0.126221, acc 0.96875\n",
      "2017-04-03T20:48:02.907588: step 24111, loss 0.032638, acc 1\n",
      "2017-04-03T20:48:03.115164: step 24112, loss 0.113814, acc 0.953125\n",
      "2017-04-03T20:48:03.326777: step 24113, loss 0.148613, acc 0.96875\n",
      "2017-04-03T20:48:03.536283: step 24114, loss 0.110833, acc 0.96875\n",
      "2017-04-03T20:48:03.742482: step 24115, loss 0.192485, acc 0.921875\n",
      "2017-04-03T20:48:03.974033: step 24116, loss 0.0832617, acc 0.953125\n",
      "2017-04-03T20:48:04.189042: step 24117, loss 0.119548, acc 0.953125\n",
      "2017-04-03T20:48:04.393120: step 24118, loss 0.0711551, acc 0.96875\n",
      "2017-04-03T20:48:04.597214: step 24119, loss 0.109533, acc 0.953125\n",
      "2017-04-03T20:48:04.844472: step 24120, loss 0.0999245, acc 0.96875\n",
      "2017-04-03T20:48:05.046780: step 24121, loss 0.115981, acc 0.96875\n",
      "2017-04-03T20:48:05.255991: step 24122, loss 0.0629609, acc 0.96875\n",
      "2017-04-03T20:48:05.468167: step 24123, loss 0.0601656, acc 0.984375\n",
      "2017-04-03T20:48:05.679621: step 24124, loss 0.0925405, acc 0.96875\n",
      "2017-04-03T20:48:05.890228: step 24125, loss 0.233748, acc 0.96875\n",
      "2017-04-03T20:48:06.098260: step 24126, loss 0.146096, acc 0.953125\n",
      "2017-04-03T20:48:06.300474: step 24127, loss 0.0532804, acc 0.984375\n",
      "2017-04-03T20:48:06.502125: step 24128, loss 0.0499594, acc 0.984375\n",
      "2017-04-03T20:48:06.711231: step 24129, loss 0.119989, acc 0.96875\n",
      "2017-04-03T20:48:06.920896: step 24130, loss 0.114842, acc 0.9375\n",
      "2017-04-03T20:48:07.133980: step 24131, loss 0.176255, acc 0.953125\n",
      "2017-04-03T20:48:07.358057: step 24132, loss 0.123587, acc 0.984375\n",
      "2017-04-03T20:48:07.580609: step 24133, loss 0.112225, acc 0.96875\n",
      "2017-04-03T20:48:07.803750: step 24134, loss 0.149579, acc 0.9375\n",
      "2017-04-03T20:48:08.023338: step 24135, loss 0.165486, acc 0.96875\n",
      "2017-04-03T20:48:08.274566: step 24136, loss 0.0591084, acc 0.984375\n",
      "2017-04-03T20:48:08.478578: step 24137, loss 0.108495, acc 0.96875\n",
      "2017-04-03T20:48:08.684530: step 24138, loss 0.0165254, acc 1\n",
      "2017-04-03T20:48:08.929771: step 24139, loss 0.023678, acc 1\n",
      "2017-04-03T20:48:09.148273: step 24140, loss 0.0830801, acc 0.953125\n",
      "2017-04-03T20:48:09.362953: step 24141, loss 0.221802, acc 0.9375\n",
      "2017-04-03T20:48:09.570257: step 24142, loss 0.0303761, acc 1\n",
      "2017-04-03T20:48:09.776216: step 24143, loss 0.016011, acc 1\n",
      "2017-04-03T20:48:10.023235: step 24144, loss 0.0668272, acc 0.953125\n",
      "2017-04-03T20:48:10.238042: step 24145, loss 0.0883582, acc 0.953125\n",
      "2017-04-03T20:48:10.440868: step 24146, loss 0.274382, acc 0.921875\n",
      "2017-04-03T20:48:10.695239: step 24147, loss 0.0856075, acc 0.96875\n",
      "2017-04-03T20:48:10.908434: step 24148, loss 0.125788, acc 0.953125\n",
      "2017-04-03T20:48:11.116116: step 24149, loss 0.0633868, acc 0.96875\n",
      "2017-04-03T20:48:11.334024: step 24150, loss 0.0984121, acc 0.953125\n",
      "2017-04-03T20:48:11.544628: step 24151, loss 0.11039, acc 0.953125\n",
      "2017-04-03T20:48:11.752767: step 24152, loss 0.0692117, acc 0.96875\n",
      "2017-04-03T20:48:11.967147: step 24153, loss 0.361015, acc 0.921875\n",
      "2017-04-03T20:48:12.214270: step 24154, loss 0.0729071, acc 0.96875\n",
      "2017-04-03T20:48:12.469508: step 24155, loss 0.119781, acc 0.96875\n",
      "2017-04-03T20:48:12.681343: step 24156, loss 0.0763641, acc 0.953125\n",
      "2017-04-03T20:48:12.898380: step 24157, loss 0.078639, acc 0.96875\n",
      "2017-04-03T20:48:13.106504: step 24158, loss 0.0242834, acc 0.984375\n",
      "2017-04-03T20:48:13.311936: step 24159, loss 0.236888, acc 0.953125\n",
      "2017-04-03T20:48:13.518919: step 24160, loss 0.0251189, acc 1\n",
      "2017-04-03T20:48:13.722767: step 24161, loss 0.471854, acc 0.9375\n",
      "2017-04-03T20:48:13.945589: step 24162, loss 0.0547711, acc 0.984375\n",
      "2017-04-03T20:48:14.158724: step 24163, loss 0.0129882, acc 1\n",
      "2017-04-03T20:48:14.363891: step 24164, loss 0.0858964, acc 0.953125\n",
      "2017-04-03T20:48:14.567148: step 24165, loss 0.061634, acc 0.984375\n",
      "2017-04-03T20:48:14.786607: step 24166, loss 0.227033, acc 0.984375\n",
      "2017-04-03T20:48:14.985621: step 24167, loss 0.0321512, acc 0.984375\n",
      "2017-04-03T20:48:15.186376: step 24168, loss 0.0513433, acc 0.984375\n",
      "2017-04-03T20:48:15.404421: step 24169, loss 0.0521255, acc 0.984375\n",
      "2017-04-03T20:48:15.616760: step 24170, loss 0.0903274, acc 0.96875\n",
      "2017-04-03T20:48:15.821729: step 24171, loss 0.11457, acc 0.953125\n",
      "2017-04-03T20:48:16.044857: step 24172, loss 0.164089, acc 0.96875\n",
      "2017-04-03T20:48:16.261683: step 24173, loss 0.0620594, acc 0.96875\n",
      "2017-04-03T20:48:16.485215: step 24174, loss 0.0453127, acc 0.984375\n",
      "2017-04-03T20:48:16.696742: step 24175, loss 0.133835, acc 0.953125\n",
      "2017-04-03T20:48:16.909105: step 24176, loss 0.0611807, acc 0.96875\n",
      "2017-04-03T20:48:17.122089: step 24177, loss 0.0705399, acc 0.984375\n",
      "2017-04-03T20:48:17.341731: step 24178, loss 0.0188641, acc 0.984375\n",
      "2017-04-03T20:48:17.558656: step 24179, loss 0.164467, acc 0.921875\n",
      "2017-04-03T20:48:17.759106: step 24180, loss 0.0866237, acc 0.953125\n",
      "2017-04-03T20:48:17.968375: step 24181, loss 0.0480894, acc 0.96875\n",
      "2017-04-03T20:48:18.174267: step 24182, loss 0.239932, acc 0.96875\n",
      "2017-04-03T20:48:18.372910: step 24183, loss 0.0518049, acc 0.984375\n",
      "2017-04-03T20:48:18.574402: step 24184, loss 0.138857, acc 0.96875\n",
      "2017-04-03T20:48:18.783180: step 24185, loss 0.156006, acc 0.9375\n",
      "2017-04-03T20:48:18.990570: step 24186, loss 0.0575453, acc 0.984375\n",
      "2017-04-03T20:48:19.198051: step 24187, loss 0.141131, acc 0.96875\n",
      "2017-04-03T20:48:19.406529: step 24188, loss 0.12355, acc 0.96875\n",
      "2017-04-03T20:48:19.618885: step 24189, loss 0.0698939, acc 0.96875\n",
      "2017-04-03T20:48:19.828343: step 24190, loss 0.0265315, acc 1\n",
      "2017-04-03T20:48:20.052497: step 24191, loss 0.089287, acc 0.984375\n",
      "2017-04-03T20:48:20.282931: step 24192, loss 0.0738373, acc 0.984375\n",
      "2017-04-03T20:48:20.528738: step 24193, loss 0.0200612, acc 1\n",
      "2017-04-03T20:48:20.775381: step 24194, loss 0.0695144, acc 0.96875\n",
      "2017-04-03T20:48:21.032910: step 24195, loss 0.0778594, acc 0.96875\n",
      "2017-04-03T20:48:21.284869: step 24196, loss 0.0310476, acc 0.984375\n",
      "2017-04-03T20:48:21.492668: step 24197, loss 0.110416, acc 0.96875\n",
      "2017-04-03T20:48:21.706520: step 24198, loss 0.0822322, acc 0.984375\n",
      "2017-04-03T20:48:21.929456: step 24199, loss 0.0675626, acc 0.984375\n",
      "2017-04-03T20:48:22.160206: step 24200, loss 0.108871, acc 0.953125\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:48:24.341495: step 24200, loss 8.72869, acc 0.28975\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-24200\n",
      "\n",
      "2017-04-03T20:48:24.686295: step 24201, loss 0.132128, acc 0.96875\n",
      "2017-04-03T20:48:24.897961: step 24202, loss 0.13557, acc 0.953125\n",
      "2017-04-03T20:48:25.104116: step 24203, loss 0.0402461, acc 0.984375\n",
      "2017-04-03T20:48:25.312481: step 24204, loss 0.101641, acc 0.96875\n",
      "2017-04-03T20:48:25.528842: step 24205, loss 0.236562, acc 0.953125\n",
      "2017-04-03T20:48:25.725368: step 24206, loss 0.0658453, acc 0.96875\n",
      "2017-04-03T20:48:25.930112: step 24207, loss 0.0262119, acc 1\n",
      "2017-04-03T20:48:26.141895: step 24208, loss 0.0950478, acc 0.96875\n",
      "2017-04-03T20:48:26.295958: step 24209, loss 0.146596, acc 0.9375\n",
      "2017-04-03T20:48:26.537030: step 24210, loss 0.0528538, acc 0.96875\n",
      "2017-04-03T20:48:26.745269: step 24211, loss 0.119053, acc 0.96875\n",
      "2017-04-03T20:48:26.953084: step 24212, loss 0.0834171, acc 0.96875\n",
      "2017-04-03T20:48:27.166181: step 24213, loss 0.0434812, acc 0.984375\n",
      "2017-04-03T20:48:27.372234: step 24214, loss 0.100823, acc 0.96875\n",
      "2017-04-03T20:48:27.583592: step 24215, loss 0.0821961, acc 0.984375\n",
      "2017-04-03T20:48:27.794157: step 24216, loss 0.037985, acc 0.984375\n",
      "2017-04-03T20:48:28.003844: step 24217, loss 0.0969079, acc 0.96875\n",
      "2017-04-03T20:48:28.227279: step 24218, loss 0.0521925, acc 0.984375\n",
      "2017-04-03T20:48:28.428229: step 24219, loss 0.0901988, acc 0.96875\n",
      "2017-04-03T20:48:28.640932: step 24220, loss 0.107203, acc 0.953125\n",
      "2017-04-03T20:48:28.850142: step 24221, loss 0.0254546, acc 1\n",
      "2017-04-03T20:48:29.051606: step 24222, loss 0.0822985, acc 0.984375\n",
      "2017-04-03T20:48:29.259287: step 24223, loss 0.082316, acc 0.96875\n",
      "2017-04-03T20:48:29.464283: step 24224, loss 0.0797013, acc 0.984375\n",
      "2017-04-03T20:48:29.682983: step 24225, loss 0.119712, acc 0.953125\n",
      "2017-04-03T20:48:29.889991: step 24226, loss 0.0425418, acc 0.984375\n",
      "2017-04-03T20:48:30.094239: step 24227, loss 0.0697862, acc 0.984375\n",
      "2017-04-03T20:48:30.298671: step 24228, loss 0.0339785, acc 1\n",
      "2017-04-03T20:48:30.504323: step 24229, loss 0.060498, acc 0.96875\n",
      "2017-04-03T20:48:30.707997: step 24230, loss 0.137986, acc 0.9375\n",
      "2017-04-03T20:48:30.959192: step 24231, loss 0.20957, acc 0.890625\n",
      "2017-04-03T20:48:31.164873: step 24232, loss 0.0923358, acc 0.96875\n",
      "2017-04-03T20:48:31.366783: step 24233, loss 0.153618, acc 0.96875\n",
      "2017-04-03T20:48:31.571316: step 24234, loss 0.0606961, acc 0.984375\n",
      "2017-04-03T20:48:31.779778: step 24235, loss 0.0761787, acc 0.984375\n",
      "2017-04-03T20:48:31.983973: step 24236, loss 0.0585978, acc 0.96875\n",
      "2017-04-03T20:48:32.188529: step 24237, loss 0.11483, acc 0.96875\n",
      "2017-04-03T20:48:32.397220: step 24238, loss 0.0615331, acc 0.96875\n",
      "2017-04-03T20:48:32.613862: step 24239, loss 0.016479, acc 0.984375\n",
      "2017-04-03T20:48:32.818931: step 24240, loss 0.123659, acc 0.953125\n",
      "2017-04-03T20:48:33.023709: step 24241, loss 0.118226, acc 0.9375\n",
      "2017-04-03T20:48:33.221159: step 24242, loss 0.0549452, acc 0.984375\n",
      "2017-04-03T20:48:33.425633: step 24243, loss 0.0503732, acc 0.96875\n",
      "2017-04-03T20:48:33.630752: step 24244, loss 0.135266, acc 0.96875\n",
      "2017-04-03T20:48:33.842283: step 24245, loss 0.0185966, acc 1\n",
      "2017-04-03T20:48:34.052094: step 24246, loss 0.135218, acc 0.953125\n",
      "2017-04-03T20:48:34.263120: step 24247, loss 0.0233347, acc 1\n",
      "2017-04-03T20:48:34.512409: step 24248, loss 0.0802137, acc 0.984375\n",
      "2017-04-03T20:48:34.764189: step 24249, loss 0.0668256, acc 0.984375\n",
      "2017-04-03T20:48:35.017241: step 24250, loss 0.115875, acc 0.953125\n",
      "2017-04-03T20:48:35.221752: step 24251, loss 0.0251779, acc 0.984375\n",
      "2017-04-03T20:48:35.461731: step 24252, loss 0.0723415, acc 0.96875\n",
      "2017-04-03T20:48:35.667782: step 24253, loss 0.102874, acc 0.9375\n",
      "2017-04-03T20:48:35.870099: step 24254, loss 0.0656707, acc 0.953125\n",
      "2017-04-03T20:48:36.076752: step 24255, loss 0.0452227, acc 0.96875\n",
      "2017-04-03T20:48:36.284914: step 24256, loss 0.0398504, acc 0.984375\n",
      "2017-04-03T20:48:36.493958: step 24257, loss 0.0166131, acc 1\n",
      "2017-04-03T20:48:36.700058: step 24258, loss 0.104853, acc 0.9375\n",
      "2017-04-03T20:48:36.913255: step 24259, loss 0.375241, acc 0.984375\n",
      "2017-04-03T20:48:37.136599: step 24260, loss 0.0807238, acc 0.96875\n",
      "2017-04-03T20:48:37.350621: step 24261, loss 0.0540579, acc 0.984375\n",
      "2017-04-03T20:48:37.563602: step 24262, loss 0.156907, acc 0.953125\n",
      "2017-04-03T20:48:37.776840: step 24263, loss 0.0142609, acc 1\n",
      "2017-04-03T20:48:37.978371: step 24264, loss 0.047107, acc 0.984375\n",
      "2017-04-03T20:48:38.184426: step 24265, loss 0.0139397, acc 1\n",
      "2017-04-03T20:48:38.389717: step 24266, loss 0.0464214, acc 0.984375\n",
      "2017-04-03T20:48:38.592100: step 24267, loss 0.0684547, acc 0.984375\n",
      "2017-04-03T20:48:38.801037: step 24268, loss 0.0400884, acc 0.984375\n",
      "2017-04-03T20:48:38.995841: step 24269, loss 0.0902919, acc 0.96875\n",
      "2017-04-03T20:48:39.228525: step 24270, loss 0.103484, acc 0.953125\n",
      "2017-04-03T20:48:39.477603: step 24271, loss 0.150329, acc 0.984375\n",
      "2017-04-03T20:48:39.682767: step 24272, loss 0.338576, acc 0.921875\n",
      "2017-04-03T20:48:39.882593: step 24273, loss 0.0549441, acc 0.96875\n",
      "2017-04-03T20:48:40.081863: step 24274, loss 0.115134, acc 0.96875\n",
      "2017-04-03T20:48:40.316727: step 24275, loss 0.0525459, acc 0.984375\n",
      "2017-04-03T20:48:40.520379: step 24276, loss 0.0695679, acc 0.953125\n",
      "2017-04-03T20:48:40.726258: step 24277, loss 0.00911083, acc 1\n",
      "2017-04-03T20:48:40.928362: step 24278, loss 0.0772192, acc 0.96875\n",
      "2017-04-03T20:48:41.140920: step 24279, loss 0.0566442, acc 0.984375\n",
      "2017-04-03T20:48:41.361529: step 24280, loss 0.0355774, acc 0.984375\n",
      "2017-04-03T20:48:41.573391: step 24281, loss 0.0397392, acc 0.96875\n",
      "2017-04-03T20:48:41.787623: step 24282, loss 0.0449779, acc 0.984375\n",
      "2017-04-03T20:48:42.005909: step 24283, loss 0.0294158, acc 1\n",
      "2017-04-03T20:48:42.230208: step 24284, loss 0.0586916, acc 1\n",
      "2017-04-03T20:48:42.430211: step 24285, loss 0.151366, acc 0.953125\n",
      "2017-04-03T20:48:42.634050: step 24286, loss 0.0131704, acc 1\n",
      "2017-04-03T20:48:42.848012: step 24287, loss 0.180475, acc 0.953125\n",
      "2017-04-03T20:48:43.050886: step 24288, loss 0.0349329, acc 0.984375\n",
      "2017-04-03T20:48:43.250026: step 24289, loss 0.0339387, acc 1\n",
      "2017-04-03T20:48:43.449154: step 24290, loss 0.0491457, acc 0.96875\n",
      "2017-04-03T20:48:43.650009: step 24291, loss 0.0909323, acc 0.96875\n",
      "2017-04-03T20:48:43.856195: step 24292, loss 0.0187276, acc 1\n",
      "2017-04-03T20:48:44.061204: step 24293, loss 0.166303, acc 0.9375\n",
      "2017-04-03T20:48:44.267521: step 24294, loss 0.0879621, acc 0.9375\n",
      "2017-04-03T20:48:44.467770: step 24295, loss 0.121768, acc 0.953125\n",
      "2017-04-03T20:48:44.668425: step 24296, loss 0.0648165, acc 0.984375\n",
      "2017-04-03T20:48:44.871304: step 24297, loss 0.0969178, acc 0.96875\n",
      "2017-04-03T20:48:45.078258: step 24298, loss 0.157162, acc 0.9375\n",
      "2017-04-03T20:48:45.281484: step 24299, loss 0.0600099, acc 0.984375\n",
      "2017-04-03T20:48:45.498049: step 24300, loss 0.0551143, acc 0.984375\n",
      "\n",
      "Evaluation:\n",
      "2017-04-03T20:48:47.633774: step 24300, loss 8.60646, acc 0.28225\n",
      "\n",
      "Saved model checkpoint to /home/ubuntu/cnn-text-classification-tf/runs/1491227132/checkpoints/model-24300\n",
      "\n",
      "2017-04-03T20:48:47.963820: step 24301, loss 0.0422289, acc 1\n",
      "2017-04-03T20:48:48.166592: step 24302, loss 0.02736, acc 1\n",
      "2017-04-03T20:48:48.366556: step 24303, loss 0.0707593, acc 0.96875\n",
      "2017-04-03T20:48:48.577705: step 24304, loss 0.0734156, acc 0.984375\n",
      "2017-04-03T20:48:48.777812: step 24305, loss 0.0519177, acc 1\n",
      "2017-04-03T20:48:48.980479: step 24306, loss 0.0429312, acc 1\n",
      "2017-04-03T20:48:49.191626: step 24307, loss 0.0858552, acc 0.96875\n",
      "2017-04-03T20:48:49.408864: step 24308, loss 0.0502154, acc 0.96875\n",
      "2017-04-03T20:48:49.623948: step 24309, loss 0.061195, acc 0.984375\n",
      "2017-04-03T20:48:49.830446: step 24310, loss 0.0669398, acc 0.96875\n",
      "2017-04-03T20:48:50.055929: step 24311, loss 0.0471645, acc 0.984375\n",
      "2017-04-03T20:48:50.274874: step 24312, loss 0.0678087, acc 0.96875\n",
      "2017-04-03T20:48:50.477197: step 24313, loss 0.0287649, acc 0.984375\n",
      "2017-04-03T20:48:50.684816: step 24314, loss 0.0509072, acc 1\n",
      "2017-04-03T20:48:50.888877: step 24315, loss 0.0720983, acc 0.96875\n",
      "2017-04-03T20:48:51.099948: step 24316, loss 0.157551, acc 0.953125\n",
      "2017-04-03T20:48:51.313032: step 24317, loss 0.090101, acc 0.96875\n",
      "2017-04-03T20:48:51.513105: step 24318, loss 0.0300023, acc 1\n",
      "2017-04-03T20:48:51.727513: step 24319, loss 0.138353, acc 0.9375\n",
      "2017-04-03T20:48:51.933507: step 24320, loss 0.112483, acc 0.96875\n",
      "2017-04-03T20:48:52.144046: step 24321, loss 0.074632, acc 0.984375\n",
      "2017-04-03T20:48:52.361434: step 24322, loss 0.0158462, acc 1\n",
      "2017-04-03T20:48:52.597460: step 24323, loss 0.115973, acc 0.984375\n",
      "2017-04-03T20:48:52.825080: step 24324, loss 0.174856, acc 0.96875\n",
      "2017-04-03T20:48:53.062408: step 24325, loss 0.0595846, acc 0.984375\n",
      "2017-04-03T20:48:53.281889: step 24326, loss 0.0419146, acc 0.984375\n",
      "2017-04-03T20:48:53.506487: step 24327, loss 0.0433826, acc 0.96875\n",
      "2017-04-03T20:48:53.710149: step 24328, loss 0.0915564, acc 0.9375\n",
      "2017-04-03T20:48:53.918242: step 24329, loss 0.0693344, acc 0.953125\n",
      "2017-04-03T20:48:54.121363: step 24330, loss 0.171941, acc 0.9375\n",
      "2017-04-03T20:48:54.325059: step 24331, loss 0.0478117, acc 0.984375\n",
      "2017-04-03T20:48:54.527486: step 24332, loss 0.178121, acc 0.96875\n",
      "2017-04-03T20:48:54.733960: step 24333, loss 0.0415222, acc 0.984375\n",
      "2017-04-03T20:48:54.935206: step 24334, loss 0.090966, acc 0.96875\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-c0eff3b9602e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m             \u001b[0mcurrent_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcurrent_step\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-c0eff3b9602e>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(x_batch, y_batch)\u001b[0m\n\u001b[1;32m     76\u001b[0m             _, step, summaries, loss, accuracy = sess.run(\n\u001b[1;32m     77\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_summary_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                 feed_dict)\n\u001b[0m\u001b[1;32m     79\u001b[0m             \u001b[0mtime_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misoformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{}: step {}, loss {:g}, acc {:g}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/ubuntu/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training\n",
    "# ==================================================\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    session_conf = tf.ConfigProto(\n",
    "      allow_soft_placement=FLAGS.allow_soft_placement,\n",
    "      log_device_placement=FLAGS.log_device_placement)\n",
    "    sess = tf.Session(config=session_conf)\n",
    "    with sess.as_default():\n",
    "        cnn = TextCNN(\n",
    "            sequence_length=x_train.shape[1],\n",
    "            num_classes=y_train.shape[1],\n",
    "            vocab_size=len(vocab_processor.vocabulary_),\n",
    "            embedding_size=FLAGS.embedding_dim,\n",
    "            filter_sizes=list(map(int, FLAGS.filter_sizes.split(\",\"))),\n",
    "            num_filters=FLAGS.num_filters,\n",
    "            l2_reg_lambda=FLAGS.l2_reg_lambda)\n",
    "\n",
    "        # Define Training procedure\n",
    "        global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n",
    "        optimizer = tf.train.AdamOptimizer(1e-3)\n",
    "        grads_and_vars = optimizer.compute_gradients(cnn.loss)\n",
    "        train_op = optimizer.apply_gradients(grads_and_vars, global_step=global_step)\n",
    "\n",
    "        # Keep track of gradient values and sparsity (optional)\n",
    "        grad_summaries = []\n",
    "        for g, v in grads_and_vars:\n",
    "            if g is not None:\n",
    "                grad_hist_summary = tf.summary.histogram(\"grad/hist\".format(v.name), g)\n",
    "                sparsity_summary = tf.summary.scalar(\"grad/sparsity\".format(v.name), tf.nn.zero_fraction(g))\n",
    "                grad_summaries.append(grad_hist_summary)\n",
    "                grad_summaries.append(sparsity_summary)\n",
    "        grad_summaries_merged = tf.summary.merge(grad_summaries)\n",
    "\n",
    "        # Output directory for models and summaries\n",
    "        timestamp = str(int(time.time()))\n",
    "        out_dir = os.path.abspath(os.path.join(os.path.curdir, \"runs\", timestamp))\n",
    "        print(\"Writing to {}\\n\".format(out_dir))\n",
    "\n",
    "        # Summaries for loss and accuracy\n",
    "        loss_summary = tf.summary.scalar(\"loss\", cnn.loss)\n",
    "        acc_summary = tf.summary.scalar(\"accuracy\", cnn.accuracy)\n",
    "\n",
    "        # Train Summaries\n",
    "        train_summary_op = tf.summary.merge([loss_summary, acc_summary, grad_summaries_merged])\n",
    "        train_summary_dir = os.path.join(out_dir, \"summaries\", \"train\")\n",
    "        train_summary_writer = tf.summary.FileWriter(train_summary_dir, sess.graph)\n",
    "\n",
    "        # Dev summaries\n",
    "        dev_summary_op = tf.summary.merge([loss_summary, acc_summary])\n",
    "        dev_summary_dir = os.path.join(out_dir, \"summaries\", \"dev\")\n",
    "        dev_summary_writer = tf.summary.FileWriter(dev_summary_dir, sess.graph)\n",
    "\n",
    "        # Checkpoint directory. Tensorflow assumes this directory already exists so we need to create it\n",
    "        checkpoint_dir = os.path.abspath(os.path.join(out_dir, \"checkpoints\"))\n",
    "        checkpoint_prefix = os.path.join(checkpoint_dir, \"model\")\n",
    "        if not os.path.exists(checkpoint_dir):\n",
    "            os.makedirs(checkpoint_dir)\n",
    "        saver = tf.train.Saver(tf.global_variables(), max_to_keep=FLAGS.num_checkpoints)\n",
    "\n",
    "        # Write vocabulary\n",
    "        vocab_processor.save(os.path.join(out_dir, \"vocab\"))\n",
    "\n",
    "        # Initialize all variables\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        def train_step(x_batch, y_batch):\n",
    "            \"\"\"\n",
    "            A single training step\n",
    "            \"\"\"\n",
    "            feed_dict = {\n",
    "              cnn.input_x: x_batch,\n",
    "              cnn.input_y: y_batch,\n",
    "              cnn.dropout_keep_prob: FLAGS.dropout_keep_prob\n",
    "            }\n",
    "            _, step, summaries, loss, accuracy = sess.run(\n",
    "                [train_op, global_step, train_summary_op, cnn.loss, cnn.accuracy],\n",
    "                feed_dict)\n",
    "            time_str = datetime.datetime.now().isoformat()\n",
    "            print(\"{}: step {}, loss {:g}, acc {:g}\".format(time_str, step, loss, accuracy))\n",
    "            train_summary_writer.add_summary(summaries, step)\n",
    "\n",
    "        def dev_step(x_batch, y_batch, writer=None):\n",
    "            \"\"\"\n",
    "            Evaluates model on a dev set\n",
    "            \"\"\"\n",
    "            feed_dict = {\n",
    "              cnn.input_x: x_batch,\n",
    "              cnn.input_y: y_batch,\n",
    "              cnn.dropout_keep_prob: 1.0\n",
    "            }\n",
    "            step, summaries, loss, accuracy = sess.run(\n",
    "                [global_step, dev_summary_op, cnn.loss, cnn.accuracy],\n",
    "                feed_dict)\n",
    "            time_str = datetime.datetime.now().isoformat()\n",
    "            print(\"{}: step {}, loss {:g}, acc {:g}\".format(time_str, step, loss, accuracy))\n",
    "            if writer:\n",
    "                writer.add_summary(summaries, step)\n",
    "\n",
    "        # Generate batches\n",
    "        batches = data_helpers.batch_iter(\n",
    "            list(zip(x_train, y_train)), FLAGS.batch_size, FLAGS.num_epochs)\n",
    "        # Training loop. For each batch...\n",
    "        for batch in batches:\n",
    "            x_batch, y_batch = zip(*batch)\n",
    "            train_step(x_batch, y_batch)\n",
    "            current_step = tf.train.global_step(sess, global_step)\n",
    "            if current_step % FLAGS.evaluate_every == 0:\n",
    "                print(\"\\nEvaluation:\")\n",
    "                dev_step(x_dev, y_dev, writer=dev_summary_writer)\n",
    "                print(\"\")\n",
    "            if current_step % FLAGS.checkpoint_every == 0:\n",
    "                path = saver.save(sess, checkpoint_prefix, global_step=current_step)\n",
    "                print(\"Saved model checkpoint to {}\\n\".format(path))\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
